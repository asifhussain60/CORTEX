# Knowledge Base - Published Patterns

**Version:** 1.1 (v4.3 Guardrails)  
**Purpose:** Store reusable patterns with anti-bloat guardrails  
**Governed By:** Rule #14 (Publishing), Rule #16 (Mandatory Post-Task)

---

## ðŸ›¡ï¸ Publishing Guardrails (v4.3)

### Capacity Limits
- **Max 10 patterns per category** (hard limit)
- **Consolidation triggered at 8 patterns** (soft limit)
- **Alert when approaching capacity**

### Quality Gates
- **Minimum success rate:** 80%
- **Minimum reuse count:** 3 (must reuse 3+ times before publishing)
- **Evidence required:** Git commits, test results, or production usage

### Deduplication
- **>85% similarity:** AUTO-REJECT (use existing pattern)
- **60-84% similarity:** CONSOLIDATE (merge patterns)
- **<60% similarity:** UNIQUE (publish as new)

### Sunset Policy
- **90-day threshold:** Auto-archive to `.archived/` if unused
- **Git-based tracking:** Last Used timestamp + git history
- **Monthly cleanup:** Automated during health reports

---

## Purpose
This folder contains validated, successful patterns published by Copilot for reuse across tasks. It serves as institutional knowledge to prevent repeated trial-and-error.

## Structure

### test-patterns/
Successful Playwright test patterns - what worked, what didn't.

**Examples:**
- `playwright-element-selection.md` - Reliable selector strategies
- `api-testing-with-retry.md` - Retry logic for flaky endpoints
- `visual-regression-setup.md` - Percy snapshot configuration

### test-data/
Validated test data that can be reliably used for testing.

**Examples:**
- `session-212.md` - Session ID 212 with known state
- `pasted-image-test-data.md` - Image upload test data
- `multi-user-scenario-data.md` - Multiple participant test data

### ui-mappings/
UI element to data-testid mappings for Playwright selectors.

**Examples:**
- `canvas-element-testids.md` - Canvas UI element selectors
- `modal-dialog-selectors.md` - Modal dialog mappings
- `navigation-menu-ids.md` - Navigation element IDs

### workflows/
End-to-end workflow patterns that have been validated.

**Examples:**
- `zoom-integration-flow.md` - Zoom connection workflow
- `participant-registration-flow.md` - Participant onboarding
- `annotation-broadcast-workflow.md` - Real-time annotation sync

### update-requests/
Requests to update stale documentation (generated by knowledge-retriever agent).

**Format:** `YYYY-MM-DD-{issue-summary}.md`

## Publishing Workflow

### Step 1: Identify Pattern
After a successful test, implementation, or workflow, identify if it's reusable.

### Step 2: Invoke Publish Workflow
```
@workspace /execute #file:KDS/keys/{key}/handoffs/publish-pattern.json
```

### Step 3: Validation
The `publish.md` workflow validates:
- Pattern has required sections
- Success rate is documented
- "What Didn't Work" is included
- No duplicates exist

### Step 4: Categorization
Pattern is automatically categorized into:
- `test-patterns/` - Test implementation patterns
- `test-data/` - Validated data for testing
- `ui-mappings/` - UI element selectors
- `workflows/` - End-to-end flows

### Step 5: Publishing
Pattern is saved to appropriate subfolder and indexed.

## When to Publish

### Test Patterns
- Test passes after multiple attempts (capture what finally worked)
- Pattern reused 3+ times across different features
- Reliable selector strategy discovered

### Test Data
- Data validated across multiple test scenarios
- Known good state for regression testing
- Edge cases that exposed bugs

### UI Mappings
- Elements reliably selected by Playwright
- Complex UI interactions documented
- Data-testid added to new UI elements (Rule #15)

### Workflows
- End-to-end flow completes successfully
- Multi-step process validated
- Integration between components proven

## Pattern Format

All patterns follow this structure:

```markdown
# Pattern: {Name}

**Category**: {test-patterns | test-data | ui-mappings | workflows}
**Published**: {YYYY-MM-DD}
**Success Rate**: {X/Y attempts}
**Reuse Count**: {number}

## Context
{When to use this pattern}

## Implementation
{Code/data/configuration}

## What Worked
{Successful approaches}

## What Didn't Work
{Failed approaches to avoid}

## Related Patterns
{Links to related knowledge}
```

## Governance

### Rule #14: Publishing Mechanism (v4.3 Guardrails)
- Max 10 patterns per category (hard limit)
- Consolidation at 8 patterns (soft limit)
- Auto-reject duplicates >85% similarity
- Consolidate similar patterns 60-84% similarity
- 90-day sunset policy (auto-archive unused patterns)
- 80% minimum success rate
- 3+ minimum reuse count
- Weekly + monthly health reports

### Rule #15: UI Test Identifiers
When adding UI elements, ALWAYS add `data-testid` and publish mapping to `ui-mappings/`.

### Rule #16: Mandatory Post-Task Execution
Publishing is AUTOMATIC after every task (Step 2). NO user reminders needed.

### Validation
- Patterns must include "What Didn't Work" section
- Success rate must be documented (â‰¥80%)
- Minimum 3 reuse count required
- Deduplication check (auto-reject >85%)
- Capacity check (block at 10/10)
- All patterns reviewed in post-task validation

---

**Last Updated**: 2025-11-02  
**Version**: 1.1 (v4.3 Guardrails)  
**Governed By**: Rule #14, Rule #15, Rule #16  
**Anti-Patterns**: See `KDS/docs/KDS-ANTI-PATTERNS.md`
