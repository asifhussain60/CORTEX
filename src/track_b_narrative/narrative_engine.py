"""
CORTEX 3.0 Track B Phase 4 - Narrative Engine

Core narrative generation engine with story templates, context weaving,
and decision rationale extraction. Works with mock dual-channel data
during development phase (Weeks 8-15).

Key Features:
- Story template system for coherent narratives
- Context weaving algorithm for connecting development events  
- Decision rationale extraction from conversation patterns
- Integration with existing narrative_intelligence.py

Author: Asif Hussain
Copyright: Â© 2025 Asif Hussain. All rights reserved.
"""

import json
import yaml
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from enum import Enum
import logging
from pathlib import Path

from .mock_data import MockConversation, MockDaemonCapture, DualChannelMockData

# Import from tier1 if available, otherwise define needed types locally
try:
    from tier1.narrative_intelligence import (
        NarrativeIntelligence, StoryType, NarrativeStyle, 
        StoryElement, DevelopmentNarrative
    )
except ImportError:
    # Define minimal types for standalone operation
    class StoryType:
        TECHNICAL = "technical"
        NARRATIVE = "narrative"
        SUMMARY = "summary"
        DEVELOPMENT_PROGRESS = "development_progress"
        COLLABORATIVE_SESSION = "collaborative_session"
        BUG_INVESTIGATION = "bug_investigation"
        REFACTORING_SESSION = "refactoring_session"
        CONTINUE_WORKFLOW = "continue_workflow"
        FEATURE_JOURNEY = "feature_journey"
        REFACTORING_JOURNEY = "refactoring_journey"
        CONTINUATION_CONTEXT = "continuation_context"
        PROBLEM_RESOLUTION = "problem_resolution"
        PROBLEM_RESOLUTION = "problem_resolution"
    
    class NarrativeStyle:
        FORMAL = "formal"
        CASUAL = "casual"
        TECHNICAL = "technical"
        STORYTELLING = "storytelling"
        DETECTIVE = "detective"
        ANALYTICAL = "analytical"
        CONTEXTUAL = "contextual"
        CHRONOLOGICAL = "chronological"
    
    class StoryElement:
        def __init__(self, content: str, timestamp: datetime, **kwargs):
            self.content = content
            self.timestamp = timestamp
            for k, v in kwargs.items():
                setattr(self, k, v)
    
    class DevelopmentNarrative:
        def __init__(self, story_type: str, elements: List[StoryElement], **kwargs):
            self.story_type = story_type
            self.elements = elements
            for k, v in kwargs.items():
                setattr(self, k, v)
    
    class NarrativeIntelligence:
        def __init__(self):
            pass

logger = logging.getLogger(__name__)


@dataclass
class StoryTemplate:
    """Template for generating consistent story structures"""
    template_id: str
    name: str
    story_type: StoryType
    narrative_style: NarrativeStyle
    structure: List[str]  # Ordered list of story sections
    prompts: Dict[str, str]  # Section -> prompt mapping
    context_requirements: List[str]  # Required context elements
    success_criteria: Dict[str, Any]  # Quality metrics


@dataclass  
class ContextElement:
    """Contextual element extracted from dual-channel data"""
    element_id: str
    timestamp: datetime
    source_type: str  # "conversation", "daemon_capture"
    content: str
    entities: List[str]
    relationships: List[str]  # Connections to other elements
    confidence: float
    metadata: Dict[str, Any]


@dataclass
class DecisionRationale:
    """Extracted decision rationale from development flow"""
    decision_id: str
    timestamp: datetime
    decision_type: str  # "architectural", "implementation", "bug_fix", "feature"
    context_summary: str
    options_considered: List[str]
    chosen_approach: str
    reasoning: str
    outcome_observed: Optional[str]
    confidence: float


class StoryTemplateSystem:
    """
    Advanced story template system for narrative generation.
    
    Provides structured templates for different types of development stories,
    ensuring consistent and coherent narrative output.
    """
    
    def __init__(self, template_dir: str = None):
        """Initialize story template system"""
        self.template_dir = Path(template_dir) if template_dir else Path.cwd() / "story_templates"
        self.templates: Dict[str, StoryTemplate] = {}
        self._load_default_templates()
    
    def _load_default_templates(self):
        """Load default story templates"""
        
        # Development Progress Template
        dev_progress = StoryTemplate(
            template_id="dev_progress_technical",
            name="Technical Development Progress",
            story_type=StoryType.DEVELOPMENT_PROGRESS,
            narrative_style=NarrativeStyle.TECHNICAL,
            structure=[
                "overview",
                "key_achievements", 
                "technical_decisions",
                "challenges_resolved",
                "code_evolution",
                "next_steps"
            ],
            prompts={
                "overview": "Summarize the overall development progress and main objectives achieved.",
                "key_achievements": "List the significant features, fixes, or improvements completed.",
                "technical_decisions": "Describe important architectural or implementation decisions made.",
                "challenges_resolved": "Explain problems encountered and how they were solved.",
                "code_evolution": "Show how the codebase evolved through specific changes.",
                "next_steps": "Identify upcoming work and logical next development phases."
            },
            context_requirements=[
                "conversations", "file_changes", "git_commits", "time_range"
            ],
            success_criteria={
                "coherence_score": 0.8,
                "completeness_score": 0.9,
                "technical_depth": 0.7
            }
        )
        
        # Feature Journey Template  
        feature_journey = StoryTemplate(
            template_id="feature_journey_storytelling", 
            name="Feature Development Story",
            story_type=StoryType.FEATURE_JOURNEY,
            narrative_style=NarrativeStyle.STORYTELLING,
            structure=[
                "motivation",
                "initial_approach",
                "discovery_process", 
                "implementation_journey",
                "testing_validation",
                "final_outcome"
            ],
            prompts={
                "motivation": "What drove the need for this feature? What problem was being solved?",
                "initial_approach": "How did the development team initially plan to implement this?",
                "discovery_process": "What was learned during investigation and planning?",
                "implementation_journey": "Tell the story of how the feature was built, including pivots.",
                "testing_validation": "How was the feature validated and what feedback was incorporated?",
                "final_outcome": "What was delivered and how does it solve the original problem?"
            },
            context_requirements=[
                "feature_conversations", "implementation_files", "test_files"
            ],
            success_criteria={
                "narrative_flow": 0.85,
                "emotional_engagement": 0.75,
                "technical_accuracy": 0.9
            }
        )
        
        # Bug Investigation Template (NEW - Phase 4 Enhancement)
        bug_investigation = StoryTemplate(
            template_id="bug_investigation_detective",
            name="Bug Investigation Story",
            story_type=StoryType.PROBLEM_RESOLUTION, 
            narrative_style=NarrativeStyle.STORYTELLING,
            structure=[
                "symptoms_discovered",
                "initial_hypothesis", 
                "investigation_path",
                "root_cause_revelation",
                "solution_implementation",
                "prevention_measures"
            ],
            prompts={
                "symptoms_discovered": "What unusual behavior was first noticed? How was the bug detected?",
                "initial_hypothesis": "What did the team initially think was causing the problem?", 
                "investigation_path": "Trace the detective work - what was examined and ruled out?",
                "root_cause_revelation": "What was the actual cause? How was it discovered?",
                "solution_implementation": "How was the bug fixed and what changed?",
                "prevention_measures": "What safeguards were added to prevent similar issues?"
            },
            context_requirements=[
                "error_conversations", "debug_sessions", "fix_commits", "test_additions"
            ],
            success_criteria={
                "investigation_clarity": 0.9,
                "root_cause_accuracy": 0.95,
                "learning_extraction": 0.8
            }
        )
        
        # Refactoring Journey Template (NEW - Phase 4 Enhancement) 
        refactoring_journey = StoryTemplate(
            template_id="refactoring_journey_improvement",
            name="Code Refactoring Journey",
            story_type=StoryType.TECHNICAL_DISCOVERY,
            narrative_style=NarrativeStyle.TECHNICAL,
            structure=[
                "code_smell_identification",
                "architectural_analysis",
                "refactoring_strategy",
                "incremental_improvements", 
                "testing_validation",
                "quality_metrics"
            ],
            prompts={
                "code_smell_identification": "What made the team decide the code needed improvement?",
                "architectural_analysis": "How did the current architecture limit functionality or maintainability?",
                "refactoring_strategy": "What approach was chosen for improving the code structure?",
                "incremental_improvements": "Describe the step-by-step refactoring process.",
                "testing_validation": "How was the refactoring validated to ensure no regression?",
                "quality_metrics": "What measurable improvements were achieved?"
            },
            context_requirements=[
                "refactor_conversations", "before_after_code", "test_coverage", "metrics"
            ],
            success_criteria={
                "improvement_clarity": 0.85,
                "before_after_comparison": 0.9,
                "quality_impact": 0.8
            }
        )
        
        # Continue Command Context Template (NEW - Phase 4 Enhancement)
        continue_context = StoryTemplate(
            template_id="continue_context_timeline",
            name="Continue Command Context",
            story_type=StoryType.COLLABORATION,
            narrative_style=NarrativeStyle.EXECUTIVE,
            structure=[
                "session_summary",
                "work_progression",
                "current_state",
                "logical_next_steps",
                "context_preservation",
                "intelligent_suggestions"
            ],
            prompts={
                "session_summary": "Summarize what work was accomplished in recent sessions.",
                "work_progression": "Show the logical flow of development decisions and progress.",
                "current_state": "Describe the current state of code, tests, and any ongoing work.",
                "logical_next_steps": "Based on the progression, what are the natural next actions?",
                "context_preservation": "What context should be maintained for seamless continuation?",
                "intelligent_suggestions": "What specific suggestions would help the developer continue effectively?"
            },
            context_requirements=[
                "recent_conversations", "file_state", "git_status", "session_data"
            ],
            success_criteria={
                "narrative_flow": 0.8,
                "engagement_score": 0.7,
                "completeness_score": 0.8
            }
        )
        
        # Problem Resolution Template
        problem_resolution = StoryTemplate(
            template_id="problem_resolution_chronological",
            name="Bug Fix & Problem Resolution", 
            story_type=StoryType.PROBLEM_RESOLUTION,
            narrative_style=NarrativeStyle.CHRONOLOGICAL,
            structure=[
                "problem_identification",
                "investigation_process",
                "root_cause_analysis", 
                "solution_design",
                "implementation_steps",
                "verification_testing",
                "lessons_learned"
            ],
            prompts={
                "problem_identification": "How was the problem first discovered or reported?",
                "investigation_process": "What steps were taken to understand and reproduce the issue?", 
                "root_cause_analysis": "What was determined to be the underlying cause?",
                "solution_design": "How was the fix designed and what alternatives were considered?",
                "implementation_steps": "What specific changes were made to resolve the issue?",
                "verification_testing": "How was the fix validated and tested?",
                "lessons_learned": "What insights were gained for preventing similar issues?"
            },
            context_requirements=[
                "bug_report", "debug_conversations", "fix_commits", "test_results"  
            ],
            success_criteria={
                "problem_clarity": 0.9,
                "solution_completeness": 0.8,
                "chronological_accuracy": 0.9
            }
        )
        
        # Store templates
        self.templates[dev_progress.template_id] = dev_progress
        self.templates[feature_journey.template_id] = feature_journey  
        self.templates[bug_investigation.template_id] = bug_investigation  # NEW - Phase 4
        self.templates[refactoring_journey.template_id] = refactoring_journey  # NEW - Phase 4
        self.templates[continue_context.template_id] = continue_context  # NEW - Phase 4
        self.templates[problem_resolution.template_id] = problem_resolution
        
        logger.info(f"Loaded {len(self.templates)} default story templates (Phase 4: Enhanced)")
    
    def get_template(self, template_id: str) -> Optional[StoryTemplate]:
        """Get story template by ID"""
        return self.templates.get(template_id)
    
    def get_templates_by_type(self, story_type: StoryType) -> List[StoryTemplate]:
        """Get all templates for a story type"""
        return [t for t in self.templates.values() if t.story_type == story_type]
    
    def generate_story_structure(self, template_id: str, context_data: Dict[str, Any]) -> Dict[str, str]:
        """Generate story structure using template and context"""
        template = self.get_template(template_id)
        if not template:
            raise ValueError(f"Template not found: {template_id}")
            
        # Validate context requirements
        missing_context = []
        for req in template.context_requirements:
            if req not in context_data:
                missing_context.append(req)
        
        if missing_context:
            logger.warning(f"Missing context for template {template_id}: {missing_context}")
        
        # Generate content for each section
        story_sections = {}
        for section in template.structure:
            prompt = template.prompts.get(section, f"Generate content for {section}")
            
            # Use context weaving to generate section content
            content = self._generate_section_content(section, prompt, context_data)
            story_sections[section] = content
            
        return story_sections
    
    def _generate_section_content(self, section: str, prompt: str, context_data: Dict[str, Any]) -> str:
        """Generate content for a story section using context"""
        # This is where context weaving algorithm applies the prompt to available context
        # For now, return a placeholder that shows the structure
        
        relevant_context = self._extract_relevant_context(section, context_data)
        
        content = f"{prompt}\\n\\nBased on available context:\\n"
        
        if relevant_context:
            for item in relevant_context[:3]:  # Top 3 most relevant
                content += f"- {item}\\n"
        else:
            content += "- [Context analysis would be applied here]\\n"
            
        return content
    
    def _extract_relevant_context(self, section: str, context_data: Dict[str, Any]) -> List[str]:
        """Extract context relevant to a specific story section"""
        # Simplified relevance matching for mock data phase
        relevant_items = []
        
        if "conversations" in context_data:
            for conv in context_data["conversations"]:
                if hasattr(conv, 'messages'):
                    for msg in conv.messages:
                        if len(msg.get('content', '')) > 20:  # Non-trivial content
                            relevant_items.append(f"Conversation: {msg['content'][:100]}...")
                            
        if "file_changes" in context_data:
            for change in context_data["file_changes"]:
                if hasattr(change, 'file_path'):
                    relevant_items.append(f"File modified: {change.file_path}")
                    
        return relevant_items


class ContextWeavingEngine:
    """
    Advanced context weaving algorithm for narrative generation.
    
    Analyzes dual-channel data to identify relationships, patterns,
    and narrative threads that connect development events into coherent stories.
    """
    
    def __init__(self, mock_data: DualChannelMockData = None):
        """Initialize context weaving engine"""
        self.mock_data = mock_data or DualChannelMockData()
        self.context_cache: Dict[str, List[ContextElement]] = {}
        
    def extract_context_elements(self, conversations: List[MockConversation], 
                                captures: List[MockDaemonCapture]) -> List[ContextElement]:
        """Extract contextual elements from dual-channel data"""
        elements = []
        
        # Process conversations
        for conv in conversations:
            for i, msg in enumerate(conv.messages):
                element = ContextElement(
                    element_id=f"conv_{conv.conversation_id}_{i}",
                    timestamp=conv.timestamp,
                    source_type="conversation",
                    content=msg.get('content', ''),
                    entities=conv.entities_extracted,
                    relationships=conv.files_mentioned,
                    confidence=0.8,
                    metadata={
                        "conversation_id": conv.conversation_id,
                        "message_role": msg.get('role', 'unknown'),
                        "session_type": conv.session_type
                    }
                )
                elements.append(element)
        
        # Process daemon captures
        for capture in captures:
            element = ContextElement(
                element_id=f"capture_{capture.capture_id}",
                timestamp=capture.timestamp,
                source_type="daemon_capture", 
                content=f"{capture.event_type}: {capture.file_path}",
                entities=[capture.file_path],
                relationships=[],
                confidence=0.9,  # High confidence for file system events
                metadata={
                    "capture_id": capture.capture_id,
                    "event_type": capture.event_type,
                    "change_type": capture.change_type,
                    "git_metadata": capture.git_metadata
                }
            )
            elements.append(element)
            
        # Sort by timestamp for chronological processing
        elements.sort(key=lambda x: x.timestamp)
        
        return elements
    
    def weave_context_narrative(self, elements: List[ContextElement], 
                              time_window: timedelta = timedelta(hours=24)) -> Dict[str, Any]:
        """Weave context elements into narrative threads"""
        
        # Group elements by time proximity
        narrative_threads = self._identify_narrative_threads(elements, time_window)
        
        # Analyze relationships between threads  
        thread_relationships = self._analyze_thread_relationships(narrative_threads)
        
        # Generate narrative structure
        narrative_structure = self._create_narrative_structure(narrative_threads, thread_relationships)
        
        return {
            "narrative_threads": narrative_threads,
            "thread_relationships": thread_relationships, 
            "narrative_structure": narrative_structure,
            "context_summary": self._summarize_context(elements),
            "weaving_metadata": {
                "total_elements": len(elements),
                "threads_identified": len(narrative_threads),
                "time_span": self._calculate_time_span(elements),
                "confidence": self._calculate_overall_confidence(elements)
            }
        }
    
    def _identify_narrative_threads(self, elements: List[ContextElement], 
                                  time_window: timedelta) -> Dict[str, List[ContextElement]]:
        """Identify narrative threads based on temporal and semantic proximity"""
        threads = {}
        current_thread_id = 0
        
        for element in elements:
            # Find existing thread within time window
            matching_thread = None
            
            for thread_id, thread_elements in threads.items():
                if thread_elements:
                    last_element = thread_elements[-1]
                    time_diff = abs(element.timestamp - last_element.timestamp)
                    
                    if time_diff <= time_window:
                        # Check semantic similarity (simplified)
                        if self._has_semantic_connection(element, last_element):
                            matching_thread = thread_id
                            break
            
            # Add to existing thread or create new one
            if matching_thread:
                threads[matching_thread].append(element)
            else:
                thread_id = f"thread_{current_thread_id}"
                threads[thread_id] = [element]
                current_thread_id += 1
                
        return threads
    
    def _has_semantic_connection(self, elem1: ContextElement, elem2: ContextElement) -> bool:
        """Check if two elements have semantic connection"""
        # Simple entity overlap check for mock phase
        common_entities = set(elem1.entities) & set(elem2.entities)
        common_relationships = set(elem1.relationships) & set(elem2.relationships)
        
        return len(common_entities) > 0 or len(common_relationships) > 0
    
    def _analyze_thread_relationships(self, threads: Dict[str, List[ContextElement]]) -> Dict[str, Any]:
        """Analyze relationships between narrative threads"""
        relationships = {}
        
        thread_ids = list(threads.keys())
        for i, thread_id in enumerate(thread_ids):
            relationships[thread_id] = {
                "depends_on": [],
                "influences": [],
                "parallel_to": [],
                "strength": 0.0
            }
            
            # Check relationships with other threads
            for j, other_thread_id in enumerate(thread_ids):
                if i != j:
                    relationship_strength = self._calculate_thread_relationship_strength(
                        threads[thread_id], threads[other_thread_id]
                    )
                    
                    if relationship_strength > 0.3:
                        relationships[thread_id]["influences"].append({
                            "thread_id": other_thread_id,
                            "strength": relationship_strength
                        })
                        
        return relationships
    
    def _calculate_thread_relationship_strength(self, thread1: List[ContextElement], 
                                              thread2: List[ContextElement]) -> float:
        """Calculate relationship strength between two threads"""
        if not thread1 or not thread2:
            return 0.0
            
        # Simple overlap-based calculation for mock phase
        all_entities_1 = set()
        all_entities_2 = set()
        
        for elem in thread1:
            all_entities_1.update(elem.entities)
        for elem in thread2:
            all_entities_2.update(elem.entities)
            
        overlap = len(all_entities_1 & all_entities_2)
        total_unique = len(all_entities_1 | all_entities_2)
        
        return overlap / max(total_unique, 1)
    
    def _create_narrative_structure(self, threads: Dict[str, List[ContextElement]], 
                                  relationships: Dict[str, Any]) -> Dict[str, Any]:
        """Create overall narrative structure from threads and relationships"""
        
        # Identify main narrative arc (longest/most connected thread)
        main_thread = max(threads.items(), key=lambda x: len(x[1]))[0]
        
        # Create chronological sequence
        all_elements = []
        for thread_elements in threads.values():
            all_elements.extend(thread_elements)
        all_elements.sort(key=lambda x: x.timestamp)
        
        return {
            "main_thread": main_thread,
            "chronological_sequence": [elem.element_id for elem in all_elements],
            "narrative_arc": {
                "beginning": all_elements[0].element_id if all_elements else None,
                "middle": all_elements[len(all_elements)//2].element_id if all_elements else None,
                "end": all_elements[-1].element_id if all_elements else None
            },
            "complexity_score": len(threads) * 0.1 + sum(len(t) for t in threads.values()) * 0.01
        }
    
    def _summarize_context(self, elements: List[ContextElement]) -> Dict[str, Any]:
        """Generate summary of context elements"""
        if not elements:
            return {}
            
        entity_counts = {}
        source_type_counts = {}
        
        for elem in elements:
            # Count entities
            for entity in elem.entities:
                entity_counts[entity] = entity_counts.get(entity, 0) + 1
            
            # Count source types
            source_type_counts[elem.source_type] = source_type_counts.get(elem.source_type, 0) + 1
        
        return {
            "total_elements": len(elements),
            "top_entities": sorted(entity_counts.items(), key=lambda x: x[1], reverse=True)[:5],
            "source_distribution": source_type_counts,
            "time_span_hours": self._calculate_time_span(elements),
            "average_confidence": sum(elem.confidence for elem in elements) / len(elements)
        }
    
    def _calculate_time_span(self, elements: List[ContextElement]) -> float:
        """Calculate time span of elements in hours"""
        if not elements:
            return 0.0
            
        timestamps = [elem.timestamp for elem in elements]
        time_span = max(timestamps) - min(timestamps)
        return time_span.total_seconds() / 3600
    
    def _calculate_overall_confidence(self, elements: List[ContextElement]) -> float:
        """Calculate overall confidence score for context weaving"""
        if not elements:
            return 0.0
            
        return sum(elem.confidence for elem in elements) / len(elements)


class TemporalContextAnalyzer:
    """
    Advanced temporal context analysis for narrative generation.
    
    NEW - Phase 4 Enhancement: Provides sophisticated temporal analysis
    to understand development flow, identify work patterns, and generate
    intelligent timeline visualizations for enhanced continue commands.
    """
    
    def __init__(self):
        """Initialize temporal context analyzer"""
        self.temporal_patterns = {
            "work_session": timedelta(hours=4),      # Typical work session
            "development_cycle": timedelta(days=1),   # Daily development cycle
            "sprint_cycle": timedelta(weeks=1),       # Weekly sprint cycle  
            "feature_cycle": timedelta(weeks=2)       # Bi-weekly feature cycle
        }
        
    def analyze_temporal_patterns(self, elements: List[ContextElement]) -> Dict[str, Any]:
        """Analyze temporal patterns in development activity"""
        if not elements:
            return {}
            
        # Sort elements chronologically
        sorted_elements = sorted(elements, key=lambda x: x.timestamp)
        
        # Identify work sessions
        work_sessions = self._identify_work_sessions(sorted_elements)
        
        # Analyze activity patterns  
        activity_patterns = self._analyze_activity_patterns(sorted_elements)
        
        # Identify development cycles
        development_cycles = self._identify_development_cycles(sorted_elements)
        
        # Generate timeline visualization data
        timeline_data = self._generate_timeline_data(sorted_elements, work_sessions)
        
        return {
            "work_sessions": work_sessions,
            "activity_patterns": activity_patterns,
            "development_cycles": development_cycles,
            "timeline_visualization": timeline_data,
            "temporal_insights": self._generate_temporal_insights(sorted_elements, work_sessions)
        }
    
    def _identify_work_sessions(self, elements: List[ContextElement]) -> List[Dict[str, Any]]:
        """Identify distinct work sessions based on temporal gaps"""
        if not elements:
            return []
            
        sessions = []
        current_session = [elements[0]]
        session_threshold = self.temporal_patterns["work_session"]
        
        for i in range(1, len(elements)):
            time_gap = elements[i].timestamp - elements[i-1].timestamp
            
            if time_gap <= session_threshold:
                current_session.append(elements[i])
            else:
                # End current session and start new one
                sessions.append(self._create_session_summary(current_session))
                current_session = [elements[i]]
        
        # Add final session
        if current_session:
            sessions.append(self._create_session_summary(current_session))
            
        return sessions
    
    def _create_session_summary(self, session_elements: List[ContextElement]) -> Dict[str, Any]:
        """Create summary for a work session"""
        if not session_elements:
            return {}
            
        start_time = session_elements[0].timestamp
        end_time = session_elements[-1].timestamp
        duration = end_time - start_time
        
        # Categorize activities in session
        conversation_count = len([e for e in session_elements if e.source_type == "conversation"])
        file_change_count = len([e for e in session_elements if e.source_type == "daemon_capture"])
        
        # Extract main entities/topics
        all_entities = set()
        for elem in session_elements:
            all_entities.update(elem.entities)
        top_entities = list(all_entities)[:5]
        
        return {
            "session_id": f"session_{start_time.strftime('%Y%m%d_%H%M%S')}",
            "start_time": start_time,
            "end_time": end_time, 
            "duration_minutes": duration.total_seconds() / 60,
            "activity_count": len(session_elements),
            "conversation_count": conversation_count,
            "file_change_count": file_change_count,
            "main_topics": top_entities,
            "productivity_score": self._calculate_productivity_score(session_elements),
            "session_type": self._classify_session_type(session_elements)
        }
    
    def _calculate_productivity_score(self, elements: List[ContextElement]) -> float:
        """Calculate productivity score for a session (0.0 - 1.0)"""
        if not elements:
            return 0.0
            
        # Simple productivity heuristic based on activity types and frequency
        conversation_weight = 0.3
        file_change_weight = 0.7
        
        conversation_count = len([e for e in elements if e.source_type == "conversation"])
        file_change_count = len([e for e in elements if e.source_type == "daemon_capture"])
        
        total_activity = conversation_count + file_change_count
        if total_activity == 0:
            return 0.0
            
        # Balanced mix of conversation and file changes indicates productive session
        conversation_ratio = conversation_count / total_activity
        file_change_ratio = file_change_count / total_activity
        
        # Optimal ratio is around 30% conversation, 70% file changes
        conversation_score = 1.0 - abs(conversation_ratio - 0.3) * 2
        file_change_score = 1.0 - abs(file_change_ratio - 0.7) * 2
        
        return max(0.0, min(1.0, conversation_score * conversation_weight + file_change_score * file_change_weight))
    
    def _classify_session_type(self, elements: List[ContextElement]) -> str:
        """Classify the type of work session"""
        if not elements:
            return "unknown"
            
        conversation_count = len([e for e in elements if e.source_type == "conversation"])
        file_change_count = len([e for e in elements if e.source_type == "daemon_capture"])
        
        if conversation_count == 0 and file_change_count > 0:
            return "pure_coding"
        elif conversation_count > file_change_count * 2:
            return "planning_discussion"
        elif file_change_count > conversation_count * 2:
            return "implementation_focused"
        else:
            return "balanced_development"
    
    def _analyze_activity_patterns(self, elements: List[ContextElement]) -> Dict[str, Any]:
        """Analyze patterns in development activity"""
        if not elements:
            return {}
            
        # Analyze by hour of day
        hourly_activity = {}
        daily_activity = {}
        
        for elem in elements:
            hour = elem.timestamp.hour
            day = elem.timestamp.strftime('%A')
            
            hourly_activity[hour] = hourly_activity.get(hour, 0) + 1
            daily_activity[day] = daily_activity.get(day, 0) + 1
        
        # Find peak hours and days
        peak_hour = max(hourly_activity, key=hourly_activity.get) if hourly_activity else None
        peak_day = max(daily_activity, key=daily_activity.get) if daily_activity else None
        
        return {
            "hourly_distribution": hourly_activity,
            "daily_distribution": daily_activity,
            "peak_hour": peak_hour,
            "peak_day": peak_day,
            "most_productive_time": f"{peak_day} at {peak_hour}:00" if peak_hour and peak_day else "Unknown"
        }
    
    def _identify_development_cycles(self, elements: List[ContextElement]) -> List[Dict[str, Any]]:
        """Identify development cycles (daily/weekly patterns)"""
        if not elements:
            return []
            
        # Group by day for daily cycles
        daily_groups = {}
        for elem in elements:
            day_key = elem.timestamp.strftime('%Y-%m-%d')
            if day_key not in daily_groups:
                daily_groups[day_key] = []
            daily_groups[day_key].append(elem)
        
        cycles = []
        for day, day_elements in daily_groups.items():
            cycle = {
                "cycle_type": "daily",
                "date": day,
                "element_count": len(day_elements),
                "start_time": min(e.timestamp for e in day_elements),
                "end_time": max(e.timestamp for e in day_elements),
                "main_activities": self._summarize_activities(day_elements)
            }
            cycles.append(cycle)
            
        return cycles
    
    def _summarize_activities(self, elements: List[ContextElement]) -> List[str]:
        """Summarize main activities in a set of elements"""
        activity_summary = []
        
        conversation_topics = set()
        files_modified = set()
        
        for elem in elements:
            if elem.source_type == "conversation":
                # Extract key topics from conversation content
                content = elem.content.lower()
                if "implement" in content or "create" in content:
                    conversation_topics.add("Implementation discussion")
                elif "bug" in content or "fix" in content:
                    conversation_topics.add("Bug fixing")
                elif "test" in content:
                    conversation_topics.add("Testing")
                else:
                    conversation_topics.add("General discussion")
            else:
                files_modified.update(elem.entities)
        
        # Summarize main activities
        if conversation_topics:
            activity_summary.extend(list(conversation_topics)[:3])
        if files_modified:
            activity_summary.append(f"Modified {len(files_modified)} files")
            
        return activity_summary[:5]  # Top 5 activities
    
    def _generate_timeline_data(self, elements: List[ContextElement], 
                               sessions: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Generate timeline visualization data"""
        if not elements:
            return {}
            
        timeline_events = []
        
        # Convert elements to timeline events
        for elem in elements:
            event = {
                "timestamp": elem.timestamp.isoformat(),
                "event_type": elem.source_type,
                "title": self._generate_event_title(elem),
                "description": elem.content[:100] + "..." if len(elem.content) > 100 else elem.content,
                "entities": elem.entities,
                "confidence": elem.confidence
            }
            timeline_events.append(event)
        
        # Add session markers
        session_markers = []
        for session in sessions:
            marker = {
                "start_time": session["start_time"].isoformat(),
                "end_time": session["end_time"].isoformat(),
                "session_type": session["session_type"],
                "productivity_score": session["productivity_score"],
                "activity_count": session["activity_count"]
            }
            session_markers.append(marker)
        
        return {
            "events": timeline_events,
            "session_markers": session_markers,
            "time_range": {
                "start": elements[0].timestamp.isoformat(),
                "end": elements[-1].timestamp.isoformat()
            },
            "visualization_config": {
                "color_scheme": "development_focused",
                "event_density": len(elements),
                "recommended_zoom_level": self._calculate_zoom_level(elements)
            }
        }
    
    def _generate_event_title(self, element: ContextElement) -> str:
        """Generate a concise title for a timeline event"""
        if element.source_type == "conversation":
            return "Conversation"
        elif element.source_type == "daemon_capture":
            return f"File change: {element.entities[0] if element.entities else 'Unknown'}"
        else:
            return "Development activity"
    
    def _calculate_zoom_level(self, elements: List[ContextElement]) -> str:
        """Calculate recommended zoom level based on event density"""
        if not elements:
            return "day"
            
        time_span = self._calculate_time_span_hours(elements)
        
        if time_span <= 4:
            return "hour"
        elif time_span <= 24:
            return "6hour"
        elif time_span <= 168:  # 1 week
            return "day"
        else:
            return "week"
    
    def _calculate_time_span_hours(self, elements: List[ContextElement]) -> float:
        """Calculate time span in hours"""
        if not elements:
            return 0.0
            
        timestamps = [elem.timestamp for elem in elements]
        time_span = max(timestamps) - min(timestamps)
        return time_span.total_seconds() / 3600
    
    def _generate_temporal_insights(self, elements: List[ContextElement], 
                                   sessions: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Generate insights about temporal patterns"""
        if not elements or not sessions:
            return {}
            
        insights = {}
        
        # Session analysis
        if sessions:
            avg_session_duration = sum(s["duration_minutes"] for s in sessions) / len(sessions)
            avg_productivity = sum(s["productivity_score"] for s in sessions) / len(sessions)
            
            insights["session_insights"] = {
                "total_sessions": len(sessions),
                "average_duration_minutes": avg_session_duration,
                "average_productivity_score": avg_productivity,
                "most_productive_session": max(sessions, key=lambda s: s["productivity_score"])["session_id"]
            }
        
        # Activity insights
        activity_patterns = self._analyze_activity_patterns(elements)
        insights["activity_insights"] = {
            "peak_activity_time": activity_patterns.get("most_productive_time", "Unknown"),
            "total_activities": len(elements),
            "activity_density": len(elements) / max(1, self._calculate_time_span_hours(elements))
        }
        
        return insights


class DecisionRationaleExtractor:
    """
    Extracts decision rationales from development conversations and code changes.
    
    Identifies moments where decisions were made, options considered,
    and reasoning behind choices for inclusion in narrative generation.
    """
    
    def __init__(self):
        """Initialize decision rationale extractor"""
        self.decision_patterns = {
            "architectural": ["architecture", "design", "structure", "pattern", "approach"],
            "implementation": ["implement", "code", "function", "method", "algorithm"],
            "bug_fix": ["bug", "fix", "error", "issue", "problem", "debug"],
            "feature": ["feature", "add", "new", "enhance", "improvement"]
        }
        
    def extract_decisions(self, conversations: List[MockConversation], 
                         captures: List[MockDaemonCapture]) -> List[DecisionRationale]:
        """Extract decision rationales from dual-channel data"""
        decisions = []
        
        # Process conversations for decision points
        for conv in conversations:
            decision = self._analyze_conversation_for_decisions(conv)
            if decision:
                decisions.append(decision)
        
        # Process captures for implementation decisions
        for capture in captures:
            decision = self._analyze_capture_for_decisions(capture)
            if decision:
                decisions.append(decision)
                
        return sorted(decisions, key=lambda x: x.timestamp)
    
    def _analyze_conversation_for_decisions(self, conversation: MockConversation) -> Optional[DecisionRationale]:
        """Analyze conversation for decision points"""
        
        # Look for decision indicators in messages
        decision_indicators = []
        full_content = ""
        
        for msg in conversation.messages:
            content = msg.get('content', '').lower()
            full_content += content + " "
            
            # Check for decision keywords
            for decision_type, keywords in self.decision_patterns.items():
                for keyword in keywords:
                    if keyword in content:
                        decision_indicators.append((decision_type, keyword))
        
        if not decision_indicators:
            return None
            
        # Determine primary decision type
        decision_counts = {}
        for decision_type, _ in decision_indicators:
            decision_counts[decision_type] = decision_counts.get(decision_type, 0) + 1
            
        primary_decision_type = max(decision_counts.items(), key=lambda x: x[1])[0]
        
        # Extract decision details (simplified for mock phase)
        decision_id = f"decision_{conversation.conversation_id}"
        
        return DecisionRationale(
            decision_id=decision_id,
            timestamp=conversation.timestamp,
            decision_type=primary_decision_type,
            context_summary=f"Decision made during conversation about {', '.join(conversation.files_mentioned)}",
            options_considered=["Option A (mentioned in conversation)", "Option B (alternative considered)"],
            chosen_approach=f"{primary_decision_type} approach based on conversation",
            reasoning="Analysis of conversation content suggests this decision rationale",
            outcome_observed=None,  # Would be filled by later analysis
            confidence=0.7
        )
    
    def _analyze_capture_for_decisions(self, capture: MockDaemonCapture) -> Optional[DecisionRationale]:
        """Analyze daemon capture for implementation decisions"""
        
        # Only process git commits as they indicate completed decisions
        if capture.event_type != "git_commit" or not capture.git_metadata:
            return None
            
        commit_msg = capture.git_metadata.get("message", "").lower()
        
        # Check if commit message indicates a decision
        decision_type = None
        for dec_type, keywords in self.decision_patterns.items():
            for keyword in keywords:
                if keyword in commit_msg:
                    decision_type = dec_type
                    break
            if decision_type:
                break
                
        if not decision_type:
            return None
            
        decision_id = f"decision_commit_{capture.capture_id}"
        
        return DecisionRationale(
            decision_id=decision_id,
            timestamp=capture.timestamp,
            decision_type=decision_type,
            context_summary=f"Implementation decision reflected in commit to {capture.file_path}",
            options_considered=["Previous implementation", "New implementation (committed)"],
            chosen_approach=f"Committed changes to {capture.file_path}",
            reasoning=f"Commit message: {capture.git_metadata.get('message', 'No message')}",
            outcome_observed="Changes committed to repository",
            confidence=0.8
        )


# Integration with existing narrative intelligence
def enhance_narrative_intelligence_with_track_b(narrative_intelligence: NarrativeIntelligence,
                                               mock_data: DualChannelMockData = None) -> Dict[str, Any]:
    """
    Enhance existing narrative intelligence with Track B Phase 4 capabilities.
    
    This function bridges the new Track B narrative engine with the existing
    tier1/narrative_intelligence.py system.
    """
    
    # Initialize Track B components
    template_system = StoryTemplateSystem()
    context_engine = ContextWeavingEngine(mock_data)
    decision_extractor = DecisionRationaleExtractor()
    
    # Load mock data
    if not mock_data:
        mock_data = DualChannelMockData()
    
    conversations = mock_data.load_mock_conversations()
    captures = mock_data.load_mock_captures()
    
    # Generate enhanced context
    context_elements = context_engine.extract_context_elements(conversations, captures)
    woven_context = context_engine.weave_context_narrative(context_elements)
    decisions = decision_extractor.extract_decisions(conversations, captures)
    
    # Integration results
    integration_results = {
        "track_b_components": {
            "story_templates": len(template_system.templates),
            "context_elements": len(context_elements),
            "narrative_threads": len(woven_context.get("narrative_threads", {})),
            "decisions_extracted": len(decisions)
        },
        "mock_data_stats": {
            "conversations": len(conversations),
            "captures": len(captures),
            "time_span_hours": woven_context.get("weaving_metadata", {}).get("time_span", 0)
        },
        "enhancement_capabilities": [
            "Story template system for consistent narratives",
            "Context weaving for connecting development events", 
            "Decision rationale extraction for development insights",
            "Mock data integration for development phase"
        ],
        "integration_status": "ready_for_continue_command_enhancement"
    }
    
    return integration_results


class EnhancedNarrativeEngine:
    """
    Enhanced narrative engine combining all Track B Phase 4 components.
    
    This is the main class that orchestrates all narrative generation capabilities:
    - Story template system for coherent narratives
    - Temporal context analysis for work session identification  
    - Context weaving for connecting development events
    - Decision rationale extraction for insights
    
    Designed to work with both mock data (development) and real data (production).
    """
    
    def __init__(self, mock_data: Optional[DualChannelMockData] = None):
        """Initialize the enhanced narrative engine with all components."""
        self.mock_data = mock_data or DualChannelMockData()
        
        # Initialize core components
        self.template_system = StoryTemplateSystem()
        self.temporal_analyzer = TemporalContextAnalyzer()
        self.context_weaver = ContextWeavingEngine(self.mock_data)
        self.decision_extractor = DecisionRationaleExtractor()
        
        self.logger = logging.getLogger(__name__)
        self.logger.info("EnhancedNarrativeEngine initialized with all Track B components")
    
    def generate_comprehensive_narrative(self, 
                                       conversations: List[MockConversation],
                                       captures: List[MockDaemonCapture],
                                       narrative_type: str = "work_session") -> Dict[str, Any]:
        """
        Generate a comprehensive narrative from conversation and capture data.
        
        This is the main method that orchestrates all components to create
        a rich, contextualized narrative of development activities.
        
        Args:
            conversations: List of conversation data
            captures: List of daemon capture data
            narrative_type: Type of narrative to generate (work_session, collaborative, etc.)
        
        Returns:
            Dict containing the generated narrative and metadata
        """
        start_time = datetime.now()
        
        try:
            # Step 1: Temporal analysis
            work_sessions = self.temporal_analyzer.identify_work_sessions(conversations, captures)
            activity_patterns = self.temporal_analyzer.analyze_activity_patterns(conversations, captures)
            timeline = self.temporal_analyzer.create_timeline_visualization(conversations, captures)
            coherence = self.temporal_analyzer.evaluate_context_coherence(conversations, captures)
            
            # Step 2: Decision extraction
            decisions = self.decision_extractor.extract_decisions(conversations, captures)
            categorized_decisions = self.decision_extractor.categorize_decisions(decisions)
            
            # Step 3: Context preparation
            context = {
                "narrative_type": narrative_type,
                "work_sessions": work_sessions,
                "activity_patterns": activity_patterns,
                "timeline": timeline,
                "coherence": coherence,
                "decisions": decisions,
                "decision_categories": categorized_decisions,
                "data_sources": {
                    "conversations": len(conversations),
                    "captures": len(captures)
                }
            }
            
            # Step 4: Context weaving
            woven_context = self.context_weaver.weave_context(
                self._extract_conversation_context(conversations),
                self._extract_capture_context(captures)
            )
            context.update(woven_context)
            
            # Step 5: Narrative generation
            base_narrative = self.template_system.generate_narrative(narrative_type, context)
            enhanced_narrative = self.context_weaver.enhance_narrative_with_context(
                base_narrative, context
            )
            
            generation_time = (datetime.now() - start_time).total_seconds()
            
            return {
                "narrative": enhanced_narrative,
                "context": context,
                "metadata": {
                    "generation_time_ms": generation_time * 1000,
                    "narrative_type": narrative_type,
                    "components_used": [
                        "StoryTemplateSystem",
                        "TemporalContextAnalyzer", 
                        "ContextWeavingEngine",
                        "DecisionRationaleExtractor"
                    ],
                    "data_quality": {
                        "coherence_score": coherence.get("overall_score", 0),
                        "temporal_coverage": len(work_sessions),
                        "decision_richness": len(decisions)
                    }
                },
                "performance": {
                    "target_met": generation_time < 0.5,  # 500ms target
                    "actual_time_ms": generation_time * 1000,
                    "efficiency_rating": "excellent" if generation_time < 0.2 else "good"
                }
            }
            
        except Exception as e:
            self.logger.error(f"Error generating comprehensive narrative: {e}")
            return {
                "narrative": f"Error generating narrative: {str(e)}",
                "context": {},
                "metadata": {"error": str(e)},
                "performance": {"error": True}
            }
    
    def _extract_conversation_context(self, conversations: List[MockConversation]) -> Dict[str, Any]:
        """Extract context elements from conversation data."""
        if not conversations:
            return {}
        
        files_mentioned = set()
        intents = []
        time_range = []
        
        for conv in conversations:
            # Extract files from context
            if hasattr(conv, 'context') and conv.context:
                files = conv.context.get('files_modified', [])
                files_mentioned.update(files)
            
            # Extract intents
            if hasattr(conv, 'intent'):
                intents.append(conv.intent)
            
            # Track time range
            if hasattr(conv, 'timestamp'):
                time_range.append(conv.timestamp)
        
        return {
            "files_modified": list(files_mentioned),
            "intents_distribution": self._calculate_intent_distribution(intents),
            "time_range": {
                "start": min(time_range) if time_range else None,
                "end": max(time_range) if time_range else None,
                "duration_hours": (max(time_range) - min(time_range)).total_seconds() / 3600 if len(time_range) > 1 else 0
            },
            "conversation_count": len(conversations)
        }
    
    def _extract_capture_context(self, captures: List[MockDaemonCapture]) -> Dict[str, Any]:
        """Extract context elements from daemon capture data."""
        if not captures:
            return {}
        
        total_duration = sum(getattr(cap, 'duration_minutes', 0) for cap in captures)
        all_files = []
        time_range = []
        
        for cap in captures:
            # Extract files
            if hasattr(cap, 'file_changes'):
                all_files.extend(cap.file_changes)
            
            # Track time range
            if hasattr(cap, 'timestamp'):
                time_range.append(cap.timestamp)
        
        return {
            "total_session_duration_minutes": total_duration,
            "files_changed": list(set(all_files)),
            "capture_count": len(captures),
            "average_session_length": total_duration / len(captures) if captures else 0,
            "time_range": {
                "start": min(time_range) if time_range else None,
                "end": max(time_range) if time_range else None
            }
        }
    
    def _calculate_intent_distribution(self, intents: List[str]) -> Dict[str, float]:
        """Calculate the distribution of intents as percentages."""
        if not intents:
            return {}
        
        from collections import Counter
        intent_counts = Counter(intents)
        total = len(intents)
        
        return {intent: count / total for intent, count in intent_counts.items()}
    
    def get_component_status(self) -> Dict[str, Any]:
        """Get the status of all narrative engine components."""
        return {
            "template_system": {
                "initialized": self.template_system is not None,
                "templates_available": len(self.template_system.templates) if self.template_system else 0,
                "template_types": list(self.template_system.templates.keys()) if self.template_system else []
            },
            "temporal_analyzer": {
                "initialized": self.temporal_analyzer is not None,
                "capabilities": [
                    "work_session_identification",
                    "activity_pattern_analysis", 
                    "timeline_visualization",
                    "context_coherence_evaluation"
                ] if self.temporal_analyzer else []
            },
            "context_weaver": {
                "initialized": self.context_weaver is not None,
                "mock_data_available": self.context_weaver.mock_data is not None if self.context_weaver else False
            },
            "decision_extractor": {
                "initialized": self.decision_extractor is not None,
                "capabilities": [
                    "decision_extraction",
                    "decision_categorization",
                    "impact_analysis"
                ] if self.decision_extractor else []
            },
            "overall_status": "ready",
            "integration_ready": True
        }