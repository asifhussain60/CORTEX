# CORTEX Hands-On Tutorial Program

**Purpose:** Interactive learning program teaching CORTEX through practical exercises  
**Version:** 1.0  
**Status:** ‚úÖ PRODUCTION READY  
**Duration:** 15-30 minutes (customizable)

---

## üéØ Tutorial Overview

This hands-on program guides you through CORTEX capabilities with real exercises, not just documentation. You'll learn by doing:

1. **CORTEX Basics** (5 min) - Understanding the system
2. **Planning Workflow** (5-7 min) - How to plan features
3. **Development with TDD** (8-10 min) - Write tests, implement features
4. **Testing & Validation** (5-7 min) - Verify your work
5. **Architecture Intelligence** (5-7 min) - Strategic health analysis and trend tracking

**What You'll Build:** A simple user authentication feature (login form with validation) + architecture health tracking

---

## üìö Tutorial Structure

### Learning Path Options

**üöÄ Quick Start (15 min)**
- Learn essentials only (Modules 1-3)
- Skip theory, focus on commands
- Build simplified version

**üìñ Standard (30 min)**
- Balanced theory + practice (Modules 1-4)
- All core workflows covered
- Complete feature implementation

**üéì Comprehensive (40 min)**
- Deep understanding (Modules 1-5)
- Advanced features included
- Production-ready implementation + architecture analysis

---

## üéì Module 1: CORTEX Basics (5 min)

### What You'll Learn
- How CORTEX works (brain architecture)
- Natural language commands
- Help system navigation
- Brain memory system

### Hands-On Exercise 1.1: Explore CORTEX Capabilities

**Task:** Discover what CORTEX can do

**Commands to Try:**
```
help
```

**Expected Output:**
- Table of all available commands
- Natural language triggers
- Operation categories

**Understanding Check:**
- ‚úÖ Can you find the planning command?
- ‚úÖ Can you find the TDD workflow command?
- ‚úÖ Can you find the feedback command?

---

### Hands-On Exercise 1.2: Check CORTEX Brain Memory

**Task:** See what CORTEX remembers about your workspace

**Commands to Try:**
```
show context
```

**Expected Output:**
- Conversation history loaded
- Context quality score
- Memory health status

**Understanding Check:**
- ‚úÖ What's your context quality score?
- ‚úÖ How many conversations loaded?
- ‚úÖ Is your memory health good?

---

### Hands-On Exercise 1.3: System Health Check

**Task:** Validate CORTEX is working correctly

**Commands to Try:**
```
healthcheck
```

**Expected Output:**
- System status (Healthy/Warning/Unhealthy)
- Database integrity check
- Feature availability check

**Understanding Check:**
- ‚úÖ Is your CORTEX healthy?
- ‚úÖ Are all features available?
- ‚úÖ Any warnings to address?

---

## üìã Module 2: Planning Workflow (5-7 min)

### What You'll Learn
- Feature planning process
- DoR (Definition of Ready) validation
- DoD (Definition of Done) criteria
- Security review (OWASP)
- Acceptance criteria writing

### Hands-On Exercise 2.1: Plan Authentication Feature

**Task:** Create a complete plan for user login feature

**Scenario:**
You need to build a login page with:
- Email input field
- Password input field
- "Remember me" checkbox
- Submit button
- "Forgot password" link

**Commands to Try:**
```
plan user authentication
```

**CORTEX Will Ask You:**

**Q1: What EXACTLY does this feature do?**
```
Your Answer Example:
"Allows users to log in with email and password. 
Validates credentials against database. 
Shows error messages if login fails.
Redirects to dashboard on success."
```

**Q2: Who are the SPECIFIC users?**
```
Your Answer Example:
"Registered users with email accounts in our system.
Admin users (elevated permissions).
Guest users (limited access)."
```

**Q3: What are the EXACT systems/APIs/databases?**
```
Your Answer Example:
"UserDatabase (SQL Server)
AuthenticationAPI (JWT token generation)
SessionManager (cookie handling)
EmailService (password reset)"
```

**Q4: What are the MEASURABLE limits?**
```
Your Answer Example:
"Login response time: < 500ms
Failed login attempts: 3 max before lockout
Session timeout: 30 minutes
Password complexity: 8+ chars, 1 uppercase, 1 number"
```

**Q5: How do we MEASURE success?**
```
Your Answer Example:
"95% of logins complete in < 500ms
< 1% authentication errors (excluding wrong password)
Zero security vulnerabilities in penetration test
User satisfaction: 4.5+ stars"
```

**Q6: What files/services MUST exist?**
```
Your Answer Example:
"Controllers/AuthController.cs (to be created)
Models/User.cs (exists)
Services/AuthenticationService.cs (to be created)
Views/Login.cshtml (to be created)
appsettings.json (exists)"
```

**Q7: What security risks exist?**
```
Your Answer Example:
"SQL injection via email input
XSS via error messages
Brute force password attacks
Session hijacking
CSRF attacks"
```

---

### Understanding CORTEX's Response

**CORTEX will now:**

1. ‚úÖ **Validate your answers** for ambiguity
2. ‚ö†Ô∏è **Challenge vague terms** (e.g., "improve" ‚Üí "improve by how much?")
3. üîí **Run OWASP security review** automatically
4. üìã **Check DoR completion** (all checkboxes)
5. ‚úÖ **Generate planning document** when approved

**Expected Output:**
```
‚úÖ DoR Status: COMPLETE

‚úì Requirements documented (zero ambiguity)
‚úì Dependencies identified & validated
‚úì Technical design approach agreed
‚úì Test strategy defined
‚úì Acceptance criteria measurable
‚úì Security review passed (OWASP checklist complete)
‚úì User approval on scope

Creating: cortex-brain/documents/planning/features/PLAN-20251125-authentication.md
```

---

### Hands-On Exercise 2.2: Review Planning Document

**Task:** Open and review the generated plan

**File Location:**
```
cortex-brain/documents/planning/features/PLAN-20251125-authentication.md
```

**What to Look For:**
- ‚úÖ Phase breakdown (Foundation ‚Üí Core ‚Üí Validation)
- ‚úÖ Risk analysis section
- ‚úÖ Security hardening tasks
- ‚úÖ Task generation with acceptance criteria
- ‚úÖ Milestone-based implementation plan

**Understanding Check:**
- ‚úÖ Can you identify Phase 1 tasks?
- ‚úÖ Are security risks documented?
- ‚úÖ Are acceptance criteria measurable?
- ‚úÖ Is DoD (Definition of Done) clear?

---

### Hands-On Exercise 2.3: Approve Plan

**Task:** Approve the plan to move to implementation

**Commands to Try:**
```
approve plan
```

**Expected Output:**
```
‚úÖ Plan approved and moved to approved/
‚úÖ Ready for implementation
‚úÖ TDD workflow can now begin

Planning file moved to:
cortex-brain/documents/planning/features/approved/APPROVED-20251125-authentication.md
```

---

## üíª Module 3: Development with TDD (8-10 min)

### What You'll Learn
- RED‚ÜíGREEN‚ÜíREFACTOR cycle
- Test-first development
- Auto-debug on failures
- Performance-based refactoring
- Test location isolation

### Hands-On Exercise 3.1: Start TDD Workflow

**Task:** Initialize TDD session for authentication feature

**Commands to Try:**
```
start tdd workflow for user authentication
```

**Expected Output:**
```
‚úÖ Workspace discovered: [Your project type]
‚úÖ Test framework: [pytest/jest/xunit detected]
‚úÖ Ready for RED state - write your failing test

TDD Session ID: tdd-20251125-123456
Phase: RED (Write Failing Test)
```

---

### Hands-On Exercise 3.2: Discover UI Elements (View Discovery)

**Task:** Auto-discover element IDs before writing tests

**Commands to Try:**
```
discover views in src/Views/Account/Login.cshtml
```

**Expected Output:**
```
üîç Scanning: Login.cshtml

‚úÖ Found 5 elements:
   ‚Ä¢ #emailInput (text input)
   ‚Ä¢ #passwordInput (password input)
   ‚Ä¢ #rememberMeCheckbox (checkbox)
   ‚Ä¢ #loginButton (submit button)
   ‚Ä¢ #forgotPasswordLink (link)

‚úÖ Stored in brain (Tier 2)
‚úÖ Available for test generation

Selector strategies generated:
   ‚Ä¢ By ID: #emailInput
   ‚Ä¢ By Name: input[name="email"]
   ‚Ä¢ By Aria-Label: input[aria-label="Email"]
```

**Time Saved:** 60+ minutes of manual inspection ‚Üí <5 minutes automated

---

### Hands-On Exercise 3.3: Generate Tests (RED Phase)

**Task:** Create failing tests for login functionality

**Commands to Try:**
```
generate tests for login validation
```

**CORTEX will:**
1. ‚úÖ Use discovered element IDs (95%+ accuracy)
2. ‚úÖ Generate test file in YOUR repo (not CORTEX folder)
3. ‚úÖ Follow YOUR naming conventions
4. ‚úÖ Use YOUR test framework

**Expected Output:**
```
‚úÖ Test file created: tests/test_login_validation.py

Generated 6 tests:
   ‚Ä¢ test_valid_login_redirects_to_dashboard
   ‚Ä¢ test_invalid_email_shows_error
   ‚Ä¢ test_invalid_password_shows_error
   ‚Ä¢ test_empty_fields_show_validation_errors
   ‚Ä¢ test_remember_me_persists_session
   ‚Ä¢ test_forgot_password_link_navigates

Using real element IDs:
   #emailInput, #passwordInput, #loginButton
```

---

### Hands-On Exercise 3.4: Run Tests (Expect Failures - RED State)

**Task:** Execute tests to confirm RED state

**Commands to Try:**
```
run tests
```

**Expected Output:**
```
üîß Running tests with pytest...

‚ùå FAILED tests/test_login_validation.py::test_valid_login_redirects_to_dashboard
   AssertionError: Element #emailInput not found

‚ùå FAILED tests/test_login_validation.py::test_invalid_email_shows_error
   NotImplementedError: validate_email() not implemented

Tests completed in 2.50s
   Passed: 0 ‚úì
   Failed: 6 ‚úó

‚ùå Entering RED state (expected)

üìä Auto-Debug Session Started
   Debug ID: debug-20251125-123456
   Tracking function execution...
```

**Understanding Check:**
- ‚úÖ Tests failed as expected (RED state)
- ‚úÖ Auto-debug session started automatically
- ‚úÖ Error messages are clear

---

### Hands-On Exercise 3.5: Implement Feature (GREEN Phase)

**Task:** Write code to pass tests

**What to Implement:**

**File: Controllers/AuthController.cs**
```csharp
public class AuthController : Controller
{
    private readonly IAuthenticationService _authService;

    public AuthController(IAuthenticationService authService)
    {
        _authService = authService;
    }

    [HttpPost]
    public async Task<IActionResult> Login(LoginViewModel model)
    {
        if (!ModelState.IsValid)
            return View(model);

        var result = await _authService.ValidateCredentials(
            model.Email, 
            model.Password
        );

        if (result.Success)
        {
            // Create session
            await _authService.CreateSession(
                result.User, 
                model.RememberMe
            );
            
            return RedirectToAction("Dashboard", "Home");
        }

        ModelState.AddModelError("", "Invalid email or password");
        return View(model);
    }
}
```

**File: Services/AuthenticationService.cs**
```csharp
public class AuthenticationService : IAuthenticationService
{
    private readonly UserDbContext _db;

    public async Task<AuthResult> ValidateCredentials(
        string email, 
        string password)
    {
        var user = await _db.Users
            .FirstOrDefaultAsync(u => u.Email == email);

        if (user == null)
            return AuthResult.Failed("User not found");

        if (!BCrypt.Verify(password, user.PasswordHash))
            return AuthResult.Failed("Invalid password");

        return AuthResult.Success(user);
    }

    public async Task CreateSession(User user, bool rememberMe)
    {
        var session = new Session
        {
            UserId = user.Id,
            CreatedAt = DateTime.UtcNow,
            ExpiresAt = rememberMe 
                ? DateTime.UtcNow.AddDays(30)
                : DateTime.UtcNow.AddMinutes(30)
        };

        _db.Sessions.Add(session);
        await _db.SaveChangesAsync();
    }
}
```

---

### Hands-On Exercise 3.6: Run Tests Again (Expect Pass - GREEN State)

**Task:** Verify tests pass after implementation

**Commands to Try:**
```
run tests
```

**Expected Output:**
```
üîß Running tests with pytest...

‚úÖ PASSED tests/test_login_validation.py::test_valid_login_redirects_to_dashboard
‚úÖ PASSED tests/test_login_validation.py::test_invalid_email_shows_error
‚úÖ PASSED tests/test_login_validation.py::test_invalid_password_shows_error
‚úÖ PASSED tests/test_login_validation.py::test_empty_fields_show_validation_errors
‚úÖ PASSED tests/test_login_validation.py::test_remember_me_persists_session
‚úÖ PASSED tests/test_login_validation.py::test_forgot_password_link_navigates

Tests completed in 3.20s
   Passed: 6 ‚úì
   Failed: 0 ‚úó

‚úÖ Entering GREEN state

üìä Performance Data Captured:
   ‚Ä¢ ValidateCredentials: avg 145ms (SLOW_FUNCTION detected)
   ‚Ä¢ CreateSession: avg 89ms (acceptable)
   ‚Ä¢ DatabaseQuery: total 850ms (BOTTLENECK detected)

üí° Auto-Feedback Collection triggered
   Creating feedback report...
```

**Understanding Check:**
- ‚úÖ All tests passing (GREEN state)
- ‚úÖ Performance data captured automatically
- ‚úÖ Bottlenecks identified
- ‚úÖ Feedback report created

---

### Hands-On Exercise 3.7: Refactor (REFACTOR Phase)

**Task:** Get performance-based refactoring suggestions

**Commands to Try:**
```
suggest refactorings
```

**Expected Output:**
```
üéØ Found 3 performance issues:

1. ValidateCredentials() - SLOW_FUNCTION (avg 145ms)
   Confidence: 0.95
   Suggestion: Add caching for user lookups
   Impact: 70% faster (145ms ‚Üí 45ms)
   
   Recommended Change:
   ‚Ä¢ Add MemoryCache for User objects
   ‚Ä¢ Cache key: "user:email:{email}"
   ‚Ä¢ TTL: 5 minutes
   
2. DatabaseQuery() - BOTTLENECK (total 850ms)
   Confidence: 0.95
   Suggestion: Add indexes on Email and PasswordHash columns
   Impact: 60% faster (850ms ‚Üí 340ms)
   
   Recommended Change:
   ‚Ä¢ CREATE INDEX IX_Users_Email ON Users(Email)
   ‚Ä¢ Consider query optimization

3. CheckPermissions() - HOT_PATH (called 23 times)
   Confidence: 0.95
   Suggestion: Batch permission checks
   Impact: 50% fewer queries
   
   Recommended Change:
   ‚Ä¢ Load all permissions in single query
   ‚Ä¢ Use in-memory filter instead of repeated DB calls
```

---

### Hands-On Exercise 3.8: Apply Refactoring

**Task:** Implement suggested improvements

**Add Caching:**
```csharp
public class AuthenticationService : IAuthenticationService
{
    private readonly UserDbContext _db;
    private readonly IMemoryCache _cache;

    public async Task<AuthResult> ValidateCredentials(
        string email, 
        string password)
    {
        // Check cache first
        var cacheKey = $"user:email:{email}";
        if (_cache.TryGetValue(cacheKey, out User cachedUser))
        {
            if (BCrypt.Verify(password, cachedUser.PasswordHash))
                return AuthResult.Success(cachedUser);
            
            return AuthResult.Failed("Invalid password");
        }

        // Cache miss - query database
        var user = await _db.Users
            .FirstOrDefaultAsync(u => u.Email == email);

        if (user == null)
            return AuthResult.Failed("User not found");

        // Cache user for 5 minutes
        _cache.Set(cacheKey, user, TimeSpan.FromMinutes(5));

        if (!BCrypt.Verify(password, user.PasswordHash))
            return AuthResult.Failed("Invalid password");

        return AuthResult.Success(user);
    }
}
```

---

### Hands-On Exercise 3.9: Validate Refactoring

**Task:** Run tests to ensure refactoring didn't break anything

**Commands to Try:**
```
run tests
```

**Expected Output:**
```
‚úÖ All tests still passing (6/6)
‚úÖ Performance improved:
   ‚Ä¢ ValidateCredentials: 145ms ‚Üí 48ms (67% faster)
   ‚Ä¢ Total test time: 3.20s ‚Üí 1.85s (42% faster)

‚úÖ REFACTOR phase complete
‚úÖ Ready for session completion
```

---

### Hands-On Exercise 3.10: Create Git Checkpoint

**Task:** Save your work with SKULL Rule #8 compliance

**Commands to Try:**
```
git checkpoint
```

**Expected Output:**
```
‚úÖ Git checkpoint created
   Commit SHA: a1b2c3d4
   Message: "feat: Add user authentication with caching optimization"
   
‚úÖ SKULL Rule #8 compliance verified
‚úÖ Work state preserved
```

---

## ‚úÖ Module 4: Testing & Validation (5-7 min)

### What You'll Learn
- Code quality validation
- Lint checking
- Session completion reports
- Deployment readiness

### Hands-On Exercise 4.1: Validate Code Quality

**Task:** Run lint validation before completion

**Commands to Try:**
```
validate lint
```

**Expected Output:**
```
üîç Running code quality checks...

‚úÖ No critical violations found
‚ö†Ô∏è 2 warnings (non-blocking):
   ‚Ä¢ Line 45: Consider using async/await pattern
   ‚Ä¢ Line 67: Variable name could be more descriptive

‚úÖ Ready to proceed to session completion
```

---

### Hands-On Exercise 4.2: Complete TDD Session

**Task:** Generate session completion report

**Commands to Try:**
```
complete session
```

**Expected Output:**
```
üìä TDD Session Completion Report

Session ID: tdd-20251125-123456
Duration: 18 minutes 32 seconds

**Before Session:**
‚Ä¢ Tests: 0 passing
‚Ä¢ Code coverage: 0%
‚Ä¢ Performance baseline: N/A

**After Session:**
‚Ä¢ Tests: 6 passing (100% pass rate)
‚Ä¢ Code coverage: 87%
‚Ä¢ Performance: 42% improvement

**Accomplishments:**
‚úÖ Implemented user authentication
‚úÖ Added password validation
‚úÖ Optimized with caching (67% faster)
‚úÖ Created 6 comprehensive tests
‚úÖ Zero critical lint violations

**Files Modified:**
‚Ä¢ Controllers/AuthController.cs (created)
‚Ä¢ Services/AuthenticationService.cs (created)
‚Ä¢ Views/Login.cshtml (modified)
‚Ä¢ tests/test_login_validation.py (created)

Report saved: cortex-brain/documents/reports/TDD-SESSION-20251125-123456.md
```

---

### Hands-On Exercise 4.3: Generate Feedback Report

**Task:** Share performance metrics with team

**Commands to Try:**
```
generate feedback report
```

**Expected Output:**
```
üìä Generating comprehensive feedback report...

**8-Category Metrics Collected:**

1. Performance Metrics
   ‚Ä¢ Response time: 48ms (excellent)
   ‚Ä¢ Memory usage: 125MB (normal)

2. Reliability Metrics
   ‚Ä¢ Success rate: 100%
   ‚Ä¢ Error rate: 0%

3. Usage Patterns
   ‚Ä¢ TDD workflow: Used
   ‚Ä¢ Planning: Completed
   ‚Ä¢ View discovery: Utilized

4. Context Quality
   ‚Ä¢ Relevance score: 0.92 (high)
   ‚Ä¢ Retrieval accuracy: 95%

5. User Satisfaction
   ‚Ä¢ Workflow completion: 100%
   ‚Ä¢ No errors encountered

6. Brain Health
   ‚Ä¢ Database size: 45MB
   ‚Ä¢ Last cleanup: 2 days ago

7. Integration Depth
   ‚Ä¢ Feature completeness: 95%
   ‚Ä¢ All modules wired

8. Platform Stability
   ‚Ä¢ OS: macOS
   ‚Ä¢ No platform-specific issues

‚úÖ Report created: cortex-brain/feedback/reports/FEEDBACK-20251125-123456.md
‚úÖ Uploaded to GitHub Gist (private)
‚úÖ Gist URL: https://gist.github.com/[your-gist-id]
```

---

## üéì Tutorial Completion

### What You've Learned

‚úÖ **CORTEX Basics**
- Help system navigation
- Brain memory system
- Health checking

‚úÖ **Planning Workflow**
- DoR validation process
- Security review (OWASP)
- Acceptance criteria writing
- Plan approval workflow

‚úÖ **TDD Development**
- RED‚ÜíGREEN‚ÜíREFACTOR cycle
- View discovery automation
- Test generation with real IDs
- Performance-based refactoring
- Auto-debug on failures

‚úÖ **Testing & Validation**
- Lint validation
- Session completion reports
- Feedback generation
- Git checkpoints

---

### Next Steps

**üöÄ Practice More:**
1. Plan another feature using `plan [feature name]`
2. Try TDD workflow on your own code
3. Explore view discovery in different file types
4. Generate feedback reports regularly

**üìö Learn Advanced Features:**
1. System alignment (`align report`)
2. Upgrade system (`upgrade cortex`)
3. Brain export/import (`export brain`)
4. Admin operations (`admin help`)

**ü§ù Join Community:**
1. Share feedback reports with team
2. Report issues (`feedback bug`)
3. Suggest improvements (`feedback improvement`)
4. Review documentation in `.github/prompts/modules/`

---

## üèõÔ∏è Module 5: Architecture Intelligence (5-7 min)

### What You'll Learn
- Strategic architecture health analysis
- Trend tracking and forecasting
- Technical debt estimation
- Using reports for sprint planning

### Hands-On Exercise 5.1: Run Architecture Review

**Task:** Generate comprehensive architecture health report

**Commands to Try:**
```
review architecture
```

**Expected Output:**
```
üèõÔ∏è Architecture Review Complete

Overall Health: 78/100 (Warning)

Layer Breakdown:
- Discovery: 95% (19 features) ‚úÖ
- Import: 90% (18 features) ‚úÖ
- Instantiation: 85% (17 features) ‚úÖ
- Documentation: 75% (15 features) ‚ö†Ô∏è
- Testing: 70% (14 features) ‚ö†Ô∏è
- Wiring: 80% (16 features) ‚úÖ
- Optimization: 65% (13 features) ‚ùå

Feature Status:
- Healthy (90-100%): 13 features
- Warning (70-89%): 5 features
- Critical (<70%): 1 feature

Report saved: cortex-brain/documents/analysis/architecture-review-20251127-143022.md
```

**Understanding Check:**
- ‚úÖ What's the overall health score?
- ‚úÖ Which layer has the lowest score?
- ‚úÖ How many features need attention (Warning + Critical)?

---

### Hands-On Exercise 5.2: Interpret Health Report

**Task:** Open and analyze the generated report

**File Location:**
```
cortex-brain/documents/analysis/architecture-review-[timestamp].md
```

**What to Look For:**

**1. Executive Summary:**
```markdown
Current architecture health: 78% (Warning). System has improved 5% 
over the last 30 days, showing consistent upward trend. Primary 
recommendation: Address 12 features in Warning state (70-89%) to 
reach Healthy threshold.
```

**2. Trend Analysis (if historical data exists):**
```markdown
Trend Analysis (Last 30 Days):
- Velocity: +5.2% improvement
- Direction: Improving ‚ÜóÔ∏è
- Volatility: 2.3 (Low - predictable changes)
```

**3. Technical Debt Forecast:**
```markdown
3-Month Projection:
- Predicted Score: 83% (‚ÜóÔ∏è +5% from current)
- Confidence: 0.85 (High)

6-Month Projection:
- Predicted Score: 88% (‚ÜóÔ∏è +10% from current)
- Confidence: 0.72 (Medium)

Current Debt Estimate: 14 hours
```

**4. CORTEX 4.0 Recommendations:**
```markdown
1. **Improve Testing Coverage** (HIGH Priority)
   Expected Impact: +5% overall health
   
2. **Complete Documentation** (MEDIUM Priority)
   Expected Impact: +3% overall health
   
3. **Optimize Benchmarks** (LOW Priority)
   Expected Impact: +2% overall health
```

**Understanding Check:**
- ‚úÖ Is the system improving or degrading?
- ‚úÖ What's the debt estimate in hours?
- ‚úÖ What's the highest priority recommendation?

---

### Hands-On Exercise 5.3: Track Evolution Over Time

**Task:** Run multiple reviews to build historical data

**Workflow:**
```
Week 1: review architecture (baseline)
Week 2: review architecture (after improvements)
Week 3: review architecture (validate trend)
```

**Expected Progression:**
```
Week 1: 78% (Warning) - Baseline established
Week 2: 80% (Warning) - +2% improvement, velocity detected
Week 3: 82% (Warning) - +4% total, trend confirmed
```

**Commands to Check Trends:**
```
track architecture evolution
```

**Expected Output:**
```
Architecture Evolution Report

Historical Snapshots: 3
Date Range: 2025-11-20 to 2025-11-27 (7 days)

Health Progression:
- Week 1: 78% (Baseline)
- Week 2: 80% (+2%)
- Week 3: 82% (+2%)

Trend Metrics:
- Average Velocity: +2.0% per week
- Direction: Improving ‚ÜóÔ∏è
- Volatility: 1.2 (Low - very consistent)

Insights:
‚úÖ Consistent improvement maintained
‚úÖ Low volatility indicates stable development practices
‚úÖ On track to reach 85% (Warning ‚Üí Healthy boundary) in 2 weeks
```

**Understanding Check:**
- ‚úÖ What's the average velocity?
- ‚úÖ Is the trend improving or degrading?
- ‚úÖ When will system reach 85% if trend continues?

---

### Hands-On Exercise 5.4: Use Forecasts for Sprint Planning

**Task:** Plan remediation work based on debt forecast

**Scenario:**
Your architecture review shows:
- Current health: 78%
- Target: 90% (Healthy threshold)
- Debt estimate: 14 hours
- Sprint capacity: 2 hours/sprint for technical debt

**Commands to Try:**
```
forecast technical debt
```

**Expected Output:**
```
Technical Debt Forecast

Current State:
- Health: 78%
- Gap to Healthy (90%): 12%
- Estimated Work: 14 hours

3-Month Projection (Doing Nothing):
- Predicted Health: 81% (natural drift)
- Confidence: 0.88
- Still in Warning zone

3-Month Projection (With Remediation):
- Add 14 hours work over 7 sprints (2h per sprint)
- Predicted Health: 91% (Healthy threshold!)
- Confidence: 0.92

Sprint Plan Recommendation:
- Sprint 1-2: Address 5 testing gaps (4h)
- Sprint 3-4: Complete 3 documentation items (6h)
- Sprint 5-6: Optimize 1 performance benchmark (4h)
- Sprint 7: Validation and contingency

Expected Outcome: Healthy status in 7 sprints (14 weeks)
```

**Create Sprint Plan:**
```
Sprint 1 (This Week):
‚òê Add tests for AuthenticationService (2h)

Sprint 2 (Next Week):
‚òê Add tests for PaymentProcessor (2h)

Sprint 3:
‚òê Write architecture-guide.md for API module (2h)

... (continue for remaining sprints)
```

**Understanding Check:**
- ‚úÖ How many sprints to reach Healthy threshold?
- ‚úÖ What's the first remediation task?
- ‚úÖ Can you explain the confidence scores?

---

### Hands-On Exercise 5.5: Compare Strategic vs Tactical Analysis

**Task:** Understand difference between Architecture Intelligence and System Alignment

**Run Both:**
```
# Strategic (RIGHT BRAIN)
review architecture

# Tactical (LEFT BRAIN)
align report
```

**Compare Outputs:**

**Architecture Intelligence (Strategic):**
```
Focus: Where are we going?
Output:
- Trend analysis (velocity, direction, volatility)
- Debt forecasting (3-month, 6-month projections)
- ADR recommendations (prioritized improvements)
- Historical tracking (evolution over time)

Use Cases:
- Sprint planning (allocate technical debt time)
- Quarterly goals (set health targets)
- Team retrospectives (measure improvement)
- Leadership reporting (communicate architecture health)
```

**System Alignment (Tactical):**
```
Focus: What's broken right now?
Output:
- 7-layer integration validation
- Auto-remediation templates (wiring, tests, docs)
- Convention-based feature discovery
- Deployment readiness checks

Use Cases:
- Pre-deployment validation (block if <80% health)
- New feature validation (ensure fully wired)
- Template generation (auto-fix specific issues)
- CI/CD integration (automated quality gates)
```

**Understanding Check:**
- ‚úÖ When would you use Architecture Intelligence vs System Alignment?
- ‚úÖ Can they work together? How?
- ‚úÖ Which one tells you "what to fix"? Which tells you "how to fix it"?

---

### Module 5 Completion Checklist

**You've mastered Architecture Intelligence when you can:**

‚úÖ **Run architecture review** and interpret health scores  
‚úÖ **Understand layer breakdown** (Discovery ‚Üí Optimization)  
‚úÖ **Read trend analysis** (velocity, direction, volatility)  
‚úÖ **Use debt forecasts** for sprint planning  
‚úÖ **Track evolution** over multiple reviews  
‚úÖ **Apply ADR recommendations** to improve health  
‚úÖ **Distinguish strategic vs tactical** analysis  
‚úÖ **Combine both approaches** for comprehensive validation  

---

## üìñ Reference Commands

### Quick Command Reference

| Command | Purpose | Duration |
|---------|---------|----------|
| `help` | Show all commands | <1s |
| `plan [feature]` | Start planning | 3-5 min |
| `start tdd` | Begin TDD workflow | <1s |
| `discover views` | Find element IDs | <5 min |
| `run tests` | Execute tests | 1-5s |
| `suggest refactorings` | Get optimization ideas | <1s |
| `validate lint` | Check code quality | <1s |
| `complete session` | Generate report | <1s |
| `git checkpoint` | Save work | <1s |
| `feedback` | Share metrics | <1s |
| `review architecture` | Architecture health analysis | 1-2s |
| `track architecture evolution` | Historical trend tracking | <1s |
| `forecast technical debt` | 3/6-month projections | <1s |

---

## üêõ Troubleshooting

### Common Issues

**Issue: "Plan approval failed - DoR incomplete"**
- **Cause:** Vague answers to clarifying questions
- **Fix:** Be specific with measurable criteria
- **Example:** "faster" ‚Üí "response time < 500ms"

**Issue: "Tests not found"**
- **Cause:** Test file location not detected
- **Fix:** Ensure tests in correct directory (e.g., `tests/`)
- **Check:** `discover views` before test generation

**Issue: "View discovery returned 0 elements"**
- **Cause:** File path incorrect or file type not supported
- **Fix:** Check file exists, verify .razor/.cshtml extension
- **Supported:** Razor, Blazor, React, Vue, HTML

**Issue: "Refactoring suggestions not showing"**
- **Cause:** No performance data captured
- **Fix:** Run tests first to capture timing data
- **Note:** GREEN state required for refactoring

---

## üí° Pro Tips

### Efficiency Tips

1. **Use Natural Language**
   - ‚úÖ "plan authentication feature"
   - ‚ùå `/plan --feature auth --type security`

2. **Let CORTEX Discover**
   - ‚úÖ `discover views` before writing tests
   - ‚ùå Manually inspect HTML for IDs

3. **Trust the RED State**
   - ‚úÖ Let tests fail first (RED)
   - ‚ùå Don't implement before tests exist

4. **Review Refactoring Suggestions**
   - ‚úÖ Consider performance impact
   - ‚ùå Don't blindly apply all suggestions

5. **Create Checkpoints Often**
   - ‚úÖ After each GREEN state
   - ‚ùå Wait until end of day

---

## üéØ Success Criteria

### Tutorial Complete When You Can:

‚úÖ **Plan a feature** with zero ambiguity (DoR complete)  
‚úÖ **Start TDD workflow** and understand RED/GREEN/REFACTOR  
‚úÖ **Use view discovery** to auto-extract element IDs  
‚úÖ **Generate tests** that use real element selectors  
‚úÖ **Run tests** and interpret results  
‚úÖ **Implement features** to pass tests (GREEN state)  
‚úÖ **Apply refactorings** based on performance data  
‚úÖ **Complete sessions** with comprehensive reports  
‚úÖ **Share feedback** with team via GitHub Gist  
‚úÖ **Run architecture reviews** and interpret health metrics  
‚úÖ **Track architecture evolution** over time  
‚úÖ **Use debt forecasts** for sprint planning  
‚úÖ **Apply strategic and tactical analysis** together  

---

**Tutorial Version:** 2.0 (Added Module 5: Architecture Intelligence)  
**Last Updated:** November 27, 2025  
**Author:** Asif Hussain  
**Copyright:** ¬© 2024-2025 Asif Hussain. All rights reserved.  
**License:** Source-Available (Use Allowed, No Contributions)
