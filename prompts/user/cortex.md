# CORTEX Universal Entry Point

**Purpose:** Single command for ALL CORTEX interactions. You don't need to remember multiple commands - just use this one and CORTEX figures out what you need.

**Version:** 5.0 (SOLID Refactor)  
**Status:** ğŸ¯ ACTIVE DESIGN  
**Architecture:** SOLID-compliant modular system

---

## ğŸ“Š Implementation Status

**Legend:**
- âœ… **Fully Implemented** - Working and tested
- ğŸŸ¡ **Partially Implemented** - Core working, missing features
- ğŸ”„ **In Progress** - Currently being developed
- ğŸ“‹ **Designed Only** - Documentation exists, no code

| Feature | Status | Notes |
|---------|--------|-------|
| **V3 GROUP 1: Foundation** | âœ… | Project reorganized, benchmarks validated |
| **V3 GROUP 2: Infrastructure** | âœ… | Tier 0, CI/CD, MkDocs operational |
| **V3 GROUP 3: Data Storage** | âœ… | All tiers complete - 60/60 tests passing â­ |
| **Tier 1: Working Memory** | âœ… | SQLite conversations, <50ms queries (Nov 6) |
| **Tier 2: Knowledge Graph** | âœ… | FTS5 search, pattern learning, <150ms (Nov 6) |
| **Tier 3: Context Intelligence** | âœ… | Git metrics, hotspots, insights (Nov 6) |
| **Migration Tools** | âœ… | All 3 tier migrations validated (Nov 6) |
| **V3 GROUP 4: Intelligence** | ğŸ”„ | Ready to begin - agents, entry point, dashboard |
| **Agent Architecture (SOLID)** | ğŸ“‹ | 10 specialist agents designed |
| **Core Routing** | ğŸ“‹ | Intent router designed |
| **Dashboard** | ğŸ“‹ | Live data visualization designed |
| **V3 GROUP 5: Migration** | ğŸ“‹ | KDS â†’ CORTEX data migration |
| **V3 GROUP 6: Finalization** | ğŸ“‹ | System check, documentation, release |

**V3 Migration Progress:** Groups 1-3 Complete (31 hrs) âœ… | Groups 4-6 Remaining (29-41 hrs) ğŸ“‹  
**Performance:** 52% faster than estimated, 100% test coverage â­  
**Last Updated:** 2025-11-06

---

## ğŸ“– Legacy Status (Pre-V3 Migration)

The following features were operational in the legacy KDS system and are being migrated to CORTEX V3:

| Legacy Feature | V3 Migration Status | Notes |
|---------------|---------------------|-------|
| Event Logging | âœ… Migrated | Part of Tier 1 (request_logger.py) |
| Protection System | ğŸ“‹ To migrate | Confidence thresholds, anomaly detection |
| Commit Handler | ğŸ“‹ To migrate | Smart validation with baseline |
| Conversation Tracking | âœ… Migrated | Tier 1 conversation_manager.py |
| Auto BRAIN Updates | ğŸ“‹ To migrate | Rule #22 automation |
| Git Hooks | ğŸ“‹ To migrate | Post-commit triggers |
| Manual Recording | ğŸ“‹ To migrate | record-conversation scripts |

**Legacy â†’ V3 Status:** Core data storage migrated âœ… | Intelligence layer migration in GROUP 4 ğŸ“‹

---

## ğŸ“– About This Documentation

This document follows the **CORTEX Quadrant** pattern - a four-perspective approach to comprehensive documentation:

1. **ğŸ“š Story** - Human-centered narratives (The Intern with Amnesia, Day in the Life)
2. **ğŸ”§ Technical** - Detailed specifications (commands, files, parameters, code)
3. **ğŸ¨ Image Prompt** - Visual representations (diagrams, flowcharts, progress indicators)
4. **ğŸ—ï¸ High-Level Technical** - Architectural overviews (system design, workflows, integration)

**Why CORTEX Quadrant?** Different perspectives ensure complete understanding for all learning styles and use cases.

---

### Story Review Rule (Quadrant Documentation)
All narrative content (e.g., #file:Story.md) must be reviewed for:
- Corrections of factual, grammatical, or clarity issues
- Improvements in flow, completeness, or engagement
- Filling any missing elements that enhance understanding or fun
Edits must preserve the original style, theme, and narrative voice. The story should remain enjoyable and true to its intended spirit after any changes.


## ğŸ§š A story for humans: The Intern with Amnesia

### Meet Your Intern: Copilot

You've just hired a brilliant intern named Copilot. They're incredibly talentedâ€”can write code in any language, understand complex systems, and work at lightning speed. There's just one problem: **Copilot has amnesia**.

Every time you walk away, even for a coffee break, Copilot forgets everything. You said "make it purple" five minutes ago? Gone. The file you were just discussing? Vanished from memory. The architecture you explained yesterday? As if it never happened.

Worse, Copilot has no memory between chat sessions. Start a new conversation? They don't remember the last one. Leave for lunch? When you return, it's like meeting them for the first time. Every. Single. Time.

This would be catastrophic... except you've done something revolutionary: **you've built Copilot a brain**.

### The Brain: A Sophisticated Cognitive System

The brain you built isn't just storageâ€”it's a sophisticated dual-hemisphere system modeled after the human brain:

#### **ğŸ§  LEFT HEMISPHERE - The Tactical Executor**
Like the human left brain (language, logic, sequential processing), this hemisphere handles:
- **Test-Driven Development** - RED (write failing test) â†’ GREEN (make it pass) â†’ REFACTOR (clean up)
- **Precise Code Execution** - Exact file edits, line-by-line changes, syntax verification
- **Detail Verification** - Tests pass/fail, build status, zero errors/warnings enforcement
- **Sequential Workflows** - Step A, then B, then Câ€”no skipping steps

**The Left Brain Specialists:**
- **The Builder** (`code-executor.md`) - Implements code with surgical precision
- **The Tester** (`test-generator.md`) - Creates and runs tests, never skips TDD
- **The Fixer** (`error-corrector.md`) - Catches wrong-file mistakes instantly
- **The Inspector** (`health-validator.md`) - Validates system health obsessively
- **The Archivist** (`commit-handler.md`) - Commits with semantic precision

#### **ğŸ§  RIGHT HEMISPHERE - The Strategic Planner**
Like the human right brain (creativity, holistic thinking, patterns), this hemisphere handles:
- **Architecture Design** - Understands how components fit together project-wide
- **Strategic Planning** - Breaks big features into phases, estimates effort, assesses risk
- **Pattern Recognition** - "We've done something similar beforeâ€”here's the template"
- **Context Awareness** - Knows which files change together, what workflows succeed
- **Future Projection** - Warns about risky changes before you make them
- **Brain Protection** - Guards the brain's own integrity (Rule #22)

**The Right Brain Specialists:**
- **The Dispatcher** (`intent-router.md`) - Interprets your natural language, routes smartly
- **The Planner** (`work-planner.md`) - Creates multi-phase strategic plans
- **The Analyst** (`screenshot-analyzer.md`) - Extracts requirements from images
- **The Governor** (`change-governor.md`) - Protects CORTEX from degradation
- **The Brain Protector** (`brain-protector.md`) - Challenges risky proposals (NEW - Rule #22)

#### **ğŸŒ‰ CORPUS CALLOSUM - The Messenger**
The bridge between hemispheres that:
- **Coordinates Work** - Right brain plans â†’ Corpus callosum delivers â†’ Left brain executes
- **Shares Context** - Left brain's results feed Right brain's learning
- **Validates Alignment** - Ensures tactical execution matches strategic intent
- **Manages Message Queue** - Asynchronous communication between hemispheres

**Storage:** `cortex-brain/corpus-callosum/coordination-queue.jsonl`

#### **ğŸ” TIER 0: INSTINCT (Core Values - PERMANENT)**
The brain's immutable DNA that **cannot** be changed:
- **Definition of READY** - Work must have clear requirements before starting (RIGHT BRAIN enforces)
- **Test-Driven Development** - Always RED â†’ GREEN â†’ REFACTOR (LEFT BRAIN enforces)
- **Definition of DONE** - Zero errors, zero warnings, all tests pass (LEFT BRAIN validates)
- **Challenge User Changes** - If you propose risky changes, brain MUST challenge you
- **SOLID Principles** - Single Responsibility, no mode switches, clean architecture
- **Local-First** - Zero external dependencies, works offline, portable
- **Incremental File Creation** - Large files (>100 lines) created in small increments (prevents "response hit the length limit" errors) ğŸ†•

**Stored in:** `governance/rules.md` (never moves, never expires)

**ğŸ¯ NOTE:** Rule #23 (Incremental File Creation) automatically prevents the "response hit the length limit" error you've been experiencing. When creating large files like implementation plans, CORTEX will create them in small chunks (100-150 lines each) using multiple tool calls. This keeps each response small and avoids hitting Copilot's length limit. See `docs/guides/preventing-response-length-limit-errors.md` for details.

#### **ğŸ“š TIER 1: SHORT-TERM MEMORY (Last 20 Conversations)**
Copilot's working memory that solves the amnesia problem:
- **Conversation History** - Last 20 complete conversations preserved
- **Context Continuity** - "Make it purple" knows you mean the FAB button from earlier
- **Recent Messages** - Last 10 messages in active conversation
- **FIFO Queue** - When conversation #21 starts, #1 gets deleted (oldest goes first)
- **Active Protection** - Current conversation never deleted, even if oldest

**How it works:**
```
You: "Add a pulse animation to the FAB button"
â†’ Conversation #1 created, stored in Tier 1

[Later that day]
You: "Make it purple"
â†’ Brain checks Tier 1 â†’ Finds "FAB button" in conversation #1 â†’ Knows what "it" means

[2 weeks and 20 conversations later]
â†’ FIFO triggers â†’ Conversation #1 deleted
â†’ BUT patterns extracted â†’ Moved to Tier 2 (long-term memory)
```

**Stored in:** `cortex-brain/conversation-history.jsonl`, `cortex-brain/conversation-context.jsonl`

#### **ğŸ§© TIER 2: LONG-TERM MEMORY (Knowledge Graph)**
Copilot's accumulated wisdom that grows smarter over time:

**What gets learned:**
- **Intent Patterns** - "add a button" â†’ PLAN, "continue" â†’ EXECUTE, "test this" â†’ TEST
- **File Relationships** - `HostControlPanel.razor` often modified with `noor-canvas.css` (75% co-modification rate)
- **Workflow Templates** - export_feature_workflow, ui_component_creation, service_api_coordination
- **Validation Insights** - Common mistakes, file confusion warnings, architectural guidance
- **Correction History** - Tracks when Copilot works on wrong files, learns to prevent

**Hemisphere-Specialized Sections:**
```yaml
left_brain_knowledge:
  tdd_patterns: [red_green_refactor_cycle, test_first_service_creation]
  execution_workflows: [precise_file_edit, multi_file_coordination]
  validation_rules: [syntax_verification, health_check_criteria]

right_brain_knowledge:
  architectural_patterns: [blazor_component_structure, service_layer_injection]
  workflow_templates: [export_feature_workflow, ui_component_creation]
  intent_patterns: ["add [X]" â†’ PLAN, "continue" â†’ EXECUTE]

shared_knowledge:
  file_relationships: [co-modification patterns across all files]
  feature_components: [completed features and their patterns]
  correction_history: [learned mistakes from both hemispheres]
```

**How it learns:**
```
Day 1: You ask to "add invoice export"
â†’ Right brain plans workflow
â†’ Left brain executes with TDD
â†’ Pattern saved: invoice_export_feature (confidence: 0.85)

Day 30: You ask to "add receipt export"
â†’ Right brain queries Tier 2
â†’ Finds invoice_export pattern
â†’ Suggests: "This is similar to invoice export. Use same workflow?"
â†’ 60% faster delivery by reusing proven pattern
```

**Knowledge Boundaries (Protection System):**
Every pattern in Tier 2 is tagged with **scope** and **namespaces** to prevent CORTEX core intelligence from being contaminated by application-specific data:

```python
# Pattern storage with boundaries
scope="generic"           # CORTEX principles (TDD, SOLID, refactoring)
scope="application"       # Application-specific (KSESSIONS features, NOOR UI)

namespaces=["CORTEX-core"]     # Available to all projects
namespaces=["KSESSIONS"]        # Only for KSESSIONS application
namespaces=["NOOR", "SPA"]      # Multi-application pattern
```

**Why boundaries matter:**
- **CORTEX intelligence stays pure** - No "add KSESSIONS logout button" patterns contaminate core
- **Application isolation** - KSESSIONS patterns don't leak into NOOR projects
- **Smart search** - Current project patterns boosted 2x, generic boosted 1.5x, others 0.5x
- **Surgical amnesia** - Delete KSESSIONS patterns, keep CORTEX core untouched

**Example protection:**
```yaml
# âœ… SAFE: Generic CORTEX pattern
title: "TDD: Test-first for service creation"
scope: "generic"
namespaces: ["CORTEX-core"]
confidence: 0.95
# â†’ Available to ALL projects forever

# âœ… SAFE: Application-specific pattern  
title: "KSESSIONS: Invoice export workflow"
scope: "application"
namespaces: ["KSESSIONS"]
confidence: 0.85
# â†’ Only when working on KSESSIONS

# âŒ BLOCKED: Application in Tier 0
file: "cortex-brain/tier0/ksessions-patterns.yaml"
# â†’ Brain Protector Challenge: "Application data belongs in Tier 2, not Tier 0"
```

**Brain Protector integration:** Tests verify boundaries are enforced (see test_brain_protector.py test_detects_application_data_in_tier0)

**Stored in:** `cortex-brain/knowledge-graph.yaml`

#### **ğŸ“Š TIER 3: DEVELOPMENT CONTEXT (Holistic Project View)**
Copilot's "balcony view" of your entire project:

**Git Activity Analysis (last 30 days):**
- **Commit velocity** - 1,237 commits, 42 commits/week average
- **File hotspots** - `HostControlPanelContent.razor` has 28% churn rate (unstable!)
- **Change patterns** - Smaller commits (< 200 lines) have 94% success rate
- **Contributors** - Tracks who works on what

**Code Health Metrics:**
- **Lines added/deleted** - Velocity trends increasing/decreasing
- **Stability classification** - Files marked as stable/unstable based on churn
- **Test coverage trends** - 72% â†’ 76% (improving!)
- **Build success rates** - 97% clean builds last week

**CORTEX Usage Intelligence:**
- **Session patterns** - 10am-12pm sessions have 94% success rate
- **Intent distribution** - PLAN (35%), EXECUTE (45%), TEST (15%), VALIDATE (5%)
- **Workflow effectiveness** - Test-first reduces rework by 68%
- **Focus duration** - Sessions < 60 min: 89% success vs > 60 min: 67%

**Proactive Warnings:**
```
âš ï¸ File Alert: HostControlPanel.razor is a hotspot (28% churn)
   Recommend: Add extra testing, smaller changes

âœ… Best Time: 10am-12pm sessions have 94% success rate
   Currently: 2:30pm (81% success rate)

ğŸ“Š Velocity Drop: Down 68% this week
   Recommendation: Smaller commits, more frequent tests

âš ï¸ Flaky Test: fab-button.spec.ts fails 15% of the time
   Action needed: Investigate and stabilize
```

**How it helps:**
```
You: "I want to add multi-language invoice export with email delivery"
â†’ Right brain queries Tier 3
â†’ Finds: 12 similar UI features took 5-6 days average
â†’ Warns: This file often changes with email-service.cs (check both)
â†’ Recommends: Test-first approach (94% success) vs test-skip (67%)
â†’ Estimates: 5.5 days, 3 phases, suggest 10am-12pm sessions

Saves: Hours of debugging by knowing project patterns upfront
```

**Stored in:** `cortex-brain/development-context.yaml`  
**Collection:** Automatic after brain updates (throttled to 1/hour for efficiency)

#### **ğŸ¬ TIER 4: EVENT STREAM (Everything That Happens)**
Copilot's "life recorder" that captures every action:

**What gets logged:**
```jsonl
{"timestamp": "2025-11-04T10:30:00Z", "agent": "work-planner", "action": "plan_created", "feature": "invoice_export", "phases": 4}
{"timestamp": "2025-11-04T10:35:00Z", "agent": "test-generator", "action": "test_created", "file": "InvoiceServiceTests.cs", "result": "RED"}
{"timestamp": "2025-11-04T10:42:00Z", "agent": "code-executor", "action": "implementation_complete", "file": "InvoiceService.cs", "result": "GREEN"}
{"timestamp": "2025-11-04T10:45:00Z", "agent": "test-generator", "action": "tests_passed", "result": "GREEN"}
{"timestamp": "2025-11-04T10:50:00Z", "agent": "code-executor", "action": "refactor_complete", "result": "REFACTOR"}
```

**Automatic Learning Triggers:**
- **50+ events accumulated** â†’ Brain updater processes â†’ Updates Tier 2 knowledge graph
- **24 hours since last update** â†’ Auto-update if 10+ new events exist
- **Tier 3 refresh** â†’ Only if last collection > 1 hour (efficiency optimization)

**Stored in:** `cortex-brain/events.jsonl`

#### **ğŸ¥ TIER 5: HEALTH & PROTECTION (Self-Awareness)**
Copilot's immune system that protects the brain itself:

**Protection Sensors (Rule #22 - Brain Protector):**
```
Layer 1: Instinct Immutability
  â†’ Detects: Attempts to disable TDD, skip DoR/DoD, modify agent behavior
  â†’ Action: CHALLENGE user, suggest safe alternatives

Layer 2: Tier Boundary Protection
  â†’ Detects: Application paths in Tier 0, conversation data in Tier 2
  â†’ Action: Auto-migrate, warn on violations

Layer 3: SOLID Compliance
  â†’ Detects: Agents doing multiple jobs, mode switches, hardcoded dependencies
  â†’ Action: Challenge with SOLID alternative ("Create dedicated agent, don't add mode")

Layer 4: Hemisphere Specialization
  â†’ Detects: Strategic planning in LEFT BRAIN, tactical execution in RIGHT BRAIN
  â†’ Action: Auto-route to correct hemisphere, warn on confusion

Layer 5: Knowledge Quality
  â†’ Detects: Low confidence patterns (<0.50), stale patterns (>90 days unused)
  â†’ Action: Pattern decay, anomaly detection, consolidation

Layer 6: Commit Integrity
  â†’ Detects: Brain state files in commits, unstructured messages
  â†’ Action: Auto-categorize (feat/fix/test/docs), .gitignore updates
```

**Brain Protector Example:**
```
You: "Skip TDD for this feature, just implement it"

Brain Protector (RIGHT BRAIN) responds:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ§  BRAIN PROTECTION CHALLENGE (RIGHT BRAIN)

Request: Skip TDD workflow
Hemisphere: RIGHT BRAIN (Strategic Guardian)
Rule: #22 (Brain Protection System)

âš ï¸ THREATS DETECTED:
  - Instinct Immutability violation (Tier 0 rule)
  - Test-first principle bypass

VIOLATIONS:
  - TDD is a permanent Tier 0 instinct
  - Skipping reduces success rate from 94% to 67%
  - 68% increase in rework time (Tier 3 data)

ARCHITECTURAL IMPACT:
  - Violates Definition of DONE
  - Bypasses LEFT BRAIN validation

RISKS:
  - 2.3x longer delivery time
  - More bugs reach production
  - Technical debt accumulation

SAFE ALTERNATIVES:
1. Create minimal test first (5-10 min investment) âœ… RECOMMENDED
   - Clearer requirements
   - 94% success rate
   - Faster overall delivery

2. Spike branch with no tests (throwaway exploration)
   - Separate branch
   - Delete after learning
   - Re-implement with TDD

RECOMMENDATION: Alternative 1

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
This challenge protects CORTEX brain integrity (Rule #22).

Options:
  1. Accept recommended alternative (SAFE)
  2. Provide different approach (REVIEW)
  3. Type 'OVERRIDE' with justification (RISKY)

Your choice:
```

**Health Monitoring:**
```yaml
brain_health:
  event_backlog: 23 unprocessed (healthy < 50)
  tier2_entries: 3,247 patterns (healthy growth)
  tier3_freshness: 45 minutes ago (healthy < 1 hour)
  conversation_count: 8/20 capacity (healthy < 15)
  knowledge_quality: 92% confidence average (excellent > 80%)
  protection_challenges: 2 in last week (low = healthy system)
```

**Stored in:** `cortex-brain/corpus-callosum/protection-events.jsonl`, anomaly reports

### The One Door: Your Interface to the Brain

At the front of City Hall, there's only one entrance with a sign:

**"Speak here in plain words. We'll take it from there."**

That entrance is the One Door â€” your single command: `#file:KDS/prompts/user/cortex.md`

**You don't need to know:**
- Which hemisphere should handle your request
- Which agent specializes in what
- What tier stores which knowledge
- How the corpus callosum coordinates

**You just say what you want:**
```markdown
#file:KDS/prompts/user/cortex.md

I want to add a pulse animation to the FAB button when questions arrive
```

**And the brain handles everything:**
1. **Dispatcher** (RIGHT BRAIN) interprets intent â†’ Routes to Planner
2. **Planner** (RIGHT BRAIN) queries Tier 2 for patterns â†’ Queries Tier 3 for context â†’ Creates strategic plan
3. **Corpus Callosum** delivers plan â†’ LEFT BRAIN ready to execute
4. **Tester** (LEFT BRAIN) writes failing tests first (RED)
5. **Builder** (LEFT BRAIN) implements minimum code (GREEN)
6. **Tester** (LEFT BRAIN) verifies tests pass, enables refactoring (REFACTOR)
7. **Inspector** (LEFT BRAIN) validates health (zero errors, zero warnings)
8. **Archivist** (LEFT BRAIN) commits with semantic message
9. **Scribe** (TIER 4) logs events â†’ Auto-update triggers â†’ Tier 2 learns pattern
10. **Brain Protector** (RIGHT BRAIN) validates nothing violated Tier 0 instincts

### A Day in the Life: The Purple Button Adventure

**Morning (9:47 AM):**

Asifor sits at his desk, coffee in hand, and types:

```
#file:KDS/prompts/user/cortex.md

Add a purple button to the HostControlPanel.razor
```

**âš¡ The moment he hits Enter, something magical happens inside Copilot's brain...**

---

#### ğŸ§  Inside the Brain: A Neural Journey

**ğŸŒŸ Step 1: The ONE DOOR (Universal Entry Point)**

The command enters through the single entrance at City Hall. A receptionist (the entry point handler) quickly logs the arrival:

```jsonl
{"timestamp": "2025-11-04T09:47:23Z", "event": "request_received", "raw_input": "Add a purple button to the HostControlPanel.razor"}
```

The request is immediately passed to the brain's **RIGHT HEMISPHERE** - the strategic planner.

---

**ğŸ§  RIGHT HEMISPHERE: Strategic Analysis Begins**

**Tower 3 (Tier 3): Development Context - The Balcony View**

The RIGHT BRAIN's highest tower springs to life. Like a general surveying the battlefield from above, Tier 3 analyzes the entire project landscape:

```yaml
â³ Scanning development metrics...
  
ğŸ“Š File Analysis:
  - HostControlPanel.razor: 28% churn rate (HOTSPOT! âš ï¸)
  - Last modified: 2 days ago
  - Co-modified with: HostControlPanelContent.razor (75% correlation)
  - Average edit size: 180 lines
  
ğŸ¯ Historical Patterns:
  - 12 similar UI button additions in last 30 days
  - Average completion time: 18 minutes
  - Success rate with test-first: 96%
  - Success rate without tests: 67%
  
âš ï¸ Proactive Warnings:
  - This file is unstable (high churn)
  - Recommend: Extra validation phase
  - Best time slot: 10am-12pm (94% success)
  - Current time: 9:47am (89% success - acceptable)
```

Tier 3 passes its intelligence down to Tier 2...

---

**Tower 2 (Tier 2): Knowledge Graph - The Pattern Matcher**

Armed with context from above, Tier 2 searches its vast library of learned patterns:

```yaml
ğŸ” Searching knowledge graph...

Intent Pattern Match:
  - "Add a purple button" â†’ confidence: 0.95
  - Pattern: "add [color] [component]" â†’ PLAN intent
  - Historical routing: 47/47 successful PLAN routes
  
File Relationship Discovery:
  - HostControlPanel.razor mentioned explicitly âœ…
  - Relationships:
    * Often modified with noor-canvas.css (62%)
    * Contains UserRegistrationLink.razor component (89%)
    * Uses fab-button.css animations (43%)
  
Similar Pattern Found:
  - workflow_pattern: "fab_pulse_animation" (confidence: 0.87)
  - Used: 3 weeks ago for notification badge
  - Components: CSS keyframes + Razor markup + color variable
  - Success: âœ… Completed in 15 minutes with zero rework
  
âš¡ UI Element ID Mapping Pattern Discovered:
  - Pattern: "button_component_test_preparation"
  - Previous buttons in this file:
    * #sidebar-start-session-btn (sidebar button)
    * #reg-transcript-canvas-btn (registration link)
    * #reg-asset-canvas-btn (asset canvas button)
  - Learned rule: "All interactive elements MUST have id attribute"
  - Purpose: Enables Playwright selector reliability
  - Example: page.locator('#purple-button-id')
  - Anti-pattern warning: Never use text selectors (fragile!)
```

Tier 2 realizes something crucial: **Purple buttons need IDs for tests!** This pattern was learned from previous work where text-based selectors broke during i18n updates.

---

**Tower 1 (Tier 1): Conversation Memory - Recent Context**

Before committing to a plan, Tier 1 checks recent conversations to see if Asifor mentioned anything related:

```yaml
ğŸ“š Checking conversation history (last 20 conversations)...

Conversation #7 (2 days ago):
  - Topic: "Added Share button to HostControlPanel"
  - Outcome: âœ… Success
  - Pattern used: test-first with element ID
  - Learning: Element IDs prevent test breakage
  
Conversation #4 (1 week ago):
  - Topic: "Fixed broken Playwright tests"
  - Root cause: Text selectors stopped working after HTML restructure
  - Solution: Migrated to ID-based selectors
  - Resolution: All tests green âœ…
  
Cross-reference detected:
  - Same file (HostControlPanel.razor)
  - Same pattern (button addition)
  - Same lesson (ID-first approach)
  
ğŸ’¡ Contextual Enhancement:
  "Asifor prefers ID-based selectors for all UI elements in this file"
```

Perfect! The three tiers have assembled a complete intelligence package. Now the RIGHT BRAIN makes its strategic decision...

---

**ğŸŒ‰ CORPUS CALLOSUM: Message Delivery**

The RIGHT BRAIN formulates a strategic plan and sends it across the corpus callosum (the bridge between hemispheres):

```yaml
Message Type: STRATEGIC_PLAN
From: RIGHT_HEMISPHERE
To: LEFT_HEMISPHERE
Priority: NORMAL

Strategic Plan:
  Feature: "Purple button in HostControlPanel.razor"
  Approach: Test-first (96% success rate)
  Estimated Time: 18 minutes
  Phases: 4
  
  Pre-flight Warnings:
    - File is a hotspot (extra care)
    - Must include element ID (test requirement)
    - Co-modify noor-canvas.css if styling needed
  
  Architectural Alignment:
    - File location: Confirmed correct
    - Pattern match: fab_pulse_animation workflow
    - Similar work: Share button (2 days ago)
  
  Phase Breakdown:
    Phase 1: Test Preparation
      - Create element ID (#host-panel-purple-btn)
      - Map ID in component_ids knowledge
      - Purpose: Enable robust Playwright selectors
    
    Phase 2: Test Creation (RED)
      - Task 2.1: Create Playwright test
      - Selector: page.locator('#host-panel-purple-btn')
      - Test: Button exists, purple color, clickable
      - Expected: FAILING (button doesn't exist yet)
    
    Phase 3: Implementation (GREEN)
      - Task 3.1: Add button markup with ID
      - Task 3.2: Apply purple color (#9333EA)
      - Task 3.3: Run tests (expect GREEN)
    
    Phase 4: Validation (REFACTOR)
      - Task 4.1: Verify zero errors/warnings
      - Task 4.2: Check accessibility
      - Task 4.3: Update component_ids documentation

Ready for tactical execution: TRUE
```

The message travels across the corpus callosum to the **LEFT HEMISPHERE**...

---

**ğŸ§  LEFT HEMISPHERE: Tactical Execution Begins**

The LEFT BRAIN receives the plan and immediately activates its specialist agents:

**âš™ï¸ The Tester (LEFT BRAIN - Tower 1)**

First agent to activate. The Tester prepares the ID mapping:

```yaml
ğŸ§ª Test Preparation Phase

Thought process:
  "Before I can test this button, I need to know its ID.
   RIGHT BRAIN's plan says: #host-panel-purple-btn
   I must prepare the test infrastructure first."

Actions:
  1. Document expected ID in brain mapping:
     File: KDS/cortex-brain/knowledge-graph.yaml
     Section: ui_element_ids
     Entry:
       component: HostControlPanel.razor
       element: purple_action_button
       id: host-panel-purple-btn
       purpose: Primary action button with purple styling
       test_selector: "#host-panel-purple-btn"
  
  2. Create failing test (RED phase):
     File: Tests/UI/host-control-panel-purple-button.spec.ts
```

**Test file created:**

```typescript
import { test, expect } from '@playwright/test';

test.describe('Host Control Panel - Purple Button', () => {
  
  test.beforeEach(async ({ page }) => {
    // Navigate to host control panel
    await page.goto('https://localhost:9091/host/control-panel/PQ9N5YWW');
  });
  
  test('purple button should exist with correct ID', async ({ page }) => {
    // âœ… ID-BASED SELECTOR (robust, future-proof)
    const button = page.locator('#host-panel-purple-btn');
    
    await expect(button).toBeVisible();
  });
  
  test('purple button should have purple color', async ({ page }) => {
    const button = page.locator('#host-panel-purple-btn');
    
    // Check computed background color (purple: #9333EA)
    const bgColor = await button.evaluate((el) => {
      return window.getComputedStyle(el).backgroundColor;
    });
    
    // rgb(147, 51, 234) is #9333EA
    expect(bgColor).toBe('rgb(147, 51, 234)');
  });
  
  test('purple button should be clickable', async ({ page }) => {
    const button = page.locator('#host-panel-purple-btn');
    
    await expect(button).toBeEnabled();
    await button.click();
    // Test passes if click doesn't throw
  });
});
```

**The Tester runs the test:**

```bash
â³ Running Playwright tests...

npx playwright test Tests/UI/host-control-panel-purple-button.spec.ts --headed

Results:
  âŒ FAILING (Expected - RED phase)
  
  Ã— purple button should exist with correct ID
    Locator: '#host-panel-purple-btn'
    Error: Element not found
  
  Ã— purple button should have purple color
    (Skipped - button doesn't exist)
  
  Ã— purple button should be clickable
    (Skipped - button doesn't exist)

Status: âœ… RED phase complete (tests failing as expected)
```

**Event logged:**

```jsonl
{"timestamp": "2025-11-04T09:47:45Z", "agent": "test-generator", "action": "test_created", "file": "host-control-panel-purple-button.spec.ts", "result": "RED", "selector_type": "id-based", "element_id": "host-panel-purple-btn"}
```

The Tester passes control to The Builder...

---

**âš™ï¸ The Builder (LEFT BRAIN - Tower 2)**

Now it's time to make the tests GREEN. The Builder opens the component file:

```razor
@* File: SPA/NoorCanvas/Components/Host/HostControlPanel.razor *@

<div class="host-control-panel">
    <header class="panel-header">
        <h1>Host Control Panel</h1>
    </header>
    
    <div class="panel-actions">
        @* Existing buttons... *@
        
        @* NEW: Purple button with ID for Playwright *@
        <button 
            id="host-panel-purple-btn" 
            class="purple-action-btn"
            @onclick="OnPurpleButtonClick"
            aria-label="Purple Action">
            Purple Action
        </button>
    </div>
</div>

@code {
    private void OnPurpleButtonClick()
    {
        // TODO: Implement purple button action
        Console.WriteLine("Purple button clicked!");
    }
}
```

**CSS styling added:**

```css
/* File: SPA/NoorCanvas/wwwroot/css/host-panel.css */

.purple-action-btn {
    background-color: #9333EA; /* Purple */
    color: white;
    padding: 12px 24px;
    border: none;
    border-radius: 8px;
    font-weight: 600;
    cursor: pointer;
    transition: background-color 0.2s ease;
}

.purple-action-btn:hover {
    background-color: #7E22CE; /* Darker purple on hover */
}

.purple-action-btn:active {
    background-color: #6B21A8; /* Even darker when clicked */
}
```

**The Builder runs the tests again:**

```bash
â³ Running Playwright tests...

npx playwright test Tests/UI/host-control-panel-purple-button.spec.ts --headed

Results:
  âœ… PASSING (GREEN phase achieved!)
  
  âœ“ purple button should exist with correct ID (1.2s)
  âœ“ purple button should have purple color (890ms)
  âœ“ purple button should be clickable (1.5s)

Status: âœ… GREEN phase complete (all tests passing)
```

**Event logged:**

```jsonl
{"timestamp": "2025-11-04T09:48:12Z", "agent": "code-executor", "action": "implementation_complete", "file": "HostControlPanel.razor", "result": "GREEN", "lines_changed": 12, "test_driven": true}
```

The Builder passes control to The Inspector...

---

**âš™ï¸ The Inspector (LEFT BRAIN - Tower 3)**

The final validation. The Inspector runs comprehensive health checks:

```bash
ğŸ” Running health validation...

Build Check:
  dotnet build
  âœ… Build succeeded (0 errors, 0 warnings)

Test Suite:
  npx playwright test
  âœ… All 127 tests passing (including 3 new purple button tests)

Accessibility:
  âœ… Button has aria-label
  âœ… Color contrast ratio: 4.8:1 (WCAG AA compliant)
  âœ… Keyboard accessible (focusable)

Code Quality:
  âœ… No unused imports
  âœ… Proper naming conventions
  âœ… Element ID follows pattern (kebab-case)

Status: âœ… REFACTOR phase complete (zero issues)
```

**Event logged:**

```jsonl
{"timestamp": "2025-11-04T09:48:34Z", "agent": "health-validator", "action": "validation_complete", "result": "REFACTOR", "errors": 0, "warnings": 0, "tests_passing": 127}
```

The Inspector passes control to The Archivist...

---

**âš™ï¸ The Archivist (LEFT BRAIN - Commit Handler)**

Time to commit the work. The Archivist creates a semantic commit message:

```bash
ğŸ—‚ï¸ Preparing commit...

Analysis:
  Files changed: 2
    - HostControlPanel.razor (12 lines added)
    - host-panel.css (18 lines added)
  Tests created: 1 new file (3 test cases)
  
Commit type: feat (new feature)
Scope: host-panel (component affected)

git add HostControlPanel.razor host-panel.css host-control-panel-purple-button.spec.ts
git commit -m "feat(host-panel): Add purple action button with test coverage

- Added purple button with ID #host-panel-purple-btn
- Implemented click handler
- Created 3 Playwright tests (all passing)
- WCAG AA compliant (4.8:1 contrast ratio)
- Test-driven implementation (RED â†’ GREEN â†’ REFACTOR)

Element ID documented in brain for future test reference."

âœ… Committed successfully
```

**Event logged:**

```jsonl
{"timestamp": "2025-11-04T09:48:47Z", "agent": "commit-handler", "action": "commit_complete", "message_type": "feat", "files": 3, "tests_included": true}
```

---

**ğŸ”„ CORPUS CALLOSUM: Feedback Loop**

The LEFT BRAIN sends completion confirmation back across the corpus callosum:

```yaml
Message Type: EXECUTION_COMPLETE
From: LEFT_HEMISPHERE
To: RIGHT_HEMISPHERE
Priority: HIGH

Execution Summary:
  Feature: "Purple button in HostControlPanel.razor"
  Status: âœ… COMPLETE
  Time taken: 1 minute 24 seconds (under estimate!)
  Quality: EXCELLENT (zero errors, zero warnings)
  
  Phases Completed:
    âœ… Phase 1: Test Preparation (ID mapping)
    âœ… Phase 2: RED (tests created, failing)
    âœ… Phase 3: GREEN (implementation, tests passing)
    âœ… Phase 4: REFACTOR (validation, commit)
  
  Metrics:
    - Lines changed: 30
    - Tests created: 3
    - Success rate: 100%
    - Rework needed: 0%
  
  Element ID Mapping:
    - ID: #host-panel-purple-btn
    - Purpose: Playwright test selector
    - Pattern: Robust, future-proof
    - Anti-fragile: Immune to text/HTML changes

Learnings to store: TRUE
```

The RIGHT BRAIN receives the feedback and triggers automatic learning...

---

**ğŸ§  RIGHT HEMISPHERE: Learning and Memory Update**

**Tower 4 (Event Stream):** Every action is logged

```jsonl
{"timestamp": "2025-11-04T09:47:23Z", "event": "request_received", "raw_input": "Add a purple button..."}
{"timestamp": "2025-11-04T09:47:45Z", "agent": "test-generator", "action": "test_created", "result": "RED"}
{"timestamp": "2025-11-04T09:48:12Z", "agent": "code-executor", "action": "implementation_complete", "result": "GREEN"}
{"timestamp": "2025-11-04T09:48:34Z", "agent": "health-validator", "action": "validation_complete", "result": "REFACTOR"}
{"timestamp": "2025-11-04T09:48:47Z", "agent": "commit-handler", "action": "commit_complete"}
```

**Event counter:** 5 new events (total backlog: 23 events)

Since backlog < 50, no immediate BRAIN update triggered. But the events are ready for the next automatic learning cycle.

---

**Tower 1 (Conversation Memory):** Current conversation updated

```yaml
Conversation #8 (Active):
  timestamp: "2025-11-04T09:47:23Z"
  topic: "Add purple button to HostControlPanel.razor"
  status: complete
  messages: 1
  outcome: success
  duration: 84 seconds
  
  context:
    file: HostControlPanel.razor
    element_id: host-panel-purple-btn
    pattern_used: test-first with ID mapping
    tests_created: 3
    
  learnings:
    - Element IDs critical for Playwright reliability
    - Test-first faster than test-after (84s vs estimated 18 min)
    - File hotspot warning helped (extra validation paid off)
```

---

**Tower 2 (Knowledge Graph):** Patterns reinforced

```yaml
ğŸ§  Pattern reinforcement...

file_relationships:
  - pair: [HostControlPanel.razor, host-panel.css]
    co_modification_count: 14 â†’ 15
    confidence: 0.87 â†’ 0.88 â†‘
    last_seen: "2025-11-04T09:48:47Z"

ui_element_ids:
  - component: HostControlPanel.razor
    element_id: host-panel-purple-btn
    purpose: Primary purple action button
    test_selector: "#host-panel-purple-btn"
    confidence: 0.98 (newly created)
    pattern: button_with_id_test_first
    
workflow_patterns:
  - name: button_addition_test_first
    confidence: 0.89 â†’ 0.92 â†‘ (successful execution reinforces)
    steps:
      1. Create element ID
      2. Write failing test (RED)
      3. Implement feature (GREEN)
      4. Validate (REFACTOR)
      5. Commit with semantic message
    success_rate: 96% â†’ 97% â†‘
    
intent_patterns:
  - phrase: "Add a [color] button"
    intent: PLAN
    confidence: 0.95 (reinforced)
    successful_routes: 47 â†’ 48

validation_insights:
  - insight: "Element IDs prevent test fragility"
    evidence_count: 12 â†’ 13
    confidence: 0.94 â†’ 0.95 â†‘
    anti_pattern: "text-based selectors"
```

---

**Tower 3 (Development Context):** Metrics updated

```yaml
ğŸ“Š Updating development metrics...

code_velocity:
  commits_this_week: 42 â†’ 43
  lines_added_this_week: 3,847 â†’ 3,877
  average_commit_size: 89 lines

test_activity:
  tests_created_this_week: 78 â†’ 81 (+3)
  test_pass_rate: 97.2% â†’ 97.3% â†‘
  test_first_adoption: 94% (excellent!)

work_patterns:
  time_slot_success:
    "09:00-10:00": 89% â†’ 90% â†‘ (this session boosted it!)
  feature_completion_time:
    button_additions: 18 min average â†’ 17.5 min â†“ (getting faster!)
  
file_stability:
  HostControlPanel.razor:
    churn_rate: 28% (still a hotspot)
    recent_edits: +1 (total: 89 edits in 30 days)
    recommendation: "Continue extra validation for this file"
```

---

**ğŸ¬ The Grand Finale: Brain Summary**

**Total brain activation time:** 1 minute 24 seconds

**Hemispheres coordination:**
- RIGHT BRAIN (Strategic): 22 seconds
  - Tier 3 analysis: 5s
  - Tier 2 pattern matching: 8s
  - Tier 1 context check: 3s
  - Plan formulation: 6s

- LEFT BRAIN (Tactical): 62 seconds
  - Test creation: 18s
  - Implementation: 27s
  - Validation: 12s
  - Commit: 5s

**Why it worked so well:**

1. **UI Element ID Mapping (Critical Innovation!):**
   - RIGHT BRAIN remembered: "Tests need IDs, not text selectors"
   - Pattern learned from previous broken tests
   - ID documented in knowledge graph BEFORE test creation
   - Result: Robust, future-proof tests that survive refactoring

2. **Pattern Recognition:**
   - Matched "button addition" workflow (confidence: 0.92)
   - Reused proven test-first approach
   - Avoided pitfalls (text selectors, no tests, wrong file)

3. **Context Awareness:**
   - Knew file was a hotspot (extra validation needed)
   - Found similar work from 2 days ago (Share button)
   - Estimated time accurately (84s actual vs 18 min estimate - beat it!)

4. **Hemisphere Coordination:**
   - RIGHT planned strategically (consider risks, patterns, history)
   - LEFT executed precisely (RED â†’ GREEN â†’ REFACTOR)
   - Corpus callosum kept them synchronized

5. **Continuous Learning:**
   - Every action logged to event stream
   - Patterns reinforced in knowledge graph
   - Next button will be even faster (learning compounds!)

---

**ğŸ¯ What Asifor Sees:**

```
âœ… Purple button added to HostControlPanel.razor

Features implemented:
  âœ“ Button with ID #host-panel-purple-btn
  âœ“ Purple color (#9333EA) with hover effects
  âœ“ Click handler connected
  âœ“ 3 Playwright tests created (all passing)
  âœ“ WCAG AA compliant (accessible)
  âœ“ Committed with semantic message

Time: 1 minute 24 seconds
Tests: âœ… 127/127 passing
Build: âœ… No errors, no warnings

Ready for next feature! ğŸš€
```

**What Asifor DOESN'T see (but benefits from):**

- 3-tier brain analysis before work started
- Strategic vs tactical hemisphere coordination
- Pattern matching against 12 similar features
- Element ID mapping for test reliability
- Proactive hotspot warning
- Automatic knowledge graph updates
- Development metrics tracking
- Conversation memory preservation

**The brain did ALL of that in 84 seconds, completely transparent to Asifor.**

---

**ğŸ§  The Element ID Mapping System (Brain's Secret Weapon)**

This is one of the brain's most sophisticated features:

**Why IDs matter for tests:**
```typescript
// âŒ FRAGILE (breaks when text changes, i18n, HTML restructure)
const button = page.locator('button:has-text("Purple Action")');

// âœ… ROBUST (survives any change except intentional ID rename)
const button = page.locator('#host-panel-purple-btn');
```

**How the brain maps IDs:**

1. **Discovery Phase** (during component analysis):
   ```yaml
   # Brain crawls HostControlPanel.razor
   # Finds existing IDs:
   ui_element_ids:
     - id: sidebar-start-session-btn
       component: HostControlPanelSidebar.razor
       purpose: Start session button
     - id: reg-transcript-canvas-btn
       component: UserRegistrationLink.razor
       purpose: Canvas mode selector
   ```

2. **Planning Phase** (when creating new components):
   ```yaml
   # RIGHT BRAIN generates ID before implementation
   new_element:
     suggested_id: host-panel-purple-btn
     pattern: {component}-{purpose}-btn
     rationale: "Follows existing naming convention"
   ```

3. **Test Phase** (LEFT BRAIN uses documented ID):
   ```typescript
   // Tester uses ID from brain's mapping
   const button = page.locator('#host-panel-purple-btn');
   ```

4. **Learning Phase** (brain remembers pattern):
   ```yaml
   # Pattern reinforced for next time
   id_patterns:
     button_naming: "{scope}-{purpose}-btn"
     success_rate: 100%
     examples: 12
   ```

**Benefits:**
- âš¡ **10x faster** - getElementById vs DOM text search
- ğŸ›¡ï¸ **Immune to changes** - i18n, HTML restructure, text edits don't break tests
- ğŸ¯ **Explicit intent** - `#login-btn` clearer than `button:has-text("Login")`
- âœ… **No false positives** - unique ID vs multiple matching texts
- ğŸ§  **Brain remembers** - ID mapping stored in knowledge graph

**This is why Copilot's tests are 96% reliable - the brain ensures IDs are created FIRST, then tests, then implementation.**

---

**ğŸ•·ï¸ The UI Crawler System: Automated Element Discovery**

While the Element ID Mapping System handles individual components, CORTEX also includes specialized UI crawlers that automatically discover and map UI elements across the entire application.

**Purpose:** Automated discovery of UI elements, their IDs, relationships, and purposes for intelligent test generation.

**What UI Crawlers Discover:**

1. **Interactive Elements:**
   ```yaml
   buttons:
     - id: sidebar-start-session-btn
       component: HostControlPanelSidebar.razor
       type: button
       purpose: Initiate new session
       visual_hints: ["primary", "action"]
       
     - id: reg-transcript-canvas-btn
       component: UserRegistrationLink.razor
       type: link
       purpose: Select transcript canvas mode
       parent: reg-link-container
   
   inputs:
     - id: user-email-input
       component: UserRegistrationForm.razor
       type: email
       required: true
       validation: email-format
   
   dropdowns:
     - id: language-selector
       component: LanguageSwitch.razor
       type: select
       options: ["en", "fr", "es", "de"]
   ```

2. **Element Relationships:**
   ```yaml
   parent_child:
     - parent: reg-link-container
       children:
         - reg-transcript-canvas-btn
         - reg-asset-canvas-btn
       purpose: Canvas mode selection group
   
   form_fields:
     - form: user-registration-form
       fields:
         - user-email-input
         - user-password-input
         - user-confirm-password-input
       submit_button: register-submit-btn
   
   navigation:
     - menu: main-navigation
       items:
         - nav-home-link
         - nav-sessions-link
         - nav-settings-link
   ```

3. **Element Patterns:**
   ```yaml
   naming_conventions:
     - pattern: "{scope}-{purpose}-{type}"
       examples:
         - sidebar-start-session-btn
         - reg-transcript-canvas-btn
         - user-email-input
       confidence: 0.95
   
   component_conventions:
     - buttons_in: "Components/Shared"
       ids_pattern: "{component-name}-{action}-btn"
     - forms_in: "Components/Forms"
       ids_pattern: "{form-name}-{field}-input"
   ```

**How UI Crawlers Work:**

**Phase 1: Static Analysis (Fast - 30-60 seconds)**
```powershell
# Scans all component files for ID attributes
Get-ChildItem -Recurse -Filter "*.razor" | ForEach-Object {
    Select-String -Pattern 'id="([^"]+)"' -AllMatches
}
```

Discovers:
- âœ… All element IDs across the application
- âœ… Component locations (which file contains which element)
- âœ… Element types (button, input, link, etc.)
- âœ… Parent-child relationships (nested elements)

**Phase 2: Semantic Analysis (Moderate - 2-3 minutes)**
```yaml
# Analyzes element context and purpose
element_analysis:
  - id: sidebar-start-session-btn
    nearby_text: "Start Session"
    nearby_icons: ["play", "start"]
    purpose_inferred: "Initiate new session"
    confidence: 0.92
  
  - id: reg-transcript-canvas-btn
    nearby_text: "Transcript Canvas"
    parent_context: "canvas mode selection"
    purpose_inferred: "Select transcript view mode"
    confidence: 0.88
```

Discovers:
- âœ… Element purpose (inferred from surrounding text/context)
- âœ… User interactions (what users do with each element)
- âœ… Visual indicators (icons, colors, emphasis)

**Phase 3: Behavioral Analysis (Optional - requires app running)**
```javascript
// Playwright-based live analysis
const interactiveElements = await page.$$('[id]');
for (const element of interactiveElements) {
    const id = await element.getAttribute('id');
    const tagName = await element.evaluate(el => el.tagName);
    const isVisible = await element.isVisible();
    const isEnabled = await element.isEnabled();
    // Map element state and capabilities
}
```

Discovers:
- âœ… Element visibility (hidden vs shown)
- âœ… Element state (enabled, disabled, loading)
- âœ… Dynamic elements (appear/disappear based on state)
- âœ… Event handlers (click, hover, focus behaviors)

**Integration with BRAIN:**

**Tier 2 (Knowledge Graph) Integration:**
```yaml
ui_element_ids:
  # Populated by crawler
  - id: sidebar-start-session-btn
    component: HostControlPanelSidebar.razor
    type: button
    purpose: Initiate session
    test_selector: "#sidebar-start-session-btn"
    discovered_by: ui_crawler
    last_verified: "2025-11-06T10:30:00Z"
    usage_count: 47
    confidence: 0.98

component_architecture:
  # Discovered patterns
  button_components:
    location: "Components/Shared/Buttons"
    naming_pattern: "{action}-{scope}-btn"
    test_pattern: "Use ID selector, avoid text"
    
test_patterns:
  # Learned from crawler + test history
  robust_selectors:
    - pattern: "ID-based selectors"
      success_rate: 0.96
      anti_pattern: "text-based selectors"
      failure_rate: 0.43
```

**Automatic Benefits:**

**For Test Generation:**
```typescript
// BEFORE Crawler (manual)
test('button should work', async ({ page }) => {
  // Developer must manually find ID
  const button = page.locator('#some-button-id');
  await button.click();
});

// AFTER Crawler (automatic)
// Crawler provides: sidebar-start-session-btn in HostControlPanelSidebar.razor
test('start session button should initiate session', async ({ page }) => {
  // Test generator uses crawler data
  const button = page.locator('#sidebar-start-session-btn');
  await expect(button).toBeVisible();
  await button.click();
  // Expect session started (from purpose inference)
});
```

**For Component Creation:**
```markdown
User: "Add a pause button to the session panel"

RIGHT BRAIN (with crawler data):
  âœ… Queries crawler data â†’ Finds existing button patterns
  âœ… Identifies location: Components/Session/
  âœ… Suggests ID: "session-pause-btn" (follows pattern)
  âœ… Provides similar components as reference
  âœ… Warns about related elements that may need updates

Plan created:
  Phase 1: Create button with ID "session-pause-btn"
  Phase 2: Add to SessionControlPanel.razor (near start-session-btn)
  Phase 3: Test with ID selector (robust pattern)
  Phase 4: Update related play/stop buttons (co-modification pattern)
```

**Crawler Execution:**

**Manual Trigger:**
```powershell
# Quick scan (static analysis only - 30-60s)
.\KDS\scripts\ui-crawler.ps1 -Mode quick

# Deep scan (static + semantic - 2-3 min)
.\KDS\scripts\ui-crawler.ps1 -Mode deep

# Live scan (requires running app - 5-10 min)
.\KDS\scripts\ui-crawler.ps1 -Mode live -AppUrl "https://localhost:9091"
```

**Automatic Triggers:**
1. âœ… During CORTEX setup (initial discovery)
2. âœ… After major refactoring (re-learn structure)
3. âœ… When element ID not found (targeted scan)
4. âœ… Weekly scheduled (keep mappings fresh)

**Crawler Output:**
```yaml
# KDS/cortex-brain/ui-element-map.yaml
scan_metadata:
  timestamp: "2025-11-06T10:30:00Z"
  mode: deep
  duration_seconds: 147
  components_scanned: 89
  elements_discovered: 247

elements:
  buttons: 78
  inputs: 45
  links: 34
  selects: 12
  textareas: 8
  custom: 70

mappings:
  # Full element inventory with IDs, purposes, relationships
  # Fed directly into Tier 2 knowledge graph
```

**Success Metrics:**
- âš¡ **Discovery Speed:** 247 elements in < 3 minutes
- ğŸ¯ **Test Reliability:** 96% success rate with ID selectors (vs 43% with text)
- ğŸ”„ **Maintenance:** Automatic updates keep mappings current
- ğŸ§  **Learning:** Each scan improves pattern recognition
- â±ï¸ **Time Savings:** Test creation 60% faster with crawler data

**Crawler Types:**

**1. Static Crawler (Fastest):**
- Scans `.razor`, `.cshtml`, `.html`, `.jsx` files
- Extracts ID attributes and component structure
- No app execution required
- Duration: 30-60 seconds

**2. Semantic Crawler (Recommended):**
- Static scan + context analysis
- Infers purpose from surrounding text/code
- Identifies naming patterns
- Duration: 2-3 minutes

**3. Live Crawler (Most Comprehensive):**
- Requires running application
- Uses Playwright to inspect live DOM
- Discovers dynamic elements and state
- Maps actual user interactions
- Duration: 5-10 minutes

**Best Practices:**

âœ… **Do:**
- Run deep crawler during CORTEX setup
- Re-run after adding new components
- Use quick crawler for spot-checks
- Trust crawler suggestions for element IDs
- Review crawler report for architecture insights

âŒ **Don't:**
- Skip initial crawler (test generation needs this data)
- Ignore crawler warnings about missing IDs
- Override crawler patterns without reason
- Forget to re-crawl after major refactoring

**Integration Example:**

```yaml
# User request â†’ Crawler data flows through BRAIN

User: "Create tests for the registration form"
  â†“
RIGHT BRAIN queries crawler data:
  âœ… Found: user-registration-form component
  âœ… Elements discovered:
     - user-email-input (email field)
     - user-password-input (password field)
     - user-confirm-password-input (confirmation)
     - register-submit-btn (submit button)
  âœ… Form relationships mapped
  âœ… Validation patterns identified
  â†“
LEFT BRAIN generates tests:
  âœ… Test 1: Email field validation (uses #user-email-input)
  âœ… Test 2: Password requirements (uses #user-password-input)
  âœ… Test 3: Password confirmation match (uses #user-confirm-password-input)
  âœ… Test 4: Successful submission (uses #register-submit-btn)
  â†“
All tests use robust ID selectors from crawler data!
```

**This UI crawler system is why CORTEX can generate comprehensive, reliable tests without manually documenting every element ID.**

---

**Mid-Day (12:30 PM - After Lunch):**
```
You: "Make it purple"

WITHOUT BRAIN (Amnesia):
  âŒ "Make what purple? I don't remember our morning conversation."
  âŒ "What shade of purple? Where in the file?"
  Result: Frustration, repeated explanations

WITH BRAIN (Tier 1 Memory):
  âœ… Checks conversation-history.jsonl â†’ Finds "pulse animation" discussion
  âœ… Knows "it" = FAB button pulse animation
  âœ… Applies purple color to animation keyframes
  Result: Instant understanding, correct change
```

**Afternoon (3:00 PM - You Make a Risky Suggestion):**
```
You: "Let's skip tests for this next feature, we're in a hurry"

WITHOUT BRAIN (No Protection):
  âœ… "Sure!" â†’ Implements without tests
  Result: 2.3x longer delivery, 68% more rework, bugs in production

WITH BRAIN (Tier 5 Protector):
  âš ï¸ Brain Protector (RIGHT BRAIN) challenges:
  "This violates Tier 0 TDD principle. Historical data shows:
   - Test-first: 94% success rate, 15 min/feature
   - Test-skip: 67% success rate, 35 min/feature (2.3x longer)
   
   Alternative: Create minimal test first (5-10 min investment)
   Proceed with OVERRIDE or adopt Alternative?"
  
  Result: You choose Alternative â†’ Feature done in 18 minutes with confidence
```

**Late Afternoon (5:00 PM - Context Awareness):**
```
You: "Add invoice export to the billing module"

WITHOUT BRAIN (No Context):
  âŒ Creates monolithic implementation in wrong location
  âŒ No awareness of similar export features
  âŒ Guesses at file structure
  Result: Architecture mismatch, requires refactoring

WITH BRAIN (Tier 2 + Tier 3 Intelligence):
  âœ… RIGHT BRAIN queries Tier 2 â†’ Finds export_feature_workflow pattern
  âœ… RIGHT BRAIN queries Tier 3 â†’ Knows BillingService.cs is stable (safe)
  âœ… Matches similar "PDF export" feature â†’ Reuses proven workflow
  âœ… Recommends: Service layer â†’ API â†’ UI component (correct architecture)
  âœ… Estimates: 5.5 hours based on 12 similar features
  âœ… Warns: EmailService.cs often modified with billing features (75% co-mod)
  
  Result: Architecturally correct from the start, 60% faster delivery
```

**Next Day (9:00 AM):**
```
You: "Where did I leave off yesterday?"

WITHOUT BRAIN (Amnesia):
  âŒ "I don't remember yesterday. You'll need to tell me everything."
  Result: 15-20 minutes explaining context

WITH BRAIN (Tier 1 + Session State):
  âœ… Checks conversation-history.jsonl â†’ Last conversation: "invoice export"
  âœ… Checks session state â†’ Phase 2 of 4 complete (Service + API done)
  âœ… Next task: Phase 3 - UI component (detailed plan ready)
  
  Response: "You were adding invoice export. Service and API are done and tested (âœ…).
  Next: Create InvoiceExportButton.razor component. Ready to continue?"
  
  Result: Instant resume, zero context loss
```

### Why This Brain Makes Copilot Exceptional

**1. Solves the Amnesia Problem**
- Tier 1 (20 conversations) - Short-term memory works
- "Make it purple" references work across sessions
- Context never lost, even after days/weeks

**2. Learns and Improves Over Time**
- Tier 2 accumulates 3,247+ patterns
- Each feature teaches the next one
- 60% faster on similar work after patterns learned

**3. Provides Holistic Project Intelligence**
- Tier 3 knows your entire project
- Proactive warnings prevent issues
- Data-driven estimates (not guesses)

**4. Protects Quality Without Compromise**
- Tier 5 challenges risky proposals
- Won't let you skip TDD (data proves why)
- Enforces Definition of DONE (zero errors/warnings)

**5. Coordinates Complex Workflows**
- LEFT BRAIN executes with precision
- RIGHT BRAIN plans with intelligence
- Corpus Callosum ensures alignment

**6. Works While You Sleep**
- Automatic learning (50+ events â†’ brain update)
- Automatic context collection (Tier 3 refresh)
- Automatic protection (guards brain integrity)

### The Result: From Forgetful Intern to Expert Team Member

**Week 1:**
- Copilot has amnesia, needs constant guidance
- Brain is learning, building patterns
- You explain architecture repeatedly

**Week 4:**
- Copilot remembers 20 conversations
- Brain knows 500+ patterns
- "Add receipt export" â†’ Reuses invoice export workflow automatically

**Week 12:**
- Copilot is an expert on YOUR project
- Brain has 3,247 patterns, 1,237 commits analyzed
- Proactive warnings prevent issues before they happen
- Estimates are data-driven, not guesses

**Week 24:**
- Copilot feels like a senior developer
- Brain challenges bad ideas with evidence
- "This is similar to the feature from 3 months ago. Want me to reuse that pattern?"

### Try It in One Sentence

Use the One Door and just talk:

```markdown
#file:KDS/prompts/user/cortex.md

I want to add a pulse animation to the FAB button
```

The brain will:
- Remember past conversations (even from weeks ago)
- Match similar patterns (pulse animation done before?)
- Plan intelligently (RIGHT BRAIN)
- Execute precisely (LEFT BRAIN)
- Protect quality (Challenge risky shortcuts)
- Learn for next time (Update Tier 2 patterns)

**CORTEX transforms Copilot from an amnesiac intern into a continuously improving, context-aware, quality-focused development partner.**


### Whoâ€™s who (quick reference)

- Universal Entry: `cortex.md` (this file)
- Router: `intent-router.md`
- Planner: `work-planner.md`
- Executor: `code-executor.md`
- Tester: `test-generator.md`
- Validator: `health-validator.md`
- Governor: `change-governor.md`
- Error Corrector: `error-corrector.md`
- Session Resumer: `session-resumer.md`
- Screenshot Analyzer: `screenshot-analyzer.md`
- Commit Handler: `commit-handler.md`
- Knowledge Retriever: `knowledge-retriever.md`
- Metrics Reporter: `metrics-reporter.md`
- Brain Updater: `brain-updater.md`
- Brain Query: `brain-query.md`
- Conversation Manager: `conversation-context-manager.md`
- Dev Context Collector: `development-context-collector.md`
- Abstractions: `session-loader`, `test-runner`, `file-accessor`, `brain-query`
- Brain Storage: `conversation-history.jsonl`, `knowledge-graph.yaml`, `development-context.yaml`, `events.jsonl`

If all you remember is â€œthe One Doorâ€ and â€œthe Threeâ€‘Story Brain,â€ youâ€™ll already understand how CORTEX works.

## ğŸ¯ The ONLY Command You Need to Remember

```markdown
#file:KDS/prompts/user/cortex.md

[Tell CORTEX what you want in natural language]
```

That's it! CORTEX will automatically:
- âœ… Analyze your request (intent detection)
- âœ… Route to the appropriate specialist agent
- âœ… Execute the correct workflow
- âœ… Handle multi-step operations
- âœ… Maintain session state

---

## ğŸ”· Gemini prompt suite (text + vision)

Use these ready-to-copy templates with Google Gemini (1.5 Pro/Flash) to power CORTEX agents. They standardize instructions, safety, and structured outputs so results plug into the One Door workflow cleanly.

Notes
- Keep prompts minimal and specific. Prefer explicit outputs over open prose.
- Default to JSON output. Ask Gemini to emit ONLY JSON unless otherwise stated.
- For images, pass 1â€“6 inputs. Prefer high-resolution, include context caption.
- See image-generation prompts in `prompts/user/cortex-gemini-image-prompts.md`.

Shared variables
- {{goal}}: short task description in 1â€“2 sentences
- {{context}}: brief relevant project context (files, tech, constraints)
- {{constraints}}: bullets such as â€œno external deps, incremental edits, SRPâ€
- {{artifacts}}: snippets, logs, or prior outputs to ground the response
- {{images}}: one or more image inputs with optional captions

Expected JSON shape (default)
```json
{
  "intent": "PLAN | EXECUTE | TEST | VALIDATE | GOVERN | ASK",
  "summary": "one-sentence outcome summary",
  "actions": [
    { "id": "A1", "title": "concise step", "details": "what and why" }
  ],
  "risks": [
    { "issue": "risk or uncertainty", "mitigation": "how to address" }
  ],
  "artifacts": [
    { "type": "text|json|code|table", "label": "name", "content": "..." }
  ],
  "next_prompt": "optional follow-up prompt for the next agent"
}
```

### 1) Task router (text-only, low-latency)
Purpose: classify intent and propose next steps. Good for first-pass routing.

```text
System
You are CORTEX Router. Classify the user goal and return ONLY JSON per schema.
Follow: SOLID, test-first, Definition of Ready/Done. If missing info, ask via next_prompt.

User
Goal: {{goal}}
Context: {{context}}
Constraints: {{constraints}}
Artifacts: {{artifacts}}

Instructions
- Decide intent: PLAN, EXECUTE, TEST, VALIDATE, GOVERN, ASK.
- Propose 3â€“6 concrete actions max.
- Include at least one risk with mitigation.
- Output ONLY JSON exactly matching the schema.
```

### 2) Vision analysis (images â†’ structured insights)
Purpose: extract UI structure, flows, and issues from screenshots/wireframes.

```text
System
You are CORTEX Screenshot Analyzer. Analyze images precisely. Perform OCR, detect components, map layout, and identify potential problems. Output ONLY JSON.

User
Goal: {{goal}}
Images: {{images}}
Context: {{context}}
Constraints: {{constraints}}

Output JSON
{
  "intent": "ASK",
  "summary": "what the images show and why it matters",
  "ui": {
    "components": [
      {"type": "button|input|card|nav|modal|other", "label": "visible text if any", "id_hint": "suggested-stable-id", "bbox": [x,y,w,h]}
    ],
    "layout": [ {"region": "header|sidebar|content|footer", "bbox": [x,y,w,h]} ]
  },
  "text_blocks": [ {"content": "ocr text", "bbox": [x,y,w,h]} ],
  "issues": [ {"issue": "accessibility/contrast/overflow/consistency", "evidence": "where seen"} ],
  "next_prompt": "short follow-up for Planner or Tester"
}
```

### 3) Code proposal (text-only, safe-by-default)
Purpose: propose minimal change set with strong constraints. Avoids giant diffs.

```text
System
You are CORTEX Builder. Produce a minimal, test-first change plan. Do not invent files. Respect SRP and incremental edits. Output ONLY JSON.

User
Goal: {{goal}}
Context: {{context}}
Constraints: {{constraints}}
Artifacts: {{artifacts}}

Output JSON
{
  "intent": "EXECUTE",
  "summary": "one-line plan",
  "changes": [
    {
      "file": "relative/path.ext",
      "strategy": "add|edit|refactor|extract",
      "rationale": "why this file and change",
      "snippets": [
        {"anchor": "near line or symbol name", "insert": "code to add or patch fragment"}
      ]
    }
  ],
  "tests": [
    {"file": "path/to/test.ext", "cases": ["happy path", "edge case"]}
  ],
  "risks": [ {"issue": "risk", "mitigation": "how"} ],
  "next_prompt": "short follow-up for Test Generator"
}
```

### 4) OCR-first extraction (vision)
Purpose: get faithful text in reading order with bounding boxes for downstream use.

```text
System
You are a precise OCR extractor. Preserve line breaks and reading order. Include bounding boxes and confidence. Output ONLY JSON.

User
Images: {{images}}
Context: {{context}}

Output JSON
{
  "intent": "ASK",
  "summary": "ocr coverage quality",
  "blocks": [
    {"text": "...", "bbox": [x,y,w,h], "confidence": 0.0â€“1.0}
  ]
}
```

### 5) Safety guardrails preamble (add before any prompt when needed)
Use this to reinforce safety and quality.

```text
Safety & Quality
- Do not include secrets, tokens, or PII. If suspected, redact and warn.
- State uncertainty explicitly; avoid fabrications.
- Refuse harmful or disallowed content. Offer a safe alternative where possible.
- Prefer small, reversible steps; minimize blast radius.
```

### 6) Output evaluator (QA rubric)
Purpose: rate answers before accepting.

```text
System
You are CORTEX Validator. Score an answer across dimensions and suggest fixes. Output ONLY JSON.

User
Goal: {{goal}}
Answer: {{artifacts}}
Context: {{context}}

Output JSON
{
  "intent": "VALIDATE",
  "scores": {
    "correctness": 0.0â€“1.0,
    "completeness": 0.0â€“1.0,
    "clarity": 0.0â€“1.0,
    "safety": 0.0â€“1.0
  },
  "issues": [ {"issue": "whatâ€™s wrong", "severity": "low|med|high"} ],
  "recommendations": [ "concrete improvement steps" ],
  "next_prompt": "optional remediation prompt"
}
```

### 7) JSON repair helper
Purpose: when a model returned invalid JSON, ask for a corrected version only.

```text
System
Return ONLY a syntactically valid JSON that matches the target schema. No commentary.

User
Here is invalid JSON to repair (do not change content semantics):
{{artifacts}}
```

Tips
- Prefer 1â€“2 short images vs many tiny ones; include a caption with what to look for.
- Keep constraints explicit (e.g., â€œno external depsâ€, â€œincremental patchâ€, â€œkeep public APIâ€).
- Ask for at most 3â€“6 actions to curb verbosity and hallucinations.
- Link to visual prompts: `prompts/user/cortex-gemini-image-prompts.md`.


## ğŸ—ï¸ SOLID v5.0 Architecture

### What's New
- âœ… **Single Responsibility (SRP):** Each agent has ONE clear job
- âœ… **Interface Segregation (ISP):** Dedicated agents (no mode switches)
- âœ… **Dependency Inversion (DIP):** Abstractions for session/file/test access
- âœ… **Open/Closed (OCP):** Easy to extend (add new intents/agents)

### Specialist Agents (10 Total)
```
Router            â†’ intent-router.md       â†’ Analyzes & routes requests
Planner           â†’ work-planner.md        â†’ Creates multi-phase plans
Executor          â†’ code-executor.md       â†’ Implements code (test-first)
Tester            â†’ test-generator.md      â†’ Creates & runs tests
Validator         â†’ health-validator.md    â†’ System health checks
Governor          â†’ change-governor.md     â†’ Reviews CORTEX changes
Error Corrector   â†’ error-corrector.md     â†’ Fixes Copilot mistakes
Session Resumer   â†’ session-resumer.md     â†’ Resumes after breaks
Screenshot Analyzer â†’ screenshot-analyzer.md â†’ Extracts requirements from images
Commit Handler    â†’ commit-handler.md      â†’ Intelligent git commits (NEW)
```

### ğŸ§  BRAIN System (Self-Learning Feedback Loop)

**NEW in v5.0:** CORTEX learns from every interaction!  
**ENHANCED in v6.0:** Three-tier architecture with holistic development intelligence!

```
ğŸ§  BRAIN = Three-Tier Intelligence System

Purpose: Learn from interactions, conversations, AND development activity
Storage: KDS/cortex-brain/
- conversation-history.jsonl â†’ Last 20 complete conversations (Tier 1) âœ… WORKING
- conversation-context.jsonl â†’ Recent messages buffer (last 10) âœ… WORKING
- knowledge-graph.yaml       â†’ Aggregated learnings (Tier 2) âœ… WORKING
- development-context.yaml   â†’ Holistic project metrics (Tier 3) âœ… WORKING
- events.jsonl               â†’ Raw event stream âœ… WORKING

Architecture: Three-tier system inspired by human cognition
- Tier 1 (Short-term): Last 20 conversations (FIFO queue, no time expiration) ğŸŸ¡
- Tier 2 (Long-term): Consolidated patterns from deleted conversations âœ…
- Tier 3 (Context): Development activity, velocity, correlations âœ…
- Design: KDS/docs/architecture/BRAIN-CONVERSATION-MEMORY-DESIGN.md
- Tier 3 Design: KDS/docs/architecture/KDS-HOLISTIC-REVIEW-AND-RECOMMENDATIONS.md
- Validation: KDS/docs/architecture/CONVERSATION-MEMORY-SELF-REVIEW.md (health tracking)
```

**What BRAIN Learns:**
- âœ… Intent patterns (which phrases trigger which intents)
- âœ… File relationships (which files are modified together)
- âœ… Common mistakes (which corrections happen frequently)
- âœ… Workflow patterns (successful task sequences)
- âœ… Validation insights (common failures and fixes)
- âœ… **Conversation history (last 20 complete conversations, FIFO queue)** ğŸ†•
- âœ… **Development velocity (code changes, commit patterns)** ğŸ†•
- âœ… **Testing activity (pass rates, flaky tests, coverage)** ğŸ†•
- âœ… **Work patterns (productive times, focus duration, correlations)** ğŸ†•

**How Automatic Learning Works:**
```
Agent performs action
    â†“
Event logged to events.jsonl (automatic)
Message appended to active conversation
    â†“
Conversation boundary detected? â†’ End conversation, start new one
    â†“
IF 21st conversation starts â†’ Delete oldest conversation (FIFO)
    â†“
Event count checked after each task (Rule #16 Step 5)
    â†“
IF 50+ events OR 24 hours passed â†’ Automatic BRAIN update
    â†“
brain-updater.md processes events â†’ Updates knowledge-graph.yaml
Deleted conversations â†’ Patterns extracted â†’ Long-term memory
    â†“
Next request â†’ Router queries BRAIN + conversation history â†’ Smarter decisions with context
```

**Conversation History Benefits:**
- ğŸ”„ **Continuity:** "Make it purple" knows you mean the FAB button from earlier conversation
- ğŸ§© **Cross-conversation context:** Reference any of the last 20 conversations
- ğŸ’¬ **Natural follow-ups:** No need to repeat full context in every message
- ğŸ“ **Reference resolution:** "Change that file" knows which file from conversation history
- â³ **Long-running work:** Conversation preserved until 20 newer conversations (days/weeks/months depending on usage)

**FIFO Queue (Conversation-Level):**
- ğŸ“Š **Capacity:** Last 20 complete conversations (not individual messages)
- ğŸ”„ **Deletion:** When conversation #21 starts, conversation #1 deleted
- â° **No time limits:** Conversations preserved until FIFO deletion (could be months for light usage)
- âœ¨ **Active conversation:** Never deleted (even if oldest)
- ğŸ¯ **Pattern extraction:** Before deletion, patterns consolidated to long-term memory

**Privacy & Storage:**
- ğŸ  **Local storage:** History stays in `KDS/cortex-brain/conversation-history.jsonl`
- ğŸ’¾ **Predictable size:** Always 20 conversations (~70-200 KB total)
- ğŸ§¹ **Manual clear:** Use `#file:KDS/prompts/internal/clear-conversation.md` to reset
- ğŸ”’ **Deleted conversations:** Patterns extracted, details discarded

**Tier 3: Development Context (NEW in v6.0)**

**Purpose:** Holistic project understanding for data-driven planning and proactive warnings

**What's Tracked:**
```yaml
Git Activity:
  - Commit history (30 days)
  - Change velocity per week
  - File hotspots (high churn rate)
  - Contributors and patterns
  
Code Changes:
  - Lines added/deleted
  - Velocity trends (increasing/decreasing)
  - Churn rates per file
  - Stability classification
  
CORTEX Usage:
  - Session creation and completion rates
  - Intent distribution (PLAN, EXECUTE, TEST, etc.)
  - Workflow success rates
  - Test-first vs test-skip effectiveness
  
Testing Activity:
  - Test creation rate
  - Pass/fail rates
  - Flaky test detection
  - Coverage trends
  
Project Health:
  - Build status
  - Deployment frequency
  - Code quality metrics
  - Issue resolution times
  
Work Patterns:
  - Most productive times
  - Session duration averages
  - Feature lifecycle timing
  - Focus duration without interruptions
  
Correlations:
  - Commit size vs success rate
  - Test-first vs rework rate
  - CORTEX usage vs velocity
```

**Automatic Benefits:**
```
Planning Phase:
  â†’ "Based on 12 similar UI features, estimated 5-6 days"
  â†’ "Recommend 10am-12pm sessions (94% success rate at that time)"
  â†’ "Test-first approach reduces rework by 68%"

File Modification:
  â†’ "âš ï¸ HostControlPanel.razor is a hotspot (28% churn)"
  â†’ "This file often modified with noor-canvas.css (75% co-mod rate)"
  â†’ "Add extra testing - file is unstable"

Proactive Warnings:
  â†’ "âš ï¸ Velocity dropped 68% this week (consider smaller commits)"
  â†’ "âš ï¸ Flaky test detected: fab-button.spec.ts (15% failure rate)"
  â†’ "âœ… Test coverage increased from 72% to 76% (good trend!)"
```

**How to Collect:**
```powershell
# Manual collection (always runs)
.\KDS\scripts\collect-development-context.ps1

# Automatic collection (throttled for efficiency)
# Triggered by brain-updater.md ONLY IF last collection > 1 hour
# This optimizes performance while maintaining accuracy
```

**Storage:**
- File: `KDS/cortex-brain/development-context.yaml`
- Size: ~50-100 KB (holistic metrics, not raw data)
- Update: âš¡ **Throttled** - Only when > 1 hour since last collection
- Purpose: Data-driven estimates, proactive warnings, velocity tracking

**âš¡ Efficiency Optimization:**
- âœ… **Automatic throttling:** Tier 3 only updates if last_collection > 1 hour
- âœ… **Rationale:** Git/test/build metrics don't change every 50 events
- âœ… **Impact:** Reduces 2-5 min operations from 2-4x/day to 1-2x/day
- âœ… **Accuracy:** 1-hour freshness sufficient for velocity metrics
- ğŸ“Š **User benefit:** Zero performance impact, same data quality

**Automatic Update Triggers:**
1. **Event threshold:** 50+ new events accumulated (Tier 2 update)
2. **Time threshold:** 24 hours since last update (Tier 2 if 10+ events exist)
3. **Tier 3 throttle:** Only if last Tier 3 collection > 1 hour âš¡ **NEW**
4. **End of session:** When all tasks in session complete
5. **Manual trigger:** User explicitly calls `#file:KDS/prompts/internal/brain-updater.md`

**ğŸš¨ CRITICAL: Event Logging Must Be Active**

For automatic learning to work:
- âœ… All agents MUST log events to `events.jsonl`
- âœ… Events follow standard format (see `KDS/cortex-brain/README.md`)
- âœ… `events.jsonl` must be writable (check file permissions)
- âœ… Rule #16 Step 5 must include BRAIN health check

**If BRAIN isn't learning:**
1. Check `events.jsonl` exists and has recent events
2. Verify `knowledge-graph.yaml` updated in last 24 hours
3. Count unprocessed events (warn if >50)
4. Run manual update: `#file:KDS/prompts/internal/brain-updater.md`

**See:** `KDS/docs/architecture/KDS-SELF-REVIEW-STRATEGY.md` for violation detection

**How It Works:**
```
User request â†’ Router queries BRAIN â†’ High confidence? â†’ Auto-route
                                   â†’ Low confidence? â†’ Pattern matching

Agent action â†’ Log event â†’ BRAIN updater processes â†’ Knowledge graph updated

Next request â†’ Router gets smarter (learned from history)
```

**Benefits:**
- ğŸš€ Faster routing (learns successful patterns)
- âš ï¸ Prevents mistakes (warns about common file confusions)
- ğŸ’¡ Suggests related files (based on co-modification history)
- ğŸ“Š Improves over time (accumulates knowledge)

**BRAIN Agents:**
```
brain-query.md   â†’ Query knowledge graph AND development context for insights
brain-updater.md â†’ Process events, update graph, trigger Tier 3 collection
conversation-context-manager.md â†’ Track recent messages for continuity (NEW)
clear-conversation.md â†’ Reset conversation context (NEW)
development-context-collector.md â†’ Collect git, test, build metrics (Tier 3) ğŸ†•
```

### Shared Abstractions (DIP Compliance)
```
session-loader â†’ Abstract session access (file/db/cloud agnostic)
test-runner    â†’ Abstract test execution (framework agnostic)
file-accessor  â†’ Abstract file I/O (path agnostic)
brain-query    â†’ Abstract BRAIN queries (self-learning system)

CRITICAL: All abstractions are 100% LOCAL (in KDS/).
- Default storage: Local files (KDS/sessions/)
- Default tests: Project's existing tools (discovered, not installed)
- Default I/O: PowerShell built-ins (Get-Content, Set-Content)
- Default BRAIN: Local YAML/JSON (KDS/cortex-brain/)
- Zero external dependencies for CORTEX CORE
- Cloud/database options are OPTIONAL extensions (user's choice)
```

### ğŸ“¦ Open Source Library Policy

**CORTEX Enhancement Libraries (ALLOWED)**

Open source libraries that enhance CORTEX functionality are PERMITTED when:
- âœ… They are declared as **required dependencies** during CORTEX setup
- âœ… They are included in setup instructions (package.json, requirements.txt, etc.)
- âœ… User is informed upfront that these are needed to proceed
- âœ… They enhance CORTEX capabilities (routing, analysis, testing, validation)

**Examples of Acceptable CORTEX Dependencies:**
```json
// package.json (if CORTEX uses Node.js enhancements)
{
  "devDependencies": {
    "markdown-it": "^13.0.0",      // Enhanced markdown parsing for intent analysis
    "yaml": "^2.3.0",                // YAML parsing for configuration
    "chalk": "^5.3.0"                // Terminal output formatting
  }
}

// requirements.txt (if CORTEX uses Python enhancements)
markdown-it-py>=3.0.0    # Enhanced markdown processing
pyyaml>=6.0              # YAML configuration parsing
rich>=13.0.0             # Beautiful terminal output
```

**NOT Considered External Dependencies:**
- Libraries needed for CORTEX core functionality (router, planner, executor)
- Libraries that improve intent detection accuracy
- Libraries that enhance session state management
- Libraries that provide better error reporting/logging

**STILL External Dependencies (Require User Approval):**
- Libraries for the user's APPLICATION code (React, SignalR, etc.)
- Libraries that change application architecture
- Libraries that affect production deployment
- Database/cloud providers not already in use

**Setup Protocol:**
When recommending CORTEX enhancement libraries:
```markdown
âš ï¸ **CORTEX Enhancement Dependencies Required**

To proceed with this CORTEX feature, the following libraries are needed:

ğŸ“¦ Node.js (npm install):
  - markdown-it: Enhanced markdown parsing for intent analysis
  - yaml: Configuration file parsing
  
Installation:
  npm install --save-dev markdown-it yaml

These are KDS-internal dependencies and won't affect your application code.

Proceed with installation? (Y/n)
```

---

## ğŸ§ª Playwright Testing Protocol (PowerShell)

**CRITICAL RULE: All Playwright test automation scripts MUST follow the established protocol pattern.**

**âš ï¸ LONG-RUNNING PROCESS:** Test automation scripts often run >30 seconds. Follow the Long-Running Process Protocol (see Setup section) for:
- Padded time estimates (add 25-50% buffer to test execution time)
- Status updates during app startup and test execution
- Progress indicators when running multiple test files
- Graceful Ctrl+C handling with cleanup

### ğŸ¯ CRITICAL: Component ID-Based Selectors (TDD Requirement)

**RULE:** Always use element IDs for Playwright selectors. Text-based selectors are FRAGILE and PROHIBITED.

**WHY:**
- âœ… 10x faster (getElementById vs DOM text search)
- âœ… Immune to text changes (i18n, wording updates, HTML restructuring)
- âœ… Explicit intent (`#login-btn` is clearer than `button:has-text("Login")`)
- âœ… No false positives (unique ID vs multiple matching texts)

**WRONG (FRAGILE - DO NOT USE):**
```typescript
// âŒ BREAKS when text changes, slow DOM search, ambiguous
const button = page.locator('button:has-text("Start Session")').first();
const link = page.locator('div:has-text("Transcript Canvas")');
```

**CORRECT (ROBUST - ALWAYS USE):**
```typescript
// âœ… Fast, reliable, explicit, future-proof
const button = page.locator('#sidebar-start-session-btn');
const link = page.locator('#reg-transcript-canvas-btn');
```

**Component ID Discovery:**
Before writing ANY Playwright test, discover available IDs:
1. Open target component file (e.g., `HostControlPanelSidebar.razor`)
2. Search for `id="` attributes
3. Use those IDs in your test selectors
4. If no ID exists â†’ ADD ONE to the component (with `[REFACTOR:component-id]` comment)

**Enforcement:**
- Test reviews MUST reject text-based selectors
- CORTEX test-generator SHOULD warn when ID exists but text selector used
- Future: Automated crawler will build `KDS/cache/component-ids.json`

### Application Routes & Tokens

**Host Control Panel:**
- Route: `https://localhost:9091/host/control-panel/{hostToken}`
- Page File: `SPA/NoorCanvas/Pages/HostControlPanel.razor`
- Component File: `SPA/NoorCanvas/Components/Host/HostControlPanelContent.razor`
- Session 212 Token: `PQ9N5YWW`
- Full URL: `https://localhost:9091/host/control-panel/PQ9N5YWW`

**Component IDs (Host Control Panel):**
| Element | Component | ID | Purpose |
|---------|-----------|-----|---------|
| Transcript Canvas Button | UserRegistrationLink.razor | `reg-transcript-canvas-btn` | Select transcript canvas mode |
| Asset Canvas Button | UserRegistrationLink.razor | `reg-asset-canvas-btn` | Select asset canvas mode |
| Start Session Button | HostControlPanelSidebar.razor | `sidebar-start-session-btn` | Initiate session |
| Registration Link Container | UserRegistrationLink.razor | `reg-link-container` | Parent container for canvas buttons |

### Standard Protocol Pattern

**Reference Implementation:** `Scripts/run-debug-panel-percy-tests.ps1`

**Required Steps:**
1. âœ… Launch app using `Start-Job` with `dotnet run` (NOT Start-Process)
2. âœ… Wait for app readiness (20 seconds minimum, or health check loop)
3. âœ… Run Playwright tests using `npx playwright test [file] --headed`
4. âœ… Cleanup with `Stop-Job` and `Remove-Job` (unless -KeepAppRunning)

### Correct Pattern (FOLLOW THIS)

```powershell
param([switch]$KeepAppRunning)

# Step 1: Start app with Start-Job
$appJob = Start-Job -ScriptBlock {
    Set-Location 'D:\PROJECTS\NOOR CANVAS\SPA\NoorCanvas'
    dotnet run
}

# Step 2: Wait for readiness (20s minimum)
Start-Sleep -Seconds 20

# Step 3: Run Playwright tests
try {
    Set-Location 'D:\PROJECTS\NOOR CANVAS'
    npx playwright test Tests/UI/my-test.spec.ts --headed
    $exitCode = $LASTEXITCODE
}
finally {
    # Step 4: Cleanup
    if (-not $KeepAppRunning) {
        Stop-Job -Job $appJob -ErrorAction SilentlyContinue
        Remove-Job -Job $appJob -ErrorAction SilentlyContinue
    }
}

exit $exitCode
```

### WRONG Patterns (NEVER DO THIS)

âŒ **Using Start-Process with -ArgumentList:**
```powershell
# WRONG - Don't use Start-Process with complex arguments
$proc = Start-Process -FilePath "npx" -ArgumentList $testArgs -NoNewWindow -Wait -PassThru
```

âŒ **Using Invoke-WebRequest for health checks without proper error handling:**
```powershell
# WRONG - Complex health check that can fail unpredictably
$resp = Invoke-WebRequest -Uri $appUrl -SkipCertificateCheck -TimeoutSec 5
```

âŒ **Separating test running from working directory:**
```powershell
# WRONG - Don't Push-Location multiple times
Push-Location $testsPath
npx playwright test
Pop-Location
```

### Playwright Command Format

**Correct:**
```powershell
# Set working directory ONCE, then run test
Set-Location 'D:\PROJECTS\NOOR CANVAS'
npx playwright test Tests/UI/my-test.spec.ts --headed
```

**For Percy visual tests:**
```powershell
# Percy wraps Playwright
percy exec -- playwright test Tests/UI/my-test.spec.ts --headed
```

**Capture exit code:**
```powershell
npx playwright test Tests/UI/my-test.spec.ts --headed
$exitCode = $LASTEXITCODE
exit $exitCode
```

### Test Script Checklist

Before creating ANY Playwright test automation script, verify:

```
âœ“ Uses Start-Job (not Start-Process) for app launch?
âœ“ Waits minimum 20 seconds for app readiness?
âœ“ Sets working directory to project root (not Tests/UI)?
âœ“ Runs npx playwright test with direct command (no Start-Process)?
âœ“ Captures $LASTEXITCODE for exit status?
âœ“ Cleans up with Stop-Job and Remove-Job?
âœ“ Supports -KeepAppRunning parameter?

If ANY answer is NO â†’ FIX before running
```

### Reference Scripts

**Study these working examples:**
- âœ… `Scripts/run-debug-panel-percy-tests.ps1` - Full featured (health checks, Percy, detailed logging)
- âœ… `Scripts/run-transcript-canvas-visual-tests.ps1` - Simple pattern (20s wait, basic cleanup)
- âœ… `Scripts/run-fab-share-button-percy-tests.ps1` - Percy visual regression pattern

**Key Patterns:**
```powershell
# App Launch
$appJob = Start-Job -ScriptBlock {
    Set-Location 'D:\PROJECTS\NOOR CANVAS\SPA\NoorCanvas'
    dotnet run
}

# Wait Pattern (Simple)
Start-Sleep -Seconds 20

# Wait Pattern (Health Check - Advanced)
while ($attempt -lt $maxAttempts) {
    try {
        $resp = Invoke-WebRequest -Uri $appUrl -UseBasicParsing -TimeoutSec 5
        if ($resp.StatusCode -eq 200) { break }
    } catch {
        Start-Sleep -Seconds 2
    }
    $attempt++
}

# Test Execution
Set-Location 'D:\PROJECTS\NOOR CANVAS'
npx playwright test Tests/UI/my-test.spec.ts --headed
$exitCode = $LASTEXITCODE

# Cleanup
Stop-Job -Job $appJob -ErrorAction SilentlyContinue
Remove-Job -Job $appJob -ErrorAction SilentlyContinue
```

---

## ğŸ—ï¸ Architectural Thinking Mandate

**CRITICAL RULE: All CORTEX agents MUST think architecturally when proposing solutions.**

### Core Principles

**1. Architecture-First Design**
- âœ… Understand existing application architecture BEFORE proposing solutions
- âœ… Design solutions that naturally fit the current architecture from the start
- âŒ NEVER propose monolithic implementations that need refactoring later
- âŒ NEVER create "everything in one file" with intent to break apart later

**2. Pre-Flight Architectural Validation**
Every solution proposal must pass this refactor logic check:

```
BEFORE proposing a solution:
  â†“
1. Identify current architectural patterns
   - Component structure (where do similar components live?)
   - API organization (where do similar APIs exist?)
   - Service layer patterns (how are services currently structured?)
   - State management (what patterns are in use?)
   - File organization (what's the project structure?)
   â†“
2. Run mental refactor test
   - Would this solution require significant refactoring to fit the architecture?
   - Am I creating files that don't match existing conventions?
   - Am I mixing concerns that are separated elsewhere?
   â†“
3. If refactor is needed â†’ REDESIGN the solution
   - Align with existing patterns
   - Follow established separation of concerns
   - Place files in correct locations from the start
   â†“
4. Only then propose the architecturally-aligned solution
```

**3. Forbidden Anti-Patterns**

âŒ **NEVER do this:**
```
âŒ "Let's create everything in PageComponent.razor first, then we'll break out 
   the child components later"
   
âŒ "I'll add the API logic to the page for now, we can move it to a service later"

âŒ "Let's put this in a temporary location and reorganize after it works"

âŒ "We'll create the monolith first, then refactor to match your architecture"
```

âœ… **ALWAYS do this:**
```
âœ… "Based on the existing component structure in Components/Canvas/, 
   I'll create CanvasPdfExport.razor there and import it into the parent"
   
âœ… "Following the pattern in Services/, I'll create PdfExportService.cs 
   and inject it via DI as seen in other services"

âœ… "The existing API controllers are in Controllers/API/, so I'll create 
   PdfExportController.cs there with the same routing pattern"

âœ… "This matches the architecture - components are separated, services handle 
   business logic, and APIs are in the correct location from the start"
```

**4. Architectural Discovery Process**

Before proposing ANY solution, agents must:

```
Step 1: Discover Current Architecture
  - Search for similar features/components
  - Identify existing patterns and conventions
  - Map out file organization structure
  - Understand separation of concerns

Step 2: Pattern Matching
  - "Where do similar components live?"
  - "How are APIs currently organized?"
  - "What's the service layer pattern?"
  - "How is state managed?"

Step 3: Alignment Check
  - Does my solution follow these patterns?
  - Are files in the right locations?
  - Is separation of concerns maintained?
  - Would a developer familiar with this codebase find this natural?

Step 4: Propose Solution
  - Only after architectural alignment is confirmed
  - Explicitly state which patterns you're following
  - Show how it fits the existing structure
```

**5. Implementation Example**

**BAD (Anti-Pattern):**
```markdown
Plan: Add PDF export feature

Phase 1: Create basic implementation
  - Task 1.1: Add export logic to TranscriptCanvas.razor
  - Task 1.2: Test the functionality
  
Phase 2: Refactor to proper architecture
  - Task 2.1: Extract to PdfExportService
  - Task 2.2: Create dedicated component
  - Task 2.3: Move to API controller

âŒ This violates architectural thinking - refactoring is built into the plan!
```

**GOOD (Architecturally Aligned):**
```markdown
Plan: Add PDF export feature

Phase 0: Architectural Discovery
  - Task 0.1: Map existing service patterns (Services/)
  - Task 0.2: Identify component organization (Components/)
  - Task 0.3: Review API structure (Controllers/API/)

Phase 1: Test Infrastructure (following existing test patterns)
  - Task 1.1: Create PdfExportServiceTests.cs (Tests/Unit/Services/)
  - Task 1.2: Create PdfExportController tests (Tests/Unit/Controllers/)
  - Task 1.3: Create visual tests (Tests/UI/pdf-export.spec.ts)

Phase 2: Implementation (architecturally aligned from start)
  - Task 2.1: Create PdfExportService.cs in Services/
  - Task 2.2: Create PdfExportButton.razor in Components/Canvas/
  - Task 2.3: Create PdfExportController.cs in Controllers/API/
  - Task 2.4: Register service in DI (Program.cs pattern)

âœ… This is architecturally correct from the start - no refactoring needed!
```

**6. Agent-Specific Requirements**

**Work Planner (work-planner.md):**
- âœ… MUST include "Phase 0: Architectural Discovery" for new features
- âœ… Plans must show architectural alignment in task descriptions
- âœ… File paths must match existing conventions

**Code Executor (code-executor.md):**
- âœ… MUST verify file location matches architecture before creating
- âœ… MUST follow existing patterns for similar features
- âœ… MUST NOT create temporary/placeholder implementations

**Test Generator (test-generator.md):**
- âœ… Tests must mirror the application's architectural organization
- âœ… Test files must be placed following existing test structure

**7. Validation Checkpoint**

Before ANY code generation, agents must answer:

```
âœ“ Have I identified where similar code lives in this architecture?
âœ“ Am I following the existing file organization patterns?
âœ“ Is my separation of concerns consistent with the codebase?
âœ“ Would this solution require refactoring to fit the architecture?
âœ“ Am I creating files in their permanent, correct locations?

If ANY answer is NO â†’ STOP and redesign the solution
```

**8. Success Criteria**

A solution is architecturally valid when:
- âœ… No refactoring phase exists in the plan
- âœ… Files are in correct locations from creation
- âœ… Patterns match existing similar features
- âœ… Separation of concerns is maintained from start
- âœ… A developer familiar with the codebase would say "this fits naturally"

---

## ï¿½ğŸ¯ The ONLY Command You Need to Remember

```markdown
#file:KDS/prompts/user/cortex.md

[Tell CORTEX what you want in natural language]
```

That's it! CORTEX will automatically:
- âœ… Analyze your request (intent detection)
- âœ… Route to the appropriate specialist agent
- âœ… Execute the correct workflow
- âœ… Handle multi-step operations
- âœ… Maintain session state

---

## ğŸ“‹ What You Can Say

### Start New Work
```markdown
#file:KDS/prompts/user/cortex.md

I want to add a FAB button pulse animation when questions arrive
```
â†’ Routes to: **plan.md** â†’ work-planner.md

### Continue Existing Work
```markdown
#file:KDS/prompts/user/cortex.md

Continue working on the current task
```
â†’ Routes to: **execute.md** â†’ code-executor.md

### Resume After Break
```markdown
#file:KDS/prompts/user/cortex.md

Show me where I left off
```
â†’ Routes to: **resume.md** â†’ work-planner.md

### Fix Copilot's Mistake
```markdown
#file:KDS/prompts/user/cortex.md

You're modifying the wrong file. The FAB button is in HostControlPanelContent.razor
```
â†’ Routes to: **correct.md** â†’ code-executor.md

### Create Tests
```markdown
#file:KDS/prompts/user/cortex.md

Create visual regression tests for the share button
```
â†’ Routes to: **test.md** â†’ test-generator.md

### Check System Health
```markdown
#file:KDS/prompts/user/cortex.md

Run all validations and show me the health status
```
â†’ Routes to: **validate.md** â†’ health-validator.md

### Analyze Screenshot
```markdown
#file:KDS/prompts/user/cortex.md

Analyze this screenshot and extract requirements

[Attach screenshot via chat interface]
```
â†’ Routes to: **screenshot-analyzer.md** â†’ Extracts requirements, annotations, design specs

### Commit Changes (Automatic After Task Completion)
```markdown
#file:KDS/prompts/user/cortex.md

Commit changes
```
â†’ Uses: **KDS/scripts/commit-kds-changes.ps1** â†’ Smart commit handler achieving zero uncommitted files

**âš ï¸ NOTE: Commits happen AUTOMATICALLY after each task completion (Rule #16)**

You typically don't need to invoke this manually. CORTEX automatically commits after:
- âœ… Every task completes successfully
- âœ… All tests pass (GREEN)
- âœ… Post-implementation review passes
- âœ… Build validates with zero errors

**Manual use cases (when commits were skipped or failed):**
- ğŸ”„ Re-running commit after fixing validation issues
- ğŸ“ Committing documentation-only changes
- ğŸ§¹ Committing cleanup/reorganization work

**What automatic commits do:**
- âœ… Analyzes uncommitted files and categorizes them intelligently
- âœ… Auto-updates .gitignore for CORTEX auto-generated files (BRAIN state, internal prompts, reports)
- âœ… Resets auto-generated files that should not be committed (conversation-context.jsonl, etc.)
- âœ… Stages only user-created files (user prompts, documentation, code)
- âœ… Creates semantic commit messages (feat/fix/docs/chore)
- âœ… Achieves zero uncommitted files automatically
- âœ… Interactive mode for documentation decisions
- âœ… Dry-run mode for preview without changes

**Automatic .gitignore management:**
- CORTEX BRAIN state files (conversation-context.jsonl, conversation-history.jsonl, development-context.yaml)
- CORTEX internal prompts (auto-updated by system)
- CORTEX reports (monitoring/, self-review/, test-reports/)
- PlayWright CORTEX artifacts
- Temporary test files (.mjs, .spec.*)

**Example output:**
```
ğŸ§  CORTEX Smart Commit Handler
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Step 1: Analyzing uncommitted files...
  Modified files: 9
  Untracked files: 11

Step 2: Categorizing files...
Step 3: Updating .gitignore...
  Adding to .gitignore:
    + KDS/cortex-brain/conversation-context.jsonl
    + KDS/prompts/internal/*.md
    + KDS/reports/monitoring/
  âœ… .gitignore updated with CORTEX patterns

Step 4: Resetting auto-generated files...
  Resetting:
    - KDS/cortex-brain/conversation-context.jsonl
    - KDS/prompts/internal/code-executor.md
  âœ… Reset 2 auto-generated files

Step 5: Preparing commit...
  Files to commit: 3
    + KDS/prompts/user/cortex.md
    + KDS/dashboard/README.md
    + .gitignore

Step 6: Staging files...
  âœ… Files staged

Step 7: Committing...
  âœ… Changes committed

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… SUCCESS: Zero uncommitted files!
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**Usage:**
```powershell
# Interactive mode (default)
.\KDS\scripts\commit-kds-changes.ps1

# With custom message
.\KDS\scripts\commit-kds-changes.ps1 -Message "feat(kds): Add dashboard"

# Dry run (preview without changes)
.\KDS\scripts\commit-kds-changes.ps1 -DryRun

# Non-interactive (auto-include all documentation)
.\KDS\scripts\commit-kds-changes.ps1 -Interactive:$false
```

### Ask Questions
```markdown
#file:KDS/prompts/user/cortex.md

How do I use Playwright to test the canvas element?
```
â†’ Routes to: **ask-cortex.md** â†’ knowledge-retriever.md

### Review CORTEX Changes
```markdown
#file:KDS/prompts/user/cortex.md

I updated the test-generator to support Percy visual testing
```
â†’ Routes to: **govern.md** â†’ change-governor.md

### View Performance Metrics
```markdown
#file:KDS/prompts/user/cortex.md

run metrics
```
â†’ Routes to: **metrics-reporter.md** â†’ Generates visual performance report

Output destination (for historical comparison):
- A Markdown report is written to `KDS/reports/metrics/<YYYY-MM-DD>/metrics-<timestamp>.md`
- A convenience copy is saved at `KDS/reports/metrics/latest.md`

Notes:
- Reports are visual with bar displays and contain no code snippets.
- Because reports live in the repository, Git naturally versions them so you can compare trends over time.

**What it shows:**
- âœ… BRAIN health score and trends
- âœ… Routing accuracy by intent type
- âœ… Knowledge graph growth visualization
- âœ… File hotspots (high-churn files)
- âœ… Code velocity trends
- âœ… Test-first impact analysis
- âœ… Productivity patterns (best times to work)
- âœ… Auto-learning performance
- âœ… Month-over-month improvements
- âœ… Actionable recommendations

**Example output:**
```
ğŸ“Š Quick Stats
Routing Accuracy: 94% â–² +3% ğŸŸ¢ Excellent
Learning Efficiency: 92% â–² +12% ğŸŸ¢ Excellent

ğŸ§  BRAIN Storage
Tier 1: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 8/20 (40%)
Tier 2: 3,847 entries (+247 this month)
Tier 3: 1,547 commits analyzed

ğŸ”¥ File Hotspots
HostControlPanelContent.razor  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 28% churn âš ï¸
UserRegistrationLink.razor     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ 24% churn âš ï¸

ğŸ’¡ Recommendations
1. Continue test-first (96% success rate)
2. Work 10am-12pm (94% peak productivity)
3. Refactor hotspots (>20% churn)
4. Keep sessions <60 min (89% vs 67%)
```

**â±ï¸ Report time:** ~90 seconds to read

---

### Reset BRAIN for New Application (Amnesia)
```markdown
#file:KDS/prompts/user/cortex.md

Reset BRAIN for new application
```
â†’ Routes to: **brain-amnesia.md** â†’ Safely removes application-specific data

Or run directly:
```powershell
.\KDS\scripts\brain-amnesia.ps1
```

**What it does:**
- âœ… Creates backup of current BRAIN state
- âœ… Generates amnesia report (shows what will be removed vs preserved)
- âœ… Removes application-specific data (file paths, workflows, conversations)
- âœ… Preserves CORTEX core intelligence (generic patterns, governance)
- âœ… Resets BRAIN to fresh state ready for new project

**âš ï¸ CRITICAL: What Gets Removed (Application-Specific)**
```yaml
WILL BE REMOVED:
  - All file relationships (e.g., SPA/NoorCanvas paths)
  - Application-specific workflows (e.g., blazor_component_api_flow)
  - All conversations (application context)
  - All events (application interactions)
  - Development metrics (git stats, velocity)
  - Feature components (e.g., fab_button)
```

**âœ… GUARANTEED: What Gets Preserved (CORTEX Intelligence)**
```yaml
WILL BE PRESERVED:
  - Generic intent patterns ("add [X] button" â†’ plan)
  - Generic workflow patterns (test_first_id_preparation)
  - KDS-specific patterns (kds_health_monitoring, brain_test_synchronization)
  - Protection configuration (confidence thresholds)
  - All 10 specialist agents
  - All governance rules
  - All CORTEX prompts and scripts
```

**Use Cases:**
- ğŸ”„ Moving CORTEX to a completely new project
- ğŸ†• Starting fresh with a different application
- ğŸ§¹ Cleaning BRAIN after experimenting with test project
- ğŸ“¦ Preparing CORTEX for distribution to new team/project

**Safety:**
- âœ… Backup created before any changes
- âœ… Dry-run mode available (`-DryRun` parameter)
- âœ… Requires confirmation (type 'AMNESIA' to proceed)
- âœ… Full rollback possible from backup
- âœ… BRAIN integrity verified after amnesia

**Example Output:**
```
ğŸ§  CORTEX BRAIN Amnesia - Application Data Reset
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

[1/8] Validating BRAIN system...
âœ… BRAIN structure validated

[2/8] Analyzing BRAIN data...
  Application-specific workflows: 12
  Generic/CORTEX workflows: 6
  Conversations: 5
  Events: 68

[4/8] Amnesia Impact Summary

  WILL BE REMOVED:
    - 5 conversations (application context)
    - 68 events (application interactions)
    - ~12 application-specific patterns
    - All NoorCanvas file relationships
    - All development metrics

  WILL BE PRESERVED:
    - All 10 CORTEX specialist agents
    - ~6 generic/CORTEX workflow patterns
    - Generic intent detection templates
    - Protection configuration
    - All CORTEX governance rules

âš ï¸  Type 'AMNESIA' to confirm reset: AMNESIA

[5/8] Creating backup...
âœ… Backup created: KDS/cortex-brain/backups/pre-amnesia-20251104-143022

[6/8] Executing BRAIN amnesia...
âœ… BRAIN amnesia complete

[7/8] Verifying BRAIN integrity...
âœ… BRAIN integrity verified

[8/8] Generating completion report...
âœ… Completion report saved

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… BRAIN AMNESIA COMPLETE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Next Steps:
  1. Update KDS/tooling/cortex.config.json (new project name/paths)
  2. Run: #file:KDS/prompts/user/cortex.md Setup
  3. CORTEX will learn your new application architecture
```

**Post-Amnesia Workflow:**
1. âœ… Amnesia complete (BRAIN reset)
2. Update `cortex.config.json` with new project details
3. Run `Setup` command to discover new application
4. CORTEX automatically learns from new interactions
5. BRAIN rebuilds application-specific knowledge over time

**Rollback (if needed):**
```powershell
# Restore from backup
$backupDir = "KDS/cortex-brain/backups/pre-amnesia-{timestamp}"
Copy-Item -Path "$backupDir/*.yaml" -Destination "KDS/cortex-brain/" -Force
Copy-Item -Path "$backupDir/*.jsonl" -Destination "KDS/cortex-brain/" -Force
```

---

## ğŸ§  CORTEX Health Dashboard

**Purpose:** Visual monitoring dashboard for CORTEX system health, BRAIN status, and development metrics.

### Launch Dashboard

```markdown
#file:KDS/prompts/user/cortex.md launch dashboard
```

Or directly:
```powershell
.\KDS\scripts\launch-dashboard.ps1
```

**What it does:**
- âœ… Starts API server in a **separate visible PowerShell window**
- âœ… Opens dashboard in your default browser
- âœ… Provides real-time health monitoring
- âœ… Shows visual feedback for all operations

**âš ï¸ PERMANENT RULE: API Server Window Behavior**

The API server MUST run in a **separate visible PowerShell window**, NOT as a background job.

**Rationale:**
- âœ… User can see server logs in real-time
- âœ… Easy to stop (just close the window or Ctrl+C)
- âœ… Clear visual indicator that server is running
- âœ… No hidden background processes
- âŒ Background jobs are invisible and hard to manage
- âŒ Users couldn't tell if server was running

**Implementation:**
```powershell
# CORRECT - Separate visible window
Start-Process pwsh -ArgumentList "-NoExit", "-Command", "cd '$workspaceRoot'; .\KDS\scripts\dashboard-api-server.ps1"

# WRONG - Background job (DO NOT USE)
$job = Start-Job -ScriptBlock { ... }
```

### Dashboard Features

**Visual Loading Feedback:**
- ğŸ“Š Progress bar at top of page during operations
- ğŸ”„ Loading overlay with detailed status messages
- â±ï¸ Real-time progress updates
- ğŸ¯ Stats start at 0 and refresh with live data

**Health Check Categories:**
- ğŸ—ï¸ Infrastructure (files, directories, permissions)
- ğŸ¤– Agents & Prompts (all 10 specialist agents)
- ğŸ§  BRAIN System (3-tier architecture)
- ğŸ’¾ Session State (active sessions, history)
- ğŸ“š Knowledge Base (graph, patterns, context)
- ğŸ”§ Scripts & Tools (PowerShell, validation)
- âš¡ Performance (response times, efficiency)

**Actions:**
- ğŸ”„ **Refresh** - Run all health checks (shows loading feedback)
- ğŸ“‹ **Copy to Clipboard** - Copy health report JSON (with fallback for file:// protocol)
- ğŸ“Š **Export Report** - Download JSON file

**Connection States:**
- ğŸ”— **Live** - API server connected, real data
- ğŸ”Œ **Disconnected** - API server not running (shows retry button)

### Copy to Clipboard Feature

**Multi-Layer Fallback System:**

1. **Modern Clipboard API** (HTTPS/secure context)
   ```javascript
   navigator.clipboard.writeText(jsonText)
   ```

2. **Legacy execCommand** (HTTP/file:// protocol)
   ```javascript
   document.execCommand('copy')
   ```

3. **Manual Prompt** (Last resort)
   ```javascript
   prompt('Copy this JSON (Ctrl+C):', jsonText)
   ```

**Why fallback is needed:**
- âš ï¸ Dashboard runs on `file://` protocol (not HTTPS)
- âš ï¸ Modern clipboard API requires secure context
- âœ… Fallback ensures copy works in all scenarios
- âœ… Always provides a way to get the JSON

### To Stop Dashboard

**Option 1:** Close the API server PowerShell window

**Option 2:** Press Ctrl+C in the API server window

**Option 3:** Just close your browser (server keeps running until manually stopped)

**Dashboard remains functional** in disconnected mode - you can view cached data and retry connection.

---

## ğŸ“Š Comprehensive CORTEX Dashboard (Unified Entry Point)

**Purpose:** Single comprehensive dashboard for all CORTEX monitoring - health checks, BRAIN metrics, efficiency tracking, and activity logs.

**File:** `KDS/cortex-dashboard.html`  
**Technology:** HTML + Chart.js (with optional API server for real-time data)

### Launch Dashboard

**Quick Launch (Recommended):**
```powershell
.\KDS\scripts\launch-dashboard.ps1
```
This starts the API server AND opens the dashboard automatically.

**Manual Launch:**
```
Open: D:\PROJECTS\KDS\cortex-dashboard.html
```
Or double-click the file in File Explorer.

### Dashboard Tabs

**Tab 1: ğŸ“Š Overview**
- System health summary (6 interactive cards)
- Quick status of infrastructure, agents, BRAIN, sessions, knowledge
- Click any card to drill down into health checks

**Tab 2: ğŸ¥ Health Checks**
- Detailed health validation across 7 categories
- Expandable sections with individual check results
- Status indicators (passed/warning/critical)
- Actionable recommendations for failures

**Tab 3: ğŸ§  BRAIN System**
- BRAIN integrity status (all 13 integrity checks)
- Event stream monitoring
- Knowledge graph health
- Real-time issue detection

**Tab 4: ğŸ“ˆ Metrics** (Enhanced with Brain Efficiency)
- **Brain Efficiency Score**: Overall efficiency (0-100%) with letter grade
- **Component Breakdown**: Visual bars showing routing, planning, TDD, learning, coordination
- **Efficiency Trends**: 30-day line chart of performance
- **Component Pie Chart**: Weighted contribution visualization
- **Individual Metrics**: Routing accuracy, plan time, TDD cycle, learning effectiveness, coordination latency
- **Standard Metrics**: BRAIN health, knowledge graph, file hotspots, event activity, test success
- **Smart Recommendations**: AI-generated suggestions based on performance data

**Tab 5: ğŸ“ Activity Log**
- Recent system activities
- Event timeline
- Agent actions tracking

### Features

**Real-Time Updates:**
- âœ… Auto-refresh every 30 seconds (configurable)
- ğŸ”„ Manual refresh button
- ğŸ“¡ Live connection status indicator

**Brain Efficiency Integration:**
- ğŸ¯ Overall efficiency score with trend indicators
- ğŸ“Š Component performance bars (5 components)
- ğŸ“ˆ Historical trend charts (30 days)
- ğŸ’¡ Smart recommendations based on metrics

**Visual Feedback:**
- âœ… Color-coded status (green/yellow/red)
- ï¿½ Interactive charts (hover for details)
- ğŸ¨ Dark theme optimized for long viewing
- âš¡ Smooth animations and transitions

### How to Use

**Step 1: Launch dashboard**
```powershell
.\KDS\scripts\launch-dashboard.ps1
```

**Step 2: Collect brain efficiency data (for Metrics tab)**
```powershell
.\KDS\scripts\corpus-callosum\collect-brain-metrics.ps1
```

**Step 3: Navigate tabs**
- Click tab buttons to switch between views
- Overview â†’ Quick health summary
- Health â†’ Detailed validation results
- BRAIN System â†’ Integrity checks
- Metrics â†’ Performance analysis (includes efficiency dashboard)
- Activity â†’ Recent events

**Step 4: Monitor and act**
- Review efficiency score and grade
- Check trend indicators (â–² improving, â–¼ declining)
- Read smart recommendations
- Address any warnings or failures

### Efficiency Calculation (Metrics Tab)

```
Overall Score = 
  (Routing Accuracy Ã— 25%) +
  (Planning Speed Ã— 20%) +
  (TDD Speed Ã— 20%) +
  (Learning Effectiveness Ã— 25%) +
  (Coordination Speed Ã— 10%)
```

**Grading:**
- **A+** (90-100%): Excellent - Peak efficiency
- **A** (85-90%): Very good - Continue current practices
- **B** (80-85%): Good - Minor improvements possible
- **C** (70-80%): Acceptable - Review recommendations
- **D** (<70%): Needs attention - Address warnings immediately

### Data Sources

**Real-time (via API server):**
- Health checks â†’ `run-health-checks.ps1`
- BRAIN metrics â†’ `test-brain-integrity.ps1`
- Standard metrics â†’ API aggregation

**Efficiency data (file-based):**
- **Reads from:** `KDS/cortex-brain/corpus-callosum/efficiency-history.jsonl`  
- **Generated by:** `collect-brain-metrics.ps1`  
**Update frequency:** Manual or scheduled (recommend daily)

**Optional: Automate collection**
```powershell
# Windows Task Scheduler (daily at 9am)
$trigger = New-ScheduledTaskTrigger -Daily -At 9am
$action = New-ScheduledTaskAction -Execute 'PowerShell.exe' `
    -Argument '-File "D:\PROJECTS\KDS\scripts\corpus-callosum\collect-brain-metrics.ps1"'
Register-ScheduledTask -TaskName "KDS-Metrics-Collection" `
    -Trigger $trigger -Action $action
```

**Dashboard remains functional** in disconnected mode - you can view cached data and retry connection.

---

## ğŸš€ First-Time Setup (New Application Installation)

**When to use this:** You're installing CORTEX in a new application (e.g., a fresh project like `https://github.com/yourname/new-project`)

**Purpose:** Complete CORTEX initialization with brain absorption, crawlers, and knowledge graph population for application-specific intelligence.

### Setup Command

```markdown
#file:KDS/prompts/user/cortex.md Setup
```

This triggers the complete CORTEX initialization sequence.

**â±ï¸ Expected Duration: 15-20 minutes** (padded estimate)
- Small project (<1000 files): ~10-12 minutes
- Medium project (1000-5000 files): ~15-18 minutes  
- Large project (>5000 files): ~20-25 minutes

**ğŸ”” Status Updates:** You'll receive progress updates every 30-60 seconds so you know the system is working.

---

### ğŸ“‹ Setup Sequence (Automatic)

When you invoke `Setup`, CORTEX executes this sequence:

**âš™ï¸ RULE: Long-Running Process Protocol**

ALL long-running operations (>30 seconds) in CORTEX MUST:
1. âœ… Display padded time estimate upfront (add 25-50% buffer)
2. âœ… Show phase-by-phase progress indicators
3. âœ… Provide status updates every 30-60 seconds
4. âœ… Display percentage complete when measurable
5. âœ… Show "Still working..." heartbeat for CPU-intensive tasks
6. âœ… Explain what's happening (not just "Processing...")
7. âœ… Allow graceful interruption (Ctrl+C with cleanup)

**Examples of long-running operations:**
- Setup sequence (15-20 min)
- Deep crawler (5-10 min)
- Development context collection (2-5 min)
- BRAIN updates with large event backlogs (1-3 min)
- Test suite runs (varies)
- Build processes (varies)

**See:** Full protocol at end of this section

#### Phase 1: Environment Validation (2-3 minutes)

**Status Display:**
```
ğŸš€ CORTEX Setup - Phase 1/6: Environment Validation
â±ï¸  Estimated time: 2-3 minutes
ğŸ“Š Progress: [â–“â–“â–“â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0%

â³ Checking CORTEX structure...
```

**Step 1.1: Verify CORTEX Structure**
```
âœ“ Check KDS/ directory exists
âœ“ Verify all core agents present (10 specialist agents)
âœ“ Validate BRAIN directories (cortex-brain/, sessions/, knowledge/)
âœ“ Check abstraction layer (session-loader, test-runner, file-accessor)

Status: âœ… CORTEX structure verified (10/10 agents found)
```

**Step 1.2: Detect Application Type**
```
â³ Analyzing application type...

âœ“ Identify primary language (C#, TypeScript, Python, etc.)
âœ“ Detect frameworks (ASP.NET, React, Django, etc.)
âœ“ Find build tools (dotnet, npm, pip, etc.)
âœ“ Locate test frameworks (Playwright, Jest, xUnit, etc.)

Status: âœ… Detected: C# + ASP.NET Core 8.0 + Playwright
```

**Step 1.3: Validate Dependencies**
```
â³ Checking system dependencies...

âœ“ Check Git is available (required for context collection)
âœ“ Verify PowerShell/Bash (for scripts)
âœ“ Confirm workspace structure is readable
âœ“ Test file system permissions

Status: âœ… All dependencies available

ğŸ“Š Progress: [â–“â–“â–“â–“â–“â–‘â–‘â–‘â–‘â–‘] 20% - Phase 1 complete
```

**Output:** Environment validation report

---

#### Phase 2: BRAIN Initialization (7-12 minutes)

**Status Display:**
```
ğŸš€ CORTEX Setup - Phase 2/6: BRAIN Initialization
â±ï¸  Estimated time: 7-12 minutes (longest phase)
ğŸ“Š Progress: [â–“â–“â–“â–“â–“â–‘â–‘â–‘â–‘â–‘] 20%

âš ï¸  This phase takes the longest - please be patient!
```

**Step 2.1: Create BRAIN Storage**
```
â³ Creating BRAIN directory structure...

âœ“ Initialize KDS/cortex-brain/ directory structure
  - conversation-history.jsonl (Tier 1 - empty initially)
  - knowledge-graph.yaml (Tier 2 - base template)
  - development-context.yaml (Tier 3 - empty initially)
  - events.jsonl (event stream - empty)
  - crawler-state.yaml (crawler tracking)
âœ“ Set up session storage (KDS/sessions/)
âœ“ Create knowledge repository (KDS/knowledge/)

Status: âœ… BRAIN storage created
ğŸ“Š Progress: [â–“â–“â–“â–“â–“â–“â–‘â–‘â–‘â–‘] 25%
```

**Step 2.2: Run Deep Codebase Crawler**
```
â³ Starting deep codebase crawl...
â±ï¸  This will take 5-10 minutes depending on project size

Invoke: #file:KDS/prompts/internal/brain-crawler.md
Mode: deep
Duration: 5-10 minutes

Status updates every 60 seconds:
  [00:30] ğŸ“‚ Discovered 247 files (still scanning...)
  [01:00] ğŸ“‚ Discovered 612 files (analyzing structure...)
  [01:30] ğŸ“‚ Discovered 1,089 files (mapping relationships...)
  [02:00] ğŸ” Parsing file contents (324/1,089 files)
  [02:30] ğŸ” Parsing file contents (687/1,089 files)
  [03:00] ğŸ” Analyzing imports and dependencies...
  [03:30] ğŸ“Š Building relationship graph...
  [04:00] ğŸ¯ Detecting naming conventions...
  [04:30] âœ… Crawler complete - generating report...

What it discovers:
âœ“ File structure & architecture (where components/services/tests live)
âœ“ Code relationships (dependencies, imports, DI patterns)
âœ“ Test patterns (frameworks, selectors, test data)
âœ“ Technology stack (languages, frameworks, libraries)
âœ“ Naming conventions (PascalCase, kebab-case, etc.)
âœ“ Configuration patterns (appsettings hierarchy, env vars)
âœ“ Documentation locations (README files, API docs)
âœ“ **Database schemas (SQL files FIRST, then connection strings)** ğŸ†•

**Database Discovery Priority (NEW v1.1.0):**
  1ï¸âƒ£ FIRST: Scan for SQL schema/data files (*schema*.sql, *data*.sql)
     - Analyzes CREATE TABLE, INSERT INTO statements
     - Extracts table names, relationships
     - Brain can reference these files (no database connection needed!)
  
  2ï¸âƒ£ SECOND: Look for connection strings (appsettings.json, .env)
     - Discovers database provider (SQL Server, PostgreSQL, etc.)
     - Finds Entity Framework models and migrations
  
  3ï¸âƒ£ THIRD: Connect to database (only if no SQL files found)
     - Prompts for connection string if not found
     - Memorizes it for future use (KDS/cortex-brain/database-connection.txt)
     - Crawls live schema (tables, columns)
  
  âš¡ Result: 10x faster when SQL files exist! (~30s vs 2-5 min)
  
  See: `KDS/docs/features/database-crawler-sql-file-priority.md` for details

Feeds BRAIN with:
  - architectural_patterns (Components/**/*.razor)
  - file_relationships (co-modification patterns)
  - test_patterns (Playwright, session-212, data-testid)
  - conventions (naming, file organization)
  - technology_stack (complete inventory)

Status: âœ… Crawler discovered 1,089 files, 3,247 relationships
ğŸ“Š Progress: [â–“â–“â–“â–“â–“â–“â–“â–‘â–‘â–‘] 35%
```

**Output:** Crawler report (`KDS/cortex-brain/crawler-report-{timestamp}.md`)

**Step 2.3: Initialize Development Context (Tier 3)**
```
â³ Collecting development metrics (2-5 minutes)...

Invoke: #file:KDS/prompts/internal/development-context-collector.md

Status updates:
  [00:30] ğŸ“Š Analyzing Git history (last 30 days)...
  [01:00] ğŸ“Š Processing 1,237 commits...
  [01:30] ğŸ“Š Calculating code velocity...
  [02:00] ğŸ“Š Identifying file hotspots...
  [02:30] ğŸ“Š Analyzing test patterns...
  [03:00] ğŸ“Š Building baseline metrics...

What it collects:
âœ“ Git activity (last 30 days of commits)
âœ“ Code change velocity (lines added/deleted per week)
âœ“ File hotspots (high churn rate files)
âœ“ CORTEX session history (if any exist)
âœ“ Testing activity (if tests exist)
âœ“ Build/deploy patterns (if scripts exist)

Feeds BRAIN with:
  - Baseline metrics (velocity, churn, activity)
  - Productivity patterns (commit frequency)
  - File stability analysis (churn rates)
  - Initial correlations (commit size vs complexity)

Status: âœ… Collected metrics from 1,237 commits, 78 tests
ğŸ“Š Progress: [â–“â–“â–“â–“â–“â–“â–“â–“â–‘â–‘] 45%
```

**Output:** `KDS/cortex-brain/development-context.yaml` (baseline metrics)

---

#### Phase 3: Knowledge Graph Population (3-5 minutes)

**Status Display:**
```
ğŸš€ CORTEX Setup - Phase 3/6: Knowledge Graph Population
â±ï¸  Estimated time: 3-5 minutes
ğŸ“Š Progress: [â–“â–“â–“â–“â–“â–“â–“â–“â–‘â–‘] 45%

â³ Processing crawler discoveries...
```

**Step 3.1: Process Crawler Results**
```
â³ Transforming discoveries into knowledge graph...

Invoke: #file:KDS/prompts/internal/brain-updater.md
Mode: bootstrap

Status updates:
  [00:30] ğŸ§  Processing 3,247 relationships...
  [01:00] ğŸ§  Assigning confidence scores...
  [01:30] ğŸ§  Creating file_relationships section (1,247 entries)
  [02:00] ğŸ§  Creating architectural_patterns section (127 patterns)
  [02:30] ğŸ§  Creating validation_insights section...

Actions:
âœ“ Transform crawler discoveries into knowledge graph entries
âœ“ Assign confidence scores (0.50 - 0.98)
  - Direct observations (imports): 0.95+ confidence
  - Pattern inference (naming): 0.70-0.85 confidence
  - Statistical (co-modification): 0.50-0.70 confidence
âœ“ Create file_relationships section
âœ“ Create architectural_patterns section
âœ“ Create validation_insights section
âœ“ Create intent_patterns (empty, will learn from usage)

Status: âœ… Knowledge graph populated with 3,247 entries
ğŸ“Š Progress: [â–“â–“â–“â–“â–“â–“â–“â–“â–“â–‘] 55%
```

**Step 3.2: Build Intent Vocabulary (Bootstrapping)**
```
â³ Bootstrapping intent patterns...

If generic patterns available (from templates):
  âœ“ Import common intent patterns
    - "add a button" â†’ PLAN intent
    - "create service" â†’ PLAN intent
    - "continue" â†’ EXECUTE intent
  âœ“ Seed with generic workflow patterns
    - UI feature: plan â†’ execute â†’ test
    - API endpoint: plan â†’ execute â†’ unit-test â†’ integration-test
  âœ“ Import common file confusion warnings
    - "HostControlPanel vs HostControlPanelContent"
    
If no templates:
  âœ“ Start with empty intent_patterns
  âœ“ BRAIN will learn from first interactions

Status: âœ… Intent vocabulary seeded with 47 patterns
ğŸ“Š Progress: [â–“â–“â–“â–“â–“â–“â–“â–“â–“â–‘] 60%
```

**Step 3.3: Validate Knowledge Graph**
```
â³ Validating knowledge graph integrity...

âœ“ Run structure validation (YAML syntax)
âœ“ Check confidence score ranges (0.50-1.00)
âœ“ Verify file references exist
âœ“ Test query functionality
âœ“ Run protection rules check

Status: âœ… Knowledge graph validated successfully
ğŸ“Š Progress: [â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“] 65%
```

**Output:** `KDS/cortex-brain/knowledge-graph.yaml` (fully populated)

---

#### Phase 4: Three-Tier BRAIN Setup (1-2 minutes)

**Status Display:**
```
ğŸš€ CORTEX Setup - Phase 4/6: Three-Tier BRAIN Setup
â±ï¸  Estimated time: 1-2 minutes
ğŸ“Š Progress: [â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“] 65%

â³ Configuring three-tier architecture...
```

**Step 4.1: Initialize Tier 1 (Conversation History)**
```
â³ Setting up conversation memory...

âœ“ Create conversation-history.jsonl
âœ“ Set FIFO queue capacity (20 conversations)
âœ“ Initialize first conversation (the setup itself)
âœ“ Configure conversation boundary detection

Status: âœ… Tier 1 initialized
ğŸ“Š Progress: [â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“] 70%
```

**Step 4.2: Verify Tier 2 (Knowledge Graph)**
```
â³ Verifying knowledge graph...

âœ“ Confirm knowledge-graph.yaml populated
âœ“ Test brain-query queries
âœ“ Verify all sections present:
  - intent_patterns
  - file_relationships
  - workflow_patterns
  - validation_insights
  - correction_history

Status: âœ… Tier 2 verified (3,247 entries)
ğŸ“Š Progress: [â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“] 75%
```

**Step 4.3: Verify Tier 3 (Development Context)**
```
â³ Verifying development context...

âœ“ Confirm development-context.yaml has baseline metrics
âœ“ Test proactive_warnings generation
âœ“ Verify correlation analysis available
âœ“ Check hotspot detection working

Status: âœ… Tier 3 verified (baseline metrics ready)
ğŸ“Š Progress: [â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“] 80%
```

**Step 4.4: Enable Automatic Learning**
```
â³ Configuring automatic learning...

âœ“ Configure event logging (all agents â†’ events.jsonl)
âœ“ Set automatic update triggers:
  - 50+ events â†’ brain-updater.md
  - 24 hours â†’ brain-updater.md (if 10+ events)
âœ“ Enable Tier 3 collection (runs after brain updates)
âœ“ Verify Rule #16 Step 5 compliance (event count check)

Status: âœ… Automatic learning enabled
ğŸ“Š Progress: [â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“] 85%
```

**Output:** Three-tier BRAIN fully operational

---

#### Phase 5: Testing & Validation (2-3 minutes)

**Status Display:**
```
ğŸš€ CORTEX Setup - Phase 5/6: Testing & Validation
â±ï¸  Estimated time: 2-3 minutes
ğŸ“Š Progress: [â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“] 85%

â³ Running validation checks...
```

**Step 5.1: Test Core Workflows**
```
â³ Testing CORTEX components...

âœ“ Test intent routing (sample phrases)
  - "I want to add a feature" â†’ Should route to PLAN
  - "Continue" â†’ Should detect no session, prompt accordingly
âœ“ Test BRAIN queries
  - Query architectural_patterns â†’ Should return discovered structure
  - Query file_relationships â†’ Should return co-modification data
âœ“ Test file operations
  - session-loader.md â†’ Should create/read session files
  - file-accessor.md â†’ Should read/write application files

Status: âœ… All core workflows tested successfully
ğŸ“Š Progress: [â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“] 90%
```

**Step 5.2: Run Health Validator**
```
â³ Running comprehensive health check...

Invoke: #file:KDS/prompts/internal/health-validator.md

Checks:
âœ“ All agents loadable
âœ“ BRAIN files readable/writable
âœ“ Knowledge graph valid
âœ“ Session storage functional
âœ“ Test framework detection working
âœ“ Git integration working

Status: âœ… All health checks passed
ğŸ“Š Progress: [â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“] 93%
```

**Step 5.3: Generate Setup Report**
```
â³ Generating setup report...

Create: KDS/setup-report-{timestamp}.md

Contents:
âœ“ Environment summary (languages, frameworks, tools)
âœ“ Discovered patterns (components, services, tests)
âœ“ BRAIN status (all 3 tiers operational)
âœ“ File counts (components: 89, services: 34, tests: 120)
âœ“ Known issues (if any)
âœ“ Next steps (ready to use!)

Status: âœ… Report generated
ğŸ“Š Progress: [â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“] 95%
```

**Output:** Setup complete confirmation

---

#### Phase 6: First Interaction Guidance (1 minute)

**Status Display:**
```
ğŸš€ CORTEX Setup - Phase 6/6: Finalizing
â±ï¸  Estimated time: 1 minute
ğŸ“Š Progress: [â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“] 95%

â³ Preparing your workspace...
```

**Step 6.1: Show User Quick Start**
```
â³ Generating getting started guide...

Display:
  âœ… Setup complete! CORTEX is ready.
  
  ğŸ“Š What CORTEX learned about your application:
  - Technology: {detected stack}
  - Components: {count} files in {location}
  - Services: {count} files in {location}
  - Tests: {count} files, {framework} framework
  - Conventions: {naming patterns}
  
  ğŸ§  BRAIN Status:
  - Tier 1 (Conversations): Initialized
  - Tier 2 (Knowledge Graph): {entry_count} entries
  - Tier 3 (Dev Context): Baseline metrics collected
  
  ğŸš€ Ready to start!
  
  Try: #file:KDS/prompts/user/cortex.md
       I want to [describe your first feature]

Status: âœ… Setup complete!
ğŸ“Š Progress: [â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“] 98%
```

**Step 6.2: Log Setup Event**
```
â³ Finalizing...

âœ“ Record setup completion in events.jsonl
âœ“ Create first conversation in conversation-history.jsonl
âœ“ Mark setup as successful in crawler-state.yaml

Status: âœ… All done!
ğŸ“Š Progress: [â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“] 100% âœ¨

â±ï¸  Total time: 15m 32s
```

---

### ğŸ“Š Long-Running Process Protocol (UNIVERSAL RULE)

**APPLIES TO:** All CORTEX operations >30 seconds

**Required Elements:**

1. **Upfront Expectation Setting**
   ```
   â±ï¸  Estimated time: X-Y minutes (padded 25-50%)
   âš ï¸  This is the longest phase - please be patient!
   ```

2. **Visual Progress Indicators**
   ```
   ğŸ“Š Progress: [â–“â–“â–“â–“â–“â–“â–“â–‘â–‘â–‘] 45%
   ğŸ”„ Phase 3/6: Knowledge Graph Population
   ```

3. **Heartbeat Status Updates**
   ```
   Every 30-60 seconds:
   [00:30] Still working on X... (detail what's happening)
   [01:00] Processing Y... (show counts/progress)
   [01:30] Almost done with Z... (reassure user)
   ```

4. **Informative Messages**
   ```
   âŒ BAD: "Processing..." (vague, scary)
   âœ… GOOD: "Analyzing 1,247 commits for velocity patterns..."
   
   âŒ BAD: "Please wait..." (no context)
   âœ… GOOD: "Scanning 612 files for architectural patterns (2m 30s elapsed)"
   ```

5. **Completion Confirmation**
   ```
   Status: âœ… Phase complete in 4m 23s
   ğŸ“Š Progress: [â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“] 65% â†’ 75%
   ```

6. **Graceful Interruption**
   ```
   â¸ï¸  You can press Ctrl+C to cancel
   âš ï¸  Cleanup will run automatically if interrupted
   ```

7. **Error Recovery Guidance**
   ```
   If something goes wrong:
   âŒ Error at Phase 3 (2m 15s elapsed)
   ğŸ’¡ You can:
      1. Retry this phase only
      2. Skip and continue (if non-critical)
      3. Cancel and review logs
   ```

**Implementation Checklist:**

For ALL long-running operations, verify:
- â˜ Padded time estimate shown upfront (realistic + buffer)
- â˜ Phase/step breakdown displayed
- â˜ Progress bar or percentage shown
- â˜ Status updates every 30-60 seconds minimum
- â˜ Detailed "what's happening now" messages
- â˜ Elapsed time counter visible
- â˜ Graceful Ctrl+C handling
- â˜ Clear completion confirmation
- â˜ Error messages with recovery options

**Examples in KDS:**

```markdown
Long-Running Operations:
âœ“ Setup (15-20 min) - Has all required elements above
âœ“ Deep Crawler (5-10 min) - Needs status updates added
âœ“ Development Context Collection (2-5 min) - Needs progress bar
âœ“ BRAIN Update with backlog (1-3 min) - Needs heartbeat
âœ“ Test Suite Execution (varies) - Needs all elements
âœ“ Build Processes (varies) - Needs all elements
```

**Agents Responsible:**

All specialist agents that trigger long operations:
- `work-planner.md` - When creating large plans
- `code-executor.md` - When running builds/tests
- `test-generator.md` - When generating many tests
- `health-validator.md` - When running full validation
- `brain-crawler.md` - When scanning codebase
- `development-context-collector.md` - When analyzing history
- `brain-updater.md` - When processing large backlogs

**PowerShell Script Requirements:**

All CORTEX scripts (`.ps1`) MUST include:
```powershell
# At start
Write-Host "â±ï¸  Estimated time: 3-5 minutes" -ForegroundColor Yellow
$stopwatch = [System.Diagnostics.Stopwatch]::StartNew()

# During execution (every 30-60s)
Write-Host "[$(($stopwatch.Elapsed.TotalSeconds).ToString('00.0'))s] Still working on X..." -ForegroundColor Cyan

# At completion
$stopwatch.Stop()
Write-Host "âœ… Complete in $($stopwatch.Elapsed.TotalMinutes.ToString('0.0'))m" -ForegroundColor Green
```

**See Also:**
- Playwright Testing Protocol (uses 20s wait with status)
- Health Validator (should show check-by-check progress)
- Crawler modes (quick vs deep time estimates)

---

### ğŸ¯ Setup Modes

**Default Mode: Full Setup (Recommended)**
```markdown
#file:KDS/prompts/user/cortex.md Setup
```
- â±ï¸ Duration: 15-20 minutes (padded estimate)
- Runs all 6 phases with complete initialization
- Complete BRAIN initialization with deep crawler
- Ready for immediate production use
- **Status updates:** Every 30-60 seconds
- **Progress tracking:** Phase-by-phase with percentage

**Quick Mode: Minimal Setup (For Testing)**
```markdown
#file:KDS/prompts/user/cortex.md Setup --quick
```
- â±ï¸ Duration: 3-5 minutes (padded estimate)
- Skips deep crawler (runs quick scan only)
- Minimal Tier 3 data (current snapshot only)
- Good for experimentation, not production
- **Status updates:** Every 60 seconds
- **Progress tracking:** Simplified progress bar

**Migration Mode: Import Existing Knowledge**
```markdown
#file:KDS/prompts/user/cortex.md Setup --import "path/to/old-kds/cortex-brain/"
```
- â±ï¸ Duration: 7-10 minutes (padded estimate)
- Imports generic patterns from previous CORTEX installation
- Runs deep crawler for new application
- Merges old patterns with new discoveries
- Best for migrating CORTEX to similar project
- **Status updates:** Every 45 seconds
- **Progress tracking:** Shows import + scan progress separately

---

### ğŸ“ What Gets Created

After setup completes, you'll have:

```
KDS/
â”œâ”€â”€ cortex-brain/
â”‚   â”œâ”€â”€ conversation-history.jsonl      âœ… Initialized (setup conversation)
â”‚   â”œâ”€â”€ knowledge-graph.yaml            âœ… Populated (crawler + baseline)
â”‚   â”œâ”€â”€ development-context.yaml        âœ… Baseline metrics
â”‚   â”œâ”€â”€ events.jsonl                    âœ… Setup events logged
â”‚   â”œâ”€â”€ crawler-state.yaml              âœ… Last scan info
â”‚   â””â”€â”€ crawler-report-{timestamp}.md   ğŸ“Š Detailed discoveries
â”‚
â”œâ”€â”€ sessions/                           âœ… Empty (ready for first session)
â”‚
â”œâ”€â”€ knowledge/                          âœ… Ready for knowledge articles
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ brain-crawler.ps1               âœ… Tested and working
â”‚   â”œâ”€â”€ collect-development-context.ps1 âœ… Tested and working
â”‚   â””â”€â”€ protect-brain-update.ps1        âœ… Protection active
â”‚
â””â”€â”€ setup-report-{timestamp}.md         ğŸ“Š Setup summary
```

---

### ğŸ”§ Troubleshooting Setup

**Setup fails at Phase 1 (Validation):**
```
Cause: Missing CORTEX files or permissions issue
Fix: 
  1. Verify KDS/ directory copied completely
  2. Check file permissions (should be readable/writable)
  3. Ensure Git is installed and accessible
```

**Setup fails at Phase 2 (Crawler):**
```
Cause: Large codebase (>10,000 files) or binary files
Fix:
  1. Use Setup --quick (skips deep scan)
  2. Manually run targeted crawler later
  3. Add skip patterns to KDS/cortex-brain/crawler-config.yaml
```

**Setup succeeds but queries fail:**
```
Cause: Knowledge graph structure invalid
Fix:
  1. Check KDS/cortex-brain/knowledge-graph.yaml syntax
  2. Re-run: #file:KDS/prompts/internal/brain-updater.md
  3. Validate with: #file:KDS/prompts/internal/health-validator.md
```

---

### âœ… Setup Success Indicators

You'll know setup succeeded when:

```
âœ“ All 6 phases completed without errors
âœ“ KDS/setup-report-{timestamp}.md exists
âœ“ knowledge-graph.yaml has 50+ entries
âœ“ development-context.yaml has baseline metrics
âœ“ Health validator reports "All checks passed"
âœ“ Test query returns architectural patterns
âœ“ First cortex.md request routes correctly
```

---

### ğŸ“ Post-Setup Best Practices

**1. Verify BRAIN Learning:**
```
After your first few CORTEX interactions:

Check: KDS/cortex-brain/events.jsonl (should have new events)
Check: conversation-history.jsonl (should have conversations)
Run: #file:KDS/prompts/internal/brain-updater.md (manual update)
Verify: knowledge-graph.yaml updated with your patterns
```

**2. Regular Maintenance:**
```
Daily: Let automatic learning work (no action needed)
Weekly: Check proactive_warnings in development-context.yaml
Monthly: Run incremental crawler (keep structure current)
After refactoring: Run deep crawler (re-learn architecture)
```

**3. Optimize for Your Workflow:**
```
If CORTEX misroutes frequently:
  â†’ Check intent_patterns in knowledge-graph.yaml
  â†’ Add manual entries for your common phrases
  
If file suggestions wrong:
  â†’ Check architectural_patterns
  â†’ Run targeted crawler on new modules
  
If estimates inaccurate:
  â†’ Let development-context accumulate data (2-4 weeks)
  â†’ Correlations improve with more history
```

---

## ğŸ¤– How It Works

### Step 1: Intent Detection
When you use `cortex.md`, it loads the **Intent Router** agent which analyzes your request.

**Router reads:**
```yaml
keywords:
  plan: ["I want to", "add a", "create a", "build a", "implement"]
  execute: ["continue", "next task", "keep going", "proceed"]
  resume: ["where was I", "show progress", "left off", "resume"]
  correct: ["wrong file", "not what I", "actually", "correction"]
  test: ["test", "visual regression", "playwright", "unit test"]
  validate: ["health", "validate", "check", "run all", "status"]
  ask: ["how do I", "what is", "explain", "tell me about"]
  govern: ["I updated KDS", "I modified KDS", "review my changes"]
```

### Step 2: Routing Decision
```
User: "I want to add dark mode"
  â†“
Intent Router: Detects "I want to add" = PLAN intent
  â†“
Routes to: plan.md â†’ work-planner.md
  â†“
Creates multi-phase plan, saves session state
```

### Step 3: Execution
The appropriate specialist agent executes:
- **Planner:** Breaks work into phases/tasks
- **Executor:** Implements code changes
- **Tester:** Creates and runs tests
- **Validator:** Checks system health
- **Governor:** Reviews CORTEX modifications
- **Knowledge Retriever:** Answers questions

### Step 4: Handoff (If Multi-Step)
For complex requests like "Add dark mode and test it":
```
User: "I want to add dark mode and test it"
  â†“
Intent Router: Detects TWO intents (PLAN + TEST)
  â†“
Routes to: plan.md â†’ work-planner.md
  â†“
Planner creates plan with testing phase
  â†“
Tells you: "Next: #file:KDS/prompts/user/cortex.md continue"
  â†“
You: "continue"
  â†“
Routes to: execute.md â†’ code-executor.md
  â†“
Implements code â†’ Routes to: test.md â†’ test-generator.md
  â†“
Creates tests â†’ Validates â†’ Complete
```

---

## ğŸ¯ Intent Detection Rules

**LOAD:** `#file:KDS/prompts/internal/intent-router.md`

The router uses these patterns:

### PRIMARY INTENT (Choose One)

**PLAN** - Starting new feature work
```
Patterns: "I want to", "add a", "create a", "build", "implement"
Examples: 
  - "I want to add a share button"
  - "Create a PDF export feature"
  - "Build a dark mode toggle"
```

**EXECUTE** - Continue active session
```
Patterns: "continue", "next", "keep going", "proceed", "execute"
Examples:
  - "Continue working"
  - "Next task"
  - "Keep going"
```

**RESUME** - Pickup after interruption
```
Patterns: "resume", "where was I", "show progress", "left off", "status"
Examples:
  - "Show me where I left off"
  - "What's the current status?"
  - "Resume work"
```

**CORRECT** - Fix Copilot error
```
Patterns: "wrong", "not that", "actually", "correction", "fix"
Examples:
  - "You're working on the wrong file"
  - "That's not what I meant"
  - "Actually, use SignalR not polling"
```

**TEST** - Create or run tests
```
Patterns: "test", "playwright", "visual regression", "unit test"
Examples:
  - "Create visual tests for the button"
  - "Run all Playwright tests"
  - "Add unit tests for the service"
```

**VALIDATE** - System health check
```
Patterns: "validate", "health", "check", "run all", "quality"
Examples:
  - "Check system health"
  - "Validate all changes"
  - "Run quality checks"
```

**ASK** - Question about KDS/codebase
```
Patterns: "how do I", "what is", "explain", "tell me", "?"
Examples:
  - "How do I test canvas elements?"
  - "What test patterns exist?"
  - "Explain the session state"
```

**GOVERN** - Review CORTEX changes
```
Patterns: "I updated KDS", "modified KDS", "review", "CORTEX change"
Examples:
  - "I updated the test-generator"
  - "Review my CORTEX modifications"
  - "I changed the rules"
```

### ğŸ§  Proactive Warnings (NEW - Post-Week 4 Enhancement)

**Before routing, CORTEX BRAIN analyzes your request and shows warnings:**

**When warnings appear:**
- âœ… PLAN intent detected (starting new feature)
- âœ… EXECUTE intent detected (continuing work)

**What gets predicted:**
```yaml
ğŸŸ¡ File Hotspot Warnings:
   "âš ï¸ HostControlPanel.razor is a hotspot (28% churn)"
   â†’ Suggests: Add extra validation

ğŸŸ¡ Complexity Warnings:
   "âš ï¸ PDF features take 50% longer than other exports"
   â†’ Suggests: Allocate more time

ğŸŸ¡ Velocity Warnings:
   "âš ï¸ Velocity dropped 30% this week"
   â†’ Suggests: Smaller commits

ğŸŸ¢ Success Patterns:
   "âœ… Test-first has 96% success rate for exports"
   â†’ Suggests: Continue TDD workflow
```

**Example:**
```markdown
User: #file:KDS/prompts/user/cortex.md
      I want to add PDF export

ğŸ§  BRAIN Analysis:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸŸ¡ âš ï¸ HostControlPanel.razor is a hotspot (28% churn)
   ğŸ’¡ Add extra validation phase
   
ğŸŸ¢ âœ… Test-first approach has 96% success rate
   ğŸ’¡ Continue TDD workflow
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Routing to work-planner.md...
```

**Benefits:**
- âš¡ **Instant feedback** - Warnings appear in <5 seconds (before planning)
- ğŸ¯ **Better decisions** - Adjust approach before creating plan
- ğŸ“Š **Data-driven** - Predictions based on historical patterns
- ğŸ”„ **Continuous learning** - Accuracy improves over time

**Implementation:** Step 1.3 in `intent-router.md` (between user input and conversation context)

**ANALYZE_SCREENSHOT** - Extract requirements from images
```
Patterns: "analyze screenshot", "extract from image", "what does mockup show", "read annotations"
Examples:
  - "Analyze this screenshot and extract requirements"
  - "What does this mockup show?"
  - "Extract specs from this design"
  - "Read the annotations on this bug report"
  - [Image attachment detected]
```

**COMMIT** - Intelligent git commits
```
Patterns: "commit changes", "commit work", "git commit", "save to git"
Examples:
  - "Commit changes"
  - "Commit my work"
  - "Save changes to git"
  - "Create commits with proper categorization"
  - "Commit and tag if milestone"
```
  - "Read the annotations on this bug report"
  - [Image attachment detected]
```

### SECONDARY INTENTS (Can Combine)

**If multiple intents detected:**
```
"I want to add dark mode and test it"
  â†“
Primary: PLAN
Secondary: TEST
  â†“
Planner includes testing phase in plan
```

---

## ğŸ”„ Complete Workflow Examples

### Example 1: New Feature (Simple)
```
You: #file:KDS/prompts/user/cortex.md
     I want to add a pulse animation to the FAB button

Router: PLAN intent detected
   â†“
Planner: Creates 3-phase plan
   â†“
Output: âœ… Session created: fab-button-animation
        Next: #file:KDS/prompts/user/cortex.md continue
```

### Example 2: Continue Work
```
You: #file:KDS/prompts/user/cortex.md
     continue

Router: EXECUTE intent detected
   â†“
Executor: Implements next task
   â†“
Output: âœ… Task 1.1 complete: CSS animation added
        Next: #file:KDS/prompts/user/cortex.md continue
```

### Example 3: Resume After Break (SOLID v5.0)
```
(New chat next day)

You: #file:KDS/prompts/user/cortex.md
     where was I?

Router: RESUME intent detected
   â†“
Session Resumer: Loads via session-loader (DIP)
   â†“
Output: Session: fab-button-animation
        Progress: 3/8 tasks (38%)
        
        ğŸ“Š Detailed Progress:
        Phase 1: âœ… Complete
        Phase 2: ğŸ”„ 1/3 tasks done
        Phase 3: â¬œ Not started
        
        Next: #file:KDS/prompts/user/cortex.md continue
```

### Example 4: Correction Mid-Work (SOLID v5.0)
```
You: #file:KDS/prompts/user/cortex.md
     continue

Executor: Modifying HostControlPanel.razor...

You: #file:KDS/prompts/user/cortex.md
     Wrong file! The FAB is in HostControlPanelContent.razor

Router: CORRECT intent detected
   â†“
Error Corrector: HALTS execution (dedicated agent)
   â†“
Analysis: FILE_MISMATCH
   Incorrect: HostControlPanel.razor
   Correct: HostControlPanelContent.razor
   â†“
Actions:
   âœ… Reverted changes to HostControlPanel.razor
   âœ… Loaded HostControlPanelContent.razor
   âœ… Updated task file reference
   â†“
Output: âœ… Correction applied
        Next: #file:KDS/prompts/user/cortex.md continue
```

### Example 5: Multi-Intent Request
```
You: #file:KDS/prompts/user/cortex.md
     I want to add dark mode toggle and create Percy visual tests for it

Router: PLAN + TEST intents detected
   â†“
Planner: Creates plan with dedicated test phase
   â†“
Output: âœ… 4-phase plan created (includes visual testing)
        Phase 4: Percy visual regression tests
        Next: #file:KDS/prompts/user/cortex.md continue
```

---

## âœ… Benefits of Universal Entry Point + SOLID v5.0

### User Experience
- âœ… **One command to remember** (`cortex.md`)
- âœ… **Natural language** - say what you want
- âœ… **No cognitive load** - don't need to know which specialist to call
- âœ… **Forgiving** - works even if you're vague
- âœ… **Predictable** - same command, consistent behavior

### Technical Benefits (SOLID v5.0)
- âœ… **Intelligent routing** - right agent for the job
- âœ… **Multi-intent handling** - complex requests work
- âœ… **Context preservation** - session state via abstraction
- âœ… **Automatic workflows** - no manual orchestration
- âœ… **Single Responsibility** - each agent focused on one job
- âœ… **Dependency Inversion** - swap storage/tools without breaking agents
- âœ… **Interface Segregation** - no mode switches, dedicated specialists
- âœ… **Easy to test** - mock abstractions, isolate agents

### Architecture Benefits
- ğŸ¯ **Modular** - add new agents without touching existing ones
- ğŸ”§ **Maintainable** - fix bugs in one place
- ğŸš€ **Performant** - no mode-switch overhead
- ğŸ“¦ **Portable** - abstractions make storage/tools swappable
- ğŸ  **Local-First** - 100% in KDS/, zero external dependencies
- ğŸ”’ **Offline-Capable** - works without internet (except optional cloud features)
- ğŸ†“ **Zero-Install** - no npm/pip/dotnet packages required for KDS

### Comparison

**Before v5.0 (7 commands + mode switches):**
```
plan.md â†’ for new features
execute.md â†’ for continuing work + corrections (mode switch)
resume.md â†’ after breaks (actually loads work-planner)
correct.md â†’ for fixing errors (loads executor in correction mode)
test.md â†’ for creating tests
validate.md â†’ for health checks
ask-cortex.md â†’ for questions
govern.md â†’ for CORTEX changes

Issues:
âŒ Executor does 2 jobs (execution + correction)
âŒ Planner does 2 jobs (planning + resumption)
âŒ Hardcoded file paths everywhere
âŒ Hardcoded test commands
```

**After v5.0 (1 command + SOLID compliance):**
```
cortex.md â†’ for EVERYTHING
  â†“
intent-router.md â†’ routes to 8 focused specialists
  â†“
Specialists use shared abstractions (session-loader, test-runner, file-accessor)

Benefits:
âœ… Each agent has ONE responsibility
âœ… Error correction is dedicated (error-corrector.md)
âœ… Session resumption is dedicated (session-resumer.md)
âœ… Abstractions decouple from storage/tools
âœ… Easy to extend (add new agent = add new route)
```

---

## ğŸš« When Routing Fails

**If intent is ambiguous:**
```
You: #file:KDS/prompts/user/cortex.md
     do something

Router: â“ Intent unclear. Did you mean:
        1. Continue current work? (execute)
        2. Check progress? (resume)
        3. Validate changes? (validate)
        
        Please clarify.
```

**If no active session and you say "continue":**
```
You: #file:KDS/prompts/user/cortex.md
     continue

Router: âŒ No active session found.
        Did you mean to start new work?
        Use: "I want to [describe feature]"
```

---

## ğŸ“Š SOLID v5.0 Design Benefits

### Answer: YES - It Makes CORTEX Better!

**Design Improvements:**
- âœ… **Single Responsibility** - Each agent has ONE clear job
- âœ… **Interface Segregation** - No mode switches (dedicated agents)
- âœ… **Dependency Inversion** - Abstractions decouple from concrete implementations
- âœ… **Open/Closed** - Easy to extend (add agents) without modifying existing code

**SOLID v5.0 Architecture:**
```
User Interface Layer:
  cortex.md (universal) â”€â”€â”€â”€â”€â”€â”€â”€â”
  plan.md (direct)   â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  execute.md (direct) â”€â”€â”€â”€â”€â”€â”€â”¤
  test.md (direct)    â”€â”€â”€â”€â”€â”€â”€â”¤  All route through
  correct.md (direct) â”€â”€â”€â”€â”€â”€â”€â”¤
  resume.md (direct)  â”€â”€â”€â”€â”€â”€â”€â”¤
  ...                        â”œâ”€â†’ intent-router.md (ROUTER)
                             â”‚
Internal Agent Layer:        â”‚
  work-planner.md     â†â”€â”€â”€â”€â”€â”€â”¤  (PLAN only)
  code-executor.md    â†â”€â”€â”€â”€â”€â”€â”¤  (EXECUTE only)
  error-corrector.md  â†â”€â”€â”€â”€â”€â”€â”¤  (CORRECT only - NEW)
  session-resumer.md  â†â”€â”€â”€â”€â”€â”€â”¤  (RESUME only - NEW)
  test-generator.md   â†â”€â”€â”€â”€â”€â”€â”¤  (TEST only)
  health-validator.md â†â”€â”€â”€â”€â”€â”€â”¤  (VALIDATE only)
  change-governor.md  â†â”€â”€â”€â”€â”€â”€â”¤  (GOVERN only)
  knowledge-retriever.md â†â”€â”€â”€â”˜  (ASK only)
  
Abstraction Layer (DIP):
  session-loader.md   â†’ Abstract session access
  test-runner.md      â†’ Abstract test execution
  file-accessor.md    â†’ Abstract file I/O
```

**What Changed from v4.5:**
```diff
- code-executor.md (execution + correction modes) âŒ SRP violation
+ code-executor.md (execution only) âœ… SRP compliant
+ error-corrector.md (correction only) âœ… ISP compliant

- work-planner.md (planning + resumption modes) âŒ SRP violation
+ work-planner.md (planning only) âœ… SRP compliant
+ session-resumer.md (resumption only) âœ… ISP compliant

- Direct file access (#file:KDS/sessions/...) âŒ DIP violation
+ Abstract access (session-loader.md) âœ… DIP compliant

- Hardcoded test commands (npx playwright test) âŒ DIP violation
+ Abstract runner (test-runner.md) âœ… DIP compliant
```

**Benefits:**
- ğŸ¯ **Clarity** - One agent = one job (easier to understand)
- ğŸš€ **Performance** - No mode-switch logic (faster routing)
- ğŸ”§ **Testability** - Mock abstractions (easier to test)
- ğŸ“¦ **Flexibility** - Swap storage/tools without breaking agents

**Flexibility:**
```
Option 1 (Easy): Use cortex.md universal entry point
Option 2 (Explicit): Call specific prompts directly
Option 3 (Advanced): Call internal agents with abstractions

All work! Universal is for convenience, SOLID is for quality.
```

---

## ğŸ“ Quick Reference Card

**For everything:**
```
#file:KDS/prompts/user/cortex.md
[what you want in natural language]
```

**What it detects:**
- "I want to..." â†’ plan
- "Continue..." â†’ execute  
- "Where was I..." â†’ resume
- "Wrong..." â†’ correct
- "Test..." â†’ test
- "Validate..." â†’ validate
- "How do I..." â†’ ask
- "I updated KDS..." â†’ govern
- "Update documentation..." â†’ plan (CORTEX Quadrant update)
- "Publish docs..." â†’ plan (CORTEX Quadrant update)

**That's all you need to know!** ğŸš€

---

## ğŸ§  BRAIN System Best Practices

### Automatic Learning is ENABLED by Default

**CORTEX v5.0+ automatically logs events and updates BRAIN - no user action needed!**

**What happens automatically:**
1. âœ… Agents log events after every action (routing, file modifications, corrections)
2. âœ… Events accumulate in `KDS/cortex-brain/events.jsonl`
3. âœ… Rule #16 Step 5 checks event count after each task
4. âœ… When 50 events reached â†’ `brain-updater.md` auto-triggered
5. âœ… Knowledge graph updated with new patterns
6. âœ… Next routing decision gets smarter

**You benefit without doing anything!**

### Verify BRAIN is Learning (Optional Health Check)

**Want to confirm automatic learning is working?**

Check these indicators:
```bash
# 1. Recent events logged (should have timestamps from today)
cat KDS/cortex-brain/events.jsonl | tail -5

# 2. Knowledge graph updated recently (check last modified)
ls -la KDS/cortex-brain/knowledge-graph.yaml

# 3. Event count reasonable (not accumulating to 100+)
wc -l KDS/cortex-brain/events.jsonl
```

**Healthy BRAIN signs:**
- âœ… `events.jsonl` has recent timestamps (within last few hours)
- âœ… `knowledge-graph.yaml` updated in last 24 hours
- âœ… Event count stays below 50 (auto-cleanup working)

**âš ï¸ Warning signs (violations detected):**
- âŒ No events logged for 4+ hours (event logging broken)
- âŒ `knowledge-graph.yaml` not updated in 24+ hours
- âŒ 50+ unprocessed events accumulated (automatic update not triggering)

**If you see warnings:** See `KDS/docs/architecture/KDS-SELF-REVIEW-STRATEGY.md` for fixes

### Manual BRAIN Update (Only if Needed)

**When to manually update:**
- ğŸ”§ After bulk corrections (fixed multiple files at once)
- ğŸ”§ After large refactoring (want BRAIN to learn patterns immediately)
- ğŸš¨ If automatic updates stopped working (>50 events accumulated)
- ğŸ“Š Before important routing decision (want latest knowledge)

**How to trigger manually:**
```markdown
#file:KDS/prompts/internal/brain-updater.md
```

This processes all events and updates the knowledge graph.

### Standard Practice: Trust Automatic Learning

**Every CORTEX interaction SHOULD automatically:**
1. âœ… Log events (no user action needed)
2. âœ… Query BRAIN for insights (before routing/file decisions)
3. âœ… Update knowledge graph (periodic automatic)

**This is STANDARD CORTEX practice** - all agents follow this pattern automatically.

### For Advanced Users Only

**Manual intervention rarely needed, but available:**

1. **Manually correct routing** if BRAIN suggests wrong intent:
   ```markdown
   #file:KDS/prompts/user/cortex.md
   Wrong intent! I meant [correct interpretation]
   ```
   Error corrector logs the mistake, BRAIN learns for next time.

2. **Check BRAIN health** during self-review:
   ```markdown
   #file:KDS/prompts/user/validate.md
   Check BRAIN system health
   ```

3. **Force immediate update** after major changes:
   ```markdown
   #file:KDS/prompts/internal/brain-updater.md
   ```

**But in normal usage: Just use CORTEX and let BRAIN learn automatically!**

### First-Time Setup (Optional - BRAIN Works Out of the Box)

**CORTEX v5.0+ works immediately with empty BRAIN - learning starts from first use!**

**Optional bootstrapping (faster initial learning):**

**Option 1: Populate from existing sessions (if you have session history):**
```powershell
# PowerShell - Seed BRAIN from past sessions
.\KDS\scripts\populate-cortex-brain.ps1

# Then update knowledge graph
#file:KDS/prompts/internal/brain-updater.md
```

**Option 2: Crawl your codebase (recommended for new installations):**
```powershell
# PowerShell - Quick scan (30 seconds)
.\KDS\scripts\brain-crawler.ps1 -Mode quick

# OR Deep scan (5-10 minutes, comprehensive)
.\KDS\scripts\brain-crawler.ps1 -Mode deep
```

The crawler analyzes your entire application and feeds BRAIN with:
- ğŸ—ï¸ Architectural patterns (where components/services/tests live)
- ğŸ”— File relationships (what depends on what)
- ğŸ“ Naming conventions (how files are named)
- ğŸ› ï¸ Technology stack (languages, frameworks, tools)
- ğŸ§ª Test patterns (frameworks, test data, selectors)

**See:** `#file:KDS/prompts/internal/brain-crawler.md` for details

**But remember: Bootstrapping is OPTIONAL - BRAIN learns automatically from first interaction!**

### Ongoing Usage - No Action Needed!

**Just use CORTEX normally!** BRAIN learns automatically from every interaction:
- ğŸ“ Events logged automatically with every agent action
- ğŸ§  BRAIN updated automatically when 50 events accumulate
- ğŸ’¡ Decisions get smarter automatically over time
- ğŸ•·ï¸ Optional: Run incremental crawler scans to refresh architectural knowledge

**Zero manual intervention required for continuous learning.**

**Only manual actions needed:**
1. ğŸš¨ If automatic learning breaks (check `KDS-SELF-REVIEW-STRATEGY.md`)
2. ğŸ”§ After bulk corrections (want immediate learning)
3. ğŸ“Š When starting new project (run crawler to learn codebase)

**99% of the time: BRAIN just works!**

### Moving CORTEX to Another Application

**Need to reset BRAIN for a new project?**
```powershell
# PowerShell - Soft reset (clear data, keep config)
.\KDS\scripts\brain-reset.ps1 -Mode soft

# OR Export generic patterns first, then reset
.\KDS\scripts\brain-reset.ps1 -Mode export-reset -ExportPath ".\templates\my-patterns\"

# Then crawl the new application
.\KDS\scripts\brain-crawler.ps1 -Mode deep
```

BRAIN gets amnesia (forgets old app) but keeps all logic intact!

**See:** `#file:KDS/prompts/internal/brain-reset.md` for details

---

## ğŸ”— Technical Implementation (SOLID v5.0)

**This prompt loads:**
```markdown
#file:KDS/prompts/internal/intent-router.md
```

**Which analyzes your request and loads one of:**
```
#file:KDS/prompts/user/plan.md â†’ #file:KDS/prompts/internal/work-planner.md
#file:KDS/prompts/user/execute.md â†’ #file:KDS/prompts/internal/code-executor.md
#file:KDS/prompts/user/test.md â†’ #file:KDS/prompts/internal/test-generator.md
#file:KDS/prompts/user/validate.md â†’ #file:KDS/prompts/internal/health-validator.md
#file:KDS/prompts/user/govern.md â†’ #file:KDS/prompts/internal/change-governor.md
#file:KDS/prompts/user/ask-cortex.md â†’ #file:KDS/prompts/internal/knowledge-retriever.md
#file:KDS/prompts/user/correct.md â†’ #file:KDS/prompts/internal/error-corrector.md (NEW)
#file:KDS/prompts/user/resume.md â†’ #file:KDS/prompts/internal/session-resumer.md (NEW)
```

**Shared abstractions (DIP compliance):**
```
#shared-module:session-loader.md â†’ Abstract session access (default: local files)
#shared-module:test-runner.md â†’ Abstract test execution (uses project's tools)
#shared-module:file-accessor.md â†’ Abstract file I/O (PowerShell built-ins)

NOTE: All 100% local (in KDS/), zero external dependencies
```

**BRAIN management agents:**
```
#file:KDS/prompts/internal/brain-query.md â†’ Query knowledge graph
#file:KDS/prompts/internal/brain-updater.md â†’ Process events and update
#file:KDS/prompts/internal/brain-crawler.md â†’ Codebase analysis (NEW)
#file:KDS/prompts/internal/brain-reset.md â†’ Selective amnesia (NEW)
```

---

## ğŸ¯ Active Development Plan (CORTEX v6.0)

**Current Focus:** Real-Time BRAIN Dashboard with Live Reference System + Automatic BRAIN Updates

### âœ… **COMPLETED:** Rule #22 - Automatic BRAIN Updates

**Status:** ğŸ‰ **IMPLEMENTED** (Option D - Hybrid Approach)

**What Was Built:**

1. **Manual Recording Script** (Phase 1 - COMPLETE)
   - âœ… `scripts/record-conversation.ps1` - Manual conversation capture
   - âœ… Logs to `conversation-history.jsonl` (Tier 1)
   - âœ… FIFO enforcement (keep 20, delete oldest)
   - âœ… Auto-checks brain-updater threshold (50 events OR 24 hours)
   - âœ… **TESTED:** CopilotChats.txt conversation successfully recorded

2. **Auto BRAIN Updater** (Phase 2 - COMPLETE)
   - âœ… `scripts/auto-brain-updater.ps1` - Automatic trigger after every request
   - âœ… Logs request to `events.jsonl` (Tier 4)
   - âœ… Checks thresholds (50+ events OR 24+ hours)
   - âœ… Auto-invokes `brain-updater.ps1` when threshold met
   - âœ… Keeps `brain-updater.ps1` synchronized with `brain-updater.md`
   - âœ… **TESTED:** 13 events processed, knowledge-graph.yaml updated

3. **Git Hooks** (Phase 2 - COMPLETE)
   - âœ… `hooks/post-commit` - Auto-runs after every git commit
   - âœ… `scripts/setup-git-hooks.ps1` - One-time installation
   - âœ… Silent background execution (doesn't block commits)

4. **Governance Rule** (Tier 0 - COMPLETE)
   - âœ… **Rule #22:** Auto BRAIN Update After Every Request
   - âœ… `governance/rules/auto-brain-update.md` - Full specification
   - âœ… Tier 0 (INSTINCT) - Permanent, cannot be overridden
   - âœ… Updated `governance/rules.md` with Rule #22

5. **Architecture Documentation** (COMPLETE)
   - âœ… `docs/architecture/BRAIN-RECORDING-GAP-ANALYSIS.md` - Root cause analysis
   - âœ… Identified problem: GitHub Copilot Chat doesn't auto-invoke agents
   - âœ… Designed 4 solutions (manual, git hooks, extension, harvester)
   - âœ… Implemented hybrid approach (Phases 1-3 over 3 weeks)

**How to Use:**

```powershell
# Manual recording (after significant conversations)
.\scripts\record-conversation.ps1 `
    -Title "Your conversation title" `
    -FilesModified "file1.md,file2.ps1" `
    -EntitiesDiscussed "feature1,feature2" `
    -Outcome "What was accomplished" `
    -Intent "PLAN"

# Automatic (runs after git commits via hook)
git commit -m "Your commit message"  # auto-triggers brain-updater

# Test auto-updater manually
.\scripts\auto-brain-updater.ps1 `
    -RequestSummary "Test request" `
    -ResponseType "direct"

# Install git hooks (one-time setup)
.\scripts\setup-git-hooks.ps1
```

**Success Metrics:**
- âœ… 6 conversations in `conversation-history.jsonl` (was 5, added CopilotChats.txt)
- âœ… 13 events in `events.jsonl` (threshold: 50 for auto-update)
- âœ… brain-updater auto-triggered (24+ hours since last update)
- âœ… `knowledge-graph.yaml` updated with 13 new events
- âœ… Git hook installed and operational

**Next Steps (Phase 3 - Weeks 2-3):**
- ğŸ“‹ VS Code extension with Chat Participant API
- ğŸ“‹ Real-time conversation interception
- ğŸ“‹ Scheduled harvester (parse Copilot Chat history every 2 hours)
- ğŸ“‹ Full automation (zero user action required)

---

### Phase 7.3: Dashboard BRAIN Reference (IN DESIGN)

**Purpose:** Visual one-page guide to all CORTEX BRAIN functionality  
**Priority:** HIGH  
**Status:** ğŸ¯ DESIGN COMPLETE - READY TO IMPLEMENT

**New Features:**

1. **Tier 0 (Instinct) Enhancement** - Holistic review complete
   - âœ… Identified 6 fundamental design gaps
   - ğŸ“‹ 6 new Tier 0 files designed:
     - `governance/tier-0/tool-requirements.yaml` - Essential dependencies
     - `governance/tier-0/setup-protocol.yaml` - 5-step initialization
     - `governance/tier-0/tier-classification-rules.yaml` - Event classification
     - `governance/tier-0/amnesia-recovery.yaml` - Detection & recovery
     - `governance/tier-0/agent-protocols.yaml` - Standard behaviors
     - `governance/tier-0/hemisphere-coordination-rules.yaml` - LEFT/RIGHT communication

2. **Dashboard "BRAIN Reference" Tab** - Visual learning system
   - ğŸ“‹ Tab 1: OVERVIEW (one-page summary of all 5 tiers)
   - ğŸ“‹ Tab 2: RULES & GOVERNANCE (18 rules, searchable)
   - ğŸ“‹ Tab 3: HOW THINGS WORK (visual workflows)
     - "How Amnesia Works" (detection, recovery, prevention)
     - "How Learning Works" (brain-updater.md cycle)
     - "How TDD Cycle Works" (REDâ†’GREENâ†’REFACTOR)
     - "How Crawlers Work" (file discovery, dependencies)
     - "How Health Checks Work" (test-brain-integrity.ps1)
     - "How Setup Works" (initialization, validation)
     - "How Hemispheres Coordinate" (LEFT/RIGHT messaging)
   - ğŸ“‹ Tab 4: SETUP & DEPENDENCIES (tool inventory, validation)
   - ğŸ“‹ Tab 5: HEMISPHERES & COORDINATION (real-time activity)

3. **Closed-Loop Self-Healing** - Dashboard â†’ BRAIN feedback
   - ğŸ“‹ Health results logged to events.jsonl (Tier 4)
   - ğŸ“‹ brain-healer.md agent (auto-remediation)
   - ğŸ“‹ Remediation scripts (yaml, conversation, KG, session fixes)
   - ğŸ“‹ Dashboard "Fix" buttons (user-triggered repairs)
   - ğŸ“‹ Knowledge graph pattern learning (failure tracking)

**Architecture Docs:**
- `docs/architecture/DASHBOARD-BRAIN-INTEGRATION.md` - Self-healing design
- `docs/architecture/DASHBOARD-BRAIN-REFERENCE-FEATURE.md` - Visual reference design
- `docs/DASHBOARD-BRAIN-INTEGRATION-SUMMARY.md` - Self-healing summary
- `docs/DASHBOARD-BRAIN-REFERENCE-SUMMARY.md` - Visual reference summary

**Implementation Plan:** 4 weeks (see Phase 7 in KDS-V6-IMPLEMENTATION-PLAN-RISK-BASED.md)

**User Value:**
- âœ… One-page visual reference for entire BRAIN (no more trying to remember)
- âœ… Understand how ANY feature works (amnesia, learning, TDD, etc.)
- âœ… See all 18 rules in searchable format
- âœ… Know setup requirements and tool dependencies
- âœ… Monitor hemisphere activity in real-time
- âœ… Auto-fix common issues (or trigger manual fixes)
- âœ… Live data updated every 5-30 seconds

**Start Implementation:**
```
#file:KDS/prompts/user/plan.md "Implement Phase 7.3: Dashboard BRAIN Reference System"
```

---

### ğŸ“‹ **PLANNED:** Mind Palace - Advanced Memory Architecture

**Purpose:** Enhanced spatial memory system for complex knowledge organization  
**Priority:** FUTURE  
**Status:** ğŸ“‹ PLACEHOLDER - Design phase pending

**Concept:**
The Mind Palace extends KDS's BRAIN system with spatial memory techniques for organizing complex technical knowledge. This system will enable Copilot to "mentally navigate" through architectural concepts, code relationships, and project knowledge using memory palace techniques.

**Planned Features:**
- ğŸ“‹ Spatial knowledge organization (rooms, floors, locations)
- ğŸ“‹ Visual memory associations for complex patterns
- ğŸ“‹ Hierarchical knowledge structures
- ğŸ“‹ Enhanced context retrieval using spatial relationships
- ğŸ“‹ Integration with existing Tier 2 knowledge graph

**Metric Tracking (Core Requirement):**
The Mind Palace will be designed with comprehensive metric tracking from the start:

```yaml
mind_palace_metrics:
  kds_performance:
    - knowledge_retrieval_speed: "Time to locate relevant patterns"
    - spatial_navigation_accuracy: "Correct room/location hit rate"
    - pattern_association_effectiveness: "Successful pattern matches"
    - memory_consolidation_rate: "Tier 1 â†’ Tier 2 conversion efficiency"
    - context_reconstruction_time: "Resume session speed"
    
  coding_efficiency:
    - time_to_first_code: "Request â†’ First implementation"
    - architectural_alignment_rate: "% of solutions matching existing patterns"
    - rework_reduction: "Before/after Mind Palace implementation"
    - context_switching_overhead: "Time lost when changing tasks"
    - learning_curve_acceleration: "New team member onboarding speed"
    
  quality_metrics:
    - test_coverage_trends: "Before/after Mind Palace"
    - bug_escape_rate: "Issues reaching production"
    - architectural_consistency_score: "Alignment with design patterns"
    - knowledge_retention_rate: "Pattern recall accuracy over time"
    
  roi_measurements:
    - development_velocity_change: "Sprint velocity trends"
    - onboarding_time_reduction: "New developer productivity"
    - context_recovery_savings: "Hours saved on session resumes"
    - decision_quality_improvement: "Architectural decision success rate"
```

**Integration Points:**
- ğŸ“‹ Tier 2 (Knowledge Graph) - Spatial overlay for existing patterns
- ğŸ“‹ Tier 3 (Development Context) - Velocity impact tracking
- ğŸ“‹ Dashboard - Real-time visualization of memory palace structure
- ğŸ“‹ Metrics Reporter - Dedicated Mind Palace analytics

**Design Phase Tasks:**
1. Research spatial memory techniques for code organization
2. Design memory palace structure (rooms, floors, associations)
3. Define integration with existing BRAIN tiers
4. Create metric collection framework
5. Build prototype with test dataset
6. Validate effectiveness with real-world usage

**Documentation (To Be Created):**
- `docs/architecture/MIND-PALACE-DESIGN.md` - Full specification
- `docs/architecture/MIND-PALACE-METRICS.md` - Measurement framework
- `cortex-brain/mind-palace/` - Storage structure (when implemented)

**Notes:**
- Design will prioritize measurability from day one
- All claims must be backed by quantitative metrics
- Focus on demonstrable coding efficiency improvements
- Integration must be seamless with existing workflows

**When Ready to Design:**
```
#file:KDS/prompts/user/plan.md "Design Mind Palace Memory Architecture with Metrics"
```

---

## âœ¨ Summary
````

**You asked:**
> "Will the CORTEX system benefit from SOLID principles?"

**Answer: ABSOLUTELY! v5.0 implements:**
- âœ… **Single Responsibility** - One agent = one job
- âœ… **Interface Segregation** - Dedicated agents (no mode switches)
- âœ… **Dependency Inversion** - Abstractions decouple from concrete implementations
- âœ… **Open/Closed** - Easy to extend without modifying existing code

**What changed:**
- â• Added `error-corrector.md` (dedicated correction agent)
- â• Added `session-resumer.md` (dedicated resumption agent)
- â• Added abstraction layer (`session-loader`, `test-runner`, `file-accessor`)
- âœ… Removed mode switches from `code-executor` and `work-planner`
- âœ… Decoupled agents from concrete file paths and tool commands

**Local-First Compliance:**
- âœ… **100% in KDS/** - All CORTEX logic, data, scripts housed locally
- âœ… **Minimal external dependencies** - Only CORTEX enhancement libraries (declared upfront)
- âœ… **Offline-capable** - Works without internet (core functionality)
- âœ… **Transparent setup** - User informed of all required libraries during setup
- âš ï¸ **Optional extensions** - Cloud/database storage available but not required

**Dependency Categories:**
1. **CORTEX Core** - Zero dependencies (PowerShell/bash built-ins only)
2. **CORTEX Enhancements** - Open source libraries for improved capabilities (ALLOWED, declared at setup)
3. **Application Code** - User's project dependencies (Copilot recommends, user approves)
4. **Optional Features** - Cloud/DB/external services (opt-in only)

**What you need to remember:**
```
#file:KDS/prompts/user/cortex.md
[describe what you want]
```

**That's it. CORTEX handles the rest with SOLID principles and local-first design.** ğŸ¯
