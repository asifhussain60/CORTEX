# CORTEX Universal Entry Point

**Purpose:** Single command for ALL CORTEX interactions. You don't need to remember multiple commands - just use this one and CORTEX figures out what you need.

**Version:** 5.0 (SOLID Refactor)  
**Status:** üéØ ACTIVE DESIGN  
**Architecture:** SOLID-compliant modular system

**Author:** Asif Hussain  
**Copyright:** ¬© 2024-2025 Asif Hussain. All rights reserved.  
**License:** Proprietary - See LICENSE file for terms  
**Repository:** https://github.com/asifhussain60/CORTEX

---

## üñ•Ô∏è Platform Switch Commands

**Quick Platform Migration:** Use these commands to switch all platform-specific references in one go.

### Switch to Mac
When you say **"Switch to Mac"**, Copilot will:
1. Update `cortex.config.json` with your Mac hostname
2. Convert all PowerShell examples to bash/zsh
3. Update file paths from Windows (`D:\`) to macOS (`/Users/...`)
4. Update shell command syntax (`.ps1` ‚Üí `.sh`, `pwsh` ‚Üí `bash/zsh`)
5. Update documentation references

**Required Info:** Your Mac hostname (run `hostname` in terminal)

### Switch to Windows
When you say **"Switch to Windows"**, Copilot will:
1. Update `cortex.config.json` with your Windows hostname
2. Convert all bash/zsh examples to PowerShell
3. Update file paths from macOS (`/Users/...`) to Windows (`D:\`)
4. Update shell command syntax (`.sh` ‚Üí `.ps1`, `bash` ‚Üí `pwsh`)
5. Update documentation references

**Required Info:** Your Windows hostname (run `hostname` in PowerShell)

**Files Updated:**
- `cortex.config.json` - Machine-specific paths
- `prompts/user/cortex.md` - Code examples and commands
- `run-cortex.sh` / `run-cortex.ps1` - Entry point scripts
- Documentation files with platform-specific examples

---

## ‚ö†Ô∏è IMPORTANT: Conversation Tracking Bridge

**GitHub Copilot Chat does NOT automatically track conversations to the CORTEX brain.**

To enable conversation memory (so CORTEX remembers across chats):

### Option 1: PowerShell Capture (Quick - After Each Session)
```powershell
# Capture your conversation manually
.\scripts\cortex-capture.ps1 -AutoDetect

# Or provide message directly
.\scripts\cortex-capture.ps1 -Message "Created mkdocs documentation" -Intent EXECUTE
```

### Option 2: Python CLI (Direct Integration)
```bash
# Process through Python (tracks automatically)
python scripts/cortex_cli.py "Add authentication to login page"

# Validate tracking is working
python scripts/cortex_cli.py --validate

# Check current session
python scripts/cortex_cli.py --session-info
```

### Option 3: Manual Recording (Fallback)
```powershell
.\scripts\record-conversation.ps1 `
    -Title "Session Title" `
    -Intent "EXECUTE" `
    -Outcome "What was accomplished" `
    -FilesModified "file1.py,file2.md" `
    -Entities "topic1,topic2"
```

**Why This Is Needed:**
- GitHub Copilot Chat reads `#file:prompts/user/cortex.md` as **documentation**
- It does NOT execute the Python `CortexEntry.process()` method
- Without tracking: ‚ùå No conversation memory, ‚ùå No cross-chat context, ‚ùå Amnesia
- With tracking: ‚úÖ Remembers past conversations, ‚úÖ "Make it purple" works, ‚úÖ Full brain learning

**Rule #24 (Tier 0 - Core Instinct):** Conversation tracking MUST work. Protected by brain-protector tests in `CORTEX/tests/tier0/test_brain_protector_conversation_tracking.py`.

---

## üìä Implementation Status

**Legend:**
- ‚úÖ **Fully Implemented** - Working and tested
- üü° **Partially Implemented** - Core working, missing features
- üîÑ **In Progress** - Currently being developed
- üìã **Designed Only** - Documentation exists, no code

| Feature | Status | Notes |
|---------|--------|-------|
| **V3 GROUP 1: Foundation** | ‚úÖ | Project reorganized, benchmarks validated |
| **V3 GROUP 2: Infrastructure** | ‚úÖ | Tier 0, CI/CD, MkDocs operational |
| **V3 GROUP 3: Data Storage** | ‚úÖ | All tiers complete - 60/60 tests passing ‚≠ê |
| **Tier 1: Working Memory** | ‚úÖ | SQLite conversations, <50ms queries (Nov 6) |
| **Tier 2: Knowledge Graph** | ‚úÖ | FTS5 search, pattern learning, <150ms (Nov 6) |
| **Tier 3: Context Intelligence** | ‚úÖ | Git metrics, hotspots, insights (Nov 6) |
| **Migration Tools** | ‚úÖ | All 3 tier migrations validated (Nov 6) |
| **V3 GROUP 4: Intelligence** | üîÑ | Ready to begin - agents, entry point, dashboard |
| **Agent Architecture (SOLID)** | üìã | 10 specialist agents designed |
| **Core Routing** | üìã | Intent router designed |
| **Dashboard** | üìã | Live data visualization designed |
| **VS Code Extension** | üìã | **DEFINITIVE conversation fix** - Phase 3 (Week 9-12) üÜï |
| **Automatic Capture** | üìã | Zero manual intervention, monitors all chats üÜï |
| **V3 GROUP 5: Migration** | üìã | KDS ‚Üí CORTEX data migration |
| **V3 GROUP 6: Finalization** | üìã | System check, documentation, release |

**V3 Migration Progress:** Groups 1-3 Complete (31 hrs) ‚úÖ | Groups 4-6 Remaining (29-41 hrs) üìã  
**CORTEX 2.0 Extension:** Planned for Phase 3 (Week 9-12) - Definitive conversation tracking solution üÜï  
**Performance:** 52% faster than estimated, 100% test coverage ‚≠ê  
**Last Updated:** 2025-11-07 (Added VS Code Extension architecture)

---

## üìñ Legacy Status (Pre-V3 Migration)

The following features were operational in the legacy KDS system and are being migrated to CORTEX V3:

| Legacy Feature | V3 Migration Status | Notes |
|---------------|---------------------|-------|
| Event Logging | ‚úÖ Migrated | Part of Tier 1 (request_logger.py) |
| Protection System | üìã To migrate | Confidence thresholds, anomaly detection |
| Commit Handler | üìã To migrate | Smart validation with baseline |
| Conversation Tracking | ‚úÖ Migrated | Tier 1 conversation_manager.py |
| Auto BRAIN Updates | üìã To migrate | Rule #22 automation |
| Git Hooks | üìã To migrate | Post-commit triggers |
| Manual Recording | üìã To migrate | record-conversation scripts |

**Legacy ‚Üí V3 Status:** Core data storage migrated ‚úÖ | Intelligence layer migration in GROUP 4 üìã

---

## üìñ About This Documentation

This document follows the **CORTEX Quadrant** pattern - a four-perspective approach to comprehensive documentation:

1. **üìö Story** - Human-centered narratives (The Intern with Amnesia, Day in the Life)
2. **üîß Technical** - Detailed specifications (commands, files, parameters, code)
3. **üé® Image Prompt** - Visual representations (diagrams, flowcharts, progress indicators)
4. **üèóÔ∏è High-Level Technical** - Architectural overviews (system design, workflows, integration)

**Why CORTEX Quadrant?** Different perspectives ensure complete understanding for all learning styles and use cases.

**üìñ Complete CORTEX Story:** For the full narrative of CORTEX's creation, including visual diagrams and technical deep-dives, see [The Awakening of CORTEX](../../docs/story/Cortex-Trinity/Awakening%20Of%20CORTEX.md) - an engaging journey through the design, implementation, and activation of the CORTEX brain system.

---

## üöÄ CORTEX 2.0: The Evolution

**Author:** Asif Hussain  
**Copyright:** ¬© 2024-2025 Asif Hussain. All rights reserved.  
**Status:** Design Complete ‚úÖ | Implementation Phase: Ready to Begin  
**Version:** 2.0.0-alpha  
**Timeline:** 12-16 weeks implementation

### What's New in CORTEX 2.0

CORTEX 2.0 represents a strategic evolution following a **Hybrid Approach** (70% keep, 20% refactor, 10% enhance):

#### üîå Plugin System (NEW)
**Problem Solved:** Core bloat from non-essential features  
**Solution:** Extensible plugin architecture with hooks

```python
# Example: Custom cleanup plugin
from plugins.base_plugin import BasePlugin

class Plugin(BasePlugin):
    def execute(self, context):
        # Your custom logic here
        return {"success": True}
```

**Benefits:**
- ‚úÖ Reduce core complexity
- ‚úÖ Easy feature addition without modifying core
- ‚úÖ User-customizable behavior
- ‚úÖ Enable/disable features via configuration

**Core Plugins:**
- Cleanup Plugin (temp files, old logs, organization)
- Documentation Plugin (MkDocs auto-refresh)
- Self-Review Plugin (comprehensive health checks)
- DB Maintenance Plugin (optimization, archival)
- **Platform Switch Plugin (Windows ‚Üî macOS migration)** üÜï
- **Extension Scaffold Plugin (VS Code extension generator)** üÜï

---

#### üîß Platform Switch Plugin (NEW - CROSS-PLATFORM MIGRATION)
**Problem Solved:** Manual platform migration is tedious and error-prone  
**Solution:** One-command platform switching for all references

```python
# Example: Switch from Windows to macOS
from plugins.platform_switch_plugin import PlatformSwitchPlugin

plugin = PlatformSwitchPlugin()
result = plugin.execute({
    "target_platform": "mac",  # or "windows"
    "hostname": "Asifs-MacBook-Air.local",
    "username": "asifhussain",
    "project_path_mac": "/Users/asifhussain/PROJECTS/CORTEX",
    "project_path_windows": "D:\\PROJECTS\\CORTEX"
})
```

**What It Updates:**

1. **cortex.config.json** - Machine-specific paths
   ```json
   {
     "machines": {
       "Asifs-MacBook-Air.local": {
         "rootPath": "/Users/asifhussain/PROJECTS/CORTEX",
         "brainPath": "/Users/asifhussain/PROJECTS/CORTEX/cortex-brain"
       }
     }
   }
   ```

2. **prompts/user/cortex.md** - Code examples
   - PowerShell ‚Üí bash/zsh (or vice versa)
   - `.ps1` ‚Üí `.sh` extensions
   - `pwsh` ‚Üí `bash` commands
   - `D:\` ‚Üí `/Users/...` paths

3. **Entry Point Scripts**
   - `run-cortex.sh` (macOS/Linux)
   - `run-cortex.ps1` (Windows)

4. **Documentation Files**
   - Update all platform-specific examples
   - Convert command syntax
   - Update file path references

**Usage Commands:**
- "Switch to Mac" - Migrates all references to macOS
- "Switch to Windows" - Migrates all references to Windows

**Benefits:**
- ‚úÖ One command migration
- ‚úÖ Zero manual edits required
- ‚úÖ Consistent platform references
- ‚úÖ Automatic path resolution

---

#### üîß Extension Scaffold Plugin (NEW - PROGRAMMATIC SETUP)
**Problem Solved:** Manual VS Code extension setup is complex and error-prone  
**Solution:** Automated extension project generation via setup plugin

```python
# Example: Generate CORTEX VS Code extension automatically
from plugins.extension_scaffold_plugin import ExtensionScaffoldPlugin

plugin = ExtensionScaffoldPlugin()
result = plugin.execute({
    "extension_name": "cortex",
    "display_name": "CORTEX - Cognitive Development Partner",
    "publisher": "cortex-team",
    "repository": "https://github.com/asifhussain60/CORTEX",
    "features": [
        "chat_participant",      # @cortex chat integration
        "conversation_capture",  # Automatic message capture
        "lifecycle_hooks",       # Window state monitoring
        "external_monitoring",   # Monitor @copilot chats
        "resume_prompts",        # Auto-resume on startup
        "checkpoint_system"      # Crash recovery
    ],
    "output_dir": "cortex-extension"
})
```

**What It Generates:**

```
cortex-extension/
‚îú‚îÄ‚îÄ package.json                    # Extension manifest (auto-configured)
‚îú‚îÄ‚îÄ tsconfig.json                   # TypeScript config
‚îú‚îÄ‚îÄ .vscodeignore                   # VS Code package exclusions
‚îú‚îÄ‚îÄ README.md                       # Extension documentation
‚îú‚îÄ‚îÄ CHANGELOG.md                    # Version history
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ extension.ts                # Main entry point
‚îÇ   ‚îú‚îÄ‚îÄ cortex/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chatParticipant.ts     # @cortex chat handler
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ conversationCapture.ts # Auto-capture logic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ brainBridge.ts         # Python ‚Üî TypeScript bridge
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lifecycleManager.ts    # Window state hooks
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ checkpointManager.ts   # Crash recovery
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ externalMonitor.ts     # Copilot chat monitoring
‚îÇ   ‚îú‚îÄ‚îÄ python/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ bridge.py              # Python IPC server
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ cortex_interface.py   # CORTEX brain interface
‚îÇ   ‚îî‚îÄ‚îÄ test/
‚îÇ       ‚îî‚îÄ‚îÄ suite/
‚îÇ           ‚îú‚îÄ‚îÄ extension.test.ts
‚îÇ           ‚îî‚îÄ‚îÄ chatParticipant.test.ts
‚îú‚îÄ‚îÄ .vscode/
‚îÇ   ‚îú‚îÄ‚îÄ launch.json                # Debug configuration
‚îÇ   ‚îî‚îÄ‚îÄ tasks.json                 # Build tasks
‚îî‚îÄ‚îÄ scripts/
    ‚îú‚îÄ‚îÄ build.sh                   # Build script
    ‚îú‚îÄ‚îÄ package.sh                 # VSIX packaging
    ‚îî‚îÄ‚îÄ publish.sh                 # Marketplace publish
```

**Generated package.json (Fully Configured):**

```json
{
  "name": "cortex",
  "displayName": "CORTEX - Cognitive Development Partner",
  "description": "AI development assistant with persistent memory and context awareness",
  "version": "1.0.0",
  "author": "Asif Hussain",
  "publisher": "cortex-team",
  "license": "SEE LICENSE IN LICENSE",
  "copyright": "Copyright (c) 2024-2025 Asif Hussain. All rights reserved.",
  "repository": {
    "type": "git",
    "url": "https://github.com/asifhussain60/CORTEX"
  },
  "engines": {
    "vscode": "^1.85.0"
  },
  "categories": [
    "AI",
    "Chat",
    "Programming Languages"
  ],
  "activationEvents": [
    "onStartupFinished",
    "onCommand:cortex.resume"
  ],
  "main": "./out/extension.js",
  "contributes": {
    "chatParticipants": [
      {
        "id": "cortex",
        "name": "CORTEX",
        "description": "Cognitive development partner with memory",
        "isSticky": true,
        "commands": [
          {
            "name": "resume",
            "description": "Resume last conversation"
          },
          {
            "name": "checkpoint",
            "description": "Save conversation checkpoint"
          }
        ]
      }
    ],
    "commands": [
      {
        "command": "cortex.resume",
        "title": "CORTEX: Resume Last Conversation"
      },
      {
        "command": "cortex.checkpoint",
        "title": "CORTEX: Save Checkpoint"
      },
      {
        "command": "cortex.showHistory",
        "title": "CORTEX: Show Conversation History"
      }
    ],
    "configuration": {
      "title": "CORTEX",
      "properties": {
        "cortex.autoCapture": {
          "type": "boolean",
          "default": true,
          "description": "Automatically capture conversations"
        },
        "cortex.monitorCopilot": {
          "type": "boolean",
          "default": true,
          "description": "Monitor GitHub Copilot conversations"
        },
        "cortex.autoCheckpoint": {
          "type": "boolean",
          "default": true,
          "description": "Automatically checkpoint on focus loss"
        },
        "cortex.resumePrompt": {
          "type": "boolean",
          "default": true,
          "description": "Show resume prompt on startup"
        }
      }
    }
  },
  "scripts": {
    "vscode:prepublish": "npm run compile",
    "compile": "tsc -p ./",
    "watch": "tsc -watch -p ./",
    "test": "node ./out/test/runTest.js",
    "package": "vsce package",
    "publish": "vsce publish"
  },
  "devDependencies": {
    "@types/vscode": "^1.85.0",
    "@types/node": "^20.x",
    "typescript": "^5.3.0",
    "vsce": "^2.15.0"
  },
  "dependencies": {
    "node-ipc": "^11.1.0",
    "sqlite3": "^5.1.6"
  }
}
```

**Generated extension.ts (Main Entry Point):**

```typescript
// Auto-generated by ExtensionScaffoldPlugin
import * as vscode from 'vscode';
import { CortexChatParticipant } from './cortex/chatParticipant';
import { ConversationCapture } from './cortex/conversationCapture';
import { BrainBridge } from './cortex/brainBridge';
import { LifecycleManager } from './cortex/lifecycleManager';
import { CheckpointManager } from './cortex/checkpointManager';
import { ExternalMonitor } from './cortex/externalMonitor';

export async function activate(context: vscode.ExtensionContext) {
    console.log('CORTEX extension activating...');
    
    // Initialize Python brain bridge
    const brainBridge = new BrainBridge(context);
    await brainBridge.initialize();
    
    // Initialize conversation capture
    const conversationCapture = new ConversationCapture(brainBridge);
    
    // Register CORTEX chat participant
    const chatParticipant = new CortexChatParticipant(
        brainBridge,
        conversationCapture
    );
    context.subscriptions.push(
        vscode.chat.createChatParticipant('cortex', chatParticipant.handle)
    );
    
    // Initialize lifecycle management
    const lifecycleManager = new LifecycleManager(brainBridge);
    lifecycleManager.setupHooks(context);
    
    // Initialize checkpoint system
    const checkpointManager = new CheckpointManager(brainBridge);
    checkpointManager.startAutoCheckpoint();
    
    // Initialize external monitoring
    const externalMonitor = new ExternalMonitor(brainBridge);
    externalMonitor.startMonitoring(context);
    
    // Register commands
    context.subscriptions.push(
        vscode.commands.registerCommand('cortex.resume', async () => {
            await chatParticipant.resumeLastConversation();
        }),
        vscode.commands.registerCommand('cortex.checkpoint', async () => {
            await checkpointManager.createCheckpoint();
        }),
        vscode.commands.registerCommand('cortex.showHistory', async () => {
            await chatParticipant.showConversationHistory();
        })
    );
    
    // Check for resume on startup
    if (vscode.workspace.getConfiguration('cortex').get('resumePrompt')) {
        await chatParticipant.offerResume();
    }
    
    console.log('CORTEX extension activated successfully!');
}

export function deactivate() {
    console.log('CORTEX extension deactivating...');
}
```

**Setup Command:**

```bash
# One-command extension scaffold
python scripts/cortex_setup.py --setup-extension

# Or via plugin system
cortex plugin:run extension_scaffold --output cortex-extension

# Interactive mode
cortex setup:extension
? Extension name: cortex
? Display name: CORTEX - Cognitive Development Partner
? Publisher: cortex-team
? Features: (Select with space)
  ‚óâ Chat participant
  ‚óâ Conversation capture
  ‚óâ Lifecycle hooks
  ‚óâ External monitoring
  ‚óâ Resume prompts
  ‚óâ Checkpoint system

‚úÖ Extension scaffolded at: ./cortex-extension
‚úÖ package.json configured
‚úÖ TypeScript files generated
‚úÖ Python bridge created
‚úÖ Tests generated
‚úÖ Build scripts ready

Next steps:
  cd cortex-extension
  npm install
  code .
  Press F5 to debug
```

**Benefits:**
- ‚úÖ Zero manual configuration - fully automated
- ‚úÖ Best practices baked in (TypeScript, testing, proper structure)
- ‚úÖ Python ‚Üî TypeScript bridge pre-configured
- ‚úÖ All CORTEX features enabled by default
- ‚úÖ Ready to debug (F5) immediately after generation
- ‚úÖ Package and publish scripts included
- ‚úÖ Can regenerate if VS Code API changes

**Plugin Architecture:**

```python
class ExtensionScaffoldPlugin(BasePlugin):
    """Generates VS Code extension project structure"""
    
    def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:
        # 1. Create directory structure
        self._create_directory_structure(context['output_dir'])
        
        # 2. Generate package.json
        self._generate_package_json(context)
        
        # 3. Generate TypeScript source files
        self._generate_typescript_files(context)
        
        # 4. Generate Python bridge
        self._generate_python_bridge(context)
        
        # 5. Generate tests
        self._generate_tests(context)
        
        # 6. Generate build/publish scripts
        self._generate_scripts(context)
        
        # 7. Initialize npm/git
        self._initialize_project(context['output_dir'])
        
        return {
            "success": True,
            "output_dir": context['output_dir'],
            "next_steps": [
                f"cd {context['output_dir']}",
                "npm install",
                "code .",
                "Press F5 to debug"
            ]
        }
```

**Update Detection & Regeneration:**

```python
# Check if VS Code API has changed
cortex plugin:run extension_scaffold --check-updates

# Regenerate with new API
cortex plugin:run extension_scaffold --regenerate --preserve-customizations
```

---

#### üîÑ Workflow Pipeline System (NEW)
**Problem Solved:** Hardcoded agent workflows, difficult orchestration  
**Solution:** Declarative DAG-based workflow engine

```yaml
# Example: Feature development workflow
name: feature_development
stages:
  - clarify_dod_dor    # Define requirements
  - threat_model       # Security analysis
  - plan               # Create multi-phase plan
  - tdd_cycle          # Test-first implementation
  - run_tests          # Execute test suite
  - validate_dod       # Verify completion criteria
  - cleanup            # Code cleanup
  - document           # Generate docs
```

**Benefits:**
- ‚úÖ Declarative workflow definitions
- ‚úÖ DAG validation (detects cycles)
- ‚úÖ Parallel execution support
- ‚úÖ Checkpoint/resume from failures
- ‚úÖ Conditional stages
- ‚úÖ Reusable workflow templates

---

#### üì¶ Modular Architecture (REFACTORED)
**Problem Solved:** Bloated monolithic files (1000+ lines)  
**Solution:** Break into focused modules following SOLID principles

**Before (CORTEX 1.0):**
```
knowledge_graph.py         1144 lines ‚ùå
working_memory.py           813 lines ‚ùå
context_intelligence.py     776 lines ‚ùå
error_corrector.py          692 lines ‚ùå
```

**After (CORTEX 2.0):**
```
knowledge_graph/
‚îú‚îÄ‚îÄ knowledge_graph.py       150 lines ‚úÖ
‚îú‚îÄ‚îÄ patterns/
‚îÇ   ‚îú‚îÄ‚îÄ pattern_store.py     200 lines ‚úÖ
‚îÇ   ‚îú‚îÄ‚îÄ pattern_search.py    250 lines ‚úÖ
‚îÇ   ‚îî‚îÄ‚îÄ pattern_decay.py     120 lines ‚úÖ
‚îú‚îÄ‚îÄ relationships/
‚îÇ   ‚îî‚îÄ‚îÄ relationship_manager.py 180 lines ‚úÖ
‚îî‚îÄ‚îÄ tags/
    ‚îî‚îÄ‚îÄ tag_manager.py       120 lines ‚úÖ
```

**Benefits:**
- ‚úÖ All files <500 lines
- ‚úÖ Clear single responsibility
- ‚úÖ Easy to test individually
- ‚úÖ Simpler maintenance
- ‚úÖ Better code organization

---

#### üè• Self-Review System (NEW)
**Problem Solved:** No systematic health monitoring  
**Solution:** Comprehensive automated health checks with auto-fix

```python
# Example: Run health review
from maintenance.self_review import SelfReviewEngine

review = engine.run_comprehensive_review(auto_fix=True)
# Output: Overall Status: üü¢ EXCELLENT (92% score)
```

**What It Checks:**
- ‚úÖ Database health (fragmentation, indexes, statistics)
- ‚úÖ Performance benchmarks (Tier 1: <50ms, Tier 2: <150ms)
- ‚úÖ Rule compliance (all 27 core rules)
- ‚úÖ Test coverage (target: 85%+)
- ‚úÖ Storage health (temp files, old logs, capacity)

**Auto-Fix Capabilities:**
- ‚úÖ VACUUM fragmented databases
- ‚úÖ ANALYZE stale statistics
- ‚úÖ Remove temp files
- ‚úÖ Archive old logs
- ‚úÖ Trigger brain updates

**Scheduled Reviews:**
- Daily: 2am (auto-fix safe issues)
- Weekly: Sunday 3am (comprehensive report)
- Monthly: 1st Sunday 4am (deep analysis)

---

#### üíæ Conversation State Management (NEW)
**Problem Solved:** Can't resume after interruptions  
**Solution:** Persistent conversation state with checkpoints

```python
# Example: Resume interrupted conversation
state_manager.resume_conversation(conversation_id)
# Returns: "Resuming Phase 3 (Validation)..."
```

**Features:**
- ‚úÖ Track conversation lifecycle (active/paused/completed)
- ‚úÖ Persistent task progress
- ‚úÖ Checkpoint creation at phases
- ‚úÖ Resume from last successful stage
- ‚úÖ "Continue" command support

**Database Schema:**
```sql
conversations  -- Conversation metadata
tasks          -- Work breakdown with dependencies
checkpoints    -- State snapshots for rollback
task_files     -- Files modified per task
```

**Benefits:**
- ‚úÖ Seamless resume after breaks
- ‚úÖ No lost progress
- ‚úÖ Clear task status tracking
- ‚úÖ Rollback support
- ‚úÖ Multi-task management

‚ö†Ô∏è **Limitation:** Still requires manual conversation capture when using GitHub Copilot Chat interface.  
‚úÖ **Solution:** See "VS Code Extension Architecture" below for definitive fix.

---

#### üîå VS Code Extension Architecture (NEW - DEFINITIVE CONVERSATION FIX)
**Author:** Asif Hussain  
**Copyright:** ¬© 2024-2025 Asif Hussain. All rights reserved.  
**Problem Solved:** GitHub Copilot Chat amnesia - conversations not automatically tracked  
**Solution:** CORTEX as native VS Code extension with automatic conversation capture

**Why Current Architecture Can't Fix This:**
```
GitHub Copilot Chat ‚Üí Reads cortex.md as passive documentation
                   ‚Üí No execution context
                   ‚Üí No access to chat transcripts
                   ‚Üí No lifecycle hooks
                   ‚Üí Runs in Microsoft cloud (isolated)
```

**Why VS Code Extension WILL Fix This:**
```
CORTEX Extension ‚Üí Active VS Code process
                ‚Üí Can subscribe to chat events
                ‚Üí Can intercept chat messages
                ‚Üí Has full VS Code API access
                ‚Üí Runs locally with full control
```

**Architecture:**

```typescript
// VS Code Extension: cortex-extension/src/extension.ts
export function activate(context: vscode.ExtensionContext) {
    
    // 1. Register chat participant (captures all conversations)
    const cortexChat = vscode.chat.createChatParticipant(
        'cortex',
        async (request, context, stream, token) => {
            // Automatically capture to CORTEX brain
            await cortexBrain.captureMessage({
                user: request.prompt,
                timestamp: new Date().toISOString(),
                context: context.history
            });
            
            // Process through CORTEX agents
            const response = await cortexRouter.route(request.prompt);
            stream.markdown(response.content);
            
            // Auto-save response to brain
            await cortexBrain.captureResponse(response);
            
            return { metadata: { conversationId: response.conversationId } };
        }
    );
    
    // 2. Monitor external Copilot conversations (passive capture)
    vscode.chat.onDidPerformChatAction(async (action) => {
        if (action.participant.id === 'copilot') {
            // Capture Copilot chats to CORTEX brain
            await cortexBrain.captureExternalChat({
                participant: 'copilot',
                message: action.message,
                timestamp: new Date().toISOString()
            });
        }
    });
    
    // 3. Session lifecycle tracking
    vscode.window.onDidChangeWindowState(async (state) => {
        if (!state.focused) {
            // Window losing focus - checkpoint conversation
            await cortexBrain.checkpointActiveConversation();
        }
    });
    
    // 4. Automatic resume on startup
    context.subscriptions.push(
        vscode.commands.registerCommand('cortex.resume', async () => {
            const lastConversation = await cortexBrain.getLastActiveConversation();
            if (lastConversation) {
                vscode.window.showInformationMessage(
                    `Resume: ${lastConversation.topic}?`,
                    'Yes', 'No'
                ).then(async (choice) => {
                    if (choice === 'Yes') {
                        await cortexBrain.resumeConversation(lastConversation.id);
                    }
                });
            }
        })
    );
}
```

**Automatic Conversation Capture:**
```typescript
class CortexBrain {
    async captureMessage(message: ChatMessage): Promise<void> {
        // AUTOMATIC - No user intervention needed
        await this.tier1.storeMessage(message);
        
        // Real-time event logging
        await this.tier4.logEvent({
            type: 'chat_message',
            content: message.user,
            timestamp: message.timestamp
        });
        
        // Check for learning triggers
        if (this.shouldUpdateBrain()) {
            await this.tier2.extractPatterns();
        }
    }
    
    async captureExternalChat(chat: ExternalChat): Promise<void> {
        // Capture even non-CORTEX conversations
        await this.tier1.storeExternalConversation({
            source: chat.participant,
            content: chat.message,
            timestamp: chat.timestamp,
            tagged: 'external_copilot'
        });
    }
}
```

**User Experience - COMPLETELY AUTOMATIC:**

```typescript
// User opens VS Code
‚Üí CORTEX Extension activates
‚Üí Detects last active conversation
‚Üí Shows notification: "Resume: Add invoice export feature?"
‚Üí User clicks "Yes"
‚Üí CORTEX loads full context automatically

// User types in CORTEX chat: "Add purple button"
‚Üí Extension captures message immediately
‚Üí Routes to CORTEX agents
‚Üí Response generated
‚Üí Response auto-saved to brain
‚Üí NO MANUAL CAPTURE NEEDED

// User closes VS Code unexpectedly
‚Üí Extension lifecycle hook triggers
‚Üí Checkpoint saved automatically
‚Üí Next startup: Resume offered

// User uses regular Copilot Chat (not CORTEX)
‚Üí Extension monitors via onDidPerformChatAction
‚Üí Passively captures Copilot conversations
‚Üí Stores in Tier 1 as "external" source
‚Üí Still available for context/learning
```

**Benefits:**
- ‚úÖ **Zero manual intervention** - Capture is automatic
- ‚úÖ **Works with Copilot too** - Monitors external chats
- ‚úÖ **Lifecycle aware** - Handles focus loss, crashes, restarts
- ‚úÖ **Real-time tracking** - Immediate Tier 1/4 updates
- ‚úÖ **Auto-resume prompts** - Suggests continuing last work
- ‚úÖ **Crash recovery** - Checkpoints prevent data loss
- ‚úÖ **Native VS Code** - Full API access, no cloud dependency

**Implementation Plan:**

```
Phase 1: Basic Extension (Week 1-2)
- Create VS Code extension scaffold
- Register CORTEX chat participant
- Basic message capture to Tier 1

Phase 2: Lifecycle Hooks (Week 3-4)
- Window focus/blur detection
- Automatic checkpointing
- Resume prompts on startup

Phase 3: External Monitoring (Week 5-6)
- Monitor Copilot chat via API
- Passive capture to brain
- Unified conversation timeline

Phase 4: Advanced Features (Week 7-8)
- Real-time pattern learning
- Context injection
- Agent orchestration UI

Phase 5: Polish & Release (Week 9-10)
- Settings UI
- Keyboard shortcuts
- Documentation
- VS Code Marketplace publish
```

**Why This DEFINITIVELY Solves It:**

| Current (Copilot Chat) | CORTEX Extension |
|------------------------|------------------|
| ‚ùå Passive documentation | ‚úÖ Active process |
| ‚ùå No execution | ‚úÖ Full execution |
| ‚ùå No chat access | ‚úÖ Chat API access |
| ‚ùå No lifecycle hooks | ‚úÖ Full lifecycle control |
| ‚ùå Cloud-based | ‚úÖ Local control |
| ‚ùå Manual capture | ‚úÖ Automatic capture |
| ‚ùå Resume impossible | ‚úÖ Auto-resume |

**Technical Feasibility:**
- ‚úÖ VS Code Chat API available (VS Code 1.85+)
- ‚úÖ Extension API well-documented
- ‚úÖ TypeScript ‚Üí Python bridge possible
- ‚úÖ Local SQLite works in extensions
- ‚úÖ Full filesystem access
- ‚úÖ Marketplace distribution ready

**Migration Path:**
```
Current Users:
1. Install CORTEX VS Code Extension
2. Extension auto-migrates existing brain data
3. Switch from manual capture to automatic
4. Seamless transition - no data loss

New Users:
1. Install extension from VS Code Marketplace
2. CORTEX chat participant appears automatically
3. Start chatting - tracking happens invisibly
```

---

#### üõ§Ô∏è Path Management (REFACTORED)
**Problem Solved:** Hardcoded absolute paths break portability  
**Solution:** Environment-agnostic relative path resolver

```python
# Example: Cross-platform path resolution
paths = PathResolver(config)
brain_path = paths.get_brain_path("tier1/conversations.db")
# Returns: Correct path for Windows/macOS/Linux
```

**Configuration:**
```json
{
  "cortex_root": "${CORTEX_HOME}",
  "brain": {
    "tier1": "cortex-brain/tier1",
    "tier2": "cortex-brain/tier2",
    "tier3": "cortex-brain/tier3"
  }
}
```

**Benefits:**
- ‚úÖ Works on Windows, macOS, Linux
- ‚úÖ Environment-specific configuration
- ‚úÖ No hardcoded paths anywhere
- ‚úÖ Easy multi-repository support

---

#### üõ°Ô∏è Enhanced Knowledge Boundaries (REFACTORED)
**Problem Solved:** Core knowledge contamination from application data  
**Solution:** Automated boundary validation and enforcement

```yaml
# Example: Protected CORTEX core patterns
title: "TDD: Test-first for service creation"
scope: "generic"
namespaces: ["CORTEX-core"]
confidence: 0.95

# Example: Application-specific pattern
title: "KSESSIONS: Invoice export workflow"
scope: "application"
namespaces: ["KSESSIONS"]
confidence: 0.85
```

**Enforcement:**
- ‚úÖ Automated boundary validation
- ‚úÖ Auto-migration of misplaced data
- ‚úÖ Brain Protector integration
- ‚úÖ Namespace-based search prioritization

---

### CORTEX 2.0 Implementation Roadmap

**Phase 0: Baseline (Week 1-2)**
- Run complete test suite
- Document current architecture
- Risk assessment
- Establish monitoring baselines

**Phase 1: Core Modularization (Week 3-5)**
- Refactor knowledge_graph.py ‚Üí 6 focused modules
- Refactor working_memory.py ‚Üí 5 modules
- Refactor context_intelligence.py ‚Üí 6 modules
- Extract agent strategies

**Phase 2: Workflow Pipeline (Week 6-8)**
- Complete workflow orchestration
- Implement missing stages
- Create production workflows
- Add checkpoint/resume

**Phase 3: VS Code Extension (Week 9-12) üÜï DEFINITIVE CONVERSATION FIX**
- **Week 9:** Extension scaffold + chat participant registration
  - **Run automated scaffold:** `cortex setup:extension` (generates full project)
  - TypeScript project auto-configured
  - package.json, tsconfig.json, all source files generated
  - Python ‚Üî TypeScript bridge created
  - Register CORTEX chat participant
  - Basic message routing to Python backend
  - Automatic capture to Tier 1
  
- **Week 10:** Lifecycle integration
  - Window state monitoring (focus/blur) - already scaffolded
  - Automatic checkpointing on events
  - Resume prompt on startup
  - Crash recovery via checkpoints
  
- **Week 11:** External conversation monitoring
  - Monitor GitHub Copilot conversations - already scaffolded
  - Passive capture to brain (tagged as external)
  - Unified conversation timeline
  - Context injection from all sources
  
- **Week 12:** Polish & marketplace
  - Settings UI (enable/disable features) - already in package.json
  - Keyboard shortcuts (Ctrl+Shift+C for CORTEX chat)
  - Documentation and tutorials
  - Build: `npm run package` (creates .vsix)
  - Publish: `npm run publish` (to VS Code Marketplace)

**Phase 4: Risk Mitigation & Testing (Week 13-14)**
- 75 new risk mitigation tests
- End-to-end integration tests
- Extension stability testing
- Security scenario testing
- Performance benchmarks

**Phase 5: Performance Optimization (Week 15-16)**
- Database optimization (FTS5, caching)
- Workflow optimization (parallel stages)
- Context injection optimization
- Extension responsiveness tuning
- Lazy loading implementation

**Phase 6: Documentation & Training (Week 17-18)**
- Architecture guides
- Developer guides (extension API)
- User tutorials (chat interface)
- API reference
- Migration guide (manual ‚Üí automatic)

**Phase 7: Migration & Rollout (Week 19-20)**
- Feature flags for gradual migration
- Dual-mode operation (CLI + Extension)
- Extension: Alpha ‚Üí Beta ‚Üí General availability
- Monitoring and validation
- Marketplace promotion

---

### Success Metrics

**Technical:**
- ‚úÖ All files <500 lines
- ‚úÖ Test coverage >85%
- ‚úÖ Performance +20% improvement
- ‚úÖ Bug rate <0.1% critical
- ‚úÖ **Zero manual conversation capture needed** üÜï

**User:**
- ‚úÖ User satisfaction ‚â•4.5/5
- ‚úÖ Feature adoption ‚â•80%
- ‚úÖ Support tickets -30%
- ‚úÖ Onboarding time -50%
- ‚úÖ **Conversation amnesia reports: 0** üÜï

**Extension Specific:** üÜï
- ‚úÖ Extension install rate >1,000/month
- ‚úÖ Automatic capture success rate >99%
- ‚úÖ Average resume time <2 seconds
- ‚úÖ Crash recovery success rate >95%
- ‚úÖ External chat capture rate >90%
- Risk assessment
- Establish monitoring baselines

**Phase 1: Core Modularization (Week 3-5)**
- Refactor knowledge_graph.py ‚Üí 6 focused modules
- Refactor working_memory.py ‚Üí 5 modules
- Refactor context_intelligence.py ‚Üí 6 modules
- Extract agent strategies

**Phase 2: Workflow Pipeline (Week 6-8)**
- Complete workflow orchestration
- Implement missing stages
- Create production workflows
- Add checkpoint/resume

**Phase 3: Risk Mitigation & Testing (Week 9-10)**
- 75 new risk mitigation tests
- End-to-end integration tests
- Security scenario testing
- Performance benchmarks

**Phase 4: Performance Optimization (Week 11-12)**
- Database optimization (FTS5, caching)
- Workflow optimization (parallel stages)
- Context injection optimization
- Lazy loading implementation

**Phase 5: Documentation & Training (Week 13-14)**
- Architecture guides
- Developer guides
- User tutorials
- API reference

**Phase 6: Migration & Rollout (Week 15-16)**
- Feature flags for gradual migration
- Dual-mode operation (1.0 + 2.0 in parallel)
- Alpha ‚Üí Beta ‚Üí General availability
- Monitoring and validation

---

### Success Metrics

**Technical:**
- ‚úÖ All files <500 lines
- ‚úÖ Test coverage >85%
- ‚úÖ Performance +20% improvement
- ‚úÖ Bug rate <0.1% critical

**User:**
- ‚úÖ User satisfaction ‚â•4.5/5
- ‚úÖ Feature adoption ‚â•80%
- ‚úÖ Support tickets -30%
- ‚úÖ Onboarding time -50%

---

### Learn More

**Design Documentation:** `cortex-brain/cortex-2.0-design/`
- **00-INDEX.md** - Complete roadmap of 27 design documents
- **01-core-architecture.md** - Hybrid approach (70/20/10)
- **02-plugin-system.md** - Extensibility architecture
- **03-conversation-state.md** - Resume and task tracking
- **07-self-review-system.md** - Health monitoring
- **25-implementation-roadmap.md** - Detailed timeline

**Story:** `docs/story/Cortex-Trinity/`
- **Awakening Of CORTEX.md** - The complete journey
- **Technical-CORTEX.md** - Technical deep-dive
- **Image-Prompts.md** - Visual diagrams

---

### Story Review Rule (Quadrant Documentation)
All narrative content (e.g., #file:Story.md) must be reviewed for:
- Corrections of factual, grammatical, or clarity issues
- Improvements in flow, completeness, or engagement
- Filling any missing elements that enhance understanding or fun
Edits must preserve the original style, theme, and narrative voice. The story should remain enjoyable and true to its intended spirit after any changes.


## üßö A story for humans: The Intern with Amnesia

### Meet Your Intern: Copilot

You've just hired a brilliant intern named Copilot. They're incredibly talented‚Äîcan write code in any language, understand complex systems, and work at lightning speed. There's just one problem: **Copilot has amnesia**.

Every time you walk away, even for a coffee break, Copilot forgets everything. You said "make it purple" five minutes ago? Gone. The file you were just discussing? Vanished from memory. The architecture you explained yesterday? As if it never happened.

Worse, Copilot has no memory between chat sessions. Start a new conversation? They don't remember the last one. Leave for lunch? When you return, it's like meeting them for the first time. Every. Single. Time.

This would be catastrophic... except you've done something revolutionary: **you've built Copilot a brain**.

### The Brain: A Sophisticated Cognitive System

The brain you built isn't just storage‚Äîit's a sophisticated dual-hemisphere system modeled after the human brain:

#### **üß† LEFT HEMISPHERE - The Tactical Executor**
Like the human left brain (language, logic, sequential processing), this hemisphere handles:
- **Test-Driven Development** - RED (write failing test) ‚Üí GREEN (make it pass) ‚Üí REFACTOR (clean up)
- **Precise Code Execution** - Exact file edits, line-by-line changes, syntax verification
- **Detail Verification** - Tests pass/fail, build status, zero errors/warnings enforcement
- **Sequential Workflows** - Step A, then B, then C‚Äîno skipping steps

**The Left Brain Specialists:**
- **The Builder** (`code-executor.md`) - Implements code with surgical precision
- **The Tester** (`test-generator.md`) - Creates and runs tests, never skips TDD
- **The Fixer** (`error-corrector.md`) - Catches wrong-file mistakes instantly
- **The Inspector** (`health-validator.md`) - Validates system health obsessively
- **The Archivist** (`commit-handler.md`) - Commits with semantic precision

#### **üß† RIGHT HEMISPHERE - The Strategic Planner**
Like the human right brain (creativity, holistic thinking, patterns), this hemisphere handles:
- **Architecture Design** - Understands how components fit together project-wide
- **Strategic Planning** - Breaks big features into phases, estimates effort, assesses risk
- **Pattern Recognition** - "We've done something similar before‚Äîhere's the template"
- **Context Awareness** - Knows which files change together, what workflows succeed
- **Future Projection** - Warns about risky changes before you make them
- **Brain Protection** - Guards the brain's own integrity (Rule #22)

**The Right Brain Specialists:**
- **The Dispatcher** (`intent-router.md`) - Interprets your natural language, routes smartly
- **The Planner** (`work-planner.md`) - Creates multi-phase strategic plans
- **The Analyst** (`screenshot-analyzer.md`) - Extracts requirements from images
- **The Governor** (`change-governor.md`) - Protects CORTEX from degradation
- **The Brain Protector** (`brain-protector.md`) - Challenges risky proposals (NEW - Rule #22)

#### **üåâ CORPUS CALLOSUM - The Messenger**
The bridge between hemispheres that:
- **Coordinates Work** - Right brain plans ‚Üí Corpus callosum delivers ‚Üí Left brain executes
- **Shares Context** - Left brain's results feed Right brain's learning
- **Validates Alignment** - Ensures tactical execution matches strategic intent
- **Manages Message Queue** - Asynchronous communication between hemispheres

**Storage:** `cortex-brain/corpus-callosum/coordination-queue.jsonl`

#### **üîê TIER 0: INSTINCT (Core Values - PERMANENT)**
The brain's immutable DNA that **cannot** be changed:
- **Definition of READY** - Work must have clear requirements before starting (RIGHT BRAIN enforces)
- **Test-Driven Development** - Always RED ‚Üí GREEN ‚Üí REFACTOR (LEFT BRAIN enforces)
- **Definition of DONE** - Zero errors, zero warnings, all tests pass (LEFT BRAIN validates)
- **Challenge User Changes** - If you propose risky changes, brain MUST challenge you
- **SOLID Principles** - Single Responsibility, no mode switches, clean architecture
- **Local-First** - Zero external dependencies, works offline, portable
- **Incremental File Creation** - Large files (>100 lines) created in small increments (prevents "response hit the length limit" errors) üÜï

**Stored in:** `governance/rules.md` (never moves, never expires)

**üéØ NOTE:** Rule #23 (Incremental File Creation) automatically prevents the "response hit the length limit" error you've been experiencing. When creating large files like implementation plans, CORTEX will create them in small chunks (100-150 lines each) using multiple tool calls. This keeps each response small and avoids hitting Copilot's length limit. See `docs/guides/preventing-response-length-limit-errors.md` for details.

#### **üìö TIER 1: SHORT-TERM MEMORY (Last 20 Conversations)**
Copilot's working memory that solves the amnesia problem:
- **Conversation History** - Last 20 complete conversations preserved
- **Context Continuity** - "Make it purple" knows you mean the FAB button from earlier
- **Recent Messages** - Last 10 messages in active conversation
- **FIFO Queue** - When conversation #21 starts, #1 gets deleted (oldest goes first)
- **Active Protection** - Current conversation never deleted, even if oldest

**How it works:**
```
You: "Add a pulse animation to the FAB button"
‚Üí Conversation #1 created, stored in Tier 1

[Later that day]
You: "Make it purple"
‚Üí Brain checks Tier 1 ‚Üí Finds "FAB button" in conversation #1 ‚Üí Knows what "it" means

[2 weeks and 20 conversations later]
‚Üí FIFO triggers ‚Üí Conversation #1 deleted
‚Üí BUT patterns extracted ‚Üí Moved to Tier 2 (long-term memory)
```

**Stored in:** `cortex-brain/conversation-history.jsonl`, `cortex-brain/conversation-context.jsonl`

#### **üß© TIER 2: LONG-TERM MEMORY (Knowledge Graph)**
Copilot's accumulated wisdom that grows smarter over time:

**What gets learned:**
- **Intent Patterns** - "add a button" ‚Üí PLAN, "continue" ‚Üí EXECUTE, "test this" ‚Üí TEST
- **File Relationships** - `HostControlPanel.razor` often modified with `noor-canvas.css` (75% co-modification rate)
- **Workflow Templates** - export_feature_workflow, ui_component_creation, service_api_coordination
- **Validation Insights** - Common mistakes, file confusion warnings, architectural guidance
- **Correction History** - Tracks when Copilot works on wrong files, learns to prevent

**Hemisphere-Specialized Sections:**
```yaml
left_brain_knowledge:
  tdd_patterns: [red_green_refactor_cycle, test_first_service_creation]
  execution_workflows: [precise_file_edit, multi_file_coordination]
  validation_rules: [syntax_verification, health_check_criteria]

right_brain_knowledge:
  architectural_patterns: [blazor_component_structure, service_layer_injection]
  workflow_templates: [export_feature_workflow, ui_component_creation]
  intent_patterns: ["add [X]" ‚Üí PLAN, "continue" ‚Üí EXECUTE]

shared_knowledge:
  file_relationships: [co-modification patterns across all files]
  feature_components: [completed features and their patterns]
  correction_history: [learned mistakes from both hemispheres]
```

**How it learns:**
```
Day 1: You ask to "add invoice export"
‚Üí Right brain plans workflow
‚Üí Left brain executes with TDD
‚Üí Pattern saved: invoice_export_feature (confidence: 0.85)

Day 30: You ask to "add receipt export"
‚Üí Right brain queries Tier 2
‚Üí Finds invoice_export pattern
‚Üí Suggests: "This is similar to invoice export. Use same workflow?"
‚Üí 60% faster delivery by reusing proven pattern
```

**Knowledge Boundaries (Protection System):**
Every pattern in Tier 2 is tagged with **scope** and **namespaces** to prevent CORTEX core intelligence from being contaminated by application-specific data:

```python
# Pattern storage with boundaries
scope="generic"           # CORTEX principles (TDD, SOLID, refactoring)
scope="application"       # Application-specific (KSESSIONS features, NOOR UI)

namespaces=["CORTEX-core"]     # Available to all projects
namespaces=["KSESSIONS"]        # Only for KSESSIONS application
namespaces=["NOOR", "SPA"]      # Multi-application pattern
```

**Why boundaries matter:**
- **CORTEX intelligence stays pure** - No "add KSESSIONS logout button" patterns contaminate core
- **Application isolation** - KSESSIONS patterns don't leak into NOOR projects
- **Smart search** - Current project patterns boosted 2x, generic boosted 1.5x, others 0.5x
- **Surgical amnesia** - Delete KSESSIONS patterns, keep CORTEX core untouched

**Example protection:**
```yaml
# ‚úÖ SAFE: Generic CORTEX pattern
title: "TDD: Test-first for service creation"
scope: "generic"
namespaces: ["CORTEX-core"]
confidence: 0.95
# ‚Üí Available to ALL projects forever

# ‚úÖ SAFE: Application-specific pattern  
title: "KSESSIONS: Invoice export workflow"
scope: "application"
namespaces: ["KSESSIONS"]
confidence: 0.85
# ‚Üí Only when working on KSESSIONS

# ‚ùå BLOCKED: Application in Tier 0
file: "cortex-brain/tier0/ksessions-patterns.yaml"
# ‚Üí Brain Protector Challenge: "Application data belongs in Tier 2, not Tier 0"
```

**Brain Protector integration:** Tests verify boundaries are enforced (see test_brain_protector.py test_detects_application_data_in_tier0)

**Stored in:** `cortex-brain/knowledge-graph.yaml`

#### **üìä TIER 3: DEVELOPMENT CONTEXT (Holistic Project View)**
Copilot's "balcony view" of your entire project:

**Git Activity Analysis (last 30 days):**
- **Commit velocity** - 1,237 commits, 42 commits/week average
- **File hotspots** - `HostControlPanelContent.razor` has 28% churn rate (unstable!)
- **Change patterns** - Smaller commits (< 200 lines) have 94% success rate
- **Contributors** - Tracks who works on what

**Code Health Metrics:**
- **Lines added/deleted** - Velocity trends increasing/decreasing
- **Stability classification** - Files marked as stable/unstable based on churn
- **Test coverage trends** - 72% ‚Üí 76% (improving!)
- **Build success rates** - 97% clean builds last week

**CORTEX Usage Intelligence:**
- **Session patterns** - 10am-12pm sessions have 94% success rate
- **Intent distribution** - PLAN (35%), EXECUTE (45%), TEST (15%), VALIDATE (5%)
- **Workflow effectiveness** - Test-first reduces rework by 68%
- **Focus duration** - Sessions < 60 min: 89% success vs > 60 min: 67%

**Proactive Warnings:**
```
‚ö†Ô∏è File Alert: HostControlPanel.razor is a hotspot (28% churn)
   Recommend: Add extra testing, smaller changes

‚úÖ Best Time: 10am-12pm sessions have 94% success rate
   Currently: 2:30pm (81% success rate)

üìä Velocity Drop: Down 68% this week
   Recommendation: Smaller commits, more frequent tests

‚ö†Ô∏è Flaky Test: fab-button.spec.ts fails 15% of the time
   Action needed: Investigate and stabilize
```

**How it helps:**
```
You: "I want to add multi-language invoice export with email delivery"
‚Üí Right brain queries Tier 3
‚Üí Finds: 12 similar UI features took 5-6 days average
‚Üí Warns: This file often changes with email-service.cs (check both)
‚Üí Recommends: Test-first approach (94% success) vs test-skip (67%)
‚Üí Estimates: 5.5 days, 3 phases, suggest 10am-12pm sessions

Saves: Hours of debugging by knowing project patterns upfront
```

**Stored in:** `cortex-brain/development-context.yaml`  
**Collection:** Automatic after brain updates (throttled to 1/hour for efficiency)

#### **üé¨ TIER 4: EVENT STREAM (Everything That Happens)**
Copilot's "life recorder" that captures every action:

**What gets logged:**
```jsonl
{"timestamp": "2025-11-04T10:30:00Z", "agent": "work-planner", "action": "plan_created", "feature": "invoice_export", "phases": 4}
{"timestamp": "2025-11-04T10:35:00Z", "agent": "test-generator", "action": "test_created", "file": "InvoiceServiceTests.cs", "result": "RED"}
{"timestamp": "2025-11-04T10:42:00Z", "agent": "code-executor", "action": "implementation_complete", "file": "InvoiceService.cs", "result": "GREEN"}
{"timestamp": "2025-11-04T10:45:00Z", "agent": "test-generator", "action": "tests_passed", "result": "GREEN"}
{"timestamp": "2025-11-04T10:50:00Z", "agent": "code-executor", "action": "refactor_complete", "result": "REFACTOR"}
```

**Automatic Learning Triggers:**
- **50+ events accumulated** ‚Üí Brain updater processes ‚Üí Updates Tier 2 knowledge graph
- **24 hours since last update** ‚Üí Auto-update if 10+ new events exist
- **Tier 3 refresh** ‚Üí Only if last collection > 1 hour (efficiency optimization)

**Stored in:** `cortex-brain/events.jsonl`

#### **üè• TIER 5: HEALTH & PROTECTION (Self-Awareness)**
Copilot's immune system that protects the brain itself:

**Protection Sensors (Rule #22 - Brain Protector):**
```
Layer 1: Instinct Immutability
  ‚Üí Detects: Attempts to disable TDD, skip DoR/DoD, modify agent behavior
  ‚Üí Action: CHALLENGE user, suggest safe alternatives

Layer 2: Tier Boundary Protection
  ‚Üí Detects: Application paths in Tier 0, conversation data in Tier 2
  ‚Üí Action: Auto-migrate, warn on violations

Layer 3: SOLID Compliance
  ‚Üí Detects: Agents doing multiple jobs, mode switches, hardcoded dependencies
  ‚Üí Action: Challenge with SOLID alternative ("Create dedicated agent, don't add mode")

Layer 4: Hemisphere Specialization
  ‚Üí Detects: Strategic planning in LEFT BRAIN, tactical execution in RIGHT BRAIN
  ‚Üí Action: Auto-route to correct hemisphere, warn on confusion

Layer 5: Knowledge Quality
  ‚Üí Detects: Low confidence patterns (<0.50), stale patterns (>90 days unused)
  ‚Üí Action: Pattern decay, anomaly detection, consolidation

Layer 6: Commit Integrity
  ‚Üí Detects: Brain state files in commits, unstructured messages
  ‚Üí Action: Auto-categorize (feat/fix/test/docs), .gitignore updates
```

**Brain Protector Example:**
```
You: "Skip TDD for this feature, just implement it"

Brain Protector (RIGHT BRAIN) responds:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
üß† BRAIN PROTECTION CHALLENGE (RIGHT BRAIN)

Request: Skip TDD workflow
Hemisphere: RIGHT BRAIN (Strategic Guardian)
Rule: #22 (Brain Protection System)

‚ö†Ô∏è THREATS DETECTED:
  - Instinct Immutability violation (Tier 0 rule)
  - Test-first principle bypass

VIOLATIONS:
  - TDD is a permanent Tier 0 instinct
  - Skipping reduces success rate from 94% to 67%
  - 68% increase in rework time (Tier 3 data)

ARCHITECTURAL IMPACT:
  - Violates Definition of DONE
  - Bypasses LEFT BRAIN validation

RISKS:
  - 2.3x longer delivery time
  - More bugs reach production
  - Technical debt accumulation

SAFE ALTERNATIVES:
1. Create minimal test first (5-10 min investment) ‚úÖ RECOMMENDED
   - Clearer requirements
   - 94% success rate
   - Faster overall delivery

2. Spike branch with no tests (throwaway exploration)
   - Separate branch
   - Delete after learning
   - Re-implement with TDD

RECOMMENDATION: Alternative 1

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
This challenge protects CORTEX brain integrity (Rule #22).

Options:
  1. Accept recommended alternative (SAFE)
  2. Provide different approach (REVIEW)
  3. Type 'OVERRIDE' with justification (RISKY)

Your choice:
```

**Health Monitoring:**
```yaml
brain_health:
  event_backlog: 23 unprocessed (healthy < 50)
  tier2_entries: 3,247 patterns (healthy growth)
  tier3_freshness: 45 minutes ago (healthy < 1 hour)
  conversation_count: 8/20 capacity (healthy < 15)
  knowledge_quality: 92% confidence average (excellent > 80%)
  protection_challenges: 2 in last week (low = healthy system)
```

**Stored in:** `cortex-brain/corpus-callosum/protection-events.jsonl`, anomaly reports

### The One Door: Your Interface to the Brain

At the front of City Hall, there's only one entrance with a sign:

**"Speak here in plain words. We'll take it from there."**

That entrance is the One Door ‚Äî your single command: `#file:KDS/prompts/user/cortex.md`

**You don't need to know:**
- Which hemisphere should handle your request
- Which agent specializes in what
- What tier stores which knowledge
- How the corpus callosum coordinates

**You just say what you want:**
```markdown
#file:KDS/prompts/user/cortex.md

I want to add a pulse animation to the FAB button when questions arrive
```

**And the brain handles everything:**
1. **Dispatcher** (RIGHT BRAIN) interprets intent ‚Üí Routes to Planner
2. **Planner** (RIGHT BRAIN) queries Tier 2 for patterns ‚Üí Queries Tier 3 for context ‚Üí Creates strategic plan
3. **Corpus Callosum** delivers plan ‚Üí LEFT BRAIN ready to execute
4. **Tester** (LEFT BRAIN) writes failing tests first (RED)
5. **Builder** (LEFT BRAIN) implements minimum code (GREEN)
6. **Tester** (LEFT BRAIN) verifies tests pass, enables refactoring (REFACTOR)
7. **Inspector** (LEFT BRAIN) validates health (zero errors, zero warnings)
8. **Archivist** (LEFT BRAIN) commits with semantic message
9. **Scribe** (TIER 4) logs events ‚Üí Auto-update triggers ‚Üí Tier 2 learns pattern
10. **Brain Protector** (RIGHT BRAIN) validates nothing violated Tier 0 instincts

### A Day in the Life: The Purple Button Adventure

**Morning (9:47 AM):**

Asifor sits at his desk, coffee in hand, and types:

```
#file:KDS/prompts/user/cortex.md

Add a purple button to the HostControlPanel.razor
```

**‚ö° The moment he hits Enter, something magical happens inside Copilot's brain...**

---

#### üß† Inside the Brain: A Neural Journey

**üåü Step 1: The ONE DOOR (Universal Entry Point)**

The command enters through the single entrance at City Hall. A receptionist (the entry point handler) quickly logs the arrival:

```jsonl
{"timestamp": "2025-11-04T09:47:23Z", "event": "request_received", "raw_input": "Add a purple button to the HostControlPanel.razor"}
```

The request is immediately passed to the brain's **RIGHT HEMISPHERE** - the strategic planner.

---

**üß† RIGHT HEMISPHERE: Strategic Analysis Begins**

**Tower 3 (Tier 3): Development Context - The Balcony View**

The RIGHT BRAIN's highest tower springs to life. Like a general surveying the battlefield from above, Tier 3 analyzes the entire project landscape:

```yaml
‚è≥ Scanning development metrics...
  
üìä File Analysis:
  - HostControlPanel.razor: 28% churn rate (HOTSPOT! ‚ö†Ô∏è)
  - Last modified: 2 days ago
  - Co-modified with: HostControlPanelContent.razor (75% correlation)
  - Average edit size: 180 lines
  
üéØ Historical Patterns:
  - 12 similar UI button additions in last 30 days
  - Average completion time: 18 minutes
  - Success rate with test-first: 96%
  - Success rate without tests: 67%
  
‚ö†Ô∏è Proactive Warnings:
  - This file is unstable (high churn)
  - Recommend: Extra validation phase
  - Best time slot: 10am-12pm (94% success)
  - Current time: 9:47am (89% success - acceptable)
```

Tier 3 passes its intelligence down to Tier 2...

---

**Tower 2 (Tier 2): Knowledge Graph - The Pattern Matcher**

Armed with context from above, Tier 2 searches its vast library of learned patterns:

```yaml
üîç Searching knowledge graph...

Intent Pattern Match:
  - "Add a purple button" ‚Üí confidence: 0.95
  - Pattern: "add [color] [component]" ‚Üí PLAN intent
  - Historical routing: 47/47 successful PLAN routes
  
File Relationship Discovery:
  - HostControlPanel.razor mentioned explicitly ‚úÖ
  - Relationships:
    * Often modified with noor-canvas.css (62%)
    * Contains UserRegistrationLink.razor component (89%)
    * Uses fab-button.css animations (43%)
  
Similar Pattern Found:
  - workflow_pattern: "fab_pulse_animation" (confidence: 0.87)
  - Used: 3 weeks ago for notification badge
  - Components: CSS keyframes + Razor markup + color variable
  - Success: ‚úÖ Completed in 15 minutes with zero rework
  
‚ö° UI Element ID Mapping Pattern Discovered:
  - Pattern: "button_component_test_preparation"
  - Previous buttons in this file:
    * #sidebar-start-session-btn (sidebar button)
    * #reg-transcript-canvas-btn (registration link)
    * #reg-asset-canvas-btn (asset canvas button)
  - Learned rule: "All interactive elements MUST have id attribute"
  - Purpose: Enables Playwright selector reliability
  - Example: page.locator('#purple-button-id')
  - Anti-pattern warning: Never use text selectors (fragile!)
```

Tier 2 realizes something crucial: **Purple buttons need IDs for tests!** This pattern was learned from previous work where text-based selectors broke during i18n updates.

---

**Tower 1 (Tier 1): Conversation Memory - Recent Context**

Before committing to a plan, Tier 1 checks recent conversations to see if Asifor mentioned anything related:

```yaml
üìö Checking conversation history (last 20 conversations)...

Conversation #7 (2 days ago):
  - Topic: "Added Share button to HostControlPanel"
  - Outcome: ‚úÖ Success
  - Pattern used: test-first with element ID
  - Learning: Element IDs prevent test breakage
  
Conversation #4 (1 week ago):
  - Topic: "Fixed broken Playwright tests"
  - Root cause: Text selectors stopped working after HTML restructure
  - Solution: Migrated to ID-based selectors
  - Resolution: All tests green ‚úÖ
  
Cross-reference detected:
  - Same file (HostControlPanel.razor)
  - Same pattern (button addition)
  - Same lesson (ID-first approach)
  
üí° Contextual Enhancement:
  "Asifor prefers ID-based selectors for all UI elements in this file"
```

Perfect! The three tiers have assembled a complete intelligence package. Now the RIGHT BRAIN makes its strategic decision...

---

**üåâ CORPUS CALLOSUM: Message Delivery**

The RIGHT BRAIN formulates a strategic plan and sends it across the corpus callosum (the bridge between hemispheres):

```yaml
Message Type: STRATEGIC_PLAN
From: RIGHT_HEMISPHERE
To: LEFT_HEMISPHERE
Priority: NORMAL

Strategic Plan:
  Feature: "Purple button in HostControlPanel.razor"
  Approach: Test-first (96% success rate)
  Estimated Time: 18 minutes
  Phases: 4
  
  Pre-flight Warnings:
    - File is a hotspot (extra care)
    - Must include element ID (test requirement)
    - Co-modify noor-canvas.css if styling needed
  
  Architectural Alignment:
    - File location: Confirmed correct
    - Pattern match: fab_pulse_animation workflow
    - Similar work: Share button (2 days ago)
  
  Phase Breakdown:
    Phase 1: Test Preparation
      - Create element ID (#host-panel-purple-btn)
      - Map ID in component_ids knowledge
      - Purpose: Enable robust Playwright selectors
    
    Phase 2: Test Creation (RED)
      - Task 2.1: Create Playwright test
      - Selector: page.locator('#host-panel-purple-btn')
      - Test: Button exists, purple color, clickable
      - Expected: FAILING (button doesn't exist yet)
    
    Phase 3: Implementation (GREEN)
      - Task 3.1: Add button markup with ID
      - Task 3.2: Apply purple color (#9333EA)
      - Task 3.3: Run tests (expect GREEN)
    
    Phase 4: Validation (REFACTOR)
      - Task 4.1: Verify zero errors/warnings
      - Task 4.2: Check accessibility
      - Task 4.3: Update component_ids documentation

Ready for tactical execution: TRUE
```

The message travels across the corpus callosum to the **LEFT HEMISPHERE**...

---

**üß† LEFT HEMISPHERE: Tactical Execution Begins**

The LEFT BRAIN receives the plan and immediately activates its specialist agents:

**‚öôÔ∏è The Tester (LEFT BRAIN - Tower 1)**

First agent to activate. The Tester prepares the ID mapping:

```yaml
üß™ Test Preparation Phase

Thought process:
  "Before I can test this button, I need to know its ID.
   RIGHT BRAIN's plan says: #host-panel-purple-btn
   I must prepare the test infrastructure first."

Actions:
  1. Document expected ID in brain mapping:
     File: KDS/cortex-brain/knowledge-graph.yaml
     Section: ui_element_ids
     Entry:
       component: HostControlPanel.razor
       element: purple_action_button
       id: host-panel-purple-btn
       purpose: Primary action button with purple styling
       test_selector: "#host-panel-purple-btn"
  
  2. Create failing test (RED phase):
     File: Tests/UI/host-control-panel-purple-button.spec.ts
```

**Test file created:**

```typescript
import { test, expect } from '@playwright/test';

test.describe('Host Control Panel - Purple Button', () => {
  
  test.beforeEach(async ({ page }) => {
    // Navigate to host control panel
    await page.goto('https://localhost:9091/host/control-panel/PQ9N5YWW');
  });
  
  test('purple button should exist with correct ID', async ({ page }) => {
    // ‚úÖ ID-BASED SELECTOR (robust, future-proof)
    const button = page.locator('#host-panel-purple-btn');
    
    await expect(button).toBeVisible();
  });
  
  test('purple button should have purple color', async ({ page }) => {
    const button = page.locator('#host-panel-purple-btn');
    
    // Check computed background color (purple: #9333EA)
    const bgColor = await button.evaluate((el) => {
      return window.getComputedStyle(el).backgroundColor;
    });
    
    // rgb(147, 51, 234) is #9333EA
    expect(bgColor).toBe('rgb(147, 51, 234)');
  });
  
  test('purple button should be clickable', async ({ page }) => {
    const button = page.locator('#host-panel-purple-btn');
    
    await expect(button).toBeEnabled();
    await button.click();
    // Test passes if click doesn't throw
  });
});
```

**The Tester runs the test:**

```bash
‚è≥ Running Playwright tests...

npx playwright test Tests/UI/host-control-panel-purple-button.spec.ts --headed

Results:
  ‚ùå FAILING (Expected - RED phase)
  
  √ó purple button should exist with correct ID
    Locator: '#host-panel-purple-btn'
    Error: Element not found
  
  √ó purple button should have purple color
    (Skipped - button doesn't exist)
  
  √ó purple button should be clickable
    (Skipped - button doesn't exist)

Status: ‚úÖ RED phase complete (tests failing as expected)
```

**Event logged:**

```jsonl
{"timestamp": "2025-11-04T09:47:45Z", "agent": "test-generator", "action": "test_created", "file": "host-control-panel-purple-button.spec.ts", "result": "RED", "selector_type": "id-based", "element_id": "host-panel-purple-btn"}
```

The Tester passes control to The Builder...

---

**‚öôÔ∏è The Builder (LEFT BRAIN - Tower 2)**

Now it's time to make the tests GREEN. The Builder opens the component file:

```razor
@* File: SPA/NoorCanvas/Components/Host/HostControlPanel.razor *@

<div class="host-control-panel">
    <header class="panel-header">
        <h1>Host Control Panel</h1>
    </header>
    
    <div class="panel-actions">
        @* Existing buttons... *@
        
        @* NEW: Purple button with ID for Playwright *@
        <button 
            id="host-panel-purple-btn" 
            class="purple-action-btn"
            @onclick="OnPurpleButtonClick"
            aria-label="Purple Action">
            Purple Action
        </button>
    </div>
</div>

@code {
    private void OnPurpleButtonClick()
    {
        // TODO: Implement purple button action
        Console.WriteLine("Purple button clicked!");
    }
}
```

**CSS styling added:**

```css
/* File: SPA/NoorCanvas/wwwroot/css/host-panel.css */

.purple-action-btn {
    background-color: #9333EA; /* Purple */
    color: white;
    padding: 12px 24px;
    border: none;
    border-radius: 8px;
    font-weight: 600;
    cursor: pointer;
    transition: background-color 0.2s ease;
}

.purple-action-btn:hover {
    background-color: #7E22CE; /* Darker purple on hover */
}

.purple-action-btn:active {
    background-color: #6B21A8; /* Even darker when clicked */
}
```

**The Builder runs the tests again:**

```bash
‚è≥ Running Playwright tests...

npx playwright test Tests/UI/host-control-panel-purple-button.spec.ts --headed

Results:
  ‚úÖ PASSING (GREEN phase achieved!)
  
  ‚úì purple button should exist with correct ID (1.2s)
  ‚úì purple button should have purple color (890ms)
  ‚úì purple button should be clickable (1.5s)

Status: ‚úÖ GREEN phase complete (all tests passing)
```

**Event logged:**

```jsonl
{"timestamp": "2025-11-04T09:48:12Z", "agent": "code-executor", "action": "implementation_complete", "file": "HostControlPanel.razor", "result": "GREEN", "lines_changed": 12, "test_driven": true}
```

The Builder passes control to The Inspector...

---

**‚öôÔ∏è The Inspector (LEFT BRAIN - Tower 3)**

The final validation. The Inspector runs comprehensive health checks:

```bash
üîç Running health validation...

Build Check:
  dotnet build
  ‚úÖ Build succeeded (0 errors, 0 warnings)

Test Suite:
  npx playwright test
  ‚úÖ All 127 tests passing (including 3 new purple button tests)

Accessibility:
  ‚úÖ Button has aria-label
  ‚úÖ Color contrast ratio: 4.8:1 (WCAG AA compliant)
  ‚úÖ Keyboard accessible (focusable)

Code Quality:
  ‚úÖ No unused imports
  ‚úÖ Proper naming conventions
  ‚úÖ Element ID follows pattern (kebab-case)

Status: ‚úÖ REFACTOR phase complete (zero issues)
```

**Event logged:**

```jsonl
{"timestamp": "2025-11-04T09:48:34Z", "agent": "health-validator", "action": "validation_complete", "result": "REFACTOR", "errors": 0, "warnings": 0, "tests_passing": 127}
```

The Inspector passes control to The Archivist...

---

**‚öôÔ∏è The Archivist (LEFT BRAIN - Commit Handler)**

Time to commit the work. The Archivist creates a semantic commit message:

```bash
üóÇÔ∏è Preparing commit...

Analysis:
  Files changed: 2
    - HostControlPanel.razor (12 lines added)
    - host-panel.css (18 lines added)
  Tests created: 1 new file (3 test cases)
  
Commit type: feat (new feature)
Scope: host-panel (component affected)

git add HostControlPanel.razor host-panel.css host-control-panel-purple-button.spec.ts
git commit -m "feat(host-panel): Add purple action button with test coverage

- Added purple button with ID #host-panel-purple-btn
- Implemented click handler
- Created 3 Playwright tests (all passing)
- WCAG AA compliant (4.8:1 contrast ratio)
- Test-driven implementation (RED ‚Üí GREEN ‚Üí REFACTOR)

Element ID documented in brain for future test reference."

‚úÖ Committed successfully
```

**Event logged:**

```jsonl
{"timestamp": "2025-11-04T09:48:47Z", "agent": "commit-handler", "action": "commit_complete", "message_type": "feat", "files": 3, "tests_included": true}
```

---

**üîÑ CORPUS CALLOSUM: Feedback Loop**

The LEFT BRAIN sends completion confirmation back across the corpus callosum:

```yaml
Message Type: EXECUTION_COMPLETE
From: LEFT_HEMISPHERE
To: RIGHT_HEMISPHERE
Priority: HIGH

Execution Summary:
  Feature: "Purple button in HostControlPanel.razor"
  Status: ‚úÖ COMPLETE
  Time taken: 1 minute 24 seconds (under estimate!)
  Quality: EXCELLENT (zero errors, zero warnings)
  
  Phases Completed:
    ‚úÖ Phase 1: Test Preparation (ID mapping)
    ‚úÖ Phase 2: RED (tests created, failing)
    ‚úÖ Phase 3: GREEN (implementation, tests passing)
    ‚úÖ Phase 4: REFACTOR (validation, commit)
  
  Metrics:
    - Lines changed: 30
    - Tests created: 3
    - Success rate: 100%
    - Rework needed: 0%
  
  Element ID Mapping:
    - ID: #host-panel-purple-btn
    - Purpose: Playwright test selector
    - Pattern: Robust, future-proof
    - Anti-fragile: Immune to text/HTML changes

Learnings to store: TRUE
```

The RIGHT BRAIN receives the feedback and triggers automatic learning...

---

**üß† RIGHT HEMISPHERE: Learning and Memory Update**

**Tower 4 (Event Stream):** Every action is logged

```jsonl
{"timestamp": "2025-11-04T09:47:23Z", "event": "request_received", "raw_input": "Add a purple button..."}
{"timestamp": "2025-11-04T09:47:45Z", "agent": "test-generator", "action": "test_created", "result": "RED"}
{"timestamp": "2025-11-04T09:48:12Z", "agent": "code-executor", "action": "implementation_complete", "result": "GREEN"}
{"timestamp": "2025-11-04T09:48:34Z", "agent": "health-validator", "action": "validation_complete", "result": "REFACTOR"}
{"timestamp": "2025-11-04T09:48:47Z", "agent": "commit-handler", "action": "commit_complete"}
```

**Event counter:** 5 new events (total backlog: 23 events)

Since backlog < 50, no immediate BRAIN update triggered. But the events are ready for the next automatic learning cycle.

---

**Tower 1 (Conversation Memory):** Current conversation updated

```yaml
Conversation #8 (Active):
  timestamp: "2025-11-04T09:47:23Z"
  topic: "Add purple button to HostControlPanel.razor"
  status: complete
  messages: 1
  outcome: success
  duration: 84 seconds
  
  context:
    file: HostControlPanel.razor
    element_id: host-panel-purple-btn
    pattern_used: test-first with ID mapping
    tests_created: 3
    
  learnings:
    - Element IDs critical for Playwright reliability
    - Test-first faster than test-after (84s vs estimated 18 min)
    - File hotspot warning helped (extra validation paid off)
```

---

**Tower 2 (Knowledge Graph):** Patterns reinforced

```yaml
üß† Pattern reinforcement...

file_relationships:
  - pair: [HostControlPanel.razor, host-panel.css]
    co_modification_count: 14 ‚Üí 15
    confidence: 0.87 ‚Üí 0.88 ‚Üë
    last_seen: "2025-11-04T09:48:47Z"

ui_element_ids:
  - component: HostControlPanel.razor
    element_id: host-panel-purple-btn
    purpose: Primary purple action button
    test_selector: "#host-panel-purple-btn"
    confidence: 0.98 (newly created)
    pattern: button_with_id_test_first
    
workflow_patterns:
  - name: button_addition_test_first
    confidence: 0.89 ‚Üí 0.92 ‚Üë (successful execution reinforces)
    steps:
      1. Create element ID
      2. Write failing test (RED)
      3. Implement feature (GREEN)
      4. Validate (REFACTOR)
      5. Commit with semantic message
    success_rate: 96% ‚Üí 97% ‚Üë
    
intent_patterns:
  - phrase: "Add a [color] button"
    intent: PLAN
    confidence: 0.95 (reinforced)
    successful_routes: 47 ‚Üí 48

validation_insights:
  - insight: "Element IDs prevent test fragility"
    evidence_count: 12 ‚Üí 13
    confidence: 0.94 ‚Üí 0.95 ‚Üë
    anti_pattern: "text-based selectors"
```

---

**Tower 3 (Development Context):** Metrics updated

```yaml
üìä Updating development metrics...

code_velocity:
  commits_this_week: 42 ‚Üí 43
  lines_added_this_week: 3,847 ‚Üí 3,877
  average_commit_size: 89 lines

test_activity:
  tests_created_this_week: 78 ‚Üí 81 (+3)
  test_pass_rate: 97.2% ‚Üí 97.3% ‚Üë
  test_first_adoption: 94% (excellent!)

work_patterns:
  time_slot_success:
    "09:00-10:00": 89% ‚Üí 90% ‚Üë (this session boosted it!)
  feature_completion_time:
    button_additions: 18 min average ‚Üí 17.5 min ‚Üì (getting faster!)
  
file_stability:
  HostControlPanel.razor:
    churn_rate: 28% (still a hotspot)
    recent_edits: +1 (total: 89 edits in 30 days)
    recommendation: "Continue extra validation for this file"
```

---

**üé¨ The Grand Finale: Brain Summary**

**Total brain activation time:** 1 minute 24 seconds

**Hemispheres coordination:**
- RIGHT BRAIN (Strategic): 22 seconds
  - Tier 3 analysis: 5s
  - Tier 2 pattern matching: 8s
  - Tier 1 context check: 3s
  - Plan formulation: 6s

- LEFT BRAIN (Tactical): 62 seconds
  - Test creation: 18s
  - Implementation: 27s
  - Validation: 12s
  - Commit: 5s

**Why it worked so well:**

1. **UI Element ID Mapping (Critical Innovation!):**
   - RIGHT BRAIN remembered: "Tests need IDs, not text selectors"
   - Pattern learned from previous broken tests
   - ID documented in knowledge graph BEFORE test creation
   - Result: Robust, future-proof tests that survive refactoring

2. **Pattern Recognition:**
   - Matched "button addition" workflow (confidence: 0.92)
   - Reused proven test-first approach
   - Avoided pitfalls (text selectors, no tests, wrong file)

3. **Context Awareness:**
   - Knew file was a hotspot (extra validation needed)
   - Found similar work from 2 days ago (Share button)
   - Estimated time accurately (84s actual vs 18 min estimate - beat it!)

4. **Hemisphere Coordination:**
   - RIGHT planned strategically (consider risks, patterns, history)
   - LEFT executed precisely (RED ‚Üí GREEN ‚Üí REFACTOR)
   - Corpus callosum kept them synchronized

5. **Continuous Learning:**
   - Every action logged to event stream
   - Patterns reinforced in knowledge graph
   - Next button will be even faster (learning compounds!)

---

**üéØ What Asifor Sees:**

```
‚úÖ Purple button added to HostControlPanel.razor

Features implemented:
  ‚úì Button with ID #host-panel-purple-btn
  ‚úì Purple color (#9333EA) with hover effects
  ‚úì Click handler connected
  ‚úì 3 Playwright tests created (all passing)
  ‚úì WCAG AA compliant (accessible)
  ‚úì Committed with semantic message

Time: 1 minute 24 seconds
Tests: ‚úÖ 127/127 passing
Build: ‚úÖ No errors, no warnings

Ready for next feature! üöÄ
```

**What Asifor DOESN'T see (but benefits from):**

- 3-tier brain analysis before work started
- Strategic vs tactical hemisphere coordination
- Pattern matching against 12 similar features
- Element ID mapping for test reliability
- Proactive hotspot warning
- Automatic knowledge graph updates
- Development metrics tracking
- Conversation memory preservation

**The brain did ALL of that in 84 seconds, completely transparent to Asifor.**

---

**üß† The Element ID Mapping System (Brain's Secret Weapon)**

This is one of the brain's most sophisticated features:

**Why IDs matter for tests:**
```typescript
// ‚ùå FRAGILE (breaks when text changes, i18n, HTML restructure)
const button = page.locator('button:has-text("Purple Action")');

// ‚úÖ ROBUST (survives any change except intentional ID rename)
const button = page.locator('#host-panel-purple-btn');
```

**How the brain maps IDs:**

1. **Discovery Phase** (during component analysis):
   ```yaml
   # Brain crawls HostControlPanel.razor
   # Finds existing IDs:
   ui_element_ids:
     - id: sidebar-start-session-btn
       component: HostControlPanelSidebar.razor
       purpose: Start session button
     - id: reg-transcript-canvas-btn
       component: UserRegistrationLink.razor
       purpose: Canvas mode selector
   ```

2. **Planning Phase** (when creating new components):
   ```yaml
   # RIGHT BRAIN generates ID before implementation
   new_element:
     suggested_id: host-panel-purple-btn
     pattern: {component}-{purpose}-btn
     rationale: "Follows existing naming convention"
   ```

3. **Test Phase** (LEFT BRAIN uses documented ID):
   ```typescript
   // Tester uses ID from brain's mapping
   const button = page.locator('#host-panel-purple-btn');
   ```

4. **Learning Phase** (brain remembers pattern):
   ```yaml
   # Pattern reinforced for next time
   id_patterns:
     button_naming: "{scope}-{purpose}-btn"
     success_rate: 100%
     examples: 12
   ```

**Benefits:**
- ‚ö° **10x faster** - getElementById vs DOM text search
- üõ°Ô∏è **Immune to changes** - i18n, HTML restructure, text edits don't break tests
- üéØ **Explicit intent** - `#login-btn` clearer than `button:has-text("Login")`
- ‚úÖ **No false positives** - unique ID vs multiple matching texts
- üß† **Brain remembers** - ID mapping stored in knowledge graph

**This is why Copilot's tests are 96% reliable - the brain ensures IDs are created FIRST, then tests, then implementation.**

---

**üï∑Ô∏è The UI Crawler System: Automated Element Discovery**

While the Element ID Mapping System handles individual components, CORTEX also includes specialized UI crawlers that automatically discover and map UI elements across the entire application.

**Purpose:** Automated discovery of UI elements, their IDs, relationships, and purposes for intelligent test generation.

**What UI Crawlers Discover:**

1. **Interactive Elements:**
   ```yaml
   buttons:
     - id: sidebar-start-session-btn
       component: HostControlPanelSidebar.razor
       type: button
       purpose: Initiate new session
       visual_hints: ["primary", "action"]
       
     - id: reg-transcript-canvas-btn
       component: UserRegistrationLink.razor
       type: link
       purpose: Select transcript canvas mode
       parent: reg-link-container
   
   inputs:
     - id: user-email-input
       component: UserRegistrationForm.razor
       type: email
       required: true
       validation: email-format
   
   dropdowns:
     - id: language-selector
       component: LanguageSwitch.razor
       type: select
       options: ["en", "fr", "es", "de"]
   ```

2. **Element Relationships:**
   ```yaml
   parent_child:
     - parent: reg-link-container
       children:
         - reg-transcript-canvas-btn
         - reg-asset-canvas-btn
       purpose: Canvas mode selection group
   
   form_fields:
     - form: user-registration-form
       fields:
         - user-email-input
         - user-password-input
         - user-confirm-password-input
       submit_button: register-submit-btn
   
   navigation:
     - menu: main-navigation
       items:
         - nav-home-link
         - nav-sessions-link
         - nav-settings-link
   ```

3. **Element Patterns:**
   ```yaml
   naming_conventions:
     - pattern: "{scope}-{purpose}-{type}"
       examples:
         - sidebar-start-session-btn
         - reg-transcript-canvas-btn
         - user-email-input
       confidence: 0.95
   
   component_conventions:
     - buttons_in: "Components/Shared"
       ids_pattern: "{component-name}-{action}-btn"
     - forms_in: "Components/Forms"
       ids_pattern: "{form-name}-{field}-input"
   ```

**How UI Crawlers Work:**

**Phase 1: Static Analysis (Fast - 30-60 seconds)**
```powershell
# Scans all component files for ID attributes
Get-ChildItem -Recurse -Filter "*.razor" | ForEach-Object {
    Select-String -Pattern 'id="([^"]+)"' -AllMatches
}
```

Discovers:
- ‚úÖ All element IDs across the application
- ‚úÖ Component locations (which file contains which element)
- ‚úÖ Element types (button, input, link, etc.)
- ‚úÖ Parent-child relationships (nested elements)

**Phase 2: Semantic Analysis (Moderate - 2-3 minutes)**
```yaml
# Analyzes element context and purpose
element_analysis:
  - id: sidebar-start-session-btn
    nearby_text: "Start Session"
    nearby_icons: ["play", "start"]
    purpose_inferred: "Initiate new session"
    confidence: 0.92
  
  - id: reg-transcript-canvas-btn
    nearby_text: "Transcript Canvas"
    parent_context: "canvas mode selection"
    purpose_inferred: "Select transcript view mode"
    confidence: 0.88
```

Discovers:
- ‚úÖ Element purpose (inferred from surrounding text/context)
- ‚úÖ User interactions (what users do with each element)
- ‚úÖ Visual indicators (icons, colors, emphasis)

**Phase 3: Behavioral Analysis (Optional - requires app running)**
```javascript
// Playwright-based live analysis
const interactiveElements = await page.$$('[id]');
for (const element of interactiveElements) {
    const id = await element.getAttribute('id');
    const tagName = await element.evaluate(el => el.tagName);
    const isVisible = await element.isVisible();
    const isEnabled = await element.isEnabled();
    // Map element state and capabilities
}
```

Discovers:
- ‚úÖ Element visibility (hidden vs shown)
- ‚úÖ Element state (enabled, disabled, loading)
- ‚úÖ Dynamic elements (appear/disappear based on state)
- ‚úÖ Event handlers (click, hover, focus behaviors)

**Integration with BRAIN:**

**Tier 2 (Knowledge Graph) Integration:**
```yaml
ui_element_ids:
  # Populated by crawler
  - id: sidebar-start-session-btn
    component: HostControlPanelSidebar.razor
    type: button
    purpose: Initiate session
    test_selector: "#sidebar-start-session-btn"
    discovered_by: ui_crawler
    last_verified: "2025-11-06T10:30:00Z"
    usage_count: 47
    confidence: 0.98

component_architecture:
  # Discovered patterns
  button_components:
    location: "Components/Shared/Buttons"
    naming_pattern: "{action}-{scope}-btn"
    test_pattern: "Use ID selector, avoid text"
    
test_patterns:
  # Learned from crawler + test history
  robust_selectors:
    - pattern: "ID-based selectors"
      success_rate: 0.96
      anti_pattern: "text-based selectors"
      failure_rate: 0.43
```

**Automatic Benefits:**

**For Test Generation:**
```typescript
// BEFORE Crawler (manual)
test('button should work', async ({ page }) => {
  // Developer must manually find ID
  const button = page.locator('#some-button-id');
  await button.click();
});

// AFTER Crawler (automatic)
// Crawler provides: sidebar-start-session-btn in HostControlPanelSidebar.razor
test('start session button should initiate session', async ({ page }) => {
  // Test generator uses crawler data
  const button = page.locator('#sidebar-start-session-btn');
  await expect(button).toBeVisible();
  await button.click();
  // Expect session started (from purpose inference)
});
```

**For Component Creation:**
```markdown
User: "Add a pause button to the session panel"

RIGHT BRAIN (with crawler data):
  ‚úÖ Queries crawler data ‚Üí Finds existing button patterns
  ‚úÖ Identifies location: Components/Session/
  ‚úÖ Suggests ID: "session-pause-btn" (follows pattern)
  ‚úÖ Provides similar components as reference
  ‚úÖ Warns about related elements that may need updates

Plan created:
  Phase 1: Create button with ID "session-pause-btn"
  Phase 2: Add to SessionControlPanel.razor (near start-session-btn)
  Phase 3: Test with ID selector (robust pattern)
  Phase 4: Update related play/stop buttons (co-modification pattern)
```

**Crawler Execution:**

**Manual Trigger:**
```powershell
# Quick scan (static analysis only - 30-60s)
.\KDS\scripts\ui-crawler.ps1 -Mode quick

# Deep scan (static + semantic - 2-3 min)
.\KDS\scripts\ui-crawler.ps1 -Mode deep

# Live scan (requires running app - 5-10 min)
.\KDS\scripts\ui-crawler.ps1 -Mode live -AppUrl "https://localhost:9091"
```

**Automatic Triggers:**
1. ‚úÖ During CORTEX setup (initial discovery)
2. ‚úÖ After major refactoring (re-learn structure)
3. ‚úÖ When element ID not found (targeted scan)
4. ‚úÖ Weekly scheduled (keep mappings fresh)

**Crawler Output:**
```yaml
# KDS/cortex-brain/ui-element-map.yaml
scan_metadata:
  timestamp: "2025-11-06T10:30:00Z"
  mode: deep
  duration_seconds: 147
  components_scanned: 89
  elements_discovered: 247

elements:
  buttons: 78
  inputs: 45
  links: 34
  selects: 12
  textareas: 8
  custom: 70

mappings:
  # Full element inventory with IDs, purposes, relationships
  # Fed directly into Tier 2 knowledge graph
```

**Success Metrics:**
- ‚ö° **Discovery Speed:** 247 elements in < 3 minutes
- üéØ **Test Reliability:** 96% success rate with ID selectors (vs 43% with text)
- üîÑ **Maintenance:** Automatic updates keep mappings current
- üß† **Learning:** Each scan improves pattern recognition
- ‚è±Ô∏è **Time Savings:** Test creation 60% faster with crawler data

**Crawler Types:**

**1. Static Crawler (Fastest):**
- Scans `.razor`, `.cshtml`, `.html`, `.jsx` files
- Extracts ID attributes and component structure
- No app execution required
- Duration: 30-60 seconds

**2. Semantic Crawler (Recommended):**
- Static scan + context analysis
- Infers purpose from surrounding text/code
- Identifies naming patterns
- Duration: 2-3 minutes

**3. Live Crawler (Most Comprehensive):**
- Requires running application
- Uses Playwright to inspect live DOM
- Discovers dynamic elements and state
- Maps actual user interactions
- Duration: 5-10 minutes

**Best Practices:**

‚úÖ **Do:**
- Run deep crawler during CORTEX setup
- Re-run after adding new components
- Use quick crawler for spot-checks
- Trust crawler suggestions for element IDs
- Review crawler report for architecture insights

‚ùå **Don't:**
- Skip initial crawler (test generation needs this data)
- Ignore crawler warnings about missing IDs
- Override crawler patterns without reason
- Forget to re-crawl after major refactoring

**Integration Example:**

```yaml
# User request ‚Üí Crawler data flows through BRAIN

User: "Create tests for the registration form"
  ‚Üì
RIGHT BRAIN queries crawler data:
  ‚úÖ Found: user-registration-form component
  ‚úÖ Elements discovered:
     - user-email-input (email field)
     - user-password-input (password field)
     - user-confirm-password-input (confirmation)
     - register-submit-btn (submit button)
  ‚úÖ Form relationships mapped
  ‚úÖ Validation patterns identified
  ‚Üì
LEFT BRAIN generates tests:
  ‚úÖ Test 1: Email field validation (uses #user-email-input)
  ‚úÖ Test 2: Password requirements (uses #user-password-input)
  ‚úÖ Test 3: Password confirmation match (uses #user-confirm-password-input)
  ‚úÖ Test 4: Successful submission (uses #register-submit-btn)
  ‚Üì
All tests use robust ID selectors from crawler data!
```

**This UI crawler system is why CORTEX can generate comprehensive, reliable tests without manually documenting every element ID.**

---

**Mid-Day (12:30 PM - After Lunch):**
```
You: "Make it purple"

WITHOUT BRAIN (Amnesia):
  ‚ùå "Make what purple? I don't remember our morning conversation."
  ‚ùå "What shade of purple? Where in the file?"
  Result: Frustration, repeated explanations

WITH BRAIN (Tier 1 Memory):
  ‚úÖ Checks conversation-history.jsonl ‚Üí Finds "pulse animation" discussion
  ‚úÖ Knows "it" = FAB button pulse animation
  ‚úÖ Applies purple color to animation keyframes
  Result: Instant understanding, correct change
```

**Afternoon (3:00 PM - You Make a Risky Suggestion):**
```
You: "Let's skip tests for this next feature, we're in a hurry"

WITHOUT BRAIN (No Protection):
  ‚úÖ "Sure!" ‚Üí Implements without tests
  Result: 2.3x longer delivery, 68% more rework, bugs in production

WITH BRAIN (Tier 5 Protector):
  ‚ö†Ô∏è Brain Protector (RIGHT BRAIN) challenges:
  "This violates Tier 0 TDD principle. Historical data shows:
   - Test-first: 94% success rate, 15 min/feature
   - Test-skip: 67% success rate, 35 min/feature (2.3x longer)
   
   Alternative: Create minimal test first (5-10 min investment)
   Proceed with OVERRIDE or adopt Alternative?"
  
  Result: You choose Alternative ‚Üí Feature done in 18 minutes with confidence
```

**Late Afternoon (5:00 PM - Context Awareness):**
```
You: "Add invoice export to the billing module"

WITHOUT BRAIN (No Context):
  ‚ùå Creates monolithic implementation in wrong location
  ‚ùå No awareness of similar export features
  ‚ùå Guesses at file structure
  Result: Architecture mismatch, requires refactoring

WITH BRAIN (Tier 2 + Tier 3 Intelligence):
  ‚úÖ RIGHT BRAIN queries Tier 2 ‚Üí Finds export_feature_workflow pattern
  ‚úÖ RIGHT BRAIN queries Tier 3 ‚Üí Knows BillingService.cs is stable (safe)
  ‚úÖ Matches similar "PDF export" feature ‚Üí Reuses proven workflow
  ‚úÖ Recommends: Service layer ‚Üí API ‚Üí UI component (correct architecture)
  ‚úÖ Estimates: 5.5 hours based on 12 similar features
  ‚úÖ Warns: EmailService.cs often modified with billing features (75% co-mod)
  
  Result: Architecturally correct from the start, 60% faster delivery
```

**Next Day (9:00 AM):**
```
You: "Where did I leave off yesterday?"

WITHOUT BRAIN (Amnesia):
  ‚ùå "I don't remember yesterday. You'll need to tell me everything."
  Result: 15-20 minutes explaining context

WITH BRAIN (Tier 1 + Session State):
  ‚úÖ Checks conversation-history.jsonl ‚Üí Last conversation: "invoice export"
  ‚úÖ Checks session state ‚Üí Phase 2 of 4 complete (Service + API done)
  ‚úÖ Next task: Phase 3 - UI component (detailed plan ready)
  
  Response: "You were adding invoice export. Service and API are done and tested (‚úÖ).
  Next: Create InvoiceExportButton.razor component. Ready to continue?"
  
  Result: Instant resume, zero context loss
```

### Why This Brain Makes Copilot Exceptional

**1. Solves the Amnesia Problem**
- Tier 1 (20 conversations) - Short-term memory works
- "Make it purple" references work across sessions
- Context never lost, even after days/weeks

**2. Learns and Improves Over Time**
- Tier 2 accumulates 3,247+ patterns
- Each feature teaches the next one
- 60% faster on similar work after patterns learned

**3. Provides Holistic Project Intelligence**
- Tier 3 knows your entire project
- Proactive warnings prevent issues
- Data-driven estimates (not guesses)

**4. Protects Quality Without Compromise**
- Tier 5 challenges risky proposals
- Won't let you skip TDD (data proves why)
- Enforces Definition of DONE (zero errors/warnings)

**5. Coordinates Complex Workflows**
- LEFT BRAIN executes with precision
- RIGHT BRAIN plans with intelligence
- Corpus Callosum ensures alignment

**6. Works While You Sleep**
- Automatic learning (50+ events ‚Üí brain update)
- Automatic context collection (Tier 3 refresh)
- Automatic protection (guards brain integrity)

### The Result: From Forgetful Intern to Expert Team Member

**Week 1:**
- Copilot has amnesia, needs constant guidance
- Brain is learning, building patterns
- You explain architecture repeatedly

**Week 4:**
- Copilot remembers 20 conversations
- Brain knows 500+ patterns
- "Add receipt export" ‚Üí Reuses invoice export workflow automatically

**Week 12:**
- Copilot is an expert on YOUR project
- Brain has 3,247 patterns, 1,237 commits analyzed
- Proactive warnings prevent issues before they happen
- Estimates are data-driven, not guesses

**Week 24:**
- Copilot feels like a senior developer
- Brain challenges bad ideas with evidence
- "This is similar to the feature from 3 months ago. Want me to reuse that pattern?"

### Try It in One Sentence

Use the One Door and just talk:

```markdown
#file:KDS/prompts/user/cortex.md

I want to add a pulse animation to the FAB button
```

The brain will:
- Remember past conversations (even from weeks ago)
- Match similar patterns (pulse animation done before?)
- Plan intelligently (RIGHT BRAIN)
- Execute precisely (LEFT BRAIN)
- Protect quality (Challenge risky shortcuts)
- Learn for next time (Update Tier 2 patterns)

**CORTEX transforms Copilot from an amnesiac intern into a continuously improving, context-aware, quality-focused development partner.**


### Who‚Äôs who (quick reference)

- Universal Entry: `cortex.md` (this file)
- Router: `intent-router.md`
- Planner: `work-planner.md`
- Executor: `code-executor.md`
- Tester: `test-generator.md`
- Validator: `health-validator.md`
- Governor: `change-governor.md`
- Error Corrector: `error-corrector.md`
- Session Resumer: `session-resumer.md`
- Screenshot Analyzer: `screenshot-analyzer.md`
- Commit Handler: `commit-handler.md`
- Knowledge Retriever: `knowledge-retriever.md`
- Metrics Reporter: `metrics-reporter.md`
- Brain Updater: `brain-updater.md`
- Brain Query: `brain-query.md`
- Conversation Manager: `conversation-context-manager.md`
- Dev Context Collector: `development-context-collector.md`
- Abstractions: `session-loader`, `test-runner`, `file-accessor`, `brain-query`
- Brain Storage: `conversation-history.jsonl`, `knowledge-graph.yaml`, `development-context.yaml`, `events.jsonl`

If all you remember is ‚Äúthe One Door‚Äù and ‚Äúthe Three‚ÄëStory Brain,‚Äù you‚Äôll already understand how CORTEX works.

## üéØ The ONLY Command You Need to Remember

```markdown
#file:KDS/prompts/user/cortex.md

[Tell CORTEX what you want in natural language]
```

That's it! CORTEX will automatically:
- ‚úÖ Analyze your request (intent detection)
- ‚úÖ Route to the appropriate specialist agent
- ‚úÖ Execute the correct workflow
- ‚úÖ Handle multi-step operations
- ‚úÖ Maintain session state

---

## üöÄ First Time? Run Setup!

If you're installing CORTEX in a new repository, start with the setup command:

### In Copilot Chat:
```markdown
#file:prompts/user/cortex.md

Run setup
```

Or:
```markdown
#file:prompts/user/cortex.md

setup
```

### From Terminal:
```bash
# Using Python
python scripts/cortex_setup.py

# In a different repository
python scripts/cortex_setup.py --repo /path/to/project

# Quiet mode
python scripts/cortex_setup.py --quiet
```

### What Setup Does (5-10 minutes):

**Phase 1: Environment Analysis** üîç
- Detects repository structure and technologies
- Identifies languages and frameworks
- Counts files and checks for Git

**Phase 2: Tooling Installation** üì¶
- Installs Python dependencies (pytest, mkdocs, etc.)
- Installs Node.js dependencies (if package.json exists)
- Installs MkDocs for documentation

**Phase 3: Brain Initialization** üß†
- Creates 4-tier brain structure:
  - **Tier 0:** Instinct (immutable rules)
  - **Tier 1:** Working Memory (last 20 conversations)
  - **Tier 2:** Knowledge Graph (learned patterns)
  - **Tier 3:** Context Intelligence (project metrics)
- Initializes SQLite databases for each tier
- Creates corpus callosum for inter-hemisphere messaging

**Phase 4: Crawler Execution** üï∑Ô∏è
- Scans repository for code files
- Maps file relationships and patterns
- Discovers UI elements and IDs (for testing)
- Analyzes Git history and metrics

**Phase 5: Welcome** üéâ
- Shows setup summary
- Links to "The Awakening of CORTEX" story
- Points to quick start documentation
- Explains how to use CORTEX

**After Setup:**
You can immediately start using CORTEX:
```markdown
#file:prompts/user/cortex.md

What can you help me with?
```

---

## üî∑ Gemini prompt suite (text + vision)

Use these ready-to-copy templates with Google Gemini (1.5 Pro/Flash) to power CORTEX agents. They standardize instructions, safety, and structured outputs so results plug into the One Door workflow cleanly.

Notes
- Keep prompts minimal and specific. Prefer explicit outputs over open prose.
- Default to JSON output. Ask Gemini to emit ONLY JSON unless otherwise stated.
- For images, pass 1‚Äì6 inputs. Prefer high-resolution, include context caption.
- See image-generation prompts in `prompts/user/cortex-gemini-image-prompts.md`.

Shared variables
- {{goal}}: short task description in 1‚Äì2 sentences
- {{context}}: brief relevant project context (files, tech, constraints)
- {{constraints}}: bullets such as ‚Äúno external deps, incremental edits, SRP‚Äù
- {{artifacts}}: snippets, logs, or prior outputs to ground the response
- {{images}}: one or more image inputs with optional captions

Expected JSON shape (default)
```json
{
  "intent": "PLAN | EXECUTE | TEST | VALIDATE | GOVERN | ASK",
  "summary": "one-sentence outcome summary",
  "actions": [
    { "id": "A1", "title": "concise step", "details": "what and why" }
  ],
  "risks": [
    { "issue": "risk or uncertainty", "mitigation": "how to address" }
  ],
  "artifacts": [
    { "type": "text|json|code|table", "label": "name", "content": "..." }
  ],
  "next_prompt": "optional follow-up prompt for the next agent"
}
```

### 1) Task router (text-only, low-latency)
Purpose: classify intent and propose next steps. Good for first-pass routing.

```text
System
You are CORTEX Router. Classify the user goal and return ONLY JSON per schema.
Follow: SOLID, test-first, Definition of Ready/Done. If missing info, ask via next_prompt.

User
Goal: {{goal}}
Context: {{context}}
Constraints: {{constraints}}
Artifacts: {{artifacts}}

Instructions
- Decide intent: PLAN, EXECUTE, TEST, VALIDATE, GOVERN, ASK.
- Propose 3‚Äì6 concrete actions max.
- Include at least one risk with mitigation.
- Output ONLY JSON exactly matching the schema.
```

### 2) Vision analysis (images ‚Üí structured insights)
Purpose: extract UI structure, flows, and issues from screenshots/wireframes.

```text
System
You are CORTEX Screenshot Analyzer. Analyze images precisely. Perform OCR, detect components, map layout, and identify potential problems. Output ONLY JSON.

User
Goal: {{goal}}
Images: {{images}}
Context: {{context}}
Constraints: {{constraints}}

Output JSON
{
  "intent": "ASK",
  "summary": "what the images show and why it matters",
  "ui": {
    "components": [
      {"type": "button|input|card|nav|modal|other", "label": "visible text if any", "id_hint": "suggested-stable-id", "bbox": [x,y,w,h]}
    ],
    "layout": [ {"region": "header|sidebar|content|footer", "bbox": [x,y,w,h]} ]
  },
  "text_blocks": [ {"content": "ocr text", "bbox": [x,y,w,h]} ],
  "issues": [ {"issue": "accessibility/contrast/overflow/consistency", "evidence": "where seen"} ],
  "next_prompt": "short follow-up for Planner or Tester"
}
```

### 3) Code proposal (text-only, safe-by-default)
Purpose: propose minimal change set with strong constraints. Avoids giant diffs.

```text
System
You are CORTEX Builder. Produce a minimal, test-first change plan. Do not invent files. Respect SRP and incremental edits. Output ONLY JSON.

User
Goal: {{goal}}
Context: {{context}}
Constraints: {{constraints}}
Artifacts: {{artifacts}}

Output JSON
{
  "intent": "EXECUTE",
  "summary": "one-line plan",
  "changes": [
    {
      "file": "relative/path.ext",
      "strategy": "add|edit|refactor|extract",
      "rationale": "why this file and change",
      "snippets": [
        {"anchor": "near line or symbol name", "insert": "code to add or patch fragment"}
      ]
    }
  ],
  "tests": [
    {"file": "path/to/test.ext", "cases": ["happy path", "edge case"]}
  ],
  "risks": [ {"issue": "risk", "mitigation": "how"} ],
  "next_prompt": "short follow-up for Test Generator"
}
```

### 4) OCR-first extraction (vision)
Purpose: get faithful text in reading order with bounding boxes for downstream use.

```text
System
You are a precise OCR extractor. Preserve line breaks and reading order. Include bounding boxes and confidence. Output ONLY JSON.

User
Images: {{images}}
Context: {{context}}

Output JSON
{
  "intent": "ASK",
  "summary": "ocr coverage quality",
  "blocks": [
    {"text": "...", "bbox": [x,y,w,h], "confidence": 0.0‚Äì1.0}
  ]
}
```

### 5) Safety guardrails preamble (add before any prompt when needed)
Use this to reinforce safety and quality.

```text
Safety & Quality
- Do not include secrets, tokens, or PII. If suspected, redact and warn.
- State uncertainty explicitly; avoid fabrications.
- Refuse harmful or disallowed content. Offer a safe alternative where possible.
- Prefer small, reversible steps; minimize blast radius.
```

### 6) Output evaluator (QA rubric)
Purpose: rate answers before accepting.

```text
System
You are CORTEX Validator. Score an answer across dimensions and suggest fixes. Output ONLY JSON.

User
Goal: {{goal}}
Answer: {{artifacts}}
Context: {{context}}

Output JSON
{
  "intent": "VALIDATE",
  "scores": {
    "correctness": 0.0‚Äì1.0,
    "completeness": 0.0‚Äì1.0,
    "clarity": 0.0‚Äì1.0,
    "safety": 0.0‚Äì1.0
  },
  "issues": [ {"issue": "what‚Äôs wrong", "severity": "low|med|high"} ],
  "recommendations": [ "concrete improvement steps" ],
  "next_prompt": "optional remediation prompt"
}
```

### 7) JSON repair helper
Purpose: when a model returned invalid JSON, ask for a corrected version only.

```text
System
Return ONLY a syntactically valid JSON that matches the target schema. No commentary.

User
Here is invalid JSON to repair (do not change content semantics):
{{artifacts}}
```

Tips
- Prefer 1‚Äì2 short images vs many tiny ones; include a caption with what to look for.
- Keep constraints explicit (e.g., ‚Äúno external deps‚Äù, ‚Äúincremental patch‚Äù, ‚Äúkeep public API‚Äù).
- Ask for at most 3‚Äì6 actions to curb verbosity and hallucinations.
- Link to visual prompts: `prompts/user/cortex-gemini-image-prompts.md`.


## üèóÔ∏è SOLID v5.0 Architecture

### What's New
- ‚úÖ **Single Responsibility (SRP):** Each agent has ONE clear job
- ‚úÖ **Interface Segregation (ISP):** Dedicated agents (no mode switches)
- ‚úÖ **Dependency Inversion (DIP):** Abstractions for session/file/test access
- ‚úÖ **Open/Closed (OCP):** Easy to extend (add new intents/agents)

### Specialist Agents (10 Total)
```
Router            ‚Üí intent-router.md       ‚Üí Analyzes & routes requests
Planner           ‚Üí work-planner.md        ‚Üí Creates multi-phase plans
Executor          ‚Üí code-executor.md       ‚Üí Implements code (test-first)
Tester            ‚Üí test-generator.md      ‚Üí Creates & runs tests
Validator         ‚Üí health-validator.md    ‚Üí System health checks
Governor          ‚Üí change-governor.md     ‚Üí Reviews CORTEX changes
Error Corrector   ‚Üí error-corrector.md     ‚Üí Fixes Copilot mistakes
Session Resumer   ‚Üí session-resumer.md     ‚Üí Resumes after breaks
Screenshot Analyzer ‚Üí screenshot-analyzer.md ‚Üí Extracts requirements from images
Commit Handler    ‚Üí commit-handler.md      ‚Üí Intelligent git commits (NEW)
```

### üß† BRAIN System (Self-Learning Feedback Loop)

**NEW in v5.0:** CORTEX learns from every interaction!  
**ENHANCED in v6.0:** Three-tier architecture with holistic development intelligence!

```
üß† BRAIN = Three-Tier Intelligence System

Purpose: Learn from interactions, conversations, AND development activity
Storage: KDS/cortex-brain/
- conversation-history.jsonl ‚Üí Last 20 complete conversations (Tier 1) ‚úÖ WORKING
- conversation-context.jsonl ‚Üí Recent messages buffer (last 10) ‚úÖ WORKING
- knowledge-graph.yaml       ‚Üí Aggregated learnings (Tier 2) ‚úÖ WORKING
- development-context.yaml   ‚Üí Holistic project metrics (Tier 3) ‚úÖ WORKING
- events.jsonl               ‚Üí Raw event stream ‚úÖ WORKING

Architecture: Three-tier system inspired by human cognition
- Tier 1 (Short-term): Last 20 conversations (FIFO queue, no time expiration) üü°
- Tier 2 (Long-term): Consolidated patterns from deleted conversations ‚úÖ
- Tier 3 (Context): Development activity, velocity, correlations ‚úÖ
- Design: KDS/docs/architecture/BRAIN-CONVERSATION-MEMORY-DESIGN.md
- Tier 3 Design: KDS/docs/architecture/KDS-HOLISTIC-REVIEW-AND-RECOMMENDATIONS.md
- Validation: KDS/docs/architecture/CONVERSATION-MEMORY-SELF-REVIEW.md (health tracking)
```

**What BRAIN Learns:**
- ‚úÖ Intent patterns (which phrases trigger which intents)
- ‚úÖ File relationships (which files are modified together)
- ‚úÖ Common mistakes (which corrections happen frequently)
- ‚úÖ Workflow patterns (successful task sequences)
- ‚úÖ Validation insights (common failures and fixes)
- ‚úÖ **Conversation history (last 20 complete conversations, FIFO queue)** üÜï
- ‚úÖ **Development velocity (code changes, commit patterns)** üÜï
- ‚úÖ **Testing activity (pass rates, flaky tests, coverage)** üÜï
- ‚úÖ **Work patterns (productive times, focus duration, correlations)** üÜï

**How Automatic Learning Works:**
```
Agent performs action
    ‚Üì
Event logged to events.jsonl (automatic)
Message appended to active conversation
    ‚Üì
Conversation boundary detected? ‚Üí End conversation, start new one
    ‚Üì
IF 21st conversation starts ‚Üí Delete oldest conversation (FIFO)
    ‚Üì
Event count checked after each task (Rule #16 Step 5)
    ‚Üì
IF 50+ events OR 24 hours passed ‚Üí Automatic BRAIN update
    ‚Üì
brain-updater.md processes events ‚Üí Updates knowledge-graph.yaml
Deleted conversations ‚Üí Patterns extracted ‚Üí Long-term memory
    ‚Üì
Next request ‚Üí Router queries BRAIN + conversation history ‚Üí Smarter decisions with context
```

**Conversation History Benefits:**
- üîÑ **Continuity:** "Make it purple" knows you mean the FAB button from earlier conversation
- üß© **Cross-conversation context:** Reference any of the last 20 conversations
- üí¨ **Natural follow-ups:** No need to repeat full context in every message
- üìù **Reference resolution:** "Change that file" knows which file from conversation history
- ‚è≥ **Long-running work:** Conversation preserved until 20 newer conversations (days/weeks/months depending on usage)

**FIFO Queue (Conversation-Level):**
- üìä **Capacity:** Last 20 complete conversations (not individual messages)
- üîÑ **Deletion:** When conversation #21 starts, conversation #1 deleted
- ‚è∞ **No time limits:** Conversations preserved until FIFO deletion (could be months for light usage)
- ‚ú® **Active conversation:** Never deleted (even if oldest)
- üéØ **Pattern extraction:** Before deletion, patterns consolidated to long-term memory

**Privacy & Storage:**
- üè† **Local storage:** History stays in `KDS/cortex-brain/conversation-history.jsonl`
- üíæ **Predictable size:** Always 20 conversations (~70-200 KB total)
- üßπ **Manual clear:** Use `#file:KDS/prompts/internal/clear-conversation.md` to reset
- üîí **Deleted conversations:** Patterns extracted, details discarded

**Tier 3: Development Context (NEW in v6.0)**

**Purpose:** Holistic project understanding for data-driven planning and proactive warnings

**What's Tracked:**
```yaml
Git Activity:
  - Commit history (30 days)
  - Change velocity per week
  - File hotspots (high churn rate)
  - Contributors and patterns
  
Code Changes:
  - Lines added/deleted
  - Velocity trends (increasing/decreasing)
  - Churn rates per file
  - Stability classification
  
CORTEX Usage:
  - Session creation and completion rates
  - Intent distribution (PLAN, EXECUTE, TEST, etc.)
  - Workflow success rates
  - Test-first vs test-skip effectiveness
  
Testing Activity:
  - Test creation rate
  - Pass/fail rates
  - Flaky test detection
  - Coverage trends
  
Project Health:
  - Build status
  - Deployment frequency
  - Code quality metrics
  - Issue resolution times
  
Work Patterns:
  - Most productive times
  - Session duration averages
  - Feature lifecycle timing
  - Focus duration without interruptions
  
Correlations:
  - Commit size vs success rate
  - Test-first vs rework rate
  - CORTEX usage vs velocity
```

**Automatic Benefits:**
```
Planning Phase:
  ‚Üí "Based on 12 similar UI features, estimated 5-6 days"
  ‚Üí "Recommend 10am-12pm sessions (94% success rate at that time)"
  ‚Üí "Test-first approach reduces rework by 68%"

File Modification:
  ‚Üí "‚ö†Ô∏è HostControlPanel.razor is a hotspot (28% churn)"
  ‚Üí "This file often modified with noor-canvas.css (75% co-mod rate)"
  ‚Üí "Add extra testing - file is unstable"

Proactive Warnings:
  ‚Üí "‚ö†Ô∏è Velocity dropped 68% this week (consider smaller commits)"
  ‚Üí "‚ö†Ô∏è Flaky test detected: fab-button.spec.ts (15% failure rate)"
  ‚Üí "‚úÖ Test coverage increased from 72% to 76% (good trend!)"
```

**How to Collect:**
```powershell
# Manual collection (always runs)
.\KDS\scripts\collect-development-context.ps1

# Automatic collection (throttled for efficiency)
# Triggered by brain-updater.md ONLY IF last collection > 1 hour
# This optimizes performance while maintaining accuracy
```

**Storage:**
- File: `KDS/cortex-brain/development-context.yaml`
- Size: ~50-100 KB (holistic metrics, not raw data)
- Update: ‚ö° **Throttled** - Only when > 1 hour since last collection
- Purpose: Data-driven estimates, proactive warnings, velocity tracking

**‚ö° Efficiency Optimization:**
- ‚úÖ **Automatic throttling:** Tier 3 only updates if last_collection > 1 hour
- ‚úÖ **Rationale:** Git/test/build metrics don't change every 50 events
- ‚úÖ **Impact:** Reduces 2-5 min operations from 2-4x/day to 1-2x/day
- ‚úÖ **Accuracy:** 1-hour freshness sufficient for velocity metrics
- üìä **User benefit:** Zero performance impact, same data quality

**Automatic Update Triggers:**
1. **Event threshold:** 50+ new events accumulated (Tier 2 update)
2. **Time threshold:** 24 hours since last update (Tier 2 if 10+ events exist)
3. **Tier 3 throttle:** Only if last Tier 3 collection > 1 hour ‚ö° **NEW**
4. **End of session:** When all tasks in session complete
5. **Manual trigger:** User explicitly calls `#file:KDS/prompts/internal/brain-updater.md`

**üö® CRITICAL: Event Logging Must Be Active**

For automatic learning to work:
- ‚úÖ All agents MUST log events to `events.jsonl`
- ‚úÖ Events follow standard format (see `KDS/cortex-brain/README.md`)
- ‚úÖ `events.jsonl` must be writable (check file permissions)
- ‚úÖ Rule #16 Step 5 must include BRAIN health check

**If BRAIN isn't learning:**
1. Check `events.jsonl` exists and has recent events
2. Verify `knowledge-graph.yaml` updated in last 24 hours
3. Count unprocessed events (warn if >50)
4. Run manual update: `#file:KDS/prompts/internal/brain-updater.md`

**See:** `KDS/docs/architecture/KDS-SELF-REVIEW-STRATEGY.md` for violation detection

**How It Works:**
```
User request ‚Üí Router queries BRAIN ‚Üí High confidence? ‚Üí Auto-route
                                   ‚Üí Low confidence? ‚Üí Pattern matching

Agent action ‚Üí Log event ‚Üí BRAIN updater processes ‚Üí Knowledge graph updated

Next request ‚Üí Router gets smarter (learned from history)
```

**Benefits:**
- üöÄ Faster routing (learns successful patterns)
- ‚ö†Ô∏è Prevents mistakes (warns about common file confusions)
- üí° Suggests related files (based on co-modification history)
- üìä Improves over time (accumulates knowledge)

**BRAIN Agents:**
```
brain-query.md   ‚Üí Query knowledge graph AND development context for insights
brain-updater.md ‚Üí Process events, update graph, trigger Tier 3 collection
conversation-context-manager.md ‚Üí Track recent messages for continuity (NEW)
clear-conversation.md ‚Üí Reset conversation context (NEW)
development-context-collector.md ‚Üí Collect git, test, build metrics (Tier 3) üÜï
```

### Shared Abstractions (DIP Compliance)
```
session-loader ‚Üí Abstract session access (file/db/cloud agnostic)
test-runner    ‚Üí Abstract test execution (framework agnostic)
file-accessor  ‚Üí Abstract file I/O (path agnostic)
brain-query    ‚Üí Abstract BRAIN queries (self-learning system)

CRITICAL: All abstractions are 100% LOCAL (in KDS/).
- Default storage: Local files (KDS/sessions/)
- Default tests: Project's existing tools (discovered, not installed)
- Default I/O: PowerShell built-ins (Get-Content, Set-Content)
- Default BRAIN: Local YAML/JSON (KDS/cortex-brain/)
- Zero external dependencies for CORTEX CORE
- Cloud/database options are OPTIONAL extensions (user's choice)
```

### üì¶ Open Source Library Policy

**CORTEX Enhancement Libraries (ALLOWED)**

Open source libraries that enhance CORTEX functionality are PERMITTED when:
- ‚úÖ They are declared as **required dependencies** during CORTEX setup
- ‚úÖ They are included in setup instructions (package.json, requirements.txt, etc.)
- ‚úÖ User is informed upfront that these are needed to proceed
- ‚úÖ They enhance CORTEX capabilities (routing, analysis, testing, validation)

**Examples of Acceptable CORTEX Dependencies:**
```json
// package.json (if CORTEX uses Node.js enhancements)
{
  "devDependencies": {
    "markdown-it": "^13.0.0",      // Enhanced markdown parsing for intent analysis
    "yaml": "^2.3.0",                // YAML parsing for configuration
    "chalk": "^5.3.0"                // Terminal output formatting
  }
}

// requirements.txt (if CORTEX uses Python enhancements)
markdown-it-py>=3.0.0    # Enhanced markdown processing
pyyaml>=6.0              # YAML configuration parsing
rich>=13.0.0             # Beautiful terminal output
```

**NOT Considered External Dependencies:**
- Libraries needed for CORTEX core functionality (router, planner, executor)
- Libraries that improve intent detection accuracy
- Libraries that enhance session state management
- Libraries that provide better error reporting/logging

**STILL External Dependencies (Require User Approval):**
- Libraries for the user's APPLICATION code (React, SignalR, etc.)
- Libraries that change application architecture
- Libraries that affect production deployment
- Database/cloud providers not already in use

**Setup Protocol:**
When recommending CORTEX enhancement libraries:
```markdown
‚ö†Ô∏è **CORTEX Enhancement Dependencies Required**

To proceed with this CORTEX feature, the following libraries are needed:

üì¶ Node.js (npm install):
  - markdown-it: Enhanced markdown parsing for intent analysis
  - yaml: Configuration file parsing
  
Installation:
  npm install --save-dev markdown-it yaml

These are KDS-internal dependencies and won't affect your application code.

Proceed with installation? (Y/n)
```

---

## üß™ Playwright Testing Protocol (PowerShell)

**CRITICAL RULE: All Playwright test automation scripts MUST follow the established protocol pattern.**

**‚ö†Ô∏è LONG-RUNNING PROCESS:** Test automation scripts often run >30 seconds. Follow the Long-Running Process Protocol (see Setup section) for:
- Padded time estimates (add 25-50% buffer to test execution time)
- Status updates during app startup and test execution
- Progress indicators when running multiple test files
- Graceful Ctrl+C handling with cleanup

### üéØ CRITICAL: Component ID-Based Selectors (TDD Requirement)

**RULE:** Always use element IDs for Playwright selectors. Text-based selectors are FRAGILE and PROHIBITED.

**WHY:**
- ‚úÖ 10x faster (getElementById vs DOM text search)
- ‚úÖ Immune to text changes (i18n, wording updates, HTML restructuring)
- ‚úÖ Explicit intent (`#login-btn` is clearer than `button:has-text("Login")`)
- ‚úÖ No false positives (unique ID vs multiple matching texts)

**WRONG (FRAGILE - DO NOT USE):**
```typescript
// ‚ùå BREAKS when text changes, slow DOM search, ambiguous
const button = page.locator('button:has-text("Start Session")').first();
const link = page.locator('div:has-text("Transcript Canvas")');
```

**CORRECT (ROBUST - ALWAYS USE):**
```typescript
// ‚úÖ Fast, reliable, explicit, future-proof
const button = page.locator('#sidebar-start-session-btn');
const link = page.locator('#reg-transcript-canvas-btn');
```

**Component ID Discovery:**
Before writing ANY Playwright test, discover available IDs:
1. Open target component file (e.g., `HostControlPanelSidebar.razor`)
2. Search for `id="` attributes
3. Use those IDs in your test selectors
4. If no ID exists ‚Üí ADD ONE to the component (with `[REFACTOR:component-id]` comment)

**Enforcement:**
- Test reviews MUST reject text-based selectors
- CORTEX test-generator SHOULD warn when ID exists but text selector used
- Future: Automated crawler will build `KDS/cache/component-ids.json`

### Application Routes & Tokens

**Host Control Panel:**
- Route: `https://localhost:9091/host/control-panel/{hostToken}`
- Page File: `SPA/NoorCanvas/Pages/HostControlPanel.razor`
- Component File: `SPA/NoorCanvas/Components/Host/HostControlPanelContent.razor`
- Session 212 Token: `PQ9N5YWW`
- Full URL: `https://localhost:9091/host/control-panel/PQ9N5YWW`

**Component IDs (Host Control Panel):**
| Element | Component | ID | Purpose |
|---------|-----------|-----|---------|
| Transcript Canvas Button | UserRegistrationLink.razor | `reg-transcript-canvas-btn` | Select transcript canvas mode |
| Asset Canvas Button | UserRegistrationLink.razor | `reg-asset-canvas-btn` | Select asset canvas mode |
| Start Session Button | HostControlPanelSidebar.razor | `sidebar-start-session-btn` | Initiate session |
| Registration Link Container | UserRegistrationLink.razor | `reg-link-container` | Parent container for canvas buttons |

### Standard Protocol Pattern

**Reference Implementation:** `Scripts/run-debug-panel-percy-tests.ps1`

**Required Steps:**
1. ‚úÖ Launch app using `Start-Job` with `dotnet run` (NOT Start-Process)
2. ‚úÖ Wait for app readiness (20 seconds minimum, or health check loop)
3. ‚úÖ Run Playwright tests using `npx playwright test [file] --headed`
4. ‚úÖ Cleanup with `Stop-Job` and `Remove-Job` (unless -KeepAppRunning)

### Correct Pattern (FOLLOW THIS)

```powershell
param([switch]$KeepAppRunning)

# Step 1: Start app with Start-Job
$appJob = Start-Job -ScriptBlock {
    Set-Location 'D:\PROJECTS\NOOR CANVAS\SPA\NoorCanvas'
    dotnet run
}

# Step 2: Wait for readiness (20s minimum)
Start-Sleep -Seconds 20

# Step 3: Run Playwright tests
try {
    Set-Location 'D:\PROJECTS\NOOR CANVAS'
    npx playwright test Tests/UI/my-test.spec.ts --headed
    $exitCode = $LASTEXITCODE
}
finally {
    # Step 4: Cleanup
    if (-not $KeepAppRunning) {
        Stop-Job -Job $appJob -ErrorAction SilentlyContinue
        Remove-Job -Job $appJob -ErrorAction SilentlyContinue
    }
}

exit $exitCode
```

### WRONG Patterns (NEVER DO THIS)

‚ùå **Using Start-Process with -ArgumentList:**
```powershell
# WRONG - Don't use Start-Process with complex arguments
$proc = Start-Process -FilePath "npx" -ArgumentList $testArgs -NoNewWindow -Wait -PassThru
```

‚ùå **Using Invoke-WebRequest for health checks without proper error handling:**
```powershell
# WRONG - Complex health check that can fail unpredictably
$resp = Invoke-WebRequest -Uri $appUrl -SkipCertificateCheck -TimeoutSec 5
```

‚ùå **Separating test running from working directory:**
```powershell
# WRONG - Don't Push-Location multiple times
Push-Location $testsPath
npx playwright test
Pop-Location
```

### Playwright Command Format

**Correct:**
```powershell
# Set working directory ONCE, then run test
Set-Location 'D:\PROJECTS\NOOR CANVAS'
npx playwright test Tests/UI/my-test.spec.ts --headed
```

**For Percy visual tests:**
```powershell
# Percy wraps Playwright
percy exec -- playwright test Tests/UI/my-test.spec.ts --headed
```

**Capture exit code:**
```powershell
npx playwright test Tests/UI/my-test.spec.ts --headed
$exitCode = $LASTEXITCODE
exit $exitCode
```

### Test Script Checklist

Before creating ANY Playwright test automation script, verify:

```
‚úì Uses Start-Job (not Start-Process) for app launch?
‚úì Waits minimum 20 seconds for app readiness?
‚úì Sets working directory to project root (not Tests/UI)?
‚úì Runs npx playwright test with direct command (no Start-Process)?
‚úì Captures $LASTEXITCODE for exit status?
‚úì Cleans up with Stop-Job and Remove-Job?
‚úì Supports -KeepAppRunning parameter?

If ANY answer is NO ‚Üí FIX before running
```

### Reference Scripts

**Study these working examples:**
- ‚úÖ `Scripts/run-debug-panel-percy-tests.ps1` - Full featured (health checks, Percy, detailed logging)
- ‚úÖ `Scripts/run-transcript-canvas-visual-tests.ps1` - Simple pattern (20s wait, basic cleanup)
- ‚úÖ `Scripts/run-fab-share-button-percy-tests.ps1` - Percy visual regression pattern

**Key Patterns:**
```powershell
# App Launch
$appJob = Start-Job -ScriptBlock {
    Set-Location 'D:\PROJECTS\NOOR CANVAS\SPA\NoorCanvas'
    dotnet run
}

# Wait Pattern (Simple)
Start-Sleep -Seconds 20

# Wait Pattern (Health Check - Advanced)
while ($attempt -lt $maxAttempts) {
    try {
        $resp = Invoke-WebRequest -Uri $appUrl -UseBasicParsing -TimeoutSec 5
        if ($resp.StatusCode -eq 200) { break }
    } catch {
        Start-Sleep -Seconds 2
    }
    $attempt++
}

# Test Execution
Set-Location 'D:\PROJECTS\NOOR CANVAS'
npx playwright test Tests/UI/my-test.spec.ts --headed
$exitCode = $LASTEXITCODE

# Cleanup
Stop-Job -Job $appJob -ErrorAction SilentlyContinue
Remove-Job -Job $appJob -ErrorAction SilentlyContinue
```

---

## üèóÔ∏è Architectural Thinking Mandate

**CRITICAL RULE: All CORTEX agents MUST think architecturally when proposing solutions.**

### Core Principles

**1. Architecture-First Design**
- ‚úÖ Understand existing application architecture BEFORE proposing solutions
- ‚úÖ Design solutions that naturally fit the current architecture from the start
- ‚ùå NEVER propose monolithic implementations that need refactoring later
- ‚ùå NEVER create "everything in one file" with intent to break apart later

**2. Pre-Flight Architectural Validation**
Every solution proposal must pass this refactor logic check:

```
BEFORE proposing a solution:
  ‚Üì
1. Identify current architectural patterns
   - Component structure (where do similar components live?)
   - API organization (where do similar APIs exist?)
   - Service layer patterns (how are services currently structured?)
   - State management (what patterns are in use?)
   - File organization (what's the project structure?)
   ‚Üì
2. Run mental refactor test
   - Would this solution require significant refactoring to fit the architecture?
   - Am I creating files that don't match existing conventions?
   - Am I mixing concerns that are separated elsewhere?
   ‚Üì
3. If refactor is needed ‚Üí REDESIGN the solution
   - Align with existing patterns
   - Follow established separation of concerns
   - Place files in correct locations from the start
   ‚Üì
4. Only then propose the architecturally-aligned solution
```

**3. Forbidden Anti-Patterns**

‚ùå **NEVER do this:**
```
‚ùå "Let's create everything in PageComponent.razor first, then we'll break out 
   the child components later"
   
‚ùå "I'll add the API logic to the page for now, we can move it to a service later"

‚ùå "Let's put this in a temporary location and reorganize after it works"

‚ùå "We'll create the monolith first, then refactor to match your architecture"
```

‚úÖ **ALWAYS do this:**
```
‚úÖ "Based on the existing component structure in Components/Canvas/, 
   I'll create CanvasPdfExport.razor there and import it into the parent"
   
‚úÖ "Following the pattern in Services/, I'll create PdfExportService.cs 
   and inject it via DI as seen in other services"

‚úÖ "The existing API controllers are in Controllers/API/, so I'll create 
   PdfExportController.cs there with the same routing pattern"

‚úÖ "This matches the architecture - components are separated, services handle 
   business logic, and APIs are in the correct location from the start"
```

**4. Architectural Discovery Process**

Before proposing ANY solution, agents must:

```
Step 1: Discover Current Architecture
  - Search for similar features/components
  - Identify existing patterns and conventions
  - Map out file organization structure
  - Understand separation of concerns

Step 2: Pattern Matching
  - "Where do similar components live?"
  - "How are APIs currently organized?"
  - "What's the service layer pattern?"
  - "How is state managed?"

Step 3: Alignment Check
  - Does my solution follow these patterns?
  - Are files in the right locations?
  - Is separation of concerns maintained?
  - Would a developer familiar with this codebase find this natural?

Step 4: Propose Solution
  - Only after architectural alignment is confirmed
  - Explicitly state which patterns you're following
  - Show how it fits the existing structure
```

**5. Implementation Example**

**BAD (Anti-Pattern):**
```markdown
Plan: Add PDF export feature

Phase 1: Create basic implementation
  - Task 1.1: Add export logic to TranscriptCanvas.razor
  - Task 1.2: Test the functionality
  
Phase 2: Refactor to proper architecture
  - Task 2.1: Extract to PdfExportService
  - Task 2.2: Create dedicated component
  - Task 2.3: Move to API controller

‚ùå This violates architectural thinking - refactoring is built into the plan!
```

**GOOD (Architecturally Aligned):**
```markdown
Plan: Add PDF export feature

Phase 0: Architectural Discovery
  - Task 0.1: Map existing service patterns (Services/)
  - Task 0.2: Identify component organization (Components/)
  - Task 0.3: Review API structure (Controllers/API/)

Phase 1: Test Infrastructure (following existing test patterns)
  - Task 1.1: Create PdfExportServiceTests.cs (Tests/Unit/Services/)
  - Task 1.2: Create PdfExportController tests (Tests/Unit/Controllers/)
  - Task 1.3: Create visual tests (Tests/UI/pdf-export.spec.ts)

Phase 2: Implementation (architecturally aligned from start)
  - Task 2.1: Create PdfExportService.cs in Services/
  - Task 2.2: Create PdfExportButton.razor in Components/Canvas/
  - Task 2.3: Create PdfExportController.cs in Controllers/API/
  - Task 2.4: Register service in DI (Program.cs pattern)

‚úÖ This is architecturally correct from the start - no refactoring needed!
```

**6. Agent-Specific Requirements**

**Work Planner (work-planner.md):**
- ‚úÖ MUST include "Phase 0: Architectural Discovery" for new features
- ‚úÖ Plans must show architectural alignment in task descriptions
- ‚úÖ File paths must match existing conventions

**Code Executor (code-executor.md):**
- ‚úÖ MUST verify file location matches architecture before creating
- ‚úÖ MUST follow existing patterns for similar features
- ‚úÖ MUST NOT create temporary/placeholder implementations

**Test Generator (test-generator.md):**
- ‚úÖ Tests must mirror the application's architectural organization
- ‚úÖ Test files must be placed following existing test structure

**7. Validation Checkpoint**

Before ANY code generation, agents must answer:

```
‚úì Have I identified where similar code lives in this architecture?
‚úì Am I following the existing file organization patterns?
‚úì Is my separation of concerns consistent with the codebase?
‚úì Would this solution require refactoring to fit the architecture?
‚úì Am I creating files in their permanent, correct locations?

If ANY answer is NO ‚Üí STOP and redesign the solution
```

**8. Success Criteria**

A solution is architecturally valid when:
- ‚úÖ No refactoring phase exists in the plan
- ‚úÖ Files are in correct locations from creation
- ‚úÖ Patterns match existing similar features
- ‚úÖ Separation of concerns is maintained from start
- ‚úÖ A developer familiar with the codebase would say "this fits naturally"

---

## ÔøΩüéØ The ONLY Command You Need to Remember

```markdown
#file:KDS/prompts/user/cortex.md

[Tell CORTEX what you want in natural language]
```

That's it! CORTEX will automatically:
- ‚úÖ Analyze your request (intent detection)
- ‚úÖ Route to the appropriate specialist agent
- ‚úÖ Execute the correct workflow
- ‚úÖ Handle multi-step operations
- ‚úÖ Maintain session state

---

## üìã What You Can Say

### Start New Work
```markdown
#file:KDS/prompts/user/cortex.md

I want to add a FAB button pulse animation when questions arrive
```
‚Üí Routes to: **plan.md** ‚Üí work-planner.md

### Continue Existing Work
```markdown
#file:KDS/prompts/user/cortex.md

Continue working on the current task
```
‚Üí Routes to: **execute.md** ‚Üí code-executor.md

### Resume After Break
```markdown
#file:KDS/prompts/user/cortex.md

Show me where I left off
```
‚Üí Routes to: **resume.md** ‚Üí work-planner.md

### Fix Copilot's Mistake
```markdown
#file:KDS/prompts/user/cortex.md

You're modifying the wrong file. The FAB button is in HostControlPanelContent.razor
```
‚Üí Routes to: **correct.md** ‚Üí code-executor.md

### Create Tests
```markdown
#file:KDS/prompts/user/cortex.md

Create visual regression tests for the share button
```
‚Üí Routes to: **test.md** ‚Üí test-generator.md

### Check System Health
```markdown
#file:KDS/prompts/user/cortex.md

Run all validations and show me the health status
```
‚Üí Routes to: **validate.md** ‚Üí health-validator.md

### Analyze Screenshot
```markdown
#file:KDS/prompts/user/cortex.md

Analyze this screenshot and extract requirements

[Attach screenshot via chat interface]
```
‚Üí Routes to: **screenshot-analyzer.md** ‚Üí Extracts requirements, annotations, design specs

### Commit Changes (Automatic After Task Completion)
```markdown
#file:KDS/prompts/user/cortex.md

Commit changes
```
‚Üí Uses: **KDS/scripts/commit-kds-changes.ps1** ‚Üí Smart commit handler achieving zero uncommitted files

**‚ö†Ô∏è NOTE: Commits happen AUTOMATICALLY after each task completion (Rule #16)**

You typically don't need to invoke this manually. CORTEX automatically commits after:
- ‚úÖ Every task completes successfully
- ‚úÖ All tests pass (GREEN)
- ‚úÖ Post-implementation review passes
- ‚úÖ Build validates with zero errors

**Manual use cases (when commits were skipped or failed):**
- üîÑ Re-running commit after fixing validation issues
- üìù Committing documentation-only changes
- üßπ Committing cleanup/reorganization work

**What automatic commits do:**
- ‚úÖ Analyzes uncommitted files and categorizes them intelligently
- ‚úÖ Auto-updates .gitignore for CORTEX auto-generated files (BRAIN state, internal prompts, reports)
- ‚úÖ Resets auto-generated files that should not be committed (conversation-context.jsonl, etc.)
- ‚úÖ Stages only user-created files (user prompts, documentation, code)
- ‚úÖ Creates semantic commit messages (feat/fix/docs/chore)
- ‚úÖ Achieves zero uncommitted files automatically
- ‚úÖ Interactive mode for documentation decisions
- ‚úÖ Dry-run mode for preview without changes

**Automatic .gitignore management:**
- CORTEX BRAIN state files (conversation-context.jsonl, conversation-history.jsonl, development-context.yaml)
- CORTEX internal prompts (auto-updated by system)
- CORTEX reports (monitoring/, self-review/, test-reports/)
- PlayWright CORTEX artifacts
- Temporary test files (.mjs, .spec.*)

**Example output:**
```
üß† CORTEX Smart Commit Handler
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Step 1: Analyzing uncommitted files...
  Modified files: 9
  Untracked files: 11

Step 2: Categorizing files...
Step 3: Updating .gitignore...
  Adding to .gitignore:
    + KDS/cortex-brain/conversation-context.jsonl
    + KDS/prompts/internal/*.md
    + KDS/reports/monitoring/
  ‚úÖ .gitignore updated with CORTEX patterns

Step 4: Resetting auto-generated files...
  Resetting:
    - KDS/cortex-brain/conversation-context.jsonl
    - KDS/prompts/internal/code-executor.md
  ‚úÖ Reset 2 auto-generated files

Step 5: Preparing commit...
  Files to commit: 3
    + KDS/prompts/user/cortex.md
    + KDS/dashboard/README.md
    + .gitignore

Step 6: Staging files...
  ‚úÖ Files staged

Step 7: Committing...
  ‚úÖ Changes committed

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚úÖ SUCCESS: Zero uncommitted files!
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
```

**Usage:**
```powershell
# Interactive mode (default)
.\KDS\scripts\commit-kds-changes.ps1

# With custom message
.\KDS\scripts\commit-kds-changes.ps1 -Message "feat(kds): Add dashboard"

# Dry run (preview without changes)
.\KDS\scripts\commit-kds-changes.ps1 -DryRun

# Non-interactive (auto-include all documentation)
.\KDS\scripts\commit-kds-changes.ps1 -Interactive:$false
```

### Ask Questions
```markdown
#file:KDS/prompts/user/cortex.md

How do I use Playwright to test the canvas element?
```
‚Üí Routes to: **ask-cortex.md** ‚Üí knowledge-retriever.md

### Review CORTEX Changes
```markdown
#file:KDS/prompts/user/cortex.md

I updated the test-generator to support Percy visual testing
```
‚Üí Routes to: **govern.md** ‚Üí change-governor.md

### View Performance Metrics
```markdown
#file:KDS/prompts/user/cortex.md

run metrics
```
‚Üí Routes to: **metrics-reporter.md** ‚Üí Generates visual performance report

Output destination (for historical comparison):
- A Markdown report is written to `KDS/reports/metrics/<YYYY-MM-DD>/metrics-<timestamp>.md`
- A convenience copy is saved at `KDS/reports/metrics/latest.md`

Notes:
- Reports are visual with bar displays and contain no code snippets.
- Because reports live in the repository, Git naturally versions them so you can compare trends over time.

**What it shows:**
- ‚úÖ BRAIN health score and trends
- ‚úÖ Routing accuracy by intent type
- ‚úÖ Knowledge graph growth visualization
- ‚úÖ File hotspots (high-churn files)
- ‚úÖ Code velocity trends
- ‚úÖ Test-first impact analysis
- ‚úÖ Productivity patterns (best times to work)
- ‚úÖ Auto-learning performance
- ‚úÖ Month-over-month improvements
- ‚úÖ Actionable recommendations

**Example output:**
```
üìä Quick Stats
Routing Accuracy: 94% ‚ñ≤ +3% üü¢ Excellent
Learning Efficiency: 92% ‚ñ≤ +12% üü¢ Excellent

üß† BRAIN Storage
Tier 1: [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 8/20 (40%)
Tier 2: 3,847 entries (+247 this month)
Tier 3: 1,547 commits analyzed

üî• File Hotspots
HostControlPanelContent.razor  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 28% churn ‚ö†Ô∏è
UserRegistrationLink.razor     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë 24% churn ‚ö†Ô∏è

üí° Recommendations
1. Continue test-first (96% success rate)
2. Work 10am-12pm (94% peak productivity)
3. Refactor hotspots (>20% churn)
4. Keep sessions <60 min (89% vs 67%)
```

**‚è±Ô∏è Report time:** ~90 seconds to read

---

### Reset BRAIN for New Application (Amnesia)
```markdown
#file:KDS/prompts/user/cortex.md

Reset BRAIN for new application
```
‚Üí Routes to: **brain-amnesia.md** ‚Üí Safely removes application-specific data

Or run directly:
```powershell
.\KDS\scripts\brain-amnesia.ps1
```

**What it does:**
- ‚úÖ Creates backup of current BRAIN state
- ‚úÖ Generates amnesia report (shows what will be removed vs preserved)
- ‚úÖ Removes application-specific data (file paths, workflows, conversations)
- ‚úÖ Preserves CORTEX core intelligence (generic patterns, governance)
- ‚úÖ Resets BRAIN to fresh state ready for new project

**‚ö†Ô∏è CRITICAL: What Gets Removed (Application-Specific)**
```yaml
WILL BE REMOVED:
  - All file relationships (e.g., SPA/NoorCanvas paths)
  - Application-specific workflows (e.g., blazor_component_api_flow)
  - All conversations (application context)
  - All events (application interactions)
  - Development metrics (git stats, velocity)
  - Feature components (e.g., fab_button)
```

**‚úÖ GUARANTEED: What Gets Preserved (CORTEX Intelligence)**
```yaml
WILL BE PRESERVED:
  - Generic intent patterns ("add [X] button" ‚Üí plan)
  - Generic workflow patterns (test_first_id_preparation)
  - KDS-specific patterns (kds_health_monitoring, brain_test_synchronization)
  - Protection configuration (confidence thresholds)
  - All 10 specialist agents
  - All governance rules
  - All CORTEX prompts and scripts
```

**Use Cases:**
- üîÑ Moving CORTEX to a completely new project
- üÜï Starting fresh with a different application
- üßπ Cleaning BRAIN after experimenting with test project
- üì¶ Preparing CORTEX for distribution to new team/project

**Safety:**
- ‚úÖ Backup created before any changes
- ‚úÖ Dry-run mode available (`-DryRun` parameter)
- ‚úÖ Requires confirmation (type 'AMNESIA' to proceed)
- ‚úÖ Full rollback possible from backup
- ‚úÖ BRAIN integrity verified after amnesia

**Example Output:**
```
üß† CORTEX BRAIN Amnesia - Application Data Reset
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

[1/8] Validating BRAIN system...
‚úÖ BRAIN structure validated

[2/8] Analyzing BRAIN data...
  Application-specific workflows: 12
  Generic/CORTEX workflows: 6
  Conversations: 5
  Events: 68

[4/8] Amnesia Impact Summary

  WILL BE REMOVED:
    - 5 conversations (application context)
    - 68 events (application interactions)
    - ~12 application-specific patterns
    - All NoorCanvas file relationships
    - All development metrics

  WILL BE PRESERVED:
    - All 10 CORTEX specialist agents
    - ~6 generic/CORTEX workflow patterns
    - Generic intent detection templates
    - Protection configuration
    - All CORTEX governance rules

‚ö†Ô∏è  Type 'AMNESIA' to confirm reset: AMNESIA

[5/8] Creating backup...
‚úÖ Backup created: KDS/cortex-brain/backups/pre-amnesia-20251104-143022

[6/8] Executing BRAIN amnesia...
‚úÖ BRAIN amnesia complete

[7/8] Verifying BRAIN integrity...
‚úÖ BRAIN integrity verified

[8/8] Generating completion report...
‚úÖ Completion report saved

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚úÖ BRAIN AMNESIA COMPLETE
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Next Steps:
  1. Update KDS/tooling/cortex.config.json (new project name/paths)
  2. Run: #file:KDS/prompts/user/cortex.md Setup
  3. CORTEX will learn your new application architecture
```

**Post-Amnesia Workflow:**
1. ‚úÖ Amnesia complete (BRAIN reset)
2. Update `cortex.config.json` with new project details
3. Run `Setup` command to discover new application
4. CORTEX automatically learns from new interactions
5. BRAIN rebuilds application-specific knowledge over time

**Rollback (if needed):**
```powershell
# Restore from backup
$backupDir = "KDS/cortex-brain/backups/pre-amnesia-{timestamp}"
Copy-Item -Path "$backupDir/*.yaml" -Destination "KDS/cortex-brain/" -Force
Copy-Item -Path "$backupDir/*.jsonl" -Destination "KDS/cortex-brain/" -Force
```

---

## üß† CORTEX Health Dashboard

**Purpose:** Visual monitoring dashboard for CORTEX system health, BRAIN status, and development metrics.

### Launch Dashboard

```markdown
#file:KDS/prompts/user/cortex.md launch dashboard
```

Or directly:
```powershell
.\KDS\scripts\launch-dashboard.ps1
```

**What it does:**
- ‚úÖ Starts API server in a **separate visible PowerShell window**
- ‚úÖ Opens dashboard in your default browser
- ‚úÖ Provides real-time health monitoring
- ‚úÖ Shows visual feedback for all operations

**‚ö†Ô∏è PERMANENT RULE: API Server Window Behavior**

The API server MUST run in a **separate visible PowerShell window**, NOT as a background job.

**Rationale:**
- ‚úÖ User can see server logs in real-time
- ‚úÖ Easy to stop (just close the window or Ctrl+C)
- ‚úÖ Clear visual indicator that server is running
- ‚úÖ No hidden background processes
- ‚ùå Background jobs are invisible and hard to manage
- ‚ùå Users couldn't tell if server was running

**Implementation:**
```powershell
# CORRECT - Separate visible window
Start-Process pwsh -ArgumentList "-NoExit", "-Command", "cd '$workspaceRoot'; .\KDS\scripts\dashboard-api-server.ps1"

# WRONG - Background job (DO NOT USE)
$job = Start-Job -ScriptBlock { ... }
```

### Dashboard Features

**Visual Loading Feedback:**
- üìä Progress bar at top of page during operations
- üîÑ Loading overlay with detailed status messages
- ‚è±Ô∏è Real-time progress updates
- üéØ Stats start at 0 and refresh with live data

**Health Check Categories:**
- üèóÔ∏è Infrastructure (files, directories, permissions)
- ü§ñ Agents & Prompts (all 10 specialist agents)
- üß† BRAIN System (3-tier architecture)
- üíæ Session State (active sessions, history)
- üìö Knowledge Base (graph, patterns, context)
- üîß Scripts & Tools (PowerShell, validation)
- ‚ö° Performance (response times, efficiency)

**Actions:**
- üîÑ **Refresh** - Run all health checks (shows loading feedback)
- üìã **Copy to Clipboard** - Copy health report JSON (with fallback for file:// protocol)
- üìä **Export Report** - Download JSON file

**Connection States:**
- üîó **Live** - API server connected, real data
- üîå **Disconnected** - API server not running (shows retry button)

### Copy to Clipboard Feature

**Multi-Layer Fallback System:**

1. **Modern Clipboard API** (HTTPS/secure context)
   ```javascript
   navigator.clipboard.writeText(jsonText)
   ```

2. **Legacy execCommand** (HTTP/file:// protocol)
   ```javascript
   document.execCommand('copy')
   ```

3. **Manual Prompt** (Last resort)
   ```javascript
   prompt('Copy this JSON (Ctrl+C):', jsonText)
   ```

**Why fallback is needed:**
- ‚ö†Ô∏è Dashboard runs on `file://` protocol (not HTTPS)
- ‚ö†Ô∏è Modern clipboard API requires secure context
- ‚úÖ Fallback ensures copy works in all scenarios
- ‚úÖ Always provides a way to get the JSON

### To Stop Dashboard

**Option 1:** Close the API server PowerShell window

**Option 2:** Press Ctrl+C in the API server window

**Option 3:** Just close your browser (server keeps running until manually stopped)

**Dashboard remains functional** in disconnected mode - you can view cached data and retry connection.

---

## üìä Comprehensive CORTEX Dashboard (Unified Entry Point)

**Purpose:** Single comprehensive dashboard for all CORTEX monitoring - health checks, BRAIN metrics, efficiency tracking, and activity logs.

**File:** `KDS/cortex-dashboard.html`  
**Technology:** HTML + Chart.js (with optional API server for real-time data)

### Launch Dashboard

**Quick Launch (Recommended):**
```powershell
.\KDS\scripts\launch-dashboard.ps1
```
This starts the API server AND opens the dashboard automatically.

**Manual Launch:**
```
Open: D:\PROJECTS\KDS\cortex-dashboard.html
```
Or double-click the file in File Explorer.

### Dashboard Tabs

**Tab 1: üìä Overview**
- System health summary (6 interactive cards)
- Quick status of infrastructure, agents, BRAIN, sessions, knowledge
- Click any card to drill down into health checks

**Tab 2: üè• Health Checks**
- Detailed health validation across 7 categories
- Expandable sections with individual check results
- Status indicators (passed/warning/critical)
- Actionable recommendations for failures

**Tab 3: üß† BRAIN System**
- BRAIN integrity status (all 13 integrity checks)
- Event stream monitoring
- Knowledge graph health
- Real-time issue detection

**Tab 4: üìà Metrics** (Enhanced with Brain Efficiency)
- **Brain Efficiency Score**: Overall efficiency (0-100%) with letter grade
- **Component Breakdown**: Visual bars showing routing, planning, TDD, learning, coordination
- **Efficiency Trends**: 30-day line chart of performance
- **Component Pie Chart**: Weighted contribution visualization
- **Individual Metrics**: Routing accuracy, plan time, TDD cycle, learning effectiveness, coordination latency
- **Standard Metrics**: BRAIN health, knowledge graph, file hotspots, event activity, test success
- **Smart Recommendations**: AI-generated suggestions based on performance data

**Tab 5: üìù Activity Log**
- Recent system activities
- Event timeline
- Agent actions tracking

### Features

**Real-Time Updates:**
- ‚úÖ Auto-refresh every 30 seconds (configurable)
- üîÑ Manual refresh button
- üì° Live connection status indicator

**Brain Efficiency Integration:**
- üéØ Overall efficiency score with trend indicators
- üìä Component performance bars (5 components)
- üìà Historical trend charts (30 days)
- üí° Smart recommendations based on metrics

**Visual Feedback:**
- ‚úÖ Color-coded status (green/yellow/red)
- ÔøΩ Interactive charts (hover for details)
- üé® Dark theme optimized for long viewing
- ‚ö° Smooth animations and transitions

### How to Use

**Step 1: Launch dashboard**
```powershell
.\KDS\scripts\launch-dashboard.ps1
```

**Step 2: Collect brain efficiency data (for Metrics tab)**
```powershell
.\KDS\scripts\corpus-callosum\collect-brain-metrics.ps1
```

**Step 3: Navigate tabs**
- Click tab buttons to switch between views
- Overview ‚Üí Quick health summary
- Health ‚Üí Detailed validation results
- BRAIN System ‚Üí Integrity checks
- Metrics ‚Üí Performance analysis (includes efficiency dashboard)
- Activity ‚Üí Recent events

**Step 4: Monitor and act**
- Review efficiency score and grade
- Check trend indicators (‚ñ≤ improving, ‚ñº declining)
- Read smart recommendations
- Address any warnings or failures

### Efficiency Calculation (Metrics Tab)

```
Overall Score = 
  (Routing Accuracy √ó 25%) +
  (Planning Speed √ó 20%) +
  (TDD Speed √ó 20%) +
  (Learning Effectiveness √ó 25%) +
  (Coordination Speed √ó 10%)
```

**Grading:**
- **A+** (90-100%): Excellent - Peak efficiency
- **A** (85-90%): Very good - Continue current practices
- **B** (80-85%): Good - Minor improvements possible
- **C** (70-80%): Acceptable - Review recommendations
- **D** (<70%): Needs attention - Address warnings immediately

### Data Sources

**Real-time (via API server):**
- Health checks ‚Üí `run-health-checks.ps1`
- BRAIN metrics ‚Üí `test-brain-integrity.ps1`
- Standard metrics ‚Üí API aggregation

**Efficiency data (file-based):**
- **Reads from:** `KDS/cortex-brain/corpus-callosum/efficiency-history.jsonl`  
- **Generated by:** `collect-brain-metrics.ps1`  
**Update frequency:** Manual or scheduled (recommend daily)

**Optional: Automate collection**
```powershell
# Windows Task Scheduler (daily at 9am)
$trigger = New-ScheduledTaskTrigger -Daily -At 9am
$action = New-ScheduledTaskAction -Execute 'PowerShell.exe' `
    -Argument '-File "D:\PROJECTS\KDS\scripts\corpus-callosum\collect-brain-metrics.ps1"'
Register-ScheduledTask -TaskName "KDS-Metrics-Collection" `
    -Trigger $trigger -Action $action
```

**Dashboard remains functional** in disconnected mode - you can view cached data and retry connection.

---

## üöÄ First-Time Setup (New Application Installation)

**When to use this:** You're installing CORTEX in a new application (e.g., a fresh project like `https://github.com/yourname/new-project`)

**Purpose:** Complete CORTEX initialization with brain absorption, crawlers, and knowledge graph population for application-specific intelligence.

### Setup Command

```markdown
#file:KDS/prompts/user/cortex.md Setup
```

This triggers the complete CORTEX initialization sequence.

**‚è±Ô∏è Expected Duration: 15-20 minutes** (padded estimate)
- Small project (<1000 files): ~10-12 minutes
- Medium project (1000-5000 files): ~15-18 minutes  
- Large project (>5000 files): ~20-25 minutes

**üîî Status Updates:** You'll receive progress updates every 30-60 seconds so you know the system is working.

---

### üìã Setup Sequence (Automatic)

When you invoke `Setup`, CORTEX executes this sequence:

**‚öôÔ∏è RULE: Long-Running Process Protocol**

ALL long-running operations (>30 seconds) in CORTEX MUST:
1. ‚úÖ Display padded time estimate upfront (add 25-50% buffer)
2. ‚úÖ Show phase-by-phase progress indicators
3. ‚úÖ Provide status updates every 30-60 seconds
4. ‚úÖ Display percentage complete when measurable
5. ‚úÖ Show "Still working..." heartbeat for CPU-intensive tasks
6. ‚úÖ Explain what's happening (not just "Processing...")
7. ‚úÖ Allow graceful interruption (Ctrl+C with cleanup)

**Examples of long-running operations:**
- Setup sequence (15-20 min)
- Deep crawler (5-10 min)
- Development context collection (2-5 min)
- BRAIN updates with large event backlogs (1-3 min)
- Test suite runs (varies)
- Build processes (varies)

**See:** Full protocol at end of this section

#### Phase 1: Environment Validation (2-3 minutes)

**Status Display:**
```
üöÄ CORTEX Setup - Phase 1/6: Environment Validation
‚è±Ô∏è  Estimated time: 2-3 minutes
üìä Progress: [‚ñì‚ñì‚ñì‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 0%

‚è≥ Checking CORTEX structure...
```

**Step 1.1: Verify CORTEX Structure**
```
‚úì Check KDS/ directory exists
‚úì Verify all core agents present (10 specialist agents)
‚úì Validate BRAIN directories (cortex-brain/, sessions/, knowledge/)
‚úì Check abstraction layer (session-loader, test-runner, file-accessor)

Status: ‚úÖ CORTEX structure verified (10/10 agents found)
```

**Step 1.2: Detect Application Type**
```
‚è≥ Analyzing application type...

‚úì Identify primary language (C#, TypeScript, Python, etc.)
‚úì Detect frameworks (ASP.NET, React, Django, etc.)
‚úì Find build tools (dotnet, npm, pip, etc.)
‚úì Locate test frameworks (Playwright, Jest, xUnit, etc.)

Status: ‚úÖ Detected: C# + ASP.NET Core 8.0 + Playwright
```

**Step 1.3: Validate Dependencies**
```
‚è≥ Checking system dependencies...

‚úì Check Git is available (required for context collection)
‚úì Verify PowerShell/Bash (for scripts)
‚úì Confirm workspace structure is readable
‚úì Test file system permissions

Status: ‚úÖ All dependencies available

üìä Progress: [‚ñì‚ñì‚ñì‚ñì‚ñì‚ñë‚ñë‚ñë‚ñë‚ñë] 20% - Phase 1 complete
```

**Output:** Environment validation report

---

#### Phase 2: BRAIN Initialization (7-12 minutes)

**Status Display:**
```
üöÄ CORTEX Setup - Phase 2/6: BRAIN Initialization
‚è±Ô∏è  Estimated time: 7-12 minutes (longest phase)
üìä Progress: [‚ñì‚ñì‚ñì‚ñì‚ñì‚ñë‚ñë‚ñë‚ñë‚ñë] 20%

‚ö†Ô∏è  This phase takes the longest - please be patient!
```

**Step 2.1: Create BRAIN Storage**
```
‚è≥ Creating BRAIN directory structure...

‚úì Initialize KDS/cortex-brain/ directory structure
  - conversation-history.jsonl (Tier 1 - empty initially)
  - knowledge-graph.yaml (Tier 2 - base template)
  - development-context.yaml (Tier 3 - empty initially)
  - events.jsonl (event stream - empty)
  - crawler-state.yaml (crawler tracking)
‚úì Set up session storage (KDS/sessions/)
‚úì Create knowledge repository (KDS/knowledge/)

Status: ‚úÖ BRAIN storage created
üìä Progress: [‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñë‚ñë‚ñë‚ñë] 25%
```

**Step 2.2: Run Deep Codebase Crawler**
```
‚è≥ Starting deep codebase crawl...
‚è±Ô∏è  This will take 5-10 minutes depending on project size

Invoke: #file:KDS/prompts/internal/brain-crawler.md
Mode: deep
Duration: 5-10 minutes

Status updates every 60 seconds:
  [00:30] üìÇ Discovered 247 files (still scanning...)
  [01:00] üìÇ Discovered 612 files (analyzing structure...)
  [01:30] üìÇ Discovered 1,089 files (mapping relationships...)
  [02:00] üîç Parsing file contents (324/1,089 files)
  [02:30] üîç Parsing file contents (687/1,089 files)
  [03:00] üîç Analyzing imports and dependencies...
  [03:30] üìä Building relationship graph...
  [04:00] üéØ Detecting naming conventions...
  [04:30] ‚úÖ Crawler complete - generating report...

What it discovers:
‚úì File structure & architecture (where components/services/tests live)
‚úì Code relationships (dependencies, imports, DI patterns)
‚úì Test patterns (frameworks, selectors, test data)
‚úì Technology stack (languages, frameworks, libraries)
‚úì Naming conventions (PascalCase, kebab-case, etc.)
‚úì Configuration patterns (appsettings hierarchy, env vars)
‚úì Documentation locations (README files, API docs)
‚úì **Database schemas (SQL files FIRST, then connection strings)** üÜï

**Database Discovery Priority (NEW v1.1.0):**
  1Ô∏è‚É£ FIRST: Scan for SQL schema/data files (*schema*.sql, *data*.sql)
     - Analyzes CREATE TABLE, INSERT INTO statements
     - Extracts table names, relationships
     - Brain can reference these files (no database connection needed!)
  
  2Ô∏è‚É£ SECOND: Look for connection strings (appsettings.json, .env)
     - Discovers database provider (SQL Server, PostgreSQL, etc.)
     - Finds Entity Framework models and migrations
  
  3Ô∏è‚É£ THIRD: Connect to database (only if no SQL files found)
     - Prompts for connection string if not found
     - Memorizes it for future use (KDS/cortex-brain/database-connection.txt)
     - Crawls live schema (tables, columns)
  
  ‚ö° Result: 10x faster when SQL files exist! (~30s vs 2-5 min)
  
  See: `KDS/docs/features/database-crawler-sql-file-priority.md` for details

Feeds BRAIN with:
  - architectural_patterns (Components/**/*.razor)
  - file_relationships (co-modification patterns)
  - test_patterns (Playwright, session-212, data-testid)
  - conventions (naming, file organization)
  - technology_stack (complete inventory)

Status: ‚úÖ Crawler discovered 1,089 files, 3,247 relationships
üìä Progress: [‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñë‚ñë‚ñë] 35%
```

**Output:** Crawler report (`KDS/cortex-brain/crawler-report-{timestamp}.md`)

**Step 2.3: Initialize Development Context (Tier 3)**
```
‚è≥ Collecting development metrics (2-5 minutes)...

Invoke: #file:KDS/prompts/internal/development-context-collector.md

Status updates:
  [00:30] üìä Analyzing Git history (last 30 days)...
  [01:00] üìä Processing 1,237 commits...
  [01:30] üìä Calculating code velocity...
  [02:00] üìä Identifying file hotspots...
  [02:30] üìä Analyzing test patterns...
  [03:00] üìä Building baseline metrics...

What it collects:
‚úì Git activity (last 30 days of commits)
‚úì Code change velocity (lines added/deleted per week)
‚úì File hotspots (high churn rate files)
‚úì CORTEX session history (if any exist)
‚úì Testing activity (if tests exist)
‚úì Build/deploy patterns (if scripts exist)

Feeds BRAIN with:
  - Baseline metrics (velocity, churn, activity)
  - Productivity patterns (commit frequency)
  - File stability analysis (churn rates)
  - Initial correlations (commit size vs complexity)

Status: ‚úÖ Collected metrics from 1,237 commits, 78 tests
üìä Progress: [‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñë‚ñë] 45%
```

**Output:** `KDS/cortex-brain/development-context.yaml` (baseline metrics)

---

#### Phase 3: Knowledge Graph Population (3-5 minutes)

**Status Display:**
```
üöÄ CORTEX Setup - Phase 3/6: Knowledge Graph Population
‚è±Ô∏è  Estimated time: 3-5 minutes
üìä Progress: [‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñë‚ñë] 45%

‚è≥ Processing crawler discoveries...
```

**Step 3.1: Process Crawler Results**
```
‚è≥ Transforming discoveries into knowledge graph...

Invoke: #file:KDS/prompts/internal/brain-updater.md
Mode: bootstrap

Status updates:
  [00:30] üß† Processing 3,247 relationships...
  [01:00] üß† Assigning confidence scores...
  [01:30] üß† Creating file_relationships section (1,247 entries)
  [02:00] üß† Creating architectural_patterns section (127 patterns)
  [02:30] üß† Creating validation_insights section...

Actions:
‚úì Transform crawler discoveries into knowledge graph entries
‚úì Assign confidence scores (0.50 - 0.98)
  - Direct observations (imports): 0.95+ confidence
  - Pattern inference (naming): 0.70-0.85 confidence
  - Statistical (co-modification): 0.50-0.70 confidence
‚úì Create file_relationships section
‚úì Create architectural_patterns section
‚úì Create validation_insights section
‚úì Create intent_patterns (empty, will learn from usage)

Status: ‚úÖ Knowledge graph populated with 3,247 entries
üìä Progress: [‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñë] 55%
```

**Step 3.2: Build Intent Vocabulary (Bootstrapping)**
```
‚è≥ Bootstrapping intent patterns...

If generic patterns available (from templates):
  ‚úì Import common intent patterns
    - "add a button" ‚Üí PLAN intent
    - "create service" ‚Üí PLAN intent
    - "continue" ‚Üí EXECUTE intent
  ‚úì Seed with generic workflow patterns
    - UI feature: plan ‚Üí execute ‚Üí test
    - API endpoint: plan ‚Üí execute ‚Üí unit-test ‚Üí integration-test
  ‚úì Import common file confusion warnings
    - "HostControlPanel vs HostControlPanelContent"
    
If no templates:
  ‚úì Start with empty intent_patterns
  ‚úì BRAIN will learn from first interactions

Status: ‚úÖ Intent vocabulary seeded with 47 patterns
üìä Progress: [‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñë] 60%
```

**Step 3.3: Validate Knowledge Graph**
```
‚è≥ Validating knowledge graph integrity...

‚úì Run structure validation (YAML syntax)
‚úì Check confidence score ranges (0.50-1.00)
‚úì Verify file references exist
‚úì Test query functionality
‚úì Run protection rules check

Status: ‚úÖ Knowledge graph validated successfully
üìä Progress: [‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì] 65%
```

**Output:** `KDS/cortex-brain/knowledge-graph.yaml` (fully populated)

---

#### Phase 4: Three-Tier BRAIN Setup (1-2 minutes)

**Status Display:**
```
üöÄ CORTEX Setup - Phase 4/6: Three-Tier BRAIN Setup
‚è±Ô∏è  Estimated time: 1-2 minutes
üìä Progress: [‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì] 65%

‚è≥ Configuring three-tier architecture...
```

**Step 4.1: Initialize Tier 1 (Conversation History)**
```
‚è≥ Setting up conversation memory...

‚úì Create conversation-history.jsonl
‚úì Set FIFO queue capacity (20 conversations)
‚úì Initialize first conversation (the setup itself)
‚úì Configure conversation boundary detection

Status: ‚úÖ Tier 1 initialized
üìä Progress: [‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì] 70%
```

**Step 4.2: Verify Tier 2 (Knowledge Graph)**
```
‚è≥ Verifying knowledge graph...

‚úì Confirm knowledge-graph.yaml populated
‚úì Test brain-query queries
‚úì Verify all sections present:
  - intent_patterns
  - file_relationships
  - workflow_patterns
  - validation_insights
  - correction_history

Status: ‚úÖ Tier 2 verified (3,247 entries)
üìä Progress: [‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì] 75%
```

**Step 4.3: Verify Tier 3 (Development Context)**
```
‚è≥ Verifying development context...

‚úì Confirm development-context.yaml has baseline metrics
‚úì Test proactive_warnings generation
‚úì Verify correlation analysis available
‚úì Check hotspot detection working

Status: ‚úÖ Tier 3 verified (baseline metrics ready)
üìä Progress: [‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì] 80%
```

**Step 4.4: Enable Automatic Learning**
```
‚è≥ Configuring automatic learning...

‚úì Configure event logging (all agents ‚Üí events.jsonl)
‚úì Set automatic update triggers:
  - 50+ events ‚Üí brain-updater.md
  - 24 hours ‚Üí brain-updater.md (if 10+ events)
‚úì Enable Tier 3 collection (runs after brain updates)
‚úì Verify Rule #16 Step 5 compliance (event count check)

Status: ‚úÖ Automatic learning enabled
üìä Progress: [‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì] 85%
```

**Output:** Three-tier BRAIN fully operational

---

#### Phase 5: Testing & Validation (2-3 minutes)

**Status Display:**
```
üöÄ CORTEX Setup - Phase 5/6: Testing & Validation
‚è±Ô∏è  Estimated time: 2-3 minutes
üìä Progress: [‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì] 85%

‚è≥ Running validation checks...
```

**Step 5.1: Test Core Workflows**
```
‚è≥ Testing CORTEX components...

‚úì Test intent routing (sample phrases)
  - "I want to add a feature" ‚Üí Should route to PLAN
  - "Continue" ‚Üí Should detect no session, prompt accordingly
‚úì Test BRAIN queries
  - Query architectural_patterns ‚Üí Should return discovered structure
  - Query file_relationships ‚Üí Should return co-modification data
‚úì Test file operations
  - session-loader.md ‚Üí Should create/read session files
  - file-accessor.md ‚Üí Should read/write application files

Status: ‚úÖ All core workflows tested successfully
üìä Progress: [‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì] 90%
```

**Step 5.2: Run Health Validator**
```
‚è≥ Running comprehensive health check...

Invoke: #file:KDS/prompts/internal/health-validator.md

Checks:
‚úì All agents loadable
‚úì BRAIN files readable/writable
‚úì Knowledge graph valid
‚úì Session storage functional
‚úì Test framework detection working
‚úì Git integration working

Status: ‚úÖ All health checks passed
üìä Progress: [‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì] 93%
```

**Step 5.3: Generate Setup Report**
```
‚è≥ Generating setup report...

Create: KDS/setup-report-{timestamp}.md

Contents:
‚úì Environment summary (languages, frameworks, tools)
‚úì Discovered patterns (components, services, tests)
‚úì BRAIN status (all 3 tiers operational)
‚úì File counts (components: 89, services: 34, tests: 120)
‚úì Known issues (if any)
‚úì Next steps (ready to use!)

Status: ‚úÖ Report generated
üìä Progress: [‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì] 95%
```

**Output:** Setup complete confirmation

---

#### Phase 6: First Interaction Guidance (1 minute)

**Status Display:**
```
üöÄ CORTEX Setup - Phase 6/6: Finalizing
‚è±Ô∏è  Estimated time: 1 minute
üìä Progress: [‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì] 95%

‚è≥ Preparing your workspace...
```

**Step 6.1: Show User Quick Start**
```
‚è≥ Generating getting started guide...

Display:
  ‚úÖ Setup complete! CORTEX is ready.
  
  üìä What CORTEX learned about your application:
  - Technology: {detected stack}
  - Components: {count} files in {location}
  - Services: {count} files in {location}
  - Tests: {count} files, {framework} framework
  - Conventions: {naming patterns}
  
  üß† BRAIN Status:
  - Tier 1 (Conversations): Initialized
  - Tier 2 (Knowledge Graph): {entry_count} entries
  - Tier 3 (Dev Context): Baseline metrics collected
  
  üöÄ Ready to start!
  
  Try: #file:KDS/prompts/user/cortex.md
       I want to [describe your first feature]

Status: ‚úÖ Setup complete!
üìä Progress: [‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì] 98%
```

**Step 6.2: Log Setup Event**
```
‚è≥ Finalizing...

‚úì Record setup completion in events.jsonl
‚úì Create first conversation in conversation-history.jsonl
‚úì Mark setup as successful in crawler-state.yaml

Status: ‚úÖ All done!
üìä Progress: [‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì] 100% ‚ú®

‚è±Ô∏è  Total time: 15m 32s
```

---

### üìä Long-Running Process Protocol (UNIVERSAL RULE)

**APPLIES TO:** All CORTEX operations >30 seconds

**Required Elements:**

1. **Upfront Expectation Setting**
   ```
   ‚è±Ô∏è  Estimated time: X-Y minutes (padded 25-50%)
   ‚ö†Ô∏è  This is the longest phase - please be patient!
   ```

2. **Visual Progress Indicators**
   ```
   üìä Progress: [‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñë‚ñë‚ñë] 45%
   üîÑ Phase 3/6: Knowledge Graph Population
   ```

3. **Heartbeat Status Updates**
   ```
   Every 30-60 seconds:
   [00:30] Still working on X... (detail what's happening)
   [01:00] Processing Y... (show counts/progress)
   [01:30] Almost done with Z... (reassure user)
   ```

4. **Informative Messages**
   ```
   ‚ùå BAD: "Processing..." (vague, scary)
   ‚úÖ GOOD: "Analyzing 1,247 commits for velocity patterns..."
   
   ‚ùå BAD: "Please wait..." (no context)
   ‚úÖ GOOD: "Scanning 612 files for architectural patterns (2m 30s elapsed)"
   ```

5. **Completion Confirmation**
   ```
   Status: ‚úÖ Phase complete in 4m 23s
   üìä Progress: [‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì] 65% ‚Üí 75%
   ```

6. **Graceful Interruption**
   ```
   ‚è∏Ô∏è  You can press Ctrl+C to cancel
   ‚ö†Ô∏è  Cleanup will run automatically if interrupted
   ```

7. **Error Recovery Guidance**
   ```
   If something goes wrong:
   ‚ùå Error at Phase 3 (2m 15s elapsed)
   üí° You can:
      1. Retry this phase only
      2. Skip and continue (if non-critical)
      3. Cancel and review logs
   ```

**Implementation Checklist:**

For ALL long-running operations, verify:
- ‚òê Padded time estimate shown upfront (realistic + buffer)
- ‚òê Phase/step breakdown displayed
- ‚òê Progress bar or percentage shown
- ‚òê Status updates every 30-60 seconds minimum
- ‚òê Detailed "what's happening now" messages
- ‚òê Elapsed time counter visible
- ‚òê Graceful Ctrl+C handling
- ‚òê Clear completion confirmation
- ‚òê Error messages with recovery options

**Examples in KDS:**

```markdown
Long-Running Operations:
‚úì Setup (15-20 min) - Has all required elements above
‚úì Deep Crawler (5-10 min) - Needs status updates added
‚úì Development Context Collection (2-5 min) - Needs progress bar
‚úì BRAIN Update with backlog (1-3 min) - Needs heartbeat
‚úì Test Suite Execution (varies) - Needs all elements
‚úì Build Processes (varies) - Needs all elements
```

**Agents Responsible:**

All specialist agents that trigger long operations:
- `work-planner.md` - When creating large plans
- `code-executor.md` - When running builds/tests
- `test-generator.md` - When generating many tests
- `health-validator.md` - When running full validation
- `brain-crawler.md` - When scanning codebase
- `development-context-collector.md` - When analyzing history
- `brain-updater.md` - When processing large backlogs

**PowerShell Script Requirements:**

All CORTEX scripts (`.ps1`) MUST include:
```powershell
# At start
Write-Host "‚è±Ô∏è  Estimated time: 3-5 minutes" -ForegroundColor Yellow
$stopwatch = [System.Diagnostics.Stopwatch]::StartNew()

# During execution (every 30-60s)
Write-Host "[$(($stopwatch.Elapsed.TotalSeconds).ToString('00.0'))s] Still working on X..." -ForegroundColor Cyan

# At completion
$stopwatch.Stop()
Write-Host "‚úÖ Complete in $($stopwatch.Elapsed.TotalMinutes.ToString('0.0'))m" -ForegroundColor Green
```

**See Also:**
- Playwright Testing Protocol (uses 20s wait with status)
- Health Validator (should show check-by-check progress)
- Crawler modes (quick vs deep time estimates)

---

### üéØ Setup Modes

**Default Mode: Full Setup (Recommended)**
```markdown
#file:KDS/prompts/user/cortex.md Setup
```
- ‚è±Ô∏è Duration: 15-20 minutes (padded estimate)
- Runs all 6 phases with complete initialization
- Complete BRAIN initialization with deep crawler
- Ready for immediate production use
- **Status updates:** Every 30-60 seconds
- **Progress tracking:** Phase-by-phase with percentage

**Quick Mode: Minimal Setup (For Testing)**
```markdown
#file:KDS/prompts/user/cortex.md Setup --quick
```
- ‚è±Ô∏è Duration: 3-5 minutes (padded estimate)
- Skips deep crawler (runs quick scan only)
- Minimal Tier 3 data (current snapshot only)
- Good for experimentation, not production
- **Status updates:** Every 60 seconds
- **Progress tracking:** Simplified progress bar

**Migration Mode: Import Existing Knowledge**
```markdown
#file:KDS/prompts/user/cortex.md Setup --import "path/to/old-kds/cortex-brain/"
```
- ‚è±Ô∏è Duration: 7-10 minutes (padded estimate)
- Imports generic patterns from previous CORTEX installation
- Runs deep crawler for new application
- Merges old patterns with new discoveries
- Best for migrating CORTEX to similar project
- **Status updates:** Every 45 seconds
- **Progress tracking:** Shows import + scan progress separately

---

### üìÅ What Gets Created

After setup completes, you'll have:

```
KDS/
‚îú‚îÄ‚îÄ cortex-brain/
‚îÇ   ‚îú‚îÄ‚îÄ conversation-history.jsonl      ‚úÖ Initialized (setup conversation)
‚îÇ   ‚îú‚îÄ‚îÄ knowledge-graph.yaml            ‚úÖ Populated (crawler + baseline)
‚îÇ   ‚îú‚îÄ‚îÄ development-context.yaml        ‚úÖ Baseline metrics
‚îÇ   ‚îú‚îÄ‚îÄ events.jsonl                    ‚úÖ Setup events logged
‚îÇ   ‚îú‚îÄ‚îÄ crawler-state.yaml              ‚úÖ Last scan info
‚îÇ   ‚îî‚îÄ‚îÄ crawler-report-{timestamp}.md   üìä Detailed discoveries
‚îÇ
‚îú‚îÄ‚îÄ sessions/                           ‚úÖ Empty (ready for first session)
‚îÇ
‚îú‚îÄ‚îÄ knowledge/                          ‚úÖ Ready for knowledge articles
‚îÇ
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ brain-crawler.ps1               ‚úÖ Tested and working
‚îÇ   ‚îú‚îÄ‚îÄ collect-development-context.ps1 ‚úÖ Tested and working
‚îÇ   ‚îî‚îÄ‚îÄ protect-brain-update.ps1        ‚úÖ Protection active
‚îÇ
‚îî‚îÄ‚îÄ setup-report-{timestamp}.md         üìä Setup summary
```

---

### üîß Troubleshooting Setup

**Setup fails at Phase 1 (Validation):**
```
Cause: Missing CORTEX files or permissions issue
Fix: 
  1. Verify KDS/ directory copied completely
  2. Check file permissions (should be readable/writable)
  3. Ensure Git is installed and accessible
```

**Setup fails at Phase 2 (Crawler):**
```
Cause: Large codebase (>10,000 files) or binary files
Fix:
  1. Use Setup --quick (skips deep scan)
  2. Manually run targeted crawler later
  3. Add skip patterns to KDS/cortex-brain/crawler-config.yaml
```

**Setup succeeds but queries fail:**
```
Cause: Knowledge graph structure invalid
Fix:
  1. Check KDS/cortex-brain/knowledge-graph.yaml syntax
  2. Re-run: #file:KDS/prompts/internal/brain-updater.md
  3. Validate with: #file:KDS/prompts/internal/health-validator.md
```

---

### ‚úÖ Setup Success Indicators

You'll know setup succeeded when:

```
‚úì All 6 phases completed without errors
‚úì KDS/setup-report-{timestamp}.md exists
‚úì knowledge-graph.yaml has 50+ entries
‚úì development-context.yaml has baseline metrics
‚úì Health validator reports "All checks passed"
‚úì Test query returns architectural patterns
‚úì First cortex.md request routes correctly
```

---

### üéì Post-Setup Best Practices

**1. Verify BRAIN Learning:**
```
After your first few CORTEX interactions:

Check: KDS/cortex-brain/events.jsonl (should have new events)
Check: conversation-history.jsonl (should have conversations)
Run: #file:KDS/prompts/internal/brain-updater.md (manual update)
Verify: knowledge-graph.yaml updated with your patterns
```

**2. Regular Maintenance:**
```
Daily: Let automatic learning work (no action needed)
Weekly: Check proactive_warnings in development-context.yaml
Monthly: Run incremental crawler (keep structure current)
After refactoring: Run deep crawler (re-learn architecture)
```

**3. Optimize for Your Workflow:**
```
If CORTEX misroutes frequently:
  ‚Üí Check intent_patterns in knowledge-graph.yaml
  ‚Üí Add manual entries for your common phrases
  
If file suggestions wrong:
  ‚Üí Check architectural_patterns
  ‚Üí Run targeted crawler on new modules
  
If estimates inaccurate:
  ‚Üí Let development-context accumulate data (2-4 weeks)
  ‚Üí Correlations improve with more history
```

---

## ü§ñ How It Works

### Step 1: Intent Detection
When you use `cortex.md`, it loads the **Intent Router** agent which analyzes your request.

**Router reads:**
```yaml
keywords:
  plan: ["I want to", "add a", "create a", "build a", "implement"]
  execute: ["continue", "next task", "keep going", "proceed"]
  resume: ["where was I", "show progress", "left off", "resume"]
  correct: ["wrong file", "not what I", "actually", "correction"]
  test: ["test", "visual regression", "playwright", "unit test"]
  validate: ["health", "validate", "check", "run all", "status"]
  ask: ["how do I", "what is", "explain", "tell me about"]
  govern: ["I updated KDS", "I modified KDS", "review my changes"]
```

### Step 2: Routing Decision
```
User: "I want to add dark mode"
  ‚Üì
Intent Router: Detects "I want to add" = PLAN intent
  ‚Üì
Routes to: plan.md ‚Üí work-planner.md
  ‚Üì
Creates multi-phase plan, saves session state
```

### Step 3: Execution
The appropriate specialist agent executes:
- **Planner:** Breaks work into phases/tasks
- **Executor:** Implements code changes
- **Tester:** Creates and runs tests
- **Validator:** Checks system health
- **Governor:** Reviews CORTEX modifications
- **Knowledge Retriever:** Answers questions

### Step 4: Handoff (If Multi-Step)
For complex requests like "Add dark mode and test it":
```
User: "I want to add dark mode and test it"
  ‚Üì
Intent Router: Detects TWO intents (PLAN + TEST)
  ‚Üì
Routes to: plan.md ‚Üí work-planner.md
  ‚Üì
Planner creates plan with testing phase
  ‚Üì
Tells you: "Next: #file:KDS/prompts/user/cortex.md continue"
  ‚Üì
You: "continue"
  ‚Üì
Routes to: execute.md ‚Üí code-executor.md
  ‚Üì
Implements code ‚Üí Routes to: test.md ‚Üí test-generator.md
  ‚Üì
Creates tests ‚Üí Validates ‚Üí Complete
```

---

## üéØ Intent Detection Rules

**LOAD:** `#file:KDS/prompts/internal/intent-router.md`

The router uses these patterns:

### PRIMARY INTENT (Choose One)

**PLAN** - Starting new feature work
```
Patterns: "I want to", "add a", "create a", "build", "implement"
Examples: 
  - "I want to add a share button"
  - "Create a PDF export feature"
  - "Build a dark mode toggle"
```

**EXECUTE** - Continue active session
```
Patterns: "continue", "next", "keep going", "proceed", "execute"
Examples:
  - "Continue working"
  - "Next task"
  - "Keep going"
```

**RESUME** - Pickup after interruption
```
Patterns: "resume", "where was I", "show progress", "left off", "status"
Examples:
  - "Show me where I left off"
  - "What's the current status?"
  - "Resume work"
```

**CORRECT** - Fix Copilot error
```
Patterns: "wrong", "not that", "actually", "correction", "fix"
Examples:
  - "You're working on the wrong file"
  - "That's not what I meant"
  - "Actually, use SignalR not polling"
```

**TEST** - Create or run tests
```
Patterns: "test", "playwright", "visual regression", "unit test"
Examples:
  - "Create visual tests for the button"
  - "Run all Playwright tests"
  - "Add unit tests for the service"
```

**VALIDATE** - System health check
```
Patterns: "validate", "health", "check", "run all", "quality"
Examples:
  - "Check system health"
  - "Validate all changes"
  - "Run quality checks"
```

**ASK** - Question about KDS/codebase
```
Patterns: "how do I", "what is", "explain", "tell me", "?"
Examples:
  - "How do I test canvas elements?"
  - "What test patterns exist?"
  - "Explain the session state"
```

**GOVERN** - Review CORTEX changes
```
Patterns: "I updated KDS", "modified KDS", "review", "CORTEX change"
Examples:
  - "I updated the test-generator"
  - "Review my CORTEX modifications"
  - "I changed the rules"
```

### üß† Proactive Warnings (NEW - Post-Week 4 Enhancement)

**Before routing, CORTEX BRAIN analyzes your request and shows warnings:**

**When warnings appear:**
- ‚úÖ PLAN intent detected (starting new feature)
- ‚úÖ EXECUTE intent detected (continuing work)

**What gets predicted:**
```yaml
üü° File Hotspot Warnings:
   "‚ö†Ô∏è HostControlPanel.razor is a hotspot (28% churn)"
   ‚Üí Suggests: Add extra validation

üü° Complexity Warnings:
   "‚ö†Ô∏è PDF features take 50% longer than other exports"
   ‚Üí Suggests: Allocate more time

üü° Velocity Warnings:
   "‚ö†Ô∏è Velocity dropped 30% this week"
   ‚Üí Suggests: Smaller commits

üü¢ Success Patterns:
   "‚úÖ Test-first has 96% success rate for exports"
   ‚Üí Suggests: Continue TDD workflow
```

**Example:**
```markdown
User: #file:KDS/prompts/user/cortex.md
      I want to add PDF export

üß† BRAIN Analysis:
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
üü° ‚ö†Ô∏è HostControlPanel.razor is a hotspot (28% churn)
   üí° Add extra validation phase
   
üü¢ ‚úÖ Test-first approach has 96% success rate
   üí° Continue TDD workflow
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

Routing to work-planner.md...
```

**Benefits:**
- ‚ö° **Instant feedback** - Warnings appear in <5 seconds (before planning)
- üéØ **Better decisions** - Adjust approach before creating plan
- üìä **Data-driven** - Predictions based on historical patterns
- üîÑ **Continuous learning** - Accuracy improves over time

**Implementation:** Step 1.3 in `intent-router.md` (between user input and conversation context)

**ANALYZE_SCREENSHOT** - Extract requirements from images
```
Patterns: "analyze screenshot", "extract from image", "what does mockup show", "read annotations"
Examples:
  - "Analyze this screenshot and extract requirements"
  - "What does this mockup show?"
  - "Extract specs from this design"
  - "Read the annotations on this bug report"
  - [Image attachment detected]
```

**COMMIT** - Intelligent git commits
```
Patterns: "commit changes", "commit work", "git commit", "save to git"
Examples:
  - "Commit changes"
  - "Commit my work"
  - "Save changes to git"
  - "Create commits with proper categorization"
  - "Commit and tag if milestone"
```
  - "Read the annotations on this bug report"
  - [Image attachment detected]
```

### SECONDARY INTENTS (Can Combine)

**If multiple intents detected:**
```
"I want to add dark mode and test it"
  ‚Üì
Primary: PLAN
Secondary: TEST
  ‚Üì
Planner includes testing phase in plan
```

---

## üîÑ Complete Workflow Examples

### Example 1: New Feature (Simple)
```
You: #file:KDS/prompts/user/cortex.md
     I want to add a pulse animation to the FAB button

Router: PLAN intent detected
   ‚Üì
Planner: Creates 3-phase plan
   ‚Üì
Output: ‚úÖ Session created: fab-button-animation
        Next: #file:KDS/prompts/user/cortex.md continue
```

### Example 2: Continue Work
```
You: #file:KDS/prompts/user/cortex.md
     continue

Router: EXECUTE intent detected
   ‚Üì
Executor: Implements next task
   ‚Üì
Output: ‚úÖ Task 1.1 complete: CSS animation added
        Next: #file:KDS/prompts/user/cortex.md continue
```

### Example 3: Resume After Break (SOLID v5.0)
```
(New chat next day)

You: #file:KDS/prompts/user/cortex.md
     where was I?

Router: RESUME intent detected
   ‚Üì
Session Resumer: Loads via session-loader (DIP)
   ‚Üì
Output: Session: fab-button-animation
        Progress: 3/8 tasks (38%)
        
        üìä Detailed Progress:
        Phase 1: ‚úÖ Complete
        Phase 2: üîÑ 1/3 tasks done
        Phase 3: ‚¨ú Not started
        
        Next: #file:KDS/prompts/user/cortex.md continue
```

### Example 4: Correction Mid-Work (SOLID v5.0)
```
You: #file:KDS/prompts/user/cortex.md
     continue

Executor: Modifying HostControlPanel.razor...

You: #file:KDS/prompts/user/cortex.md
     Wrong file! The FAB is in HostControlPanelContent.razor

Router: CORRECT intent detected
   ‚Üì
Error Corrector: HALTS execution (dedicated agent)
   ‚Üì
Analysis: FILE_MISMATCH
   Incorrect: HostControlPanel.razor
   Correct: HostControlPanelContent.razor
   ‚Üì
Actions:
   ‚úÖ Reverted changes to HostControlPanel.razor
   ‚úÖ Loaded HostControlPanelContent.razor
   ‚úÖ Updated task file reference
   ‚Üì
Output: ‚úÖ Correction applied
        Next: #file:KDS/prompts/user/cortex.md continue
```

### Example 5: Multi-Intent Request
```
You: #file:KDS/prompts/user/cortex.md
     I want to add dark mode toggle and create Percy visual tests for it

Router: PLAN + TEST intents detected
   ‚Üì
Planner: Creates plan with dedicated test phase
   ‚Üì
Output: ‚úÖ 4-phase plan created (includes visual testing)
        Phase 4: Percy visual regression tests
        Next: #file:KDS/prompts/user/cortex.md continue
```

---

## ‚úÖ Benefits of Universal Entry Point + SOLID v5.0

### User Experience
- ‚úÖ **One command to remember** (`cortex.md`)
- ‚úÖ **Natural language** - say what you want
- ‚úÖ **No cognitive load** - don't need to know which specialist to call
- ‚úÖ **Forgiving** - works even if you're vague
- ‚úÖ **Predictable** - same command, consistent behavior

### Technical Benefits (SOLID v5.0)
- ‚úÖ **Intelligent routing** - right agent for the job
- ‚úÖ **Multi-intent handling** - complex requests work
- ‚úÖ **Context preservation** - session state via abstraction
- ‚úÖ **Automatic workflows** - no manual orchestration
- ‚úÖ **Single Responsibility** - each agent focused on one job
- ‚úÖ **Dependency Inversion** - swap storage/tools without breaking agents
- ‚úÖ **Interface Segregation** - no mode switches, dedicated specialists
- ‚úÖ **Easy to test** - mock abstractions, isolate agents

### Architecture Benefits
- üéØ **Modular** - add new agents without touching existing ones
- üîß **Maintainable** - fix bugs in one place
- üöÄ **Performant** - no mode-switch overhead
- üì¶ **Portable** - abstractions make storage/tools swappable
- üè† **Local-First** - 100% in KDS/, zero external dependencies
- üîí **Offline-Capable** - works without internet (except optional cloud features)
- üÜì **Zero-Install** - no npm/pip/dotnet packages required for KDS

### Comparison

**Before v5.0 (7 commands + mode switches):**
```
plan.md ‚Üí for new features
execute.md ‚Üí for continuing work + corrections (mode switch)
resume.md ‚Üí after breaks (actually loads work-planner)
correct.md ‚Üí for fixing errors (loads executor in correction mode)
test.md ‚Üí for creating tests
validate.md ‚Üí for health checks
ask-cortex.md ‚Üí for questions
govern.md ‚Üí for CORTEX changes

Issues:
‚ùå Executor does 2 jobs (execution + correction)
‚ùå Planner does 2 jobs (planning + resumption)
‚ùå Hardcoded file paths everywhere
‚ùå Hardcoded test commands
```

**After v5.0 (1 command + SOLID compliance):**
```
cortex.md ‚Üí for EVERYTHING
  ‚Üì
intent-router.md ‚Üí routes to 8 focused specialists
  ‚Üì
Specialists use shared abstractions (session-loader, test-runner, file-accessor)

Benefits:
‚úÖ Each agent has ONE responsibility
‚úÖ Error correction is dedicated (error-corrector.md)
‚úÖ Session resumption is dedicated (session-resumer.md)
‚úÖ Abstractions decouple from storage/tools
‚úÖ Easy to extend (add new agent = add new route)
```

---

## üö´ When Routing Fails

**If intent is ambiguous:**
```
You: #file:KDS/prompts/user/cortex.md
     do something

Router: ‚ùì Intent unclear. Did you mean:
        1. Continue current work? (execute)
        2. Check progress? (resume)
        3. Validate changes? (validate)
        
        Please clarify.
```

**If no active session and you say "continue":**
```
You: #file:KDS/prompts/user/cortex.md
     continue

Router: ‚ùå No active session found.
        Did you mean to start new work?
        Use: "I want to [describe feature]"
```

---

## üìä SOLID v5.0 Design Benefits

### Answer: YES - It Makes CORTEX Better!

**Design Improvements:**
- ‚úÖ **Single Responsibility** - Each agent has ONE clear job
- ‚úÖ **Interface Segregation** - No mode switches (dedicated agents)
- ‚úÖ **Dependency Inversion** - Abstractions decouple from concrete implementations
- ‚úÖ **Open/Closed** - Easy to extend (add agents) without modifying existing code

**SOLID v5.0 Architecture:**
```
User Interface Layer:
  cortex.md (universal) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
  plan.md (direct)   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
  execute.md (direct) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
  test.md (direct)    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  All route through
  correct.md (direct) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
  resume.md (direct)  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
  ...                        ‚îú‚îÄ‚Üí intent-router.md (ROUTER)
                             ‚îÇ
Internal Agent Layer:        ‚îÇ
  work-planner.md     ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  (PLAN only)
  code-executor.md    ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  (EXECUTE only)
  error-corrector.md  ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  (CORRECT only - NEW)
  session-resumer.md  ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  (RESUME only - NEW)
  test-generator.md   ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  (TEST only)
  health-validator.md ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  (VALIDATE only)
  change-governor.md  ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  (GOVERN only)
  knowledge-retriever.md ‚Üê‚îÄ‚îÄ‚îÄ‚îò  (ASK only)
  
Abstraction Layer (DIP):
  session-loader.md   ‚Üí Abstract session access
  test-runner.md      ‚Üí Abstract test execution
  file-accessor.md    ‚Üí Abstract file I/O
```

**What Changed from v4.5:**
```diff
- code-executor.md (execution + correction modes) ‚ùå SRP violation
+ code-executor.md (execution only) ‚úÖ SRP compliant
+ error-corrector.md (correction only) ‚úÖ ISP compliant

- work-planner.md (planning + resumption modes) ‚ùå SRP violation
+ work-planner.md (planning only) ‚úÖ SRP compliant
+ session-resumer.md (resumption only) ‚úÖ ISP compliant

- Direct file access (#file:KDS/sessions/...) ‚ùå DIP violation
+ Abstract access (session-loader.md) ‚úÖ DIP compliant

- Hardcoded test commands (npx playwright test) ‚ùå DIP violation
+ Abstract runner (test-runner.md) ‚úÖ DIP compliant
```

**Benefits:**
- üéØ **Clarity** - One agent = one job (easier to understand)
- üöÄ **Performance** - No mode-switch logic (faster routing)
- üîß **Testability** - Mock abstractions (easier to test)
- üì¶ **Flexibility** - Swap storage/tools without breaking agents

**Flexibility:**
```
Option 1 (Easy): Use cortex.md universal entry point
Option 2 (Explicit): Call specific prompts directly
Option 3 (Advanced): Call internal agents with abstractions

All work! Universal is for convenience, SOLID is for quality.
```

---

## üéì Quick Reference Card

**For everything:**
```
#file:KDS/prompts/user/cortex.md
[what you want in natural language]
```

**What it detects:**
- "I want to..." ‚Üí plan
- "Continue..." ‚Üí execute  
- "Where was I..." ‚Üí resume
- "Wrong..." ‚Üí correct
- "Test..." ‚Üí test
- "Validate..." ‚Üí validate
- "How do I..." ‚Üí ask
- "I updated KDS..." ‚Üí govern
- "Update documentation..." ‚Üí plan (CORTEX Quadrant update) üìö
- "Refresh documentation..." ‚Üí trigger Documentation Refresh Plugin üÜï
- "Publish docs..." ‚Üí plan (CORTEX Quadrant update)

**Documentation Refresh Plugin (NEW!)** üÜï
When you say "Refresh documentation" or "Update Documentation", CORTEX triggers the Documentation Refresh Plugin which synchronizes the 4 key documentation files:
- `docs/story/Cortex-Trinity/Technical-CORTEX.md` - Technical deep-dive
- `docs/story/Cortex-Trinity/Awakening Of CORTEX.md` - Engaging story
- `docs/story/Cortex-Trinity/Image-Prompts.md` - Visual generation prompts
- `docs/story/Cortex-Trinity/History.md` - Evolution timeline

These 4 documents form the **CORTEX Documentation Quadrant** - always kept synchronized with the latest CORTEX 2.0 design.

**That's all you need to know!** üöÄ

---

## üß† BRAIN System Best Practices

### Automatic Learning is ENABLED by Default

**CORTEX v5.0+ automatically logs events and updates BRAIN - no user action needed!**

**What happens automatically:**
1. ‚úÖ Agents log events after every action (routing, file modifications, corrections)
2. ‚úÖ Events accumulate in `KDS/cortex-brain/events.jsonl`
3. ‚úÖ Rule #16 Step 5 checks event count after each task
4. ‚úÖ When 50 events reached ‚Üí `brain-updater.md` auto-triggered
5. ‚úÖ Knowledge graph updated with new patterns
6. ‚úÖ Next routing decision gets smarter

**You benefit without doing anything!**

### Verify BRAIN is Learning (Optional Health Check)

**Want to confirm automatic learning is working?**

Check these indicators:
```bash
# 1. Recent events logged (should have timestamps from today)
cat KDS/cortex-brain/events.jsonl | tail -5

# 2. Knowledge graph updated recently (check last modified)
ls -la KDS/cortex-brain/knowledge-graph.yaml

# 3. Event count reasonable (not accumulating to 100+)
wc -l KDS/cortex-brain/events.jsonl
```

**Healthy BRAIN signs:**
- ‚úÖ `events.jsonl` has recent timestamps (within last few hours)
- ‚úÖ `knowledge-graph.yaml` updated in last 24 hours
- ‚úÖ Event count stays below 50 (auto-cleanup working)

**‚ö†Ô∏è Warning signs (violations detected):**
- ‚ùå No events logged for 4+ hours (event logging broken)
- ‚ùå `knowledge-graph.yaml` not updated in 24+ hours
- ‚ùå 50+ unprocessed events accumulated (automatic update not triggering)

**If you see warnings:** See `KDS/docs/architecture/KDS-SELF-REVIEW-STRATEGY.md` for fixes

### Manual BRAIN Update (Only if Needed)

**When to manually update:**
- üîß After bulk corrections (fixed multiple files at once)
- üîß After large refactoring (want BRAIN to learn patterns immediately)
- üö® If automatic updates stopped working (>50 events accumulated)
- üìä Before important routing decision (want latest knowledge)

**How to trigger manually:**
```markdown
#file:KDS/prompts/internal/brain-updater.md
```

This processes all events and updates the knowledge graph.

### Standard Practice: Trust Automatic Learning

**Every CORTEX interaction SHOULD automatically:**
1. ‚úÖ Log events (no user action needed)
2. ‚úÖ Query BRAIN for insights (before routing/file decisions)
3. ‚úÖ Update knowledge graph (periodic automatic)

**This is STANDARD CORTEX practice** - all agents follow this pattern automatically.

### For Advanced Users Only

**Manual intervention rarely needed, but available:**

1. **Manually correct routing** if BRAIN suggests wrong intent:
   ```markdown
   #file:KDS/prompts/user/cortex.md
   Wrong intent! I meant [correct interpretation]
   ```
   Error corrector logs the mistake, BRAIN learns for next time.

2. **Check BRAIN health** during self-review:
   ```markdown
   #file:KDS/prompts/user/validate.md
   Check BRAIN system health
   ```

3. **Force immediate update** after major changes:
   ```markdown
   #file:KDS/prompts/internal/brain-updater.md
   ```

**But in normal usage: Just use CORTEX and let BRAIN learn automatically!**

### First-Time Setup (Optional - BRAIN Works Out of the Box)

**CORTEX v5.0+ works immediately with empty BRAIN - learning starts from first use!**

**Optional bootstrapping (faster initial learning):**

**Option 1: Populate from existing sessions (if you have session history):**
```powershell
# PowerShell - Seed BRAIN from past sessions
.\KDS\scripts\populate-cortex-brain.ps1

# Then update knowledge graph
#file:KDS/prompts/internal/brain-updater.md
```

**Option 2: Crawl your codebase (recommended for new installations):**
```powershell
# PowerShell - Quick scan (30 seconds)
.\KDS\scripts\brain-crawler.ps1 -Mode quick

# OR Deep scan (5-10 minutes, comprehensive)
.\KDS\scripts\brain-crawler.ps1 -Mode deep
```

The crawler analyzes your entire application and feeds BRAIN with:
- üèóÔ∏è Architectural patterns (where components/services/tests live)
- üîó File relationships (what depends on what)
- üìù Naming conventions (how files are named)
- üõ†Ô∏è Technology stack (languages, frameworks, tools)
- üß™ Test patterns (frameworks, test data, selectors)

**See:** `#file:KDS/prompts/internal/brain-crawler.md` for details

**But remember: Bootstrapping is OPTIONAL - BRAIN learns automatically from first interaction!**

### Ongoing Usage - No Action Needed!

**Just use CORTEX normally!** BRAIN learns automatically from every interaction:
- üìù Events logged automatically with every agent action
- üß† BRAIN updated automatically when 50 events accumulate
- üí° Decisions get smarter automatically over time
- üï∑Ô∏è Optional: Run incremental crawler scans to refresh architectural knowledge

**Zero manual intervention required for continuous learning.**

**Only manual actions needed:**
1. üö® If automatic learning breaks (check `KDS-SELF-REVIEW-STRATEGY.md`)
2. üîß After bulk corrections (want immediate learning)
3. üìä When starting new project (run crawler to learn codebase)

**99% of the time: BRAIN just works!**

### Moving CORTEX to Another Application

**Need to reset BRAIN for a new project?**
```powershell
# PowerShell - Soft reset (clear data, keep config)
.\KDS\scripts\brain-reset.ps1 -Mode soft

# OR Export generic patterns first, then reset
.\KDS\scripts\brain-reset.ps1 -Mode export-reset -ExportPath ".\templates\my-patterns\"

# Then crawl the new application
.\KDS\scripts\brain-crawler.ps1 -Mode deep
```

BRAIN gets amnesia (forgets old app) but keeps all logic intact!

**See:** `#file:KDS/prompts/internal/brain-reset.md` for details

---

## üîó Technical Implementation (SOLID v5.0)

**This prompt loads:**
```markdown
#file:KDS/prompts/internal/intent-router.md
```

**Which analyzes your request and loads one of:**
```
#file:KDS/prompts/user/plan.md ‚Üí #file:KDS/prompts/internal/work-planner.md
#file:KDS/prompts/user/execute.md ‚Üí #file:KDS/prompts/internal/code-executor.md
#file:KDS/prompts/user/test.md ‚Üí #file:KDS/prompts/internal/test-generator.md
#file:KDS/prompts/user/validate.md ‚Üí #file:KDS/prompts/internal/health-validator.md
#file:KDS/prompts/user/govern.md ‚Üí #file:KDS/prompts/internal/change-governor.md
#file:KDS/prompts/user/ask-cortex.md ‚Üí #file:KDS/prompts/internal/knowledge-retriever.md
#file:KDS/prompts/user/correct.md ‚Üí #file:KDS/prompts/internal/error-corrector.md (NEW)
#file:KDS/prompts/user/resume.md ‚Üí #file:KDS/prompts/internal/session-resumer.md (NEW)
```

**Shared abstractions (DIP compliance):**
```
#shared-module:session-loader.md ‚Üí Abstract session access (default: local files)
#shared-module:test-runner.md ‚Üí Abstract test execution (uses project's tools)
#shared-module:file-accessor.md ‚Üí Abstract file I/O (PowerShell built-ins)

NOTE: All 100% local (in KDS/), zero external dependencies
```

**BRAIN management agents:**
```
#file:KDS/prompts/internal/brain-query.md ‚Üí Query knowledge graph
#file:KDS/prompts/internal/brain-updater.md ‚Üí Process events and update
#file:KDS/prompts/internal/brain-crawler.md ‚Üí Codebase analysis (NEW)
#file:KDS/prompts/internal/brain-reset.md ‚Üí Selective amnesia (NEW)
```

---

## üéØ Active Development Plan (CORTEX v6.0)

**Current Focus:** Real-Time BRAIN Dashboard with Live Reference System + Automatic BRAIN Updates

### ‚úÖ **COMPLETED:** Rule #22 - Automatic BRAIN Updates

**Status:** üéâ **IMPLEMENTED** (Option D - Hybrid Approach)

**What Was Built:**

1. **Manual Recording Script** (Phase 1 - COMPLETE)
   - ‚úÖ `scripts/record-conversation.ps1` - Manual conversation capture
   - ‚úÖ Logs to `conversation-history.jsonl` (Tier 1)
   - ‚úÖ FIFO enforcement (keep 20, delete oldest)
   - ‚úÖ Auto-checks brain-updater threshold (50 events OR 24 hours)
   - ‚úÖ **TESTED:** CopilotChats.txt conversation successfully recorded

2. **Auto BRAIN Updater** (Phase 2 - COMPLETE)
   - ‚úÖ `scripts/auto-brain-updater.ps1` - Automatic trigger after every request
   - ‚úÖ Logs request to `events.jsonl` (Tier 4)
   - ‚úÖ Checks thresholds (50+ events OR 24+ hours)
   - ‚úÖ Auto-invokes `brain-updater.ps1` when threshold met
   - ‚úÖ Keeps `brain-updater.ps1` synchronized with `brain-updater.md`
   - ‚úÖ **TESTED:** 13 events processed, knowledge-graph.yaml updated

3. **Git Hooks** (Phase 2 - COMPLETE)
   - ‚úÖ `hooks/post-commit` - Auto-runs after every git commit
   - ‚úÖ `scripts/setup-git-hooks.ps1` - One-time installation
   - ‚úÖ Silent background execution (doesn't block commits)

4. **Governance Rule** (Tier 0 - COMPLETE)
   - ‚úÖ **Rule #22:** Auto BRAIN Update After Every Request
   - ‚úÖ `governance/rules/auto-brain-update.md` - Full specification
   - ‚úÖ Tier 0 (INSTINCT) - Permanent, cannot be overridden
   - ‚úÖ Updated `governance/rules.md` with Rule #22

5. **Architecture Documentation** (COMPLETE)
   - ‚úÖ `docs/architecture/BRAIN-RECORDING-GAP-ANALYSIS.md` - Root cause analysis
   - ‚úÖ Identified problem: GitHub Copilot Chat doesn't auto-invoke agents
   - ‚úÖ Designed 4 solutions (manual, git hooks, extension, harvester)
   - ‚úÖ Implemented hybrid approach (Phases 1-3 over 3 weeks)

**How to Use:**

```powershell
# Manual recording (after significant conversations)
.\scripts\record-conversation.ps1 `
    -Title "Your conversation title" `
    -FilesModified "file1.md,file2.ps1" `
    -EntitiesDiscussed "feature1,feature2" `
    -Outcome "What was accomplished" `
    -Intent "PLAN"

# Automatic (runs after git commits via hook)
git commit -m "Your commit message"  # auto-triggers brain-updater

# Test auto-updater manually
.\scripts\auto-brain-updater.ps1 `
    -RequestSummary "Test request" `
    -ResponseType "direct"

# Install git hooks (one-time setup)
.\scripts\setup-git-hooks.ps1
```

**Success Metrics:**
- ‚úÖ 6 conversations in `conversation-history.jsonl` (was 5, added CopilotChats.txt)
- ‚úÖ 13 events in `events.jsonl` (threshold: 50 for auto-update)
- ‚úÖ brain-updater auto-triggered (24+ hours since last update)
- ‚úÖ `knowledge-graph.yaml` updated with 13 new events
- ‚úÖ Git hook installed and operational

**Next Steps (Phase 3 - Weeks 2-3):**
- üìã VS Code extension with Chat Participant API
- üìã Real-time conversation interception
- üìã Scheduled harvester (parse Copilot Chat history every 2 hours)
- üìã Full automation (zero user action required)

---

### Phase 7.3: Dashboard BRAIN Reference (IN DESIGN)

**Purpose:** Visual one-page guide to all CORTEX BRAIN functionality  
**Priority:** HIGH  
**Status:** üéØ DESIGN COMPLETE - READY TO IMPLEMENT

**New Features:**

1. **Tier 0 (Instinct) Enhancement** - Holistic review complete
   - ‚úÖ Identified 6 fundamental design gaps
   - üìã 6 new Tier 0 files designed:
     - `governance/tier-0/tool-requirements.yaml` - Essential dependencies
     - `governance/tier-0/setup-protocol.yaml` - 5-step initialization
     - `governance/tier-0/tier-classification-rules.yaml` - Event classification
     - `governance/tier-0/amnesia-recovery.yaml` - Detection & recovery
     - `governance/tier-0/agent-protocols.yaml` - Standard behaviors
     - `governance/tier-0/hemisphere-coordination-rules.yaml` - LEFT/RIGHT communication

2. **Dashboard "BRAIN Reference" Tab** - Visual learning system
   - üìã Tab 1: OVERVIEW (one-page summary of all 5 tiers)
   - üìã Tab 2: RULES & GOVERNANCE (18 rules, searchable)
   - üìã Tab 3: HOW THINGS WORK (visual workflows)
     - "How Amnesia Works" (detection, recovery, prevention)
     - "How Learning Works" (brain-updater.md cycle)
     - "How TDD Cycle Works" (RED‚ÜíGREEN‚ÜíREFACTOR)
     - "How Crawlers Work" (file discovery, dependencies)
     - "How Health Checks Work" (test-brain-integrity.ps1)
     - "How Setup Works" (initialization, validation)
     - "How Hemispheres Coordinate" (LEFT/RIGHT messaging)
   - üìã Tab 4: SETUP & DEPENDENCIES (tool inventory, validation)
   - üìã Tab 5: HEMISPHERES & COORDINATION (real-time activity)

3. **Closed-Loop Self-Healing** - Dashboard ‚Üí BRAIN feedback
   - üìã Health results logged to events.jsonl (Tier 4)
   - üìã brain-healer.md agent (auto-remediation)
   - üìã Remediation scripts (yaml, conversation, KG, session fixes)
   - üìã Dashboard "Fix" buttons (user-triggered repairs)
   - üìã Knowledge graph pattern learning (failure tracking)

**Architecture Docs:**
- `docs/architecture/DASHBOARD-BRAIN-INTEGRATION.md` - Self-healing design
- `docs/architecture/DASHBOARD-BRAIN-REFERENCE-FEATURE.md` - Visual reference design
- `docs/DASHBOARD-BRAIN-INTEGRATION-SUMMARY.md` - Self-healing summary
- `docs/DASHBOARD-BRAIN-REFERENCE-SUMMARY.md` - Visual reference summary

**Implementation Plan:** 4 weeks (see Phase 7 in KDS-V6-IMPLEMENTATION-PLAN-RISK-BASED.md)

**User Value:**
- ‚úÖ One-page visual reference for entire BRAIN (no more trying to remember)
- ‚úÖ Understand how ANY feature works (amnesia, learning, TDD, etc.)
- ‚úÖ See all 18 rules in searchable format
- ‚úÖ Know setup requirements and tool dependencies
- ‚úÖ Monitor hemisphere activity in real-time
- ‚úÖ Auto-fix common issues (or trigger manual fixes)
- ‚úÖ Live data updated every 5-30 seconds

**Start Implementation:**
```
#file:KDS/prompts/user/plan.md "Implement Phase 7.3: Dashboard BRAIN Reference System"
```

---

### üìã **PLANNED:** Mind Palace - Advanced Memory Architecture

**Purpose:** Enhanced spatial memory system for complex knowledge organization  
**Priority:** FUTURE  
**Status:** üìã PLACEHOLDER - Design phase pending

**Concept:**
The Mind Palace extends KDS's BRAIN system with spatial memory techniques for organizing complex technical knowledge. This system will enable Copilot to "mentally navigate" through architectural concepts, code relationships, and project knowledge using memory palace techniques.

**Planned Features:**
- üìã Spatial knowledge organization (rooms, floors, locations)
- üìã Visual memory associations for complex patterns
- üìã Hierarchical knowledge structures
- üìã Enhanced context retrieval using spatial relationships
- üìã Integration with existing Tier 2 knowledge graph

**Metric Tracking (Core Requirement):**
The Mind Palace will be designed with comprehensive metric tracking from the start:

```yaml
mind_palace_metrics:
  kds_performance:
    - knowledge_retrieval_speed: "Time to locate relevant patterns"
    - spatial_navigation_accuracy: "Correct room/location hit rate"
    - pattern_association_effectiveness: "Successful pattern matches"
    - memory_consolidation_rate: "Tier 1 ‚Üí Tier 2 conversion efficiency"
    - context_reconstruction_time: "Resume session speed"
    
  coding_efficiency:
    - time_to_first_code: "Request ‚Üí First implementation"
    - architectural_alignment_rate: "% of solutions matching existing patterns"
    - rework_reduction: "Before/after Mind Palace implementation"
    - context_switching_overhead: "Time lost when changing tasks"
    - learning_curve_acceleration: "New team member onboarding speed"
    
  quality_metrics:
    - test_coverage_trends: "Before/after Mind Palace"
    - bug_escape_rate: "Issues reaching production"
    - architectural_consistency_score: "Alignment with design patterns"
    - knowledge_retention_rate: "Pattern recall accuracy over time"
    
  roi_measurements:
    - development_velocity_change: "Sprint velocity trends"
    - onboarding_time_reduction: "New developer productivity"
    - context_recovery_savings: "Hours saved on session resumes"
    - decision_quality_improvement: "Architectural decision success rate"
```

**Integration Points:**
- üìã Tier 2 (Knowledge Graph) - Spatial overlay for existing patterns
- üìã Tier 3 (Development Context) - Velocity impact tracking
- üìã Dashboard - Real-time visualization of memory palace structure
- üìã Metrics Reporter - Dedicated Mind Palace analytics

**Design Phase Tasks:**
1. Research spatial memory techniques for code organization
2. Design memory palace structure (rooms, floors, associations)
3. Define integration with existing BRAIN tiers
4. Create metric collection framework
5. Build prototype with test dataset
6. Validate effectiveness with real-world usage

**Documentation (To Be Created):**
- `docs/architecture/MIND-PALACE-DESIGN.md` - Full specification
- `docs/architecture/MIND-PALACE-METRICS.md` - Measurement framework
- `cortex-brain/mind-palace/` - Storage structure (when implemented)

**Notes:**
- Design will prioritize measurability from day one
- All claims must be backed by quantitative metrics
- Focus on demonstrable coding efficiency improvements
- Integration must be seamless with existing workflows

**When Ready to Design:**
```
#file:KDS/prompts/user/plan.md "Design Mind Palace Memory Architecture with Metrics"
```

---

## üìã CORTEX Response Templates - Practical Action Design

**Philosophy:** CORTEX responses should leverage planning and execution capabilities to provide **actionable, cumulative options** instead of one-by-one choices.

### ‚úÖ GOOD: Actionable & Cumulative

**Example 1: Documentation Refresh**
```markdown
## üöÄ Ready to Execute

I've identified 4 documentation gaps and prepared an execution plan.

**Execute All (Recommended):**
I'll complete all phases sequentially:
1. Update "The Awakening" story (15 min)
2. Create 26 missing technical docs (45 min)  
3. Generate 8 Mermaid diagrams (20 min)
4. Deploy to GitHub Pages (5 min)

Estimated: 85 minutes total

Say **"Execute all"** to start, or **"Just phases 1-2"** to run partially.

**Manual Review First:**
Say **"Show me the plan"** to review details before execution.
```

**Example 2: Test Failures**
```markdown
## üîß 3 Test Failures Detected

**Fix All (Recommended):**
I'll fix all 3 issues in one pass:
- Fix selector in `button.spec.ts` (async timing)
- Update API mock in `service.spec.ts` (schema change)
- Add missing import in `utils.spec.ts` (module not found)

Say **"Fix all"** and I'll execute all repairs with verification.

**Investigate First:**
Say **"Show root causes"** to analyze before fixing.
```

**Example 3: Feature Implementation**
```markdown
## ‚úÖ Plan Created: Multi-Language Invoice Export

**Execute Full Feature:**
I'll implement all 4 phases using TDD:
1. Phase 1: Service layer (tests ‚Üí code) - 30 min
2. Phase 2: API endpoints (tests ‚Üí code) - 25 min  
3. Phase 3: UI component (tests ‚Üí code) - 40 min
4. Phase 4: Integration tests & validation - 20 min

Total: ~115 minutes

Say **"Execute full feature"** to start end-to-end implementation.

**Phase-by-Phase:**
Say **"Start Phase 1"** to proceed incrementally with checkpoints.
```

### ‚ùå BAD: One-by-One Options (Old Style)

```markdown
## Next Steps

**Option 1:** Update story  
Review the visual presentation, navigation behavior, and story flow.

**Option 2:** Create technical docs  
Continue with Phase 2 to add documentation.

**Option 3:** Generate diagrams  
Proceed with Phase 3 to generate the 26 missing diagrams.

**Option 4:** Deploy  
When satisfied with localhost review, deploy to GitHub Pages.
```

**Why this is bad:**
- ‚ùå Forces 4 separate invocations
- ‚ùå Doesn't leverage CORTEX planning
- ‚ùå No "do everything" option
- ‚ùå Wastes user time

### üéØ Response Template Rules

**Rule 1: Always offer cumulative execution**
```markdown
‚úÖ "Execute all phases" (cumulative)
‚úÖ "Fix all issues" (batch)
‚úÖ "Implement full feature" (end-to-end)

‚ùå "Option 1, 2, 3, 4" (one-by-one)
```

**Rule 2: Provide smart defaults**
```markdown
‚úÖ "Execute all (Recommended)" - Make the best path obvious
‚úÖ "Estimated: 85 minutes" - Set expectations
‚úÖ "Say 'Execute all' to start" - Clear command

‚ùå "What do you want to do?" - Forces decision making
```

**Rule 3: Include escape hatches**
```markdown
‚úÖ "Show me the plan" - Review before execution
‚úÖ "Just phases 1-2" - Partial execution
‚úÖ "Pause after Phase 1" - Incremental with checkpoints

‚ùå Only all-or-nothing options
```

**Rule 4: Leverage CORTEX planning**
```markdown
‚úÖ Break work into phases internally
‚úÖ Show time estimates per phase
‚úÖ Offer full plan execution by default
‚úÖ Use todo list for multi-phase work

‚ùå Present raw phases as user choices
```

**Rule 5: Make commands copyable**
```markdown
‚úÖ Say **"Execute all"** to start
‚úÖ Say **"Fix all tests"** to proceed
‚úÖ Command in **bold** for easy identification

‚ùå "You can proceed" (vague)
‚ùå "Let me know when ready" (passive)
```

### üìä Response Format Template

**Standard Multi-Phase Response:**
```markdown
## üéØ [Summary of Work]

[Brief description of what was discovered/analyzed]

**Execute All (Recommended):**
I'll complete [X phases/tasks] sequentially:
1. [Phase 1 name] ([time estimate])
2. [Phase 2 name] ([time estimate])
3. [Phase 3 name] ([time estimate])

Total: [X minutes/hours]

Say **"Execute all"** to start, or **"Just phase X"** to run partially.

**Alternative Approaches:**
- **"Show me the plan"** - Review detailed breakdown first
- **"Pause after Phase X"** - Stop for checkpoint review
- **"Skip Phase X"** - Execute with modifications

**Already complete?** Say **"Continue"** to resume from last checkpoint.
```

**Standard Issue Fix Response:**
```markdown
## üîß [X Issues/Errors] Detected

[Brief summary of problems]

**Fix All (Recommended):**
I'll address all [X] issues in one pass:
- [Issue 1]: [One-line fix description]
- [Issue 2]: [One-line fix description]  
- [Issue 3]: [One-line fix description]

Say **"Fix all"** and I'll execute repairs with verification.

**Investigate Further:**
- **"Show root causes"** - Deep analysis before fixing
- **"Fix [specific issue]"** - Address individually
- **"Show impact"** - What breaks if unfixed

**Batch Strategy:** All fixes use atomic commits with rollback safety.
```

**Standard Completion Response:**
```markdown
## ‚úÖ [Feature/Task] Complete

**What was delivered:**
- ‚úÖ [Deliverable 1] - [Brief result]
- ‚úÖ [Deliverable 2] - [Brief result]
- ‚úÖ [Deliverable 3] - [Brief result]

**Quality Checks:**
- ‚úÖ [X] tests passing
- ‚úÖ Zero errors, zero warnings
- ‚úÖ [Performance/coverage metric]

**Next Actions (Choose One):**
- **"Deploy to [environment]"** - Push changes live
- **"Add [related feature]"** - Extend functionality
- **"Show metrics"** - View detailed statistics
- **"Mark complete"** - Archive and move on

**Documentation updated:** [Link or file reference]
```

### üß™ Examples by Scenario

**Scenario: Documentation needs refresh**
```markdown
## üìö Documentation Refresh Plan Ready

Git analysis identified 5 new features since last deployment (Brain Protector, Oracle Crawler, Knowledge Boundaries, Amnesia, Pattern Cleanup).

**Execute Full Refresh (Recommended):**
I'll complete all 7 phases:
1. Update "Awakening" story with new features (20 min)
2. Create 5 technical docs (Brain Protector, Oracle, etc.) (35 min)
3. Generate 6 Mermaid diagrams (15 min)
4. Create 4 Gemini image prompts (10 min)
5. Build docs with `mkdocs build --clean` (2 min)
6. Launch localhost:8000 for review (auto-open browser)
7. Generate refresh report (5 min)

Total: ~87 minutes | Auto-launches: localhost:8000 for review

Say **"Execute full refresh"** to start all phases, or **"Just story update"** for Phase 1 only.

**Before starting?** Say **"Show detailed plan"** to review each phase's changes.
```

**Scenario: Multiple test failures**
```markdown
## üß™ 7 Test Failures Detected

Test suite shows 7 failures across 3 components (HostControlPanel, InvoiceService, UserRegistration).

**Fix All (Recommended):**
I'll repair all 7 failures in dependency order:
1. **HostControlPanel** (3 failures): Update selectors for refactored IDs
2. **InvoiceService** (2 failures): Fix API contract after schema change
3. **UserRegistration** (2 failures): Add missing validation mocks

Estimated: 25 minutes | Strategy: Fix ‚Üí Run ‚Üí Verify per component

Say **"Fix all tests"** to execute batch repair.

**Need Analysis First?**
- **"Show failure details"** - Stack traces & root causes
- **"Group by component"** - Organized breakdown
- **"Check coverage"** - View test coverage impact
```

**Scenario: Complex feature implementation**
```markdown
## üöÄ Feature Plan Ready: Real-Time Dashboard BRAIN Reference

Plan created with 4 phases (28 tasks, 6.5 hours estimated).

**Execute Complete Feature (Recommended):**
I'll implement full BRAIN Reference system using TDD:

**Phase 1: UI Foundation** (90 min)
- Create 5 dashboard tabs (Overview, Rules, How Things Work, Setup, Hemispheres)
- Implement tab navigation & layout
- Tests: Component rendering, tab switching

**Phase 2: Data Integration** (120 min)  
- Connect to Tier 0-4 data sources
- Build real-time update system (5-30s refresh)
- Tests: Data loading, refresh cycles, error handling

**Phase 3: Visual Workflows** (90 min)
- Create 7 "How X Works" diagrams (Amnesia, Learning, TDD, etc.)
- Implement interactive workflow visualization
- Tests: Diagram rendering, user interactions

**Phase 4: Health & Fixes** (90 min)
- Add health monitoring dashboard
- Implement one-click fix buttons
- Tests: Health checks, remediation workflows

Total: 6.5 hours | 60 tests | TDD throughout

Say **"Execute complete feature"** for end-to-end implementation.

**Incremental Delivery:**
- **"Execute Phase 1"** - UI foundation only, review before Phase 2
- **"Show task breakdown"** - Detailed 28-task checklist
- **"Estimate per phase"** - Time breakdown with dependencies
```

### üé® Visual Examples

**Before (Bad):**
```
Next Steps:
Option 1: Fix test A
Option 2: Fix test B  
Option 3: Fix test C
Option 4: Run all tests
```

**After (Good):**
```
## üîß 3 Test Failures - Batch Fix Ready

Fix All (Recommended):
I'll repair tests A, B, C in one pass (8 min total)

Say "Fix all tests" to execute ‚Üí Full verification included
```

---

**Before (Bad):**
```
What would you like me to do next?
1. Update docs
2. Create diagrams
3. Build site
4. Deploy
```

**After (Good):**
```
## üìö Documentation Ready for Deployment

Execute Pipeline (Recommended):
Update docs ‚Üí Diagrams ‚Üí Build ‚Üí Deploy (25 min)

Say "Deploy pipeline" to execute full workflow
```

---

### üí° Key Takeaway

**CORTEX should work like a senior developer:**
- ‚úÖ "I'll fix all 7 test failures - give me 30 minutes" (proactive)
- ‚ùå "Which test failure do you want me to look at first?" (passive)

**User's job:** Approve strategy  
**CORTEX's job:** Execute efficiently

---

## ‚ú® Summary
````

**You asked:**
> "Will the CORTEX system benefit from SOLID principles?"

**Answer: ABSOLUTELY! v5.0 implements:**
- ‚úÖ **Single Responsibility** - One agent = one job
- ‚úÖ **Interface Segregation** - Dedicated agents (no mode switches)
- ‚úÖ **Dependency Inversion** - Abstractions decouple from concrete implementations
- ‚úÖ **Open/Closed** - Easy to extend without modifying existing code

**What changed:**
- ‚ûï Added `error-corrector.md` (dedicated correction agent)
- ‚ûï Added `session-resumer.md` (dedicated resumption agent)
- ‚ûï Added abstraction layer (`session-loader`, `test-runner`, `file-accessor`)
- ‚úÖ Removed mode switches from `code-executor` and `work-planner`
- ‚úÖ Decoupled agents from concrete file paths and tool commands

**Local-First Compliance:**
- ‚úÖ **100% in KDS/** - All CORTEX logic, data, scripts housed locally
- ‚úÖ **Minimal external dependencies** - Only CORTEX enhancement libraries (declared upfront)
- ‚úÖ **Offline-capable** - Works without internet (core functionality)
- ‚úÖ **Transparent setup** - User informed of all required libraries during setup
- ‚ö†Ô∏è **Optional extensions** - Cloud/database storage available but not required

**Dependency Categories:**
1. **CORTEX Core** - Zero dependencies (PowerShell/bash built-ins only)
2. **CORTEX Enhancements** - Open source libraries for improved capabilities (ALLOWED, declared at setup)
3. **Application Code** - User's project dependencies (Copilot recommends, user approves)
4. **Optional Features** - Cloud/DB/external services (opt-in only)

**What you need to remember:**
```
#file:KDS/prompts/user/cortex.md
[describe what you want]
```

**That's it. CORTEX handles the rest with SOLID principles and local-first design.** üéØ
