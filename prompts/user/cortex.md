# CORTEX Universal Entry Point

**Purpose:** Single command for ALL CORTEX interactions. You don't need to remember multiple commands - just use this one and CORTEX figures out what you need.

**Version:** 5.0 (SOLID Refactor)  
**Status:** ğŸ¯ ACTIVE DESIGN  
**Architecture:** SOLID-compliant modular system

**Author:** Asif Hussain  
**Copyright:** Â© 2024-2025 Asif Hussain. All rights reserved.  
**License:** Proprietary - See LICENSE file for terms  
**Repository:** https://github.com/asifhussain60/CORTEX

---

## ğŸ–¥ï¸ Cross-Platform Compatibility

**CORTEX 2.0 works seamlessly on Windows, macOS, and Linux.**

### âœ… What's Cross-Platform

- **All Python code** - Uses `pathlib.Path` for OS-agnostic paths
- **SQLite databases** - Binary-compatible across all platforms
- **Configuration system** - Auto-detects platform and machine
- **VS Code Extension** (Phase 3) - Native cross-platform support

### ğŸ”§ Platform-Specific Components

**Auto-Resume Prompt:**
- **Windows:** Use `scripts/auto-resume-prompt.ps1` (PowerShell)
- **macOS/Linux:** Use `scripts/auto-resume-prompt.sh` (bash/zsh)

**Installation:**

```powershell
# Windows PowerShell Profile
Add-Content $PROFILE @"
# CORTEX Auto-Resume
if (Test-Path `"`$env:CORTEX_ROOT/scripts/auto-resume-prompt.ps1`") {
    . `"`$env:CORTEX_ROOT/scripts/auto-resume-prompt.ps1`"
}
"@
```

```bash
# macOS/Linux Shell Profile (~/.bashrc or ~/.zshrc)
cat >> ~/.zshrc << 'EOF'
# CORTEX Auto-Resume
if [ -f "$CORTEX_ROOT/scripts/auto-resume-prompt.sh" ]; then
    source "$CORTEX_ROOT/scripts/auto-resume-prompt.sh"
fi
EOF
```

### ğŸ”„ Switching Between Platforms

**No initialization command needed!** Just follow these steps:

**1. Set Environment Variables:**

```bash
# macOS/Linux (~/.zshrc or ~/.bashrc)
export CORTEX_ROOT="$HOME/PROJECTS/CORTEX"
export CORTEX_BRAIN_PATH="$CORTEX_ROOT/cortex-brain"
```

```powershell
# Windows (PowerShell as Administrator)
[Environment]::SetEnvironmentVariable("CORTEX_ROOT", "D:\PROJECTS\CORTEX", "User")
[Environment]::SetEnvironmentVariable("CORTEX_BRAIN_PATH", "D:\PROJECTS\CORTEX\cortex-brain", "User")
```

**2. Update Config (Optional - if using machine-specific paths):**

```json
{
  "machines": {
    "YOUR-WINDOWS-PC": {
      "rootPath": "D:\\PROJECTS\\CORTEX",
      "brainPath": "D:\\PROJECTS\\CORTEX\\cortex-brain"
    },
    "YOUR-MACBOOK.local": {
      "rootPath": "/Users/yourname/PROJECTS/CORTEX",
      "brainPath": "/Users/yourname/PROJECTS/CORTEX/cortex-brain"
    }
  }
}
```

**3. Copy Brain Data:**

```bash
# The cortex-brain folder is 100% portable
# Just copy it to the same relative location on the new platform
cp -R cortex-brain ~/PROJECTS/CORTEX/cortex-brain
```

**That's it!** CORTEX auto-detects your platform and uses the right paths.

### ğŸ“– Detailed Migration Guide

See: [`docs/architecture/cross-platform-compatibility.md`](../../docs/architecture/cross-platform-compatibility.md)

---

## âš ï¸ IMPORTANT: Conversation Tracking Bridge

**GitHub Copilot Chat does NOT automatically track conversations to the CORTEX brain.**

To enable conversation memory (so CORTEX remembers across chats):

## ğŸ“‹ CRITICAL: CORTEX 2.0 Implementation Status Tracking

**LIVE DOCUMENT REQUIREMENT - UPDATE AFTER EVERY WORK SESSION:**

**File:** `cortex-brain/cortex-2.0-design/IMPLEMENTATION-STATUS-CHECKLIST.md`

**Update Triggers (ALWAYS update after):**
1. âœ… **Completing any task** - Mark tasks complete immediately
2. âœ… **Running tests** - Update test pass rates and coverage
3. âœ… **Performance benchmarks** - Update metrics dashboard
4. âœ… **Discovering new work** - Add to appropriate phase backlog
5. âœ… **Encountering blockers** - Document in blockers section
6. âœ… **Phase transitions** - Update phase status and progress bars

**Why This Matters:**
- Prevents duplicated work across sessions
- Tracks actual progress vs planned timeline
- Identifies blockers early before they cascade
- Provides accurate status for all stakeholders
- Ensures continuous alignment with implementation plan

**CORTEX Behavior:** Before completing ANY implementation work, always check and update the Implementation Status Checklist. This is a core requirement for CORTEX 2.0 development.

---

### Option 1: PowerShell Capture (Quick - After Each Session)
```powershell
# Capture your conversation manually
.\scripts\cortex-capture.ps1 -AutoDetect

# Or provide message directly
.\scripts\cortex-capture.ps1 -Message "Created mkdocs documentation" -Intent EXECUTE
```

### Option 2: Python CLI (Direct Integration)
```bash
# Process through Python (tracks automatically)
python scripts/cortex_cli.py "Add authentication to login page"

# Validate tracking is working
python scripts/cortex_cli.py --validate

# Check current session
python scripts/cortex_cli.py --session-info
```

### Option 3: Manual Recording (Fallback)
```powershell
.\scripts\record-conversation.ps1 `
    -Title "Session Title" `
    -Intent "EXECUTE" `
    -Outcome "What was accomplished" `
    -FilesModified "file1.py,file2.md" `
    -Entities "topic1,topic2"
```

**Why This Is Needed:**
- GitHub Copilot Chat reads `#file:prompts/user/cortex.md` as **documentation**
- It does NOT execute the Python `CortexEntry.process()` method
- Without tracking: âŒ No conversation memory, âŒ No cross-chat context, âŒ Amnesia
- With tracking: âœ… Remembers past conversations, âœ… "Make it purple" works, âœ… Full brain learning

**Rule #24 (Tier 0 - Core Instinct):** Conversation tracking MUST work. Protected by brain-protector tests in `CORTEX/tests/tier0/test_brain_protector_conversation_tracking.py`.

---

## ğŸ“Š Implementation Status

**Legend:**
- âœ… **Fully Implemented** - Working and tested
- ğŸŸ¡ **Partially Implemented** - Core working, missing features
- ğŸ”„ **In Progress** - Currently being developed
- ğŸ“‹ **Designed Only** - Documentation exists, no code
- âš¡ **Priority** - Critical for "continue" command

| Feature | Status | Notes |
|---------|--------|-------|
| **V3 GROUP 1: Foundation** | âœ… | Project reorganized, benchmarks validated |
| **V3 GROUP 2: Infrastructure** | âœ… | Tier 0, CI/CD, MkDocs operational |
| **V3 GROUP 3: Data Storage** | âœ… | All tiers complete - 60/60 tests passing â­ |
| **Tier 1: Working Memory** | âœ… | SQLite conversations, <50ms queries (Nov 6) |
| **Tier 1: FIFO Queue** | âœ… | 20-conversation limit, active protection (Nov 8) |
| **Tier 1: Entity Extraction** | âœ… | Files, classes, methods (Nov 8) |
| **Tier 2: Knowledge Graph** | ğŸŸ¡ | Modularization in progress: DB + schema extracted; patterns/search modules pending |
| **Tier 3: Context Intelligence** | âœ… | Git metrics, hotspots, insights (Nov 6) |
| **Migration Tools** | âœ… | All 3 tier migrations validated (Nov 6) |
| **Conversation Tracking** | ğŸŸ¡ | Infrastructure works, integration gap identified |
| **V3 GROUP 4: Intelligence** | ğŸ”„ | Ready to begin - agents, entry point, dashboard |
| **Agent Architecture (SOLID)** | ğŸ“‹ | 10 specialist agents designed |
| **Core Routing** | ğŸ“‹ | Intent router designed |
| **Dashboard** | ğŸ“‹ | Live data visualization designed |
| **WorkStateManager** | âš¡âœ… | CRITICAL - Track in-progress work (Nov 8) â­ |
| **SessionToken** | âš¡âœ… | CRITICAL - Persistent conversation ID (Nov 8) â­ |
| **Auto-Prompt Enhancement** | âš¡âœ… | CRITICAL - PowerShell profile integration (Nov 8) â­ |
| **Ambient Capture Daemon** | ğŸ“‹ | Background context capture (Phase 2) ğŸ†• |
| **VS Code Extension** | ğŸ“‹ | **DEFINITIVE conversation fix** - Phase 3 (Week 11-16) ğŸ†• |
| **Automatic Capture** | ğŸ“‹ | Zero manual intervention, monitors all chats ğŸ†• |
| **Proactive Resume** | ğŸ“‹ | Auto-resume prompts on startup ğŸ†• |
| **Code Review Plugin** | ğŸ“‹ | Automated PR reviews - Phase 8 (Week 25-26) ğŸ†• |
| **Web Testing Enhancements** | ğŸ“‹ | Lighthouse + axe-core - Phase 8 (Week 27) ğŸ†• |
| **Reverse Engineering Plugin** | ğŸ“‹ | Legacy code analysis - Phase 8 (Week 28) ğŸ†• |
| **UI from Spec Plugin** | ğŸ“‹ | OpenAPI â†’ UI - Phase 9 (Week 29-30) ğŸ†• |
| **Mobile Testing Plugin** | ğŸ“‹ | Appium cross-platform - Phase 9 (Week 31-32) ğŸ†• |
| **V3 GROUP 5: Migration** | ğŸ“‹ | KDS â†’ CORTEX data migration |
| **V3 GROUP 6: Finalization** | ğŸ“‹ | System check, documentation, release |

**CORTEX 2.0 Progress Summary:**
- **Completed:** Groups 1-3 (Data Storage Layer) âœ… + Phase 0 Quick Wins âœ…
- **Phase 0 Complete:** WorkStateManager, SessionToken, Auto-Prompt (77/77 tests passing)
- **Next Up:** Phase 1.2 - Tier 1 Working Memory Refactoring (Week 3-4) ğŸ“‹
- **Timeline:** 28-32 weeks total (CORTEX 2.0 Core + Capability Enhancements)
- **Critical Path:** Phase 0 âœ… â†’ Phase 1-7 (Core) â†’ Phase 8-9 (Capabilities)

**"Continue" Command Status:**
- **Current Success Rate:** ~60% (Phase 0 complete!) âœ…
- **After Phase 2:** ~85% (ambient background capture) ğŸ¯
- **After Phase 3:** ~98% (extension with automatic capture) ğŸš€

**Capability Enhancement Status (NEW - Phase 8-9):**
- **Phase 8 (Week 25-28):** Code review + Web testing + Reverse engineering
- **Phase 9 (Week 29-32):** Mobile testing + UI from spec
- **Core Ready Now:** Code writing, backend testing, code rewrite, documentation âœ…
- **Total Enhancement Footprint:** +10.9% (2,800 + 4,000 lines = 6,800 lines)
- **ROI:** Very High - Extends CORTEX into full-spectrum development assistant

**Capability Matrix:**
| Feature | Status | Phase | Footprint |
|---------|--------|-------|-----------|
| Code Writing | âœ… Ready | Core | 0% |
| Backend Testing | âœ… Ready | Core | 0% |
| Code Documentation | âœ… Ready | Core | 0% |
| Code Rewrite | âœ… Ready | Core | 0% |
| Code Review | ğŸ“‹ Phase 8.1 | Week 25-26 | +1.3% |
| Web Testing | ğŸ“‹ Phase 8.2 | Week 27 | +0.8% |
| Reverse Engineering | ğŸ“‹ Phase 8.3 | Week 28 | +2.4% |
| UI from Spec | ğŸ“‹ Phase 9.1 | Week 29-30 | +3.2% |
| Mobile Testing | ğŸ“‹ Phase 9.2 | Week 31-32 | +3.2% |
| **Figma Integration** | âŒ Deferred | Use Anima | +6.4% avoided |
| **A/B Testing** | âŒ Deferred | Use Optimizely | +4.0% avoided |

**Performance:** 52% faster than estimated, 100% test coverage â­  
**Last Updated:** 2025-11-08 (Phase 0 COMPLETE + Holistic Capability Roadmap ADDED)

---

## ğŸ” Notes and critical corrections (2025-11-08)

- Knowledge Graph scope naming is standardized in code to `cortex` and `application` (the earlier docs using `generic` refer to the same concept as `cortex`). Data migrations and validators should map `generic` â†’ `cortex`.
- Tier 2 modularization is underway. Database connection and schema have been extracted and tested; pattern store/search/decay modules are pending. Prefer importing via `src.tier2.knowledge_graph.database` (package) to avoid ambiguity with the transitional `database.py` helper.
- VS Code Chat APIs evolve. The chat participant contribution shown targets recent VS Code builds; external chat monitoring may require proposed APIs or alternative hooks. Keep an ambient capture fallback (Phase 2) enabled until the extension path is validated on your VS Code version.

### Tier 2 Modularization Progress & Remaining Tasks

| Component | Status | Action |
|-----------|--------|--------|
| database/connection.py & schema.py | âœ… Complete | Provide low-level connection + schema init (tested) |
| patterns/pattern_store.py | âœ… Extracted | CRUD, confidence, access tracking, scope normalization genericâ†’cortex |
| patterns/pattern_search.py | ğŸ“‹ Pending | Move FTS5 queries, ranking, namespace/scope filters, relevance scoring |
| patterns/pattern_decay.py | ğŸ“‹ Pending | Implement scheduled decay + exclude pinned patterns; write decay log entries |
| relationships/relationship_manager.py | ğŸ“‹ Pending | CRUD and strength updates; enforce UNIQUE triple and cascade handling |
| tags/tag_manager.py | ğŸ“‹ Pending | Tag CRUD + list-by-tag; leverage existing index; add tests |
| coordinator (KnowledgeGraph v2 facade) | ğŸ“‹ Pending | Compose store/search/relationships/tags; backward-compatible API for router |
| legacy knowledge_graph_legacy.py | ğŸŸ¡ In use | Deprecate after facade parity + migration tests |
| scope terminology harmonization | âœ… Implemented | Map 'generic'â†’'cortex' on insert; default future patterns to 'cortex' |
| abstraction duplication (ConnectionManager vs DatabaseConnection) | âš ï¸ Review | Consolidate to single API; recommend keeping ConnectionManager and removing unused DatabaseConnection helper |
| add module-specific unit tests | ğŸ”„ Ongoing | Maintain <250 lines/module; one focused test file per module |

Priority ordering (next sprint): pattern_search â†’ relationship_manager â†’ tag_manager â†’ pattern_decay â†’ coordinator â†’ legacy deprecation â†’ abstraction consolidation.

Scope Standardization Policy:
- All new patterns persist with `scope='cortex'` or `scope='application'`.
- Any legacy rows found with `scope='generic'` are migrated in-place to `cortex` during maintenance migrations.
- Pattern store enforces normalization and should be treated as the canonical write path.

Database Abstraction Consolidation:
- Two abstractions currently exist: `ConnectionManager` (actively used in tests & store) and `DatabaseConnection` (partial overlap).
- Plan: Remove `DatabaseConnection` after coordinator extraction to avoid cognitive overhead; if a higher-level facade is needed, rename instead (e.g., `KGDatabase` wrapping ConnectionManager).

## ğŸ“– Legacy Status (Pre-V3 Migration)

The following features were operational in the legacy KDS system and are being migrated to CORTEX V3:

| Legacy Feature | V3 Migration Status | Notes |
|---------------|---------------------|-------|
| Event Logging | âœ… Migrated | Part of Tier 1 (request_logger.py) |
| Protection System | ğŸ“‹ To migrate | Confidence thresholds, anomaly detection |
| Commit Handler | ğŸ“‹ To migrate | Smart validation with baseline |
| Conversation Tracking | âœ… Migrated | Tier 1 conversation_manager.py |
| Auto BRAIN Updates | ğŸ“‹ To migrate | Rule #22 automation |
| Git Hooks | ğŸ“‹ To migrate | Post-commit triggers |
| Manual Recording | ğŸ“‹ To migrate | record-conversation scripts |

**Legacy â†’ V3 Status:** Core data storage migrated âœ… | Intelligence layer migration in GROUP 4 ğŸ“‹

---

## ğŸ“– About This Documentation

This document follows the **CORTEX Quadrant** pattern - a four-perspective approach to comprehensive documentation:

1. **ğŸ“š Story** - Human-centered narratives (The Intern with Amnesia, Day in the Life)
2. **ğŸ”§ Technical** - Detailed specifications (commands, files, parameters, code)
3. **ğŸ¨ Image Prompt** - Visual representations (diagrams, flowcharts, progress indicators)
4. **ğŸ—ï¸ High-Level Technical** - Architectural overviews (system design, workflows, integration)

**Why CORTEX Quadrant?** Different perspectives ensure complete understanding for all learning styles and use cases.

**ğŸ“– Complete CORTEX Story:** For the full narrative of CORTEX's creation, including visual diagrams and technical deep-dives, see [The Awakening of CORTEX](../../docs/story/Cortex-Trinity/Awakening%20Of%20CORTEX.md) - an engaging journey through the design, implementation, and activation of the CORTEX brain system.

---

## ğŸš€ CORTEX 2.0: The Evolution

**Author:** Asif Hussain  
**Copyright:** Â© 2024-2025 Asif Hussain. All rights reserved.  
**Status:** Design Complete âœ… | Implementation Phase: Ready to Begin  
**Version:** 2.0.0-alpha  
**Timeline:** 12-16 weeks implementation

### What's New in CORTEX 2.0

CORTEX 2.0 represents a strategic evolution following a **Hybrid Approach** (70% keep, 20% refactor, 10% enhance):

#### ğŸ”Œ Plugin System (NEW)
**Problem Solved:** Core bloat from non-essential features  
**Solution:** Extensible plugin architecture with hooks

```python
# Example: Custom cleanup plugin
from plugins.base_plugin import BasePlugin

class Plugin(BasePlugin):
    def execute(self, context):
        # Your custom logic here
        return {"success": True}
```

**Benefits:**
- âœ… Reduce core complexity
- âœ… Easy feature addition without modifying core
- âœ… User-customizable behavior
- âœ… Enable/disable features via configuration

**Core Plugins:**
- Cleanup Plugin (temp files, old logs, organization)
- Documentation Plugin (MkDocs auto-refresh)
- Self-Review Plugin (comprehensive health checks)
- DB Maintenance Plugin (optimization, archival)
- **Platform Switch Plugin (Windows â†” macOS migration)** ğŸ†•
- **Extension Scaffold Plugin (VS Code extension generator)** ğŸ†•

---

#### ğŸ”§ Platform Switch Plugin (NEW - CROSS-PLATFORM MIGRATION)
**Problem Solved:** Manual platform migration is tedious and error-prone  
**Solution:** One-command platform switching for all references

```python
# Example: Switch from Windows to macOS
from plugins.platform_switch_plugin import PlatformSwitchPlugin

plugin = PlatformSwitchPlugin()
result = plugin.execute({
    "target_platform": "mac",  # or "windows"
    "hostname": "Asifs-MacBook-Air.local",
    "username": "asifhussain",
    "project_path_mac": "/Users/asifhussain/PROJECTS/CORTEX",
    "project_path_windows": "D:\\PROJECTS\\CORTEX"
})
```

**What It Updates:**

1. **cortex.config.json** - Machine-specific paths
   ```json
   {
     "machines": {
       "Asifs-MacBook-Air.local": {
         "rootPath": "/Users/asifhussain/PROJECTS/CORTEX",
         "brainPath": "/Users/asifhussain/PROJECTS/CORTEX/cortex-brain"
       }
     }
   }
   ```

2. **prompts/user/cortex.md** - Code examples
   - PowerShell â†’ bash/zsh (or vice versa)
   - `.ps1` â†’ `.sh` extensions
   - `pwsh` â†’ `bash` commands
   - `D:\` â†’ `/Users/...` paths

3. **Entry Point Scripts**
   - `run-cortex.sh` (macOS/Linux)
   - `run-cortex.ps1` (Windows)

4. **Documentation Files**
   - Update all platform-specific examples
   - Convert command syntax
   - Update file path references

**Usage Commands:**
- "Switch to Mac" - Migrates all references to macOS
- "Switch to Windows" - Migrates all references to Windows

**Benefits:**
- âœ… One command migration
- âœ… Zero manual edits required
- âœ… Consistent platform references
- âœ… Automatic path resolution

---

#### ğŸ”§ Extension Scaffold Plugin (NEW - PROGRAMMATIC SETUP)
**Problem Solved:** Manual VS Code extension setup is complex and error-prone  
**Solution:** Automated extension project generation via setup plugin

```python
# Example: Generate CORTEX VS Code extension automatically
from plugins.extension_scaffold_plugin import ExtensionScaffoldPlugin

plugin = ExtensionScaffoldPlugin()
result = plugin.execute({
    "extension_name": "cortex",
    "display_name": "CORTEX - Cognitive Development Partner",
    "publisher": "cortex-team",
    "repository": "https://github.com/asifhussain60/CORTEX",
    "features": [
        "chat_participant",      # @cortex chat integration
        "conversation_capture",  # Automatic message capture
        "lifecycle_hooks",       # Window state monitoring
        "external_monitoring",   # Monitor @copilot chats
        "resume_prompts",        # Auto-resume on startup
        "checkpoint_system"      # Crash recovery
    ],
    "output_dir": "cortex-extension"
})
```

**What It Generates:**

```
cortex-extension/
â”œâ”€â”€ package.json                    # Extension manifest (auto-configured)
â”œâ”€â”€ tsconfig.json                   # TypeScript config
â”œâ”€â”€ .vscodeignore                   # VS Code package exclusions
â”œâ”€â”€ README.md                       # Extension documentation
â”œâ”€â”€ CHANGELOG.md                    # Version history
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ extension.ts                # Main entry point
â”‚   â”œâ”€â”€ cortex/
â”‚   â”‚   â”œâ”€â”€ chatParticipant.ts     # @cortex chat handler
â”‚   â”‚   â”œâ”€â”€ conversationCapture.ts # Auto-capture logic
â”‚   â”‚   â”œâ”€â”€ brainBridge.ts         # Python â†” TypeScript bridge
â”‚   â”‚   â”œâ”€â”€ lifecycleManager.ts    # Window state hooks
â”‚   â”‚   â”œâ”€â”€ checkpointManager.ts   # Crash recovery
â”‚   â”‚   â””â”€â”€ externalMonitor.ts     # Copilot chat monitoring
â”‚   â”œâ”€â”€ python/
â”‚   â”‚   â”œâ”€â”€ bridge.py              # Python IPC server
â”‚   â”‚   â””â”€â”€ cortex_interface.py   # CORTEX brain interface
â”‚   â””â”€â”€ test/
â”‚       â””â”€â”€ suite/
â”‚           â”œâ”€â”€ extension.test.ts
â”‚           â””â”€â”€ chatParticipant.test.ts
â”œâ”€â”€ .vscode/
â”‚   â”œâ”€â”€ launch.json                # Debug configuration
â”‚   â””â”€â”€ tasks.json                 # Build tasks
â””â”€â”€ scripts/
    â”œâ”€â”€ build.sh                   # Build script
    â”œâ”€â”€ package.sh                 # VSIX packaging
    â””â”€â”€ publish.sh                 # Marketplace publish
```

**Generated package.json (Fully Configured):**

```json
{
  "name": "cortex",
  "displayName": "CORTEX - Cognitive Development Partner",
  "description": "AI development assistant with persistent memory and context awareness",
  "version": "1.0.0",
  "author": "Asif Hussain",
  "publisher": "cortex-team",
  "license": "SEE LICENSE IN LICENSE",
  "copyright": "Copyright (c) 2024-2025 Asif Hussain. All rights reserved.",
  "repository": {
    "type": "git",
    "url": "https://github.com/asifhussain60/CORTEX"
  },
  "engines": {
    "vscode": "^1.85.0"
  },
  "categories": [
    "AI",
    "Chat",
    "Programming Languages"
  ],
  "activationEvents": [
    "onStartupFinished",
    "onCommand:cortex.resume"
  ],
  "main": "./out/extension.js",
  "contributes": {
    "chatParticipants": [
      {
        "id": "cortex",
        "name": "CORTEX",
        "description": "Cognitive development partner with memory",
        "isSticky": true,
        "commands": [
          {
            "name": "resume",
            "description": "Resume last conversation"
          },
          {
            "name": "checkpoint",
            "description": "Save conversation checkpoint"
          }
        ]
      }
    ],
    "commands": [
      {
        "command": "cortex.resume",
        "title": "CORTEX: Resume Last Conversation"
      },
      {
        "command": "cortex.checkpoint",
        "title": "CORTEX: Save Checkpoint"
      },
      {
        "command": "cortex.showHistory",
        "title": "CORTEX: Show Conversation History"
      }
    ],
    "configuration": {
      "title": "CORTEX",
      "properties": {
        "cortex.autoCapture": {
          "type": "boolean",
          "default": true,
          "description": "Automatically capture conversations"
        },
        "cortex.monitorCopilot": {
          "type": "boolean",
          "default": true,
          "description": "Monitor GitHub Copilot conversations"
        },
        "cortex.autoCheckpoint": {
          "type": "boolean",
          "default": true,
          "description": "Automatically checkpoint on focus loss"
        },
        "cortex.resumePrompt": {
          "type": "boolean",
          "default": true,
          "description": "Show resume prompt on startup"
        }
      }
    }
  },
  "scripts": {
    "vscode:prepublish": "npm run compile",
    "compile": "tsc -p ./",
    "watch": "tsc -watch -p ./",
    "test": "node ./out/test/runTest.js",
    "package": "vsce package",
    "publish": "vsce publish"
  },
  "devDependencies": {
    "@types/vscode": "^1.85.0",
    "@types/node": "^20.x",
    "typescript": "^5.3.0",
    "vsce": "^2.15.0"
  },
  "dependencies": {
    "node-ipc": "^11.1.0",
    "sqlite3": "^5.1.6"
  }
}
```

**Generated extension.ts (Main Entry Point):**

```typescript
// Auto-generated by ExtensionScaffoldPlugin
import * as vscode from 'vscode';
import { CortexChatParticipant } from './cortex/chatParticipant';
import { ConversationCapture } from './cortex/conversationCapture';
import { BrainBridge } from './cortex/brainBridge';
import { LifecycleManager } from './cortex/lifecycleManager';
import { CheckpointManager } from './cortex/checkpointManager';
import { ExternalMonitor } from './cortex/externalMonitor';

export async function activate(context: vscode.ExtensionContext) {
    console.log('CORTEX extension activating...');
    
    // Initialize Python brain bridge
    const brainBridge = new BrainBridge(context);
    await brainBridge.initialize();
    
    // Initialize conversation capture
    const conversationCapture = new ConversationCapture(brainBridge);
    
    // Register CORTEX chat participant
    const chatParticipant = new CortexChatParticipant(
        brainBridge,
        conversationCapture
    );
    context.subscriptions.push(
        vscode.chat.createChatParticipant('cortex', chatParticipant.handle)
    );
    
    // Initialize lifecycle management
    const lifecycleManager = new LifecycleManager(brainBridge);
    lifecycleManager.setupHooks(context);
    
    // Initialize checkpoint system
    const checkpointManager = new CheckpointManager(brainBridge);
    checkpointManager.startAutoCheckpoint();
    
    // Initialize external monitoring
    const externalMonitor = new ExternalMonitor(brainBridge);
    externalMonitor.startMonitoring(context);
    
    // Register commands
    context.subscriptions.push(
        vscode.commands.registerCommand('cortex.resume', async () => {
            await chatParticipant.resumeLastConversation();
        }),
        vscode.commands.registerCommand('cortex.checkpoint', async () => {
            await checkpointManager.createCheckpoint();
        }),
        vscode.commands.registerCommand('cortex.showHistory', async () => {
            await chatParticipant.showConversationHistory();
        })
    );
    
    // Check for resume on startup
    if (vscode.workspace.getConfiguration('cortex').get('resumePrompt')) {
        await chatParticipant.offerResume();
    }
    
    console.log('CORTEX extension activated successfully!');
}

export function deactivate() {
    console.log('CORTEX extension deactivating...');
}
```

**Setup Command:**

```bash
# One-command extension scaffold
python scripts/cortex_setup.py --setup-extension

# Or via plugin system
cortex plugin:run extension_scaffold --output cortex-extension

# Interactive mode
cortex setup:extension
? Extension name: cortex
? Display name: CORTEX - Cognitive Development Partner
? Publisher: cortex-team
? Features: (Select with space)
  â—‰ Chat participant
  â—‰ Conversation capture
  â—‰ Lifecycle hooks
  â—‰ External monitoring
  â—‰ Resume prompts
  â—‰ Checkpoint system

âœ… Extension scaffolded at: ./cortex-extension
âœ… package.json configured
âœ… TypeScript files generated
âœ… Python bridge created
âœ… Tests generated
âœ… Build scripts ready

Next steps:
  cd cortex-extension
  npm install
  code .
  Press F5 to debug
```

**Benefits:**
- âœ… Zero manual configuration - fully automated
- âœ… Best practices baked in (TypeScript, testing, proper structure)
- âœ… Python â†” TypeScript bridge pre-configured
- âœ… All CORTEX features enabled by default
- âœ… Ready to debug (F5) immediately after generation
- âœ… Package and publish scripts included
- âœ… Can regenerate if VS Code API changes

**Plugin Architecture:**

```python
class ExtensionScaffoldPlugin(BasePlugin):
    """Generates VS Code extension project structure"""
    
    def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:
        # 1. Create directory structure
        self._create_directory_structure(context['output_dir'])
        
        # 2. Generate package.json
        self._generate_package_json(context)
        
        # 3. Generate TypeScript source files
        self._generate_typescript_files(context)
        
        # 4. Generate Python bridge
        self._generate_python_bridge(context)
        
        # 5. Generate tests
        self._generate_tests(context)
        
        # 6. Generate build/publish scripts
        self._generate_scripts(context)
        
        # 7. Initialize npm/git
        self._initialize_project(context['output_dir'])
        
        return {
            "success": True,
            "output_dir": context['output_dir'],
            "next_steps": [
                f"cd {context['output_dir']}",
                "npm install",
                "code .",
                "Press F5 to debug"
            ]
        }
```

**Update Detection & Regeneration:**

```python
# Check if VS Code API has changed
cortex plugin:run extension_scaffold --check-updates

# Regenerate with new API
cortex plugin:run extension_scaffold --regenerate --preserve-customizations
```

---

### ğŸ¯ CORTEX 2.0: Strategic Overview

**Mission:** Transform CORTEX from a functional cognitive system into a production-ready, self-sustaining CORTEX-specific development partner with zero conversation amnesia.

**Strategic Focus Shift:**
- âŒ **OLD:** Build generic reusable framework for any project
- âœ… **NEW:** Build CORTEX-specific system optimized for CORTEX development itself
- **Rationale:** Focus = Speed. Generic frameworks take 3x longer. CORTEX should first perfect helping itself before expanding.

**Primary Problem Solved:**
> **"Continue" command fails 80% of the time because conversations never reach CORTEX's brain.**

**Root Cause:** GitHub Copilot Chat has no automatic memory bridge to CORTEX Tier 1.

**Solution Architecture (Phased Evolution):**

```
Phase 0 (Quick Wins - Week 1-2): Foundation
  â”œâ”€ WorkStateManager: Track in-progress work
  â”œâ”€ SessionToken: Persistent conversation ID
  â””â”€ Auto-Prompt: Remind user to capture
  â†’ Impact: 20% â†’ 60% success rate (3x improvement in 6.5 hours)

Phase 1 (Core Modularization - Week 3-6): Architecture
  â”œâ”€ 1.1 Knowledge Graph modularization (COMPLETE âœ…)
  â””â”€ 1.2 Tier 1 Working Memory refactor (IN PROGRESS NEXT)
  â†’ Impact: Maintainability + performance foundation for plugins

Phase 2 (Ambient - Week 7-8): Automation
  â”œâ”€ File system watcher
  â”œâ”€ Terminal monitoring
  â””â”€ Git operation detection
  â†’ Impact: 60% â†’ 85% success rate (background capture)

Phase 3 (Extension - Week 11-16): Definitive Solution
  â”œâ”€ VS Code chat participant (@cortex)
  â”œâ”€ Lifecycle hooks (focus/blur)
  â”œâ”€ External monitoring (@copilot)
  â””â”€ Proactive resume prompts
  â†’ Impact: 85% â†’ 98% success rate (near-perfect)
```

**Why Extension is Definitive:**

| Limitation | Manual Scripts | Ambient Daemon | VS Code Extension |
|------------|----------------|----------------|-------------------|
| Chat transcript access | âŒ No | âŒ No | âœ… Yes |
| Lifecycle hooks | âŒ No | âš ï¸ Partial | âœ… Full |
| Proactive prompts | âŒ No | âŒ No | âœ… Yes |
| Zero user action | âŒ No | âš ï¸ Partial | âœ… Yes |
| Crash recovery | âŒ No | âŒ No | âœ… Yes |
| External monitoring | âŒ No | âŒ No | âœ… Yes |

**Timeline:** 22-24 weeks (5.5-6 months)
**Total Investment:** ~96.5 hours of development time
**ROI:** 10:1 (every hour invested saves 10+ hours of user frustration)

**Key Milestones:**

| Week | Milestone | Deliverable | Impact |
|------|-----------|-------------|--------|
| **Week 2** | Phase 0 Complete | WorkStateManager + SessionToken | "Continue" works 60% of time |
| **Week 6** | Phase 1 Complete | All modules <500 lines | Code maintainability +40% |
| **Week 10** | Phase 2 Complete | Ambient capture + workflows | "Continue" works 85% of time |
| **Week 16** | Phase 3 Complete | Extension published | "Continue" works 98% of time |
| **Week 18** | Phase 4 Complete | 90% test coverage | Production-ready quality |
| **Week 24** | Phase 7 Complete | Full rollout | 70% adoption achieved |

**Success Criteria (Phase 3 - Extension):**
- âœ… "Continue" command success rate: 98%
- âœ… Automatic capture: No user intervention required
- âœ… Conversation amnesia: Eliminated
- âœ… Time to resume: <2 seconds
- âœ… User satisfaction: â‰¥4.5/5

**Risk Mitigation:**
- Incremental delivery (phases build on each other)
- Each phase delivers measurable value
- Rollback procedures at every phase
- Dual-mode operation (CLI + Extension coexist)
- Feature flags for gradual migration

---

#### ğŸ”„ Workflow Pipeline System (NEW)
**Problem Solved:** Hardcoded agent workflows, difficult orchestration  
**Solution:** Declarative DAG-based workflow engine

```yaml
# Example: Feature development workflow
name: feature_development
stages:
  - clarify_dod_dor    # Define requirements
  - threat_model       # Security analysis
  - plan               # Create multi-phase plan
  - tdd_cycle          # Test-first implementation
  - run_tests          # Execute test suite
  - validate_dod       # Verify completion criteria
  - cleanup            # Code cleanup
  - document           # Generate docs
```

**Benefits:**
- âœ… Declarative workflow definitions
- âœ… DAG validation (detects cycles)
- âœ… Parallel execution support
- âœ… Checkpoint/resume from failures
- âœ… Conditional stages
- âœ… Reusable workflow templates

---

#### ğŸ“¦ Modular Architecture (REFACTORED)
**Problem Solved:** Bloated monolithic files (1000+ lines)  
**Solution:** Break into focused modules following SOLID principles

**Before (CORTEX 1.0):**
```
knowledge_graph.py         1144 lines âŒ
working_memory.py           813 lines âŒ
context_intelligence.py     776 lines âŒ
error_corrector.py          692 lines âŒ
```

**After (CORTEX 2.0):**
```
knowledge_graph/
â”œâ”€â”€ knowledge_graph.py       150 lines âœ…
â”œâ”€â”€ patterns/
â”‚   â”œâ”€â”€ pattern_store.py     200 lines âœ…
â”‚   â”œâ”€â”€ pattern_search.py    250 lines âœ…
â”‚   â””â”€â”€ pattern_decay.py     120 lines âœ…
â”œâ”€â”€ relationships/
â”‚   â””â”€â”€ relationship_manager.py 180 lines âœ…
â””â”€â”€ tags/
    â””â”€â”€ tag_manager.py       120 lines âœ…
```

**Benefits:**
- âœ… All files <500 lines
- âœ… Clear single responsibility
- âœ… Easy to test individually
- âœ… Simpler maintenance
- âœ… Better code organization

---

#### ğŸ¥ Self-Review System (NEW)
**Problem Solved:** No systematic health monitoring  
**Solution:** Comprehensive automated health checks with auto-fix

```python
# Example: Run health review
from maintenance.self_review import SelfReviewEngine

review = engine.run_comprehensive_review(auto_fix=True)
# Output: Overall Status: ğŸŸ¢ EXCELLENT (92% score)
```

**What It Checks:**
- âœ… Database health (fragmentation, indexes, statistics)
- âœ… Performance benchmarks (Tier 1: <50ms, Tier 2: <150ms)
- âœ… Rule compliance (all 27 core rules)
- âœ… Test coverage (target: 85%+)
- âœ… Storage health (temp files, old logs, capacity)

**Auto-Fix Capabilities:**
- âœ… VACUUM fragmented databases
- âœ… ANALYZE stale statistics
- âœ… Remove temp files
- âœ… Archive old logs
- âœ… Trigger brain updates

**Scheduled Reviews:**
- Daily: 2am (auto-fix safe issues)
- Weekly: Sunday 3am (comprehensive report)
- Monthly: 1st Sunday 4am (deep analysis)

---

#### ğŸ’¾ Conversation State Management (NEW)
**Problem Solved:** Can't resume after interruptions  
**Solution:** Persistent conversation state with checkpoints

```python
# Example: Resume interrupted conversation
state_manager.resume_conversation(conversation_id)
# Returns: "Resuming Phase 3 (Validation)..."
```

**Features:**
- âœ… Track conversation lifecycle (active/paused/completed)
- âœ… Persistent task progress
- âœ… Checkpoint creation at phases
- âœ… Resume from last successful stage
- âœ… "Continue" command support

**Database Schema:**
```sql
conversations  -- Conversation metadata
tasks          -- Work breakdown with dependencies
checkpoints    -- State snapshots for rollback
task_files     -- Files modified per task
```

**Benefits:**
- âœ… Seamless resume after breaks
- âœ… No lost progress
- âœ… Clear task status tracking
- âœ… Rollback support
- âœ… Multi-task management

âš ï¸ **Limitation:** Still requires manual conversation capture when using GitHub Copilot Chat interface.  
âœ… **Solution:** See "VS Code Extension Architecture" below for definitive fix.

---

#### ğŸ”Œ VS Code Extension Architecture (NEW - DEFINITIVE CONVERSATION FIX)
**Author:** Asif Hussain  
**Copyright:** Â© 2024-2025 Asif Hussain. All rights reserved.  
**Problem Solved:** GitHub Copilot Chat amnesia - conversations not automatically tracked  
**Solution:** CORTEX as native VS Code extension with automatic conversation capture

**Why Current Architecture Can't Fix This:**
```
GitHub Copilot Chat â†’ Reads cortex.md as passive documentation
                   â†’ No execution context
                   â†’ No access to chat transcripts
                   â†’ No lifecycle hooks
                   â†’ Runs in Microsoft cloud (isolated)
```

**Why VS Code Extension WILL Fix This:**
```
CORTEX Extension â†’ Active VS Code process
                â†’ Can subscribe to chat events
                â†’ Can intercept chat messages
                â†’ Has full VS Code API access
                â†’ Runs locally with full control
```

**Architecture:**

```typescript
// VS Code Extension: cortex-extension/src/extension.ts
export function activate(context: vscode.ExtensionContext) {
    
    // 1. Register chat participant (captures all conversations)
    const cortexChat = vscode.chat.createChatParticipant(
        'cortex',
        async (request, context, stream, token) => {
            // Automatically capture to CORTEX brain
            await cortexBrain.captureMessage({
                user: request.prompt,
                timestamp: new Date().toISOString(),
                context: context.history
            });
            
            // Process through CORTEX agents
            const response = await cortexRouter.route(request.prompt);
            stream.markdown(response.content);
            
            // Auto-save response to brain
            await cortexBrain.captureResponse(response);
            
            return { metadata: { conversationId: response.conversationId } };
        }
    );
    
    // 2. Monitor external Copilot conversations (passive capture)
    vscode.chat.onDidPerformChatAction(async (action) => {
        if (action.participant.id === 'copilot') {
            // Capture Copilot chats to CORTEX brain
            await cortexBrain.captureExternalChat({
                participant: 'copilot',
                message: action.message,
                timestamp: new Date().toISOString()
            });
        }
    });
    
    // 3. Session lifecycle tracking
    vscode.window.onDidChangeWindowState(async (state) => {
        if (!state.focused) {
            // Window losing focus - checkpoint conversation
            await cortexBrain.checkpointActiveConversation();
        }
    });
    
    // 4. Automatic resume on startup
    context.subscriptions.push(
        vscode.commands.registerCommand('cortex.resume', async () => {
            const lastConversation = await cortexBrain.getLastActiveConversation();
            if (lastConversation) {
                vscode.window.showInformationMessage(
                    `Resume: ${lastConversation.topic}?`,
                    'Yes', 'No'
                ).then(async (choice) => {
                    if (choice === 'Yes') {
                        await cortexBrain.resumeConversation(lastConversation.id);
                    }
                });
            }
        })
    );
}
```

**Automatic Conversation Capture:**
```typescript
class CortexBrain {
    async captureMessage(message: ChatMessage): Promise<void> {
        // AUTOMATIC - No user intervention needed
        await this.tier1.storeMessage(message);
        
        // Real-time event logging
        await this.tier4.logEvent({
            type: 'chat_message',
            content: message.user,
            timestamp: message.timestamp
        });
        
        // Check for learning triggers
        if (this.shouldUpdateBrain()) {
            await this.tier2.extractPatterns();
        }
    }
    
    async captureExternalChat(chat: ExternalChat): Promise<void> {
        // Capture even non-CORTEX conversations
        await this.tier1.storeExternalConversation({
            source: chat.participant,
            content: chat.message,
            timestamp: chat.timestamp,
            tagged: 'external_copilot'
        });
    }
}
```

**User Experience - COMPLETELY AUTOMATIC:**

```typescript
// User opens VS Code
â†’ CORTEX Extension activates
â†’ Detects last active conversation
â†’ Shows notification: "Resume: Add invoice export feature?"
â†’ User clicks "Yes"
â†’ CORTEX loads full context automatically

// User types in CORTEX chat: "Add purple button"
â†’ Extension captures message immediately
â†’ Routes to CORTEX agents
â†’ Response generated
â†’ Response auto-saved to brain
â†’ NO MANUAL CAPTURE NEEDED

// User closes VS Code unexpectedly
â†’ Extension lifecycle hook triggers
â†’ Checkpoint saved automatically
â†’ Next startup: Resume offered

// User uses regular Copilot Chat (not CORTEX)
â†’ Extension monitors via onDidPerformChatAction
â†’ Passively captures Copilot conversations
â†’ Stores in Tier 1 as "external" source
â†’ Still available for context/learning
```

**Benefits:**
- âœ… **Zero manual intervention** - Capture is automatic
- âœ… **Works with Copilot too** - Monitors external chats
- âœ… **Lifecycle aware** - Handles focus loss, crashes, restarts
- âœ… **Real-time tracking** - Immediate Tier 1/4 updates
- âœ… **Auto-resume prompts** - Suggests continuing last work
- âœ… **Crash recovery** - Checkpoints prevent data loss
- âœ… **Native VS Code** - Full API access, no cloud dependency

**Implementation Plan:**

```
Phase 1: Basic Extension (Week 1-2)
- Create VS Code extension scaffold
- Register CORTEX chat participant
- Basic message capture to Tier 1

Phase 2: Lifecycle Hooks (Week 3-4)
- Window focus/blur detection
- Automatic checkpointing
- Resume prompts on startup

Phase 3: External Monitoring (Week 5-6)
- Monitor Copilot chat via API
- Passive capture to brain
- Unified conversation timeline

Phase 4: Advanced Features (Week 7-8)
- Real-time pattern learning
- Context injection
- Agent orchestration UI

Phase 5: Polish & Release (Week 9-10)
- Settings UI
- Keyboard shortcuts
- Documentation
- VS Code Marketplace publish
```

**Why This DEFINITIVELY Solves It:**

| Current (Copilot Chat) | CORTEX Extension |
|------------------------|------------------|
| âŒ Passive documentation | âœ… Active process |
| âŒ No execution | âœ… Full execution |
| âŒ No chat access | âœ… Chat API access |
| âŒ No lifecycle hooks | âœ… Full lifecycle control |
| âŒ Cloud-based | âœ… Local control |
| âŒ Manual capture | âœ… Automatic capture |
| âŒ Resume impossible | âœ… Auto-resume |

**Technical Feasibility:**
- âœ… VS Code Chat API available (VS Code 1.85+)
- âœ… Extension API well-documented
- âœ… TypeScript â†’ Python bridge possible
- âœ… Local SQLite works in extensions
- âœ… Full filesystem access
- âœ… Marketplace distribution ready

**Migration Path:**
```
Current Users:
1. Install CORTEX VS Code Extension
2. Extension auto-migrates existing brain data
3. Switch from manual capture to automatic
4. Seamless transition - no data loss

New Users:
1. Install extension from VS Code Marketplace
2. CORTEX chat participant appears automatically
3. Start chatting - tracking happens invisibly
```

---

#### ğŸ›¤ï¸ Path Management (REFACTORED)
**Problem Solved:** Hardcoded absolute paths break portability  
**Solution:** Environment-agnostic relative path resolver

```python
# Example: Cross-platform path resolution
paths = PathResolver(config)
brain_path = paths.get_brain_path("tier1/conversations.db")
# Returns: Correct path for Windows/macOS/Linux
```

**Configuration:**
```json
{
  "cortex_root": "${CORTEX_HOME}",
  "brain": {
    "tier1": "cortex-brain/tier1",
    "tier2": "cortex-brain/tier2",
    "tier3": "cortex-brain/tier3"
  }
}
```

**Benefits:**
- âœ… Works on Windows, macOS, Linux
- âœ… Environment-specific configuration
- âœ… No hardcoded paths anywhere
- âœ… Easy multi-repository support

---

#### ğŸ›¡ï¸ Enhanced Knowledge Boundaries (REFACTORED)
**Problem Solved:** Core knowledge contamination from application data  
**Solution:** Automated boundary validation and enforcement

```yaml
# Example: Protected CORTEX core patterns
title: "TDD: Test-first for service creation"
scope: "generic"
namespaces: ["CORTEX-core"]
confidence: 0.95

# Example: Application-specific pattern
title: "KSESSIONS: Invoice export workflow"
scope: "application"
namespaces: ["KSESSIONS"]
confidence: 0.85
```

**Enforcement:**
- âœ… Automated boundary validation
- âœ… Auto-migration of misplaced data
- âœ… Brain Protector integration
- âœ… Namespace-based search prioritization

Note: In code, the scope enum is ['cortex', 'application'] to reflect CORTEX-core vs app-specific. The documentation's 'generic' is equivalent to 'cortex'.

---

### CORTEX 2.0 Implementation Roadmap

**Strategic Focus:** CORTEX-specific system development + High-value capability enhancements
**Timeline:** 28-32 weeks total (7-8 months)
**Phases:** 9 phases (0-7: Core CORTEX 2.0, 8-9: Capability Enhancements)
**Last Updated:** 2025-11-08

**Roadmap Structure:**
- **Phases 0-7 (Week 1-24):** Core CORTEX 2.0 - Conversation tracking, modularization, extension
- **Phase 8 (Week 25-28):** Wave 1 Capabilities - Code review, web testing, reverse engineering
- **Phase 9 (Week 29-32):** Wave 2 Capabilities - Mobile testing, UI from spec
- **Deferred:** Figma integration, A/B testing (recommend third-party integrations)

**Total Footprint Impact:**
- Core CORTEX 2.0 (Phases 0-7): Baseline + refactoring (no net increase)
- Phase 8 (Wave 1): +4.5% (~2,800 lines)
- Phase 9 (Wave 2): +6.4% (~4,000 lines)
- **Total with Enhancements: +10.9% (63,000 â†’ 69,868 lines)**
- Deferred features: +10.4% avoided by using integrations

**Key Milestones:**
- Week 2: Phase 0 complete âœ… (60% "continue" success)
- Week 6: Phase 1 complete ğŸ“‹ (modularization)
- Week 10: Phase 2 complete ğŸ“‹ (85% "continue" success)
- Week 16: Phase 3 complete ğŸ“‹ (98% "continue" success, extension live)
- Week 24: Phase 7 complete ğŸ“‹ (full rollout, core complete)
- Week 28: Phase 8 complete ğŸ“‹ (code review, web testing, reverse engineering)
- Week 32: Phase 9 complete ğŸ“‹ (mobile testing, UI generation)

---

**Phase 0: Baseline & Quick Wins (Week 1-2)** âœ… PRIORITY

**Baseline Activities:**
- Run complete test suite
- Document current architecture
- Risk assessment
- Establish monitoring baselines

**Quick Win Implementations (NEW - Critical for "continue" command):**
- âš¡ **WorkStateManager** - Track in-progress work with phase/task checkpoints (4 hours)
  - Add `work_sessions` and `work_progress` tables to Tier 1
  - Implement resume point detection
  - Enable "continue" to know exact next task
  
- âš¡ **SessionToken** - Persistent conversation ID across Copilot messages (2 hours)
  - Store session token in `.vscode/cortex-session.json`
  - 30-minute idle boundary detection (Rule #11)
  - Fix conversation ID fragmentation
  
- âš¡ **Enhanced Auto-Prompt** - PowerShell profile integration (30 minutes)
  - Prompt user after meaningful work (git commit, test run, etc.)
  - Auto-detect 5+ minute gaps since last capture
  - Reduce manual capture burden

**Success Criteria:**
- âœ… "Continue" success rate: 20% â†’ 60%
- âœ… Work state tracking: 100% (automatic)
- âœ… Resume point accuracy: 95%
- âœ… Zero code regressions (all tests passing)

**Deliverables:**
- Baseline report with architecture diagrams
- WorkStateManager implementation + tests
- SessionToken implementation + tests
- Updated PowerShell profile with auto-prompt
- Risk assessment matrix

---

**Phase 1: Core Modularization (Week 3-6)** ğŸ“‹ NEXT

**Focus:** Break monolithic files into SOLID-compliant modules (<500 lines each)

**1.1 Tier 1 Working Memory Refactoring (Week 3)**
- Refactor `working_memory.py` (823 lines) â†’ 5 focused modules:
  - `working_memory.py` (120 lines, coordinator)
  - `conversations/conversation_manager.py` (200 lines)
  - `messages/message_store.py` (180 lines)
  - `entities/entity_extractor.py` (150 lines)
  - `fifo/queue_manager.py` (173 lines)
- âœ… Already passing 22/22 tests - maintain test coverage
- Add WorkStateManager integration tests

**1.2 Knowledge Graph Refactoring (Week 4)**
- Refactor `knowledge_graph.py` (1144 lines) â†’ 6 focused modules:
  - `knowledge_graph.py` (150 lines, coordinator)
  - `patterns/pattern_store.py` (200 lines)
  - `patterns/pattern_search.py` (250 lines)
  - `patterns/pattern_decay.py` (120 lines)
  - `relationships/relationship_manager.py` (180 lines)
  - `tags/tag_manager.py` (120 lines)
- Maintain FTS5 search performance
- Add namespace-aware search (CORTEX-core, application-specific)

**1.3 Context Intelligence Refactoring (Week 5)**
- Refactor `context_intelligence.py` (776 lines) â†’ 6 focused modules:
  - `context_intelligence.py` (100 lines, coordinator)
  - `metrics/git_metrics.py` (150 lines)
  - `metrics/file_metrics.py` (130 lines)
  - `analysis/hotspot_detector.py` (140 lines)
  - `analysis/velocity_analyzer.py` (120 lines)
  - `storage/context_store.py` (136 lines)
- Maintain <150ms query performance

**1.4 Agent Modularization (Week 6)**
- Refactor 5 agents using strategy pattern:
  - `error_corrector.py` (692 lines) â†’ 4 modules (<150 lines each)
  - `health_validator.py` â†’ 3 modules
  - `code_executor.py` â†’ 4 modules
  - `test_generator.py` â†’ 3 modules
  - `work_planner.py` â†’ 4 modules
- Extract agent strategies for reusability

**Success Criteria:**
- âœ… All files <500 lines
- âœ… Zero circular dependencies
- âœ… All existing tests passing
- âœ… Test coverage â‰¥85%
- âœ… Performance maintained or improved

---

**Phase 2: Ambient Capture & Workflow Pipeline (Week 7-10)**

**2.1 Ambient Context Daemon (Week 7-8) ğŸ¯ HIGH VALUE**
- **Problem:** Manual capture still required despite Phase 0 improvements
- **Solution:** Background daemon for automatic context capture

**Implementation:**
```python
# scripts/cortex/auto_capture_daemon.py
- Watch file system for workspace changes
- Capture open files from VS Code
- Monitor terminal output
- Detect Git operations
- Auto-store context to Tier 1
- Debounce captures (5-second intervals)
```

**VS Code Integration:**
- Add `.vscode/tasks.json` entry for auto-start on folder open
- Run daemon in background (non-blocking)
- Graceful shutdown on workspace close

**Success Criteria:**
- âœ… "Continue" success rate: 60% â†’ 85%
- âœ… Zero manual capture required for 80% of sessions
- âœ… Context loss: <20%
- âœ… Capture latency: <100ms

**2.2 Workflow Pipeline System (Week 9-10)**
- Complete workflow orchestration engine
- Implement missing workflow stages
- Create production workflows (feature_development, bug_fix, etc.)
- Add checkpoint/resume capability
- DAG validation for workflow definitions
- Parallel stage execution support

**Success Criteria:**
- âœ… Declarative workflow definitions work
- âœ… Checkpoint/resume functional
- âœ… 4+ production workflows created
- âœ… Zero workflow cycles detected

---

**Phase 3: VS Code Extension (Week 11-16) ğŸš€ DEFINITIVE SOLUTION**

**Strategic Note:** This is the definitive fix for conversation tracking. Extension provides active hooks into VS Code that manual scripts cannot achieve.

**3.1 Extension Scaffold + Chat Participant (Week 11-12)**
- **Run automated scaffold:** `cortex setup:extension`
  - TypeScript project fully configured
  - package.json with all dependencies
  - Python â†” TypeScript bridge
  - Test infrastructure
- Register `@cortex` chat participant
- Implement basic message routing to Python backend
- Automatic capture to Tier 1 (real-time)
- Unit tests for extension core

**3.2 Lifecycle Integration (Week 13)**
- Window state monitoring (focus/blur events)
- Automatic checkpointing on focus loss
- Resume prompt on VS Code startup
  - "Resume: Add purple button? (2 hours ago)"
  - Show progress: "Phase 2, 3/5 tasks complete"
- Crash recovery via checkpoints
- Integration tests for lifecycle hooks

**3.3 External Conversation Monitoring (Week 14)**
- Monitor GitHub Copilot conversations via API
- Passive capture to brain (tagged as "external")
- Unified conversation timeline (CORTEX + Copilot)
- Context injection from all sources
- Conversation deduplication logic

**3.4 Proactive Resume System (Week 15)**
- Detect resume opportunities:
  - 30+ min idle (Rule #11 boundary)
  - First message in new chat session
  - Workspace open after >2 hours
- Show resume prompt automatically
- Display work progress and next task
- One-click resume to exact checkpoint

**3.5 Polish & Marketplace (Week 16)**
- Settings UI (enable/disable features)
- Keyboard shortcuts (Ctrl+Shift+C for CORTEX chat)
- Documentation and tutorials
- Extension icon and branding
- Build: `npm run package` (creates .vsix)
- Publish: `npm run publish` (to VS Code Marketplace)
- Alpha release to early adopters

**Success Criteria:**
- âœ… "Continue" success rate: 85% â†’ 98%
- âœ… Zero manual intervention required
- âœ… Automatic capture success rate >99%
- âœ… Average resume time <2 seconds
- âœ… Extension stability >95%
- âœ… External chat capture rate >90%

---

**Phase 4: Risk Mitigation & Testing (Week 17-18)**
- 75 new risk mitigation tests
  - Conversation tracking failure scenarios
  - Extension crash recovery
  - FIFO queue edge cases
  - WorkStateManager concurrency
- End-to-end integration tests
  - Full conversation lifecycle
  - Multi-phase work completion
  - Cross-tier data flow
- Extension stability testing
  - Memory leak detection
  - Performance under load
  - Rapid focus change handling
- Security scenario testing
  - Brain data protection
  - Extension permissions audit
- Performance benchmarks validation
  - Tier 1: <50ms queries
  - Tier 2: <150ms search
  - Extension: <100ms capture

**Success Criteria:**
- âœ… Test coverage >90%
- âœ… Zero critical bugs
- âœ… All performance benchmarks met
- âœ… Security audit passed

---

**Phase 5: Performance Optimization (Week 19-20)**
- Database optimization
  - VACUUM fragmented databases
  - ANALYZE stale statistics
  - Index tuning for conversation queries
  - FTS5 optimization for pattern search
  - Connection pooling for Tier 1
- Workflow optimization
  - Parallel stage execution
  - Stage result caching
  - DAG pre-compilation
- Context injection optimization
  - Selective tier loading
  - Lazy entity extraction
  - Query result caching
- Extension responsiveness tuning
  - Debounced capture events
  - Background processing for brain updates
  - Incremental context loading
- Lazy loading implementation
  - Defer Tier 2 pattern loading until needed
  - On-demand Tier 3 metrics collection

**Success Criteria:**
- âœ… 20%+ performance improvement over baseline
- âœ… Extension UI remains responsive (<100ms)
- âœ… Memory usage optimized (<50MB extension overhead)
- âœ… Database size growth controlled (<1MB/day)

---

**Phase 6: Documentation & Training (Week 21-22)**
- Architecture guides
  - CORTEX 2.0 system design
  - Tier architecture deep-dive
  - Extension architecture
  - WorkStateManager usage
- Developer guides
  - Extension API documentation
  - Contributing to CORTEX
  - Plugin development guide
  - Testing strategies
- User tutorials
  - Getting started with CORTEX extension
  - Using @cortex chat participant
  - Understanding resume prompts
  - Managing conversation history
- API reference
  - Tier 1 API (conversations, messages, entities)
  - Tier 2 API (patterns, knowledge graph)
  - Tier 3 API (context intelligence)
  - Extension Python bridge API
- Migration guide
  - Manual capture â†’ Automatic capture
  - CLI-only â†’ Extension-first
  - Data migration procedures
  - Rollback procedures

**Success Criteria:**
- âœ… All documentation complete
- âœ… Code examples validated
- âœ… User feedback incorporated
- âœ… Migration guide tested with real users

---

**Phase 7: Migration & Rollout (Week 23-24)**
- Feature flags for gradual migration
  - `cortex.useExtension` (default: true)
  - `cortex.fallbackToCLI` (default: true)
  - `cortex.betaFeatures` (default: false)
- Dual-mode operation validation
  - CLI works without extension
  - Extension works without CLI commands
  - Both can coexist safely
- Extension rollout stages:
  - Alpha: Internal testing (Week 23, Days 1-2)
  - Beta: Early adopters (Week 23, Days 3-5)
  - General Availability (Week 24, Day 1)
- Monitoring and validation
  - Capture success rate tracking
  - Resume success rate tracking
  - Error rate monitoring
  - User satisfaction surveys
- Marketplace promotion
  - VS Code Marketplace listing optimized
  - README with screenshots/demo
  - Social media announcement
  - Documentation site updated
- Deprecation notices
  - Manual capture script (6-month sunset)
  - CLI-only mode (12-month sunset)

**Success Criteria:**
- âœ… Extension adoption >70% within 2 weeks
- âœ… Zero data loss during migration
- âœ… Rollback procedures tested and documented
- âœ… User satisfaction â‰¥4.5/5
- âœ… Conversation amnesia reports: 0

---

**Phase 8: Capability Enhancement - Wave 1 (Week 25-28) ğŸ†• HIGH-VALUE ADDITIONS**

**Goal:** Enhance CORTEX with high-value development capabilities identified in capability analysis

**Strategic Rationale:**
- Leverage existing core strengths (code writing, testing, documentation)
- Add features developers request most
- Minimal footprint increase (+4.5%)
- High ROI for development teams

**8.1 Code Review Plugin (Week 25-26)**
- **Problem:** No automated PR review integration
- **Solution:** Azure DevOps / GitHub PR review integration

**Features:**
- âœ… Automated pull request review
- âœ… SOLID principle violation detection
- âœ… Pattern violation checking (against Tier 2 knowledge)
- âœ… Security vulnerability scanning (hard-coded secrets, SQL injection)
- âœ… Performance anti-pattern detection (N+1 queries, memory leaks)
- âœ… Test coverage regression detection
- âœ… Code style consistency checking
- âœ… Duplicate code detection
- âœ… Dependency vulnerability analysis

**Integration Points:**
- Azure DevOps REST API
- GitHub Actions / GitLab CI webhooks
- BitBucket Pipelines

**Deliverables:**
- Code review plugin (~500-800 lines)
- Azure DevOps integration
- GitHub integration
- Security scanning rules
- Pattern violation rules
- 15+ unit tests
- Integration tests with mock PRs
- Documentation (setup guide, configuration)

**Success Criteria:**
- âœ… PR review adoption >70%
- âœ… False positive rate <10%
- âœ… Review time <30 seconds per PR
- âœ… Security issue detection rate >90%

**Footprint Impact:** +1.3% (~800 lines)

---

**8.2 Web Testing Enhancements (Week 27)**
- **Problem:** Missing performance and accessibility testing
- **Solution:** Lighthouse and axe-core integration

**Features:**
- âœ… Performance testing (Lighthouse)
  - Core Web Vitals (LCP, FID, CLS)
  - Performance score
  - Best practices audit
  - SEO audit
- âœ… Accessibility testing (axe-core)
  - WCAG 2.1 compliance
  - ARIA attribute validation
  - Keyboard navigation checks
  - Screen reader compatibility
- âœ… Network stubbing/mocking (MSW integration)
- âœ… Visual regression enhancements (Percy optimization)

**Integration Points:**
- Lighthouse CI
- axe-playwright
- Mock Service Worker (MSW)
- Percy API

**Deliverables:**
- Performance testing templates (~200 lines)
- Accessibility testing templates (~150 lines)
- MSW integration helpers (~150 lines)
- 10+ test examples
- Documentation

**Success Criteria:**
- âœ… Performance tests cover all critical paths
- âœ… Accessibility score >90% on all pages
- âœ… Test generation time <2 minutes
- âœ… Network stubbing works for all API calls

**Footprint Impact:** +0.8% (~500 lines)

---

**8.3 Reverse Engineering Plugin (Week 28)**
- **Problem:** No automated legacy code analysis
- **Solution:** Comprehensive code analysis and documentation plugin

**Features:**
- âœ… Cyclomatic complexity analysis (radon)
- âœ… Technical debt detection
- âœ… Dead code identification (vulture)
- âœ… Duplicate code detection
- âœ… Dependency graph generation (graphviz)
- âœ… Design pattern identification (Factory, Singleton, Observer, etc.)
- âœ… Data flow tracing
- âœ… Entry point identification
- âœ… Layered architecture detection
- âœ… Mermaid diagram generation (class, sequence, component, dependency)
- âœ… Refactoring recommendations

**Multi-Language Support:**
- Python: radon, vulture, pylint, bandit
- C#: Roslyn analyzers, NDepend API
- JavaScript/TypeScript: ESLint, JSComplexity, dependency-cruiser

**Deliverables:**
- Reverse engineering plugin (~1,200-1,500 lines)
- Multi-language analyzers
- Diagram generators
- Documentation templates
- 20+ unit tests
- Integration tests with sample projects
- User guide

**Success Criteria:**
- âœ… Analyze 10,000+ line codebase in <5 minutes
- âœ… Diagram generation accuracy >95%
- âœ… Refactoring recommendations actionable >80%
- âœ… Pattern detection accuracy >85%

**Footprint Impact:** +2.4% (~1,500 lines)

---

**Phase 8 Summary:**
- **Total Time:** 4 weeks
- **Total Footprint:** +4.5% (~2,800 lines)
- **Total Value:** â­â­â­â­â­ (Very High)
- **Risk:** Low (all plugins, can be disabled)
- **Dependencies:** Standard libraries, existing APIs

---

**Phase 9: Capability Enhancement - Wave 2 (Week 29-32) ğŸ†• EXTENDED CAPABILITIES**

**Goal:** Add broader testing and UI generation capabilities

**Strategic Rationale:**
- Expand to mobile and UI generation
- Support backend-first development workflows
- Moderate footprint increase (+6.4%)
- High value for full-stack teams

**9.1 UI from Server Spec Plugin (Week 29-30)**
- **Problem:** No automated UI generation from API specs
- **Solution:** OpenAPI/GraphQL â†’ UI component generation

**Features:**
- âœ… OpenAPI/Swagger spec parsing
- âœ… GraphQL schema parsing
- âœ… JSON Schema parsing
- âœ… TypeScript interface generation
- âœ… Form component generation (React Hook Form, Formik, VeeValidate)
- âœ… CRUD UI generation (list, detail, create, edit, delete views)
- âœ… API integration code (React Query, Apollo Client, SWR)
- âœ… Validation schema generation (Yup, Zod, Joi)
- âœ… Table/grid components (sorting, filtering, pagination)
- âœ… Search/filter UI generation

**Multi-Framework Support:**
- React (primary)
- Vue (secondary)
- Angular (secondary)
- Svelte (future)

**Deliverables:**
- UI generation plugin (~1,500-2,000 lines)
- OpenAPI parser
- GraphQL schema parser
- Form generators (3 frameworks)
- CRUD component templates
- API integration helpers
- 25+ unit tests
- Integration tests with sample specs
- Documentation

**Success Criteria:**
- âœ… Generate complete CRUD UI in <1 minute
- âœ… Generated components compile without errors
- âœ… Form validation works for all field types
- âœ… API integration functional on first run

**Footprint Impact:** +3.2% (~2,000 lines)

---

**9.2 Mobile Testing Plugin (Week 31-32)**
- **Problem:** No mobile testing support (iOS, Android)
- **Solution:** Appium cross-platform mobile testing

**Features - Phase 1 (Cross-Platform):**
- âœ… Appium test generation (iOS + Android)
- âœ… Mobile-specific selectors (accessibility IDs, resource IDs, XPath)
- âœ… Device/emulator configuration
- âœ… Basic gesture testing (tap, swipe, scroll)
- âœ… Orientation testing (portrait/landscape)
- âœ… Screenshot comparison (visual regression)

**Supported Frameworks (Phase 1):**
- Appium (Python client)
- Cross-platform (iOS + Android)

**Future Phases (Post-Week 32):**
- Phase 2: Native frameworks (XCUITest for iOS, Espresso for Android)
- Phase 3: Framework-specific (Detox for React Native, Flutter test)
- Phase 4: Cloud device farms (BrowserStack, Sauce Labs)

**Deliverables:**
- Mobile testing plugin (~1,500-2,000 lines)
- Appium integration
- Selector generation helpers
- Device configuration templates
- Gesture test templates
- Visual regression setup
- 20+ unit tests
- Integration tests with sample apps
- User guide

**Success Criteria:**
- âœ… Generate mobile tests in <2 minutes
- âœ… Tests run on both iOS and Android
- âœ… Selector stability >90%
- âœ… Visual regression detection accuracy >95%

**Footprint Impact:** +3.2% (~2,000 lines)

---

**Phase 9 Summary:**
- **Total Time:** 4 weeks
- **Total Footprint:** +6.4% (~4,000 lines)
- **Total Value:** â­â­â­â­ (High)
- **Risk:** Medium (more complex integrations)
- **Dependencies:** Appium, platform SDKs, OpenAPI parsers

---

**ğŸš« Deferred Capabilities (Not Recommended for Core CORTEX)**

**Figma Integration:**
- **Recommendation:** Use third-party tools (Anima, Figma-to-Code)
- **Rationale:** High complexity (+6.4% footprint), moderate value, better existing solutions
- **Alternative:** Create lightweight integration plugin with existing tools

**A/B Testing:**
- **Recommendation:** Use existing platforms (Optimizely, LaunchDarkly, VWO)
- **Rationale:** High complexity (+4.0% footprint), specialized use case, excellent existing platforms
- **Alternative:** Create integration plugin for popular A/B testing platforms

**Total Deferred Footprint:** +10.4% (avoided by using integrations instead)

---

### ğŸ“Š Holistic CORTEX 2.0 + Capabilities Summary

**Vision:** Transform CORTEX from a conversation-tracking assistant into a **comprehensive, full-spectrum AI development partner** that rivals and exceeds traditional development tools.

**Strategic Phases:**

```
Phase 0-3 (Week 1-16): CORTEX 2.0 CORE
â”œâ”€ Fix "continue" amnesia problem (20% â†’ 98% success)
â”œâ”€ Modularize monolithic code (SOLID compliance)
â”œâ”€ Build VS Code extension (definitive solution)
â””â”€ Establish world-class conversation tracking

Phase 4-7 (Week 17-24): QUALITY & ROLLOUT
â”œâ”€ Risk mitigation testing
â”œâ”€ Performance optimization
â”œâ”€ Documentation & training
â””â”€ Production rollout

Phase 8 (Week 25-28): CAPABILITY WAVE 1 ğŸ†•
â”œâ”€ Code Review Plugin (automated PR reviews)
â”œâ”€ Web Testing Enhancements (Lighthouse + accessibility)
â””â”€ Reverse Engineering Plugin (legacy code analysis)

Phase 9 (Week 29-32): CAPABILITY WAVE 2 ğŸ†•
â”œâ”€ UI from Spec Plugin (OpenAPI â†’ React/Vue/Angular)
â””â”€ Mobile Testing Plugin (Appium cross-platform)
```

**What CORTEX Will Be After Week 32:**

| Capability Area | Status | Best-in-Class? | Competitive Edge |
|----------------|--------|----------------|------------------|
| **Conversation Memory** | âœ… 98% success | âœ… YES | Only AI with persistent memory |
| **Code Writing** | âœ… Ready | âœ… YES | Pattern-aware, test-first |
| **Code Documentation** | âœ… Ready | âœ… YES | 4-quadrant, auto-refresh |
| **Backend Testing** | âœ… Ready | âœ… YES | pytest, MSTest, Jest |
| **Code Rewrite** | âœ… Ready | âœ… YES | SOLID-compliant refactoring |
| **Code Review** | ğŸ“‹ Phase 8 | âœ… YES | Pattern + security aware |
| **Web Testing** | ğŸ“‹ Phase 8 | âœ… YES | Playwright + Lighthouse + a11y |
| **Reverse Engineering** | ğŸ“‹ Phase 8 | âœ… YES | Multi-language + diagrams |
| **UI Generation** | ğŸ“‹ Phase 9 | ğŸŸ¡ GOOD | From OpenAPI/GraphQL specs |
| **Mobile Testing** | ğŸ“‹ Phase 9 | ğŸŸ¡ GOOD | Appium cross-platform |
| **Figma Integration** | âŒ Deferred | N/A | Use Anima instead |
| **A/B Testing** | âŒ Deferred | N/A | Use Optimizely instead |

**Market Positioning After Completion:**

> **"CORTEX 2.0: The only AI development partner with perfect memory, comprehensive testing, automated code review, and full-spectrum development capabilities from backend to mobile."**

**Competitive Analysis:**

| Feature | GitHub Copilot | Cursor AI | Cody | **CORTEX 2.0** |
|---------|---------------|-----------|------|----------------|
| Code Writing | âœ… Excellent | âœ… Excellent | âœ… Good | âœ… Excellent |
| Conversation Memory | âŒ None | ğŸŸ¡ Session only | ğŸŸ¡ Basic | âœ… **Perfect (98%)** |
| Test Generation | ğŸŸ¡ Basic | ğŸŸ¡ Basic | ğŸŸ¡ Basic | âœ… **Comprehensive** |
| Code Review | âŒ None | âŒ None | âŒ None | âœ… **Automated PR** |
| Reverse Engineering | âŒ None | âŒ None | âŒ None | âœ… **Full analysis** |
| Mobile Testing | âŒ None | âŒ None | âŒ None | âœ… **Cross-platform** |
| UI Generation | âŒ None | âŒ None | âŒ None | âœ… **From specs** |
| Documentation | ğŸŸ¡ Basic | ğŸŸ¡ Basic | ğŸŸ¡ Basic | âœ… **4-quadrant** |

**Key Differentiators:**
1. **Perfect Memory:** Only AI that remembers everything across sessions
2. **Full Spectrum:** Backend â†’ Frontend â†’ Mobile â†’ Testing â†’ Review
3. **Pattern Learning:** Gets smarter with every feature built
4. **Test-First:** TDD baked into DNA
5. **Quality Obsessed:** Automated reviews, SOLID compliance, security scanning
6. **Self-Improving:** Self-review system, performance tracking

**Target Audience Expansion:**

**Phase 0-7 (Core):**
- Individual developers
- Small teams (2-5 developers)
- Focus: Conversation continuity, code quality

**Phase 8 (Wave 1):**
- Medium teams (5-20 developers)
- Enterprise teams with legacy code
- Focus: Code review automation, technical debt reduction

**Phase 9 (Wave 2):**
- Full-stack teams
- Mobile development teams
- Backend-first organizations
- Focus: UI generation, mobile testing

**ROI by Phase:**

| Phase | Investment | Value Added | ROI Multiple |
|-------|-----------|-------------|--------------|
| Phase 0 | 6.5 hours | 3x "continue" improvement | 10:1 |
| Phase 1-3 | 90 hours | 5x conversation improvement | 8:1 |
| Phase 4-7 | 60 hours | Production readiness | 5:1 |
| **Phase 8** | **40 hours** | **Code review + reverse eng** | **12:1** |
| **Phase 9** | **40 hours** | **Mobile + UI generation** | **8:1** |
| **Total** | **236.5 hours** | **Full-spectrum AI assistant** | **9:1 average** |

**Footprint Analysis:**

```
Current Codebase:        63,000 lines
+ Phase 0-7 (Core):      ~0 lines (refactoring, no net increase)
+ Phase 8 (Wave 1):      +2,800 lines (+4.5%)
+ Phase 9 (Wave 2):      +4,000 lines (+6.4%)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total After Phase 9:     69,800 lines (+10.9%)

Deferred (Smart Decision):
  Figma Integration:     +4,000 lines (use Anima instead)
  A/B Testing:           +2,500 lines (use Optimizely instead)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total Saved:             +6,500 lines (10.3% footprint avoided)
```

**Efficiency Ratio:**
- **10.9% footprint increase** for **~500% capability increase**
- This is exceptional: **46:1 value-to-footprint ratio**

**Timeline Summary:**

| Milestone | Week | Deliverable | Impact |
|-----------|------|-------------|--------|
| Phase 0 Complete | 2 | âœ… DONE | 60% continue success |
| Phase 3 Complete | 16 | Extension live | 98% continue success |
| Phase 7 Complete | 24 | Core rollout | Best AI memory |
| **Phase 8 Complete** | **28** | **Code review + reverse eng** | **Enterprise ready** |
| **Phase 9 Complete** | **32** | **Full spectrum** | **Market leader** |

**Critical Success Factors:**

1. **Maintain Quality:** Every phase must pass 85%+ test coverage
2. **No Bloat:** Strict <500 line module limit
3. **Plugin Architecture:** All enhancements must be plugins (can be disabled)
4. **Performance First:** No feature ships if it degrades performance
5. **User Validation:** Beta testing after every major phase
6. **Pragmatic Deferrals:** Don't build what exists better elsewhere

**Risk Mitigation:**

| Risk | Probability | Impact | Mitigation |
|------|------------|--------|------------|
| Timeline slip | Medium | Medium | Buffer weeks, phased delivery |
| Capability bloat | Low | High | Plugin architecture, strict limits |
| Performance degradation | Low | High | Continuous benchmarking |
| User adoption issues | Low | Medium | Beta testing, gradual rollout |
| Technical debt | Low | Medium | SOLID compliance, code review |

**Post-Week 32 (Future Roadmap):**

**Optional Enhancements (Business-Driven):**
- Native mobile frameworks (XCUITest, Espresso) if mobile adoption >50%
- Additional language support (Go, Rust, Java) if requested by >10 teams
- Cloud IDE integration (GitHub Codespaces, GitPod) if market demands
- AI pair programming mode (collaborative editing) if users request

**Community-Driven:**
- Open source plugins from community
- Custom agent development by users
- Third-party integrations (JIRA, Linear, Notion)

**Enterprise Features (If Commercialized):**
- Team analytics dashboard
- Multi-workspace sync
- Enterprise security compliance
- Role-based access control
- Audit logging

---

### Success Metrics & ROI

**ğŸ¯ "Continue" Command Success Rate (PRIMARY METRIC)**

| Phase | Success Rate | Impact | Time Investment |
|-------|-------------|--------|-----------------|
| **Current (No Fix)** | 20% | âŒ "I just told you that!" frustration | Baseline |
| **Phase 0 (Quick Wins)** | 60% | âœ… Work state tracking + session persistence | 6.5 hours |
| **Phase 2 (Ambient Capture)** | 85% | âœ… Background context capture | +30 hours |
| **Phase 3 (Extension)** | 98% | âœ… Zero-friction, automatic everything | +60 hours |

**ROI Analysis:**
- Every hour invested saves 10+ hours of user frustration over next month
- Phase 0 investment: 6.5 hours â†’ 3x improvement (20% â†’ 60%)
- Total investment: 96.5 hours â†’ 5x improvement (20% â†’ 98%)

---

**Technical Metrics:**

**Code Quality:**
- âœ… All files <500 lines (SOLID compliance)
- âœ… Test coverage >90% (Phase 4 enhancement)
- âœ… Zero circular dependencies
- âœ… Zero critical bugs

**Performance:**
- âœ… Tier 1 queries: <50ms (working memory)
- âœ… Tier 2 search: <150ms (knowledge graph)
- âœ… Tier 3 metrics: <200ms (context intelligence)
- âœ… Extension capture: <100ms (real-time tracking)
- âœ… Overall +20% improvement from baseline

**Reliability:**
- âœ… Bug rate <0.1% critical
- âœ… Crash recovery success rate >95%
- âœ… Extension stability >95%
- âœ… Data loss incidents: 0

**Conversation Tracking:**
- âœ… **Zero manual conversation capture needed** (Phase 3)
- âœ… Automatic capture success rate >99%
- âœ… Average resume time <2 seconds
- âœ… External chat capture rate >90% (Copilot monitoring)
- âœ… Session token persistence: 100%
- âœ… Work state tracking accuracy: 95%

---

**User Experience Metrics:**

**Satisfaction:**
- âœ… User satisfaction â‰¥4.5/5
- âœ… Feature adoption â‰¥80%
- âœ… Extension adoption >70% within 2 weeks
- âœ… Support tickets -30%
- âœ… Onboarding time -50%

**Productivity:**
- âœ… **Conversation amnesia reports: 0** (Phase 3)
- âœ… Time to resume work: <30 seconds (down from 5-10 minutes)
- âœ… Context loss rate: <2% (down from 80%)
- âœ… User frustration reports: -90%
- âœ… "It just works" feedback: >80%

**Extension Specific:**
- âœ… Extension install rate >1,000/month
- âœ… Active daily users: >500
- âœ… VS Code Marketplace rating: â‰¥4.5 stars
- âœ… Extension crash rate: <0.1%
- âœ… Average session length: >30 minutes (user engagement)

---

**Business Metrics:**

**Development Velocity:**
- âœ… Feature delivery time: -25% (less rework from lost context)
- âœ… Bug resolution time: -30% (better context retention)
- âœ… Developer onboarding: -50% (clearer documentation + working examples)

**Technical Debt:**
- âœ… Code maintainability: +40% (SOLID refactoring)
- âœ… Test coverage: +15% (from 75% to 90%)
- âœ… Documentation completeness: 100%

**Community & Adoption:**
- âœ… GitHub stars: >100 (if open-sourced)
- âœ… Community contributors: >5
- âœ… Extension reviews: >50 positive
- âœ… Documentation site traffic: >1,000 visitors/month

---

**Capability Enhancement Metrics (Phase 8-9):**

**Code Review (Phase 8.1):**
- âœ… PR review adoption: >70%
- âœ… False positive rate: <10%
- âœ… Review time: <30 seconds per PR
- âœ… Security issue detection: >90%
- âœ… Developer satisfaction: â‰¥4.3/5

**Web Testing Enhancements (Phase 8.2):**
- âœ… Performance test coverage: 100% of critical paths
- âœ… Accessibility score: >90% on all pages
- âœ… Core Web Vitals: All pages pass
- âœ… Test generation time: <2 minutes

**Reverse Engineering (Phase 8.3):**
- âœ… Legacy projects documented: >50
- âœ… Analysis time: <5 minutes for 10K+ line codebase
- âœ… Diagram generation accuracy: >95%
- âœ… Refactoring recommendations actionable: >80%
- âœ… Pattern detection accuracy: >85%

**UI from Spec (Phase 9.1):**
- âœ… UI generation time: <1 minute for complete CRUD
- âœ… Generated components compile: 100%
- âœ… Form validation functional: First run
- âœ… API integration functional: First run
- âœ… Adoption rate: >60%

**Mobile Testing (Phase 9.2):**
- âœ… Test generation time: <2 minutes
- âœ… Cross-platform (iOS + Android): Works
- âœ… Selector stability: >90%
- âœ… Visual regression accuracy: >95%
- âœ… Mobile test coverage: >40%

**Overall Capability Impact:**
- âœ… Developer productivity: +35% (combined with core improvements)
- âœ… Code quality: +25% (automated reviews + reverse engineering)
- âœ… Test coverage: +20% (web + mobile + backend)
- âœ… Time to market: -30% (UI generation + automated testing)

---

### ğŸ” Phase Validation Checklist (CORTEX 2.0)

**Purpose:** Ensure each implementation phase is complete, error-free, and conflict-free before proceeding.

**ğŸ“‹ Reference:** Based on `cortex-brain/cortex-2.0-design/00-INDEX.md` and `25-implementation-roadmap.md`

---

#### âœ… Universal Phase Completion Checklist

**Use this checklist for EVERY phase before requesting approval to continue.**

**1. Implementation Completeness**
- [ ] All tasks in phase completed (no partial work)
- [ ] All files created/modified as specified in design docs
- [ ] All code follows CORTEX coding standards
- [ ] All modules under 500 lines (per CORTEX 2.0 goal)
- [ ] No TODO comments or placeholder code left behind
- [ ] All functions have docstrings
- [ ] All imports organized and minimal

**2. Testing & Quality**
- [ ] All new unit tests written and passing
- [ ] All integration tests written and passing
- [ ] All existing tests still passing (zero regressions)
- [ ] Test coverage â‰¥85% for new code
- [ ] No test timeouts or flaky tests
- [ ] Performance benchmarks met (if applicable)
- [ ] Memory usage within acceptable limits

**3. Error & Warning Elimination**
- [ ] Zero Python errors (syntax, runtime, type)
- [ ] Zero linter warnings (pylint, flake8, mypy)
- [ ] Zero TypeScript errors (if extension work)
- [ ] Zero console warnings in tests
- [ ] All deprecation warnings addressed
- [ ] Build completes cleanly

**4. Cross-Phase Conflict Detection**
- [ ] No import conflicts with other phases
- [ ] No duplicate function/class names across modules
- [ ] No circular dependencies created
- [ ] No schema conflicts with database migrations
- [ ] No API signature conflicts
- [ ] Configuration changes don't break other phases
- [ ] Path references remain valid across phases

**5. Integration Validation**
- [ ] New code integrates with existing tiers (Tier 0-3)
- [ ] Agent coordination still works
- [ ] BRAIN operations unaffected (or enhanced)
- [ ] Session management still functional
- [ ] Conversation tracking still works
- [ ] File operations still work across platforms

**6. Documentation**
- [ ] Design doc updated (if changes from plan)
- [ ] API documentation generated
- [ ] Code comments explain complex logic
- [ ] Migration guide updated (if breaking changes)
- [ ] Changelog entry added
- [ ] README updated (if user-facing changes)

**7. Rollback Safety**
- [ ] Git commits are atomic and well-messaged
- [ ] Can rollback without breaking other phases
- [ ] Database migrations have down() methods
- [ ] Configuration changes are backwards compatible
- [ ] Feature flags in place (if applicable)

---

#### ğŸ“Š Phase-Specific Validation Checklists

---

##### **Phase 0: Baseline Establishment** âœ… COMPLETE

**Unique Validations:**
- [ ] Test suite baseline report generated
- [ ] Current architecture documented with diagrams
- [ ] Risk assessment matrix completed
- [ ] Monitoring baselines established
- [ ] All 27 core rules documented and validated

**Conflict Checks:**
- [ ] Baseline metrics don't interfere with existing operations
- [ ] Documentation doesn't contradict existing rules
- [ ] Test baseline can be regenerated without errors

**Deliverables:**
- [ ] `BASELINE-REPORT.md` exists and is complete
- [ ] `IMPLEMENTATION-KICKOFF.md` exists
- [ ] Architecture diagrams saved
- [ ] Risk assessment spreadsheet/doc created

---

##### **Phase 1: Core Modularization** ğŸ“‹ NEXT

**1.1 Knowledge Graph Refactoring**

**Unique Validations:**
- [ ] All 6 modules created as per design
- [ ] `knowledge_graph.py` reduced to <150 lines (coordinator only)
- [ ] Database operations isolated in `database/` modules
- [ ] Pattern operations isolated in `patterns/` modules
- [ ] Relationship operations isolated in `relationships/` modules
- [ ] Tag operations isolated in `tags/` modules
- [ ] 45 unit tests passing
- [ ] 8 integration tests passing

**Conflict Checks:**
- [ ] Old `knowledge_graph.py` imports still work (backwards compat)
- [ ] No circular imports between new modules
- [ ] Database schema unchanged (or migration provided)
- [ ] FTS5 search still works with same performance
- [ ] Pattern confidence decay still functions
- [ ] Tier 2 API unchanged for external callers
- [ ] Brain update operations still atomic
- [ ] Query performance unchanged or improved

**Cross-Phase Checks:**
- [ ] Tier 1 (working memory) can still query Tier 2
- [ ] Tier 3 (context) can still query Tier 2
- [ ] Brain updater still works
- [ ] Brain query still works
- [ ] Conversation manager integration intact

**Test Harness Updates:**
```python
# Add to tests/tier2/test_modular_integration.py
def test_no_circular_imports():
    """Ensure no circular dependencies in knowledge graph modules"""
    # Test each module can import independently
    
def test_backwards_compatibility():
    """Ensure old knowledge_graph imports still work"""
    # Test deprecated imports with warnings
    
def test_tier_integration():
    """Ensure Tier 1 and Tier 3 can still access Tier 2"""
    # Test cross-tier queries
```

---

**1.2 Tier 1 Working Memory Refactoring**

**Unique Validations:**
- [ ] All 5 modules created as per design
- [ ] `working_memory.py` reduced to <120 lines
- [ ] Conversation operations isolated in `conversations/` modules
- [ ] Message operations isolated in `messages/` modules
- [ ] Entity extraction isolated in `entities/` module
- [ ] FIFO queue logic isolated
- [ ] 38 unit tests passing
- [ ] 6 integration tests passing

**Conflict Checks:**
- [ ] Conversation history API unchanged
- [ ] Message storage format unchanged
- [ ] FIFO queue behavior identical (20 conversations)
- [ ] Entity extraction results identical
- [ ] Tier 1 API unchanged for external callers
- [ ] Session resume still works
- [ ] Conversation boundaries still detected correctly

**Cross-Phase Checks:**
- [ ] Phase 1.1 (Tier 2) can still query Tier 1
- [ ] Brain updater can still access conversation data
- [ ] Context collector can still read conversations
- [ ] No conflicts with knowledge graph refactoring
- [ ] Combined import statements work

**Test Harness Updates:**
```python
# Add to tests/tier1/test_working_memory_conflicts.py
def test_no_conflicts_with_tier2():
    """Ensure Tier 1 and Tier 2 modules don't conflict"""
    
def test_fifo_behavior_unchanged():
    """Verify FIFO queue works identically after refactor"""
    
def test_entity_extraction_consistency():
    """Ensure entity extraction produces same results"""
```

---

**1.3 Context Intelligence Refactoring**

**Unique Validations:**
- [ ] All 6 modules created as per design
- [ ] `context_intelligence.py` reduced to <100 lines
- [ ] Git metrics isolated in `metrics/` modules
- [ ] Analysis logic isolated in `analysis/` modules
- [ ] Storage isolated in `storage/` module
- [ ] 42 unit tests passing
- [ ] 7 integration tests passing

**Conflict Checks:**
- [ ] Development context API unchanged
- [ ] Git metrics collection unchanged
- [ ] File hotspot detection identical
- [ ] Velocity calculations identical
- [ ] Tier 3 API unchanged for external callers
- [ ] Proactive warnings still work
- [ ] Correlation analysis still functions

**Cross-Phase Checks:**
- [ ] No conflicts with Tier 1 refactoring (Phase 1.2)
- [ ] No conflicts with Tier 2 refactoring (Phase 1.1)
- [ ] Brain updater can still trigger Tier 3 collection
- [ ] Dashboard can still read Tier 3 data
- [ ] Metrics reporter still works

**Test Harness Updates:**
```python
# Add to tests/tier3/test_context_conflicts.py
def test_no_conflicts_with_tier1_tier2():
    """Ensure Tier 3 doesn't conflict with Tier 1 and 2 refactors"""
    
def test_metrics_consistency():
    """Verify metrics calculations identical after refactor"""
    
def test_cross_tier_data_flow():
    """Ensure data flows correctly across all 3 tiers"""
```

---

**1.4 Agent Modularization**

**Unique Validations:**
- [ ] All 5 agents refactored (error_corrector, health_validator, code_executor, test_generator, work_planner)
- [ ] Each agent reduced to <150 lines (coordinator)
- [ ] Strategy pattern implemented for each agent
- [ ] Validators isolated per agent
- [ ] Parsers isolated per agent
- [ ] 60+ unit tests passing (12 per agent)

**Conflict Checks:**
- [ ] Agent APIs unchanged (same function signatures)
- [ ] Agent behavior identical from caller perspective
- [ ] Error handling consistent across agents
- [ ] Result formats unchanged
- [ ] Agent coordination still works
- [ ] Router can still invoke all agents
- [ ] No agent strategy conflicts

**Cross-Phase Checks:**
- [ ] Agents can still access refactored Tiers 1-3
- [ ] Workflow pipeline can still orchestrate agents
- [ ] Brain updater integration intact
- [ ] All agent prompts still load correctly

**Test Harness Updates:**
```python
# Add to tests/agents/test_agent_conflicts.py
def test_no_agent_strategy_conflicts():
    """Ensure agent strategies don't conflict"""
    
def test_agent_tier_integration():
    """Verify agents work with refactored tiers"""
    
def test_agent_coordination():
    """Ensure agents can still coordinate via router"""
```

---

##### **Phase 2: Workflow Pipeline** 

**Unique Validations:**
- [ ] Core pipeline with checkpointing complete
- [ ] Parallel execution implemented
- [ ] Conditional stages work
- [ ] All 8 critical stages implemented
- [ ] 4 production workflows defined
- [ ] 32 stage tests passing
- [ ] 16 workflow integration tests passing

**Conflict Checks:**
- [ ] Workflow definitions don't conflict with each other
- [ ] Stages can run in any valid order
- [ ] DAG validation catches circular dependencies
- [ ] Checkpoint/resume doesn't interfere with agent state
- [ ] Parallel execution doesn't cause race conditions
- [ ] Workflow state isolated from agent state

**Cross-Phase Checks:**
- [ ] Workflows can invoke refactored agents (Phase 1.4)
- [ ] Workflows can access refactored tiers (Phase 1.1-1.3)
- [ ] No conflicts with existing session management
- [ ] Brain updates still work during workflow execution

**Test Harness Updates:**
```python
# Add to tests/workflows/test_workflow_conflicts.py
def test_no_workflow_race_conditions():
    """Ensure parallel stages don't conflict"""
    
def test_workflow_agent_integration():
    """Verify workflows work with refactored agents"""
    
def test_checkpoint_isolation():
    """Ensure checkpoints don't interfere with other state"""
```

---

##### **Phase 3: VS Code Extension**

**Unique Validations:**
- [ ] Extension scaffold generated
- [ ] TypeScript project builds without errors
- [ ] Python â†” TypeScript bridge functional
- [ ] Chat participant registered
- [ ] Lifecycle hooks working
- [ ] External monitoring functional
- [ ] Extension tests passing
- [ ] VSIX package builds successfully

**Conflict Checks:**
- [ ] Extension doesn't interfere with CLI mode
- [ ] Python backend still works standalone
- [ ] Extension state isolated from brain state
- [ ] Multiple extension instances don't conflict
- [ ] Extension activation doesn't break existing workflows

**Cross-Phase Checks:**
- [ ] Extension can invoke refactored agents
- [ ] Extension can access refactored tiers
- [ ] Extension workflows compatible with Phase 2 pipelines
- [ ] Extension doesn't break existing tests

**Test Harness Updates:**
```python
# Add to tests/extension/test_extension_conflicts.py
def test_cli_extension_coexistence():
    """Ensure CLI and extension can run simultaneously"""
    
def test_extension_brain_isolation():
    """Verify extension state doesn't corrupt brain"""
    
def test_extension_backwards_compat():
    """Ensure extension works with pre-extension brain data"""
```

---

##### **Phase 4: Risk Mitigation & Testing**

**Unique Validations:**
- [ ] 75 new risk mitigation tests added
- [ ] All risk scenarios covered
- [ ] End-to-end integration tests passing
- [ ] Extension stability tests passing
- [ ] Security scenario tests passing
- [ ] Performance benchmarks met

**Conflict Checks:**
- [ ] New tests don't interfere with existing tests
- [ ] Test execution order doesn't matter
- [ ] No test fixtures conflict
- [ ] No test database conflicts
- [ ] Mock objects properly isolated

**Cross-Phase Checks:**
- [ ] Risk tests cover all previous phases
- [ ] Tests validate cross-phase integration
- [ ] Performance tests cover full stack
- [ ] Security tests cover all entry points

**Test Harness Updates:**
```python
# Add to tests/risk/test_comprehensive_coverage.py
def test_all_phases_covered():
    """Ensure risk tests cover all implementation phases"""
    
def test_no_test_conflicts():
    """Verify tests can run in any order without conflicts"""
```

---

##### **Phase 5: Performance Optimization**

**Unique Validations:**
- [ ] Database optimization complete (FTS5, caching)
- [ ] Workflow optimization complete (parallel stages)
- [ ] Context injection optimized
- [ ] Extension responsiveness tuned
- [ ] Lazy loading implemented
- [ ] Performance benchmarks show â‰¥20% improvement

**Conflict Checks:**
- [ ] Optimizations don't change API behavior
- [ ] Caching doesn't cause stale data issues
- [ ] Lazy loading doesn't break initialization
- [ ] Parallel execution doesn't introduce race conditions
- [ ] Optimizations don't break tests

**Cross-Phase Checks:**
- [ ] Optimizations work with all refactored modules
- [ ] Performance gains apply to all workflows
- [ ] Extension performance improved
- [ ] No regressions in any tier

**Test Harness Updates:**
```python
# Add to tests/performance/test_optimization_correctness.py
def test_optimizations_preserve_behavior():
    """Ensure optimizations don't change results"""
    
def test_cache_consistency():
    """Verify cached data stays consistent"""
    
def test_lazy_loading_completeness():
    """Ensure lazy loading eventually loads everything"""
```

---

##### **Phase 6: Documentation & Training**

**Unique Validations:**
- [ ] Architecture guides complete
- [ ] Developer guides complete
- [ ] User tutorials complete
- [ ] API reference generated
- [ ] Migration guide complete
- [ ] All code examples working
- [ ] All links valid

**Conflict Checks:**
- [ ] Documentation doesn't contradict between guides
- [ ] Code examples don't conflict with each other
- [ ] API docs match actual implementation
- [ ] Migration guide steps tested and valid

**Cross-Phase Checks:**
- [ ] Documentation covers all previous phases
- [ ] Examples use refactored modules correctly
- [ ] Tutorials work with final implementation

**Test Harness Updates:**
```python
# Add to tests/docs/test_documentation_accuracy.py
def test_code_examples_execute():
    """Ensure all documentation code examples run"""
    
def test_api_docs_match_code():
    """Verify API docs match actual function signatures"""
```

---

##### **Phase 7: Migration & Rollout**

**Unique Validations:**
- [ ] Feature flags implemented
- [ ] Dual-mode operation working
- [ ] Alpha testing complete
- [ ] Beta testing complete
- [ ] Monitoring and validation systems operational
- [ ] Marketplace publication successful

**Conflict Checks:**
- [ ] Feature flags don't conflict with each other
- [ ] Dual-mode doesn't cause data corruption
- [ ] CLI and extension modes coexist
- [ ] Rollback procedures tested

**Cross-Phase Checks:**
- [ ] All phases work together in production
- [ ] No conflicts between any components
- [ ] Full stack integration validated
- [ ] User migration path tested

**Test Harness Updates:**
```python
# Add to tests/migration/test_full_system_integration.py
def test_all_phases_integrated():
    """Comprehensive test of all phases working together"""
    
def test_feature_flag_combinations():
    """Test all valid feature flag combinations"""
    
def test_dual_mode_isolation():
    """Ensure CLI and extension modes don't interfere"""
```

---

#### ğŸ›¡ï¸ Automated Conflict Detection

**Create Test Suite:** `tests/cortex_2.0/test_phase_conflicts.py`

```python
"""
CORTEX 2.0 Phase Conflict Detection Test Suite
Ensures no phase interferes with another phase
"""
import pytest
import importlib
import sys
from pathlib import Path

class TestPhaseConflicts:
    """Detect conflicts between implementation phases"""
    
    def test_no_circular_imports(self):
        """Ensure no circular dependencies across phases"""
        # Test each module can import independently
        phases = [
            'src.tier1', 'src.tier2', 'src.tier3',
            'src.cortex_agents', 'src.workflows'
        ]
        for phase in phases:
            try:
                importlib.import_module(phase)
            except ImportError as e:
                pytest.fail(f"Circular import detected in {phase}: {e}")
    
    def test_no_name_conflicts(self):
        """Ensure no duplicate function/class names"""
        # Scan all modules for conflicts
        pass  # Implementation depends on project structure
    
    def test_database_schema_consistency(self):
        """Ensure all phases use consistent schema"""
        # Verify no schema conflicts
        pass
    
    def test_api_signature_consistency(self):
        """Ensure API signatures remain stable across phases"""
        # Test each public API matches expected signature
        pass
    
    def test_configuration_compatibility(self):
        """Ensure config changes don't break other phases"""
        # Test config can be loaded by all phases
        pass
    
    def test_cross_tier_integration(self):
        """Ensure all tiers can communicate after refactoring"""
        # Test Tier 1 â†” Tier 2 â†” Tier 3
        pass
    
    def test_agent_coordination(self):
        """Ensure agents can coordinate after refactoring"""
        # Test router can invoke all agents
        pass
    
    def test_workflow_agent_integration(self):
        """Ensure workflows can invoke agents"""
        # Test workflow pipeline with agents
        pass
    
    def test_extension_cli_coexistence(self):
        """Ensure extension and CLI don't conflict"""
        # Test both modes simultaneously
        pass
    
    def test_performance_no_regression(self):
        """Ensure optimizations don't cause regressions"""
        # Run baseline vs current benchmarks
        pass
```

---

#### ğŸ“ Phase Completion Report Template

**Use this template when completing each phase:**

```markdown
# Phase [N]: [Phase Name] Completion Report

**Date:** [YYYY-MM-DD]
**Duration:** [X weeks/days]
**Status:** âœ… COMPLETE

## Implementation Summary
- Tasks completed: [X/X]
- Files created/modified: [N]
- Lines of code: [Added: X, Removed: Y, Net: Z]
- Modules: [List key modules]

## Testing Results
- Unit tests: [X/X passing]
- Integration tests: [X/X passing]
- Test coverage: [X%]
- Performance benchmarks: [Met/Exceeded/Within tolerance]

## Quality Metrics
- Errors: 0
- Warnings: 0
- Linter score: [X/10]
- Code complexity: [Within acceptable range]

## Conflict Detection
- Circular imports: âœ… None detected
- Name conflicts: âœ… None detected
- API conflicts: âœ… None detected
- Database conflicts: âœ… None detected
- Cross-phase integration: âœ… All tests passing

## Deliverables
- [ ] All tasks complete
- [ ] All tests passing
- [ ] Documentation updated
- [ ] Conflict tests added
- [ ] Performance validated
- [ ] Ready for next phase

## Approval
- [ ] Self-review complete
- [ ] Automated checks passed
- [ ] Ready to proceed to Phase [N+1]

**Approved by:** [Name]
**Approval Date:** [YYYY-MM-DD]
```

---

#### ğŸš¨ Blocking Issues Protocol

**If any checklist item fails:**

1. **STOP** - Do not proceed to next phase
2. **Document** - Create issue with failure details
3. **Fix** - Resolve the issue completely
4. **Retest** - Run full validation checklist again
5. **Verify** - Ensure fix doesn't create new conflicts
6. **Proceed** - Only continue when all checks pass

**Example Blocking Issue:**

```markdown
## âš ï¸ BLOCKING ISSUE: Phase 1.1

**Issue:** Circular import detected between pattern_search.py and pattern_decay.py

**Impact:** Cannot proceed to Phase 1.2 until resolved

**Resolution:**
1. Refactor pattern_decay to not import from pattern_search
2. Create shared utilities module for common functions
3. Update tests
4. Re-run validation checklist

**Status:** IN PROGRESS
**Target Resolution:** [Date]
```

---

#### âœ… Final Pre-Release Checklist

**Before declaring CORTEX 2.0 complete:**

- [ ] All 7 phases complete with passing validation
- [ ] Zero blocking issues remain
- [ ] Full system integration test passing
- [ ] All 27 core rules still enforced
- [ ] Performance â‰¥20% improvement over 1.0
- [ ] Test coverage â‰¥85%
- [ ] Documentation complete and accurate
- [ ] Migration guide tested with real users
- [ ] Rollback procedures documented and tested
- [ ] Monitoring dashboard operational
- [ ] All conflict detection tests passing
- [ ] No regressions in any existing functionality
- [ ] Extension and CLI modes both functional
- [ ] Marketplace publication approved (if applicable)

---

### Learn More

**Design Documentation:** `cortex-brain/cortex-2.0-design/`
- **00-INDEX.md** - Complete roadmap of 27 design documents
- **01-core-architecture.md** - Hybrid approach (70/20/10)
- **02-plugin-system.md** - Extensibility architecture
- **03-conversation-state.md** - Resume and task tracking
- **07-self-review-system.md** - Health monitoring
- **25-implementation-roadmap.md** - Detailed timeline

**Story:** `docs/story/Cortex-Trinity/`
- **Awakening Of CORTEX.md** - The complete journey
- **Technical-CORTEX.md** - Technical deep-dive
- **Image-Prompts.md** - Visual diagrams

---

### Story Review Rule (Quadrant Documentation)
All narrative content (e.g., #file:Story.md) must be reviewed for:
- Corrections of factual, grammatical, or clarity issues
- Improvements in flow, completeness, or engagement
- Filling any missing elements that enhance understanding or fun
Edits must preserve the original style, theme, and narrative voice. The story should remain enjoyable and true to its intended spirit after any changes.


## ğŸ§š A story for humans: The Intern with Amnesia

### Meet Your Intern: Copilot

You've just hired a brilliant intern named Copilot. They're incredibly talentedâ€”can write code in any language, understand complex systems, and work at lightning speed. There's just one problem: **Copilot has amnesia**.

Every time you walk away, even for a coffee break, Copilot forgets everything. You said "make it purple" five minutes ago? Gone. The file you were just discussing? Vanished from memory. The architecture you explained yesterday? As if it never happened.

Worse, Copilot has no memory between chat sessions. Start a new conversation? They don't remember the last one. Leave for lunch? When you return, it's like meeting them for the first time. Every. Single. Time.

This would be catastrophic... except you've done something revolutionary: **you've built Copilot a brain**.

### The Brain: A Sophisticated Cognitive System

The brain you built isn't just storageâ€”it's a sophisticated dual-hemisphere system modeled after the human brain:

#### **ğŸ§  LEFT HEMISPHERE - The Tactical Executor**
Like the human left brain (language, logic, sequential processing), this hemisphere handles:
- **Test-Driven Development** - RED (write failing test) â†’ GREEN (make it pass) â†’ REFACTOR (clean up)
- **Precise Code Execution** - Exact file edits, line-by-line changes, syntax verification
- **Detail Verification** - Tests pass/fail, build status, zero errors/warnings enforcement
- **Sequential Workflows** - Step A, then B, then Câ€”no skipping steps

**The Left Brain Specialists:**
- **The Builder** (`code-executor.md`) - Implements code with surgical precision
- **The Tester** (`test-generator.md`) - Creates and runs tests, never skips TDD
- **The Fixer** (`error-corrector.md`) - Catches wrong-file mistakes instantly
- **The Inspector** (`health-validator.md`) - Validates system health obsessively
- **The Archivist** (`commit-handler.md`) - Commits with semantic precision

#### **ğŸ§  RIGHT HEMISPHERE - The Strategic Planner**
Like the human right brain (creativity, holistic thinking, patterns), this hemisphere handles:
- **Architecture Design** - Understands how components fit together project-wide
- **Strategic Planning** - Breaks big features into phases, estimates effort, assesses risk
- **Pattern Recognition** - "We've done something similar beforeâ€”here's the template"
- **Context Awareness** - Knows which files change together, what workflows succeed
- **Future Projection** - Warns about risky changes before you make them
- **Brain Protection** - Guards the brain's own integrity (Rule #22)

**The Right Brain Specialists:**
- **The Dispatcher** (`intent-router.md`) - Interprets your natural language, routes smartly
- **The Planner** (`work-planner.md`) - Creates multi-phase strategic plans
- **The Analyst** (`screenshot-analyzer.md`) - Extracts requirements from images
- **The Governor** (`change-governor.md`) - Protects CORTEX from degradation
- **The Brain Protector** (`brain-protector.md`) - Challenges risky proposals (NEW - Rule #22)

#### **ğŸŒ‰ CORPUS CALLOSUM - The Messenger**
The bridge between hemispheres that:
- **Coordinates Work** - Right brain plans â†’ Corpus callosum delivers â†’ Left brain executes
- **Shares Context** - Left brain's results feed Right brain's learning
- **Validates Alignment** - Ensures tactical execution matches strategic intent
- **Manages Message Queue** - Asynchronous communication between hemispheres

**Storage:** `cortex-brain/corpus-callosum/coordination-queue.jsonl`

#### **ğŸ” TIER 0: INSTINCT (Core Values - PERMANENT)**
The brain's immutable DNA that **cannot** be changed:
- **Definition of READY** - Work must have clear requirements before starting (RIGHT BRAIN enforces)
- **Test-Driven Development** - Always RED â†’ GREEN â†’ REFACTOR (LEFT BRAIN enforces)
- **Definition of DONE** - Zero errors, zero warnings, all tests pass (LEFT BRAIN validates)
- **Challenge User Changes** - If you propose risky changes, brain MUST challenge you
- **SOLID Principles** - Single Responsibility, no mode switches, clean architecture
- **Local-First** - Zero external dependencies, works offline, portable
- **Incremental File Creation** - Large files (>100 lines) created in small increments (prevents "response hit the length limit" errors) ğŸ†•

**Stored in:** `governance/rules.md` (never moves, never expires)

**ğŸ¯ NOTE:** Rule #23 (Incremental File Creation) automatically prevents the "response hit the length limit" error you've been experiencing. When creating large files like implementation plans, CORTEX will create them in small chunks (100-150 lines each) using multiple tool calls. This keeps each response small and avoids hitting Copilot's length limit. See `docs/guides/preventing-response-length-limit-errors.md` for details.

#### **ğŸ“š TIER 1: SHORT-TERM MEMORY (Last 20 Conversations)**
Copilot's working memory that solves the amnesia problem:
- **Conversation History** - Last 20 complete conversations preserved
- **Context Continuity** - "Make it purple" knows you mean the FAB button from earlier
- **Recent Messages** - Last 10 messages in active conversation
- **FIFO Queue** - When conversation #21 starts, #1 gets deleted (oldest goes first)
- **Active Protection** - Current conversation never deleted, even if oldest

**How it works:**
```
You: "Add a pulse animation to the FAB button"
â†’ Conversation #1 created, stored in Tier 1

[Later that day]
You: "Make it purple"
â†’ Brain checks Tier 1 â†’ Finds "FAB button" in conversation #1 â†’ Knows what "it" means

[2 weeks and 20 conversations later]
â†’ FIFO triggers â†’ Conversation #1 deleted
â†’ BUT patterns extracted â†’ Moved to Tier 2 (long-term memory)
```

**Stored in:** `cortex-brain/conversation-history.jsonl`, `cortex-brain/conversation-context.jsonl`

#### **ğŸ§© TIER 2: LONG-TERM MEMORY (Knowledge Graph)**
Copilot's accumulated wisdom that grows smarter over time:

**What gets learned:**
- **Intent Patterns** - "add a button" â†’ PLAN, "continue" â†’ EXECUTE, "test this" â†’ TEST
- **File Relationships** - `HostControlPanel.razor` often modified with `noor-canvas.css` (75% co-modification rate)
- **Workflow Templates** - export_feature_workflow, ui_component_creation, service_api_coordination
- **Validation Insights** - Common mistakes, file confusion warnings, architectural guidance
- **Correction History** - Tracks when Copilot works on wrong files, learns to prevent

**Hemisphere-Specialized Sections:**
```yaml
left_brain_knowledge:
  tdd_patterns: [red_green_refactor_cycle, test_first_service_creation]
  execution_workflows: [precise_file_edit, multi_file_coordination]
  validation_rules: [syntax_verification, health_check_criteria]

right_brain_knowledge:
  architectural_patterns: [blazor_component_structure, service_layer_injection]
  workflow_templates: [export_feature_workflow, ui_component_creation]
  intent_patterns: ["add [X]" â†’ PLAN, "continue" â†’ EXECUTE]

shared_knowledge:
  file_relationships: [co-modification patterns across all files]
  feature_components: [completed features and their patterns]
  correction_history: [learned mistakes from both hemispheres]
```

**How it learns:**
```
Day 1: You ask to "add invoice export"
â†’ Right brain plans workflow
â†’ Left brain executes with TDD
â†’ Pattern saved: invoice_export_feature (confidence: 0.85)

Day 30: You ask to "add receipt export"
â†’ Right brain queries Tier 2
â†’ Finds invoice_export pattern
â†’ Suggests: "This is similar to invoice export. Use same workflow?"
â†’ 60% faster delivery by reusing proven pattern
```

**Knowledge Boundaries (Protection System):**
Every pattern in Tier 2 is tagged with **scope** and **namespaces** to prevent CORTEX core intelligence from being contaminated by application-specific data:

```python
# Pattern storage with boundaries
scope="cortex"           # CORTEX principles (TDD, SOLID, refactoring)
scope="application"       # Application-specific (KSESSIONS features, NOOR UI)

namespaces=["CORTEX-core"]     # Available to all projects
namespaces=["KSESSIONS"]        # Only for KSESSIONS application
namespaces=["NOOR", "SPA"]      # Multi-application pattern
```

**Why boundaries matter:**
- **CORTEX intelligence stays pure** - No "add KSESSIONS logout button" patterns contaminate core
- **Application isolation** - KSESSIONS patterns don't leak into NOOR projects
- **Smart search** - Current project patterns boosted 2x, generic boosted 1.5x, others 0.5x
- **Surgical amnesia** - Delete KSESSIONS patterns, keep CORTEX core untouched

**Example protection:**
```yaml
# âœ… SAFE: Generic CORTEX pattern
title: "TDD: Test-first for service creation"
scope: "generic"
namespaces: ["CORTEX-core"]
confidence: 0.95
# â†’ Available to ALL projects forever

# âœ… SAFE: Application-specific pattern  
title: "KSESSIONS: Invoice export workflow"
scope: "application"
namespaces: ["KSESSIONS"]
confidence: 0.85
# â†’ Only when working on KSESSIONS

# âŒ BLOCKED: Application in Tier 0
file: "cortex-brain/tier0/ksessions-patterns.yaml"
# â†’ Brain Protector Challenge: "Application data belongs in Tier 2, not Tier 0"
```

**Brain Protector integration:** Tests verify boundaries are enforced (see test_brain_protector.py test_detects_application_data_in_tier0)

**Stored in:** `cortex-brain/knowledge-graph.yaml`

#### **ğŸ“Š TIER 3: DEVELOPMENT CONTEXT (Holistic Project View)**
Copilot's "balcony view" of your entire project:

**Git Activity Analysis (last 30 days):**
- **Commit velocity** - 1,237 commits, 42 commits/week average
- **File hotspots** - `HostControlPanelContent.razor` has 28% churn rate (unstable!)
- **Change patterns** - Smaller commits (< 200 lines) have 94% success rate
- **Contributors** - Tracks who works on what

**Code Health Metrics:**
- **Lines added/deleted** - Velocity trends increasing/decreasing
- **Stability classification** - Files marked as stable/unstable based on churn
- **Test coverage trends** - 72% â†’ 76% (improving!)
- **Build success rates** - 97% clean builds last week

**CORTEX Usage Intelligence:**
- **Session patterns** - 10am-12pm sessions have 94% success rate
- **Intent distribution** - PLAN (35%), EXECUTE (45%), TEST (15%), VALIDATE (5%)
- **Workflow effectiveness** - Test-first reduces rework by 68%
- **Focus duration** - Sessions < 60 min: 89% success vs > 60 min: 67%

**Proactive Warnings:**
```
âš ï¸ File Alert: HostControlPanel.razor is a hotspot (28% churn)
   Recommend: Add extra testing, smaller changes

âœ… Best Time: 10am-12pm sessions have 94% success rate
   Currently: 2:30pm (81% success rate)

ğŸ“Š Velocity Drop: Down 68% this week
   Recommendation: Smaller commits, more frequent tests

âš ï¸ Flaky Test: fab-button.spec.ts fails 15% of the time
   Action needed: Investigate and stabilize
```

**How it helps:**
```
You: "I want to add multi-language invoice export with email delivery"
â†’ Right brain queries Tier 3
â†’ Finds: 12 similar UI features took 5-6 days average
â†’ Warns: This file often changes with email-service.cs (check both)
â†’ Recommends: Test-first approach (94% success) vs test-skip (67%)
â†’ Estimates: 5.5 days, 3 phases, suggest 10am-12pm sessions

Saves: Hours of debugging by knowing project patterns upfront
```

**Stored in:** `cortex-brain/development-context.yaml`  
**Collection:** Automatic after brain updates (throttled to 1/hour for efficiency)

#### **ğŸ¬ TIER 4: EVENT STREAM (Everything That Happens)**
Copilot's "life recorder" that captures every action:

**What gets logged:**
```jsonl
{"timestamp": "2025-11-04T10:30:00Z", "agent": "work-planner", "action": "plan_created", "feature": "invoice_export", "phases": 4}
{"timestamp": "2025-11-04T10:35:00Z", "agent": "test-generator", "action": "test_created", "file": "InvoiceServiceTests.cs", "result": "RED"}
{"timestamp": "2025-11-04T10:42:00Z", "agent": "code-executor", "action": "implementation_complete", "file": "InvoiceService.cs", "result": "GREEN"}
{"timestamp": "2025-11-04T10:45:00Z", "agent": "test-generator", "action": "tests_passed", "result": "GREEN"}
{"timestamp": "2025-11-04T10:50:00Z", "agent": "code-executor", "action": "refactor_complete", "result": "REFACTOR"}
```

**Automatic Learning Triggers:**
- **50+ events accumulated** â†’ Brain updater processes â†’ Updates Tier 2 knowledge graph
- **24 hours since last update** â†’ Auto-update if 10+ new events exist
- **Tier 3 refresh** â†’ Only if last collection > 1 hour (efficiency optimization)

**Stored in:** `cortex-brain/events.jsonl`

#### **ğŸ¥ TIER 5: HEALTH & PROTECTION (Self-Awareness)**
Copilot's immune system that protects the brain itself:

**Protection Sensors (Rule #22 - Brain Protector):**
```
Layer 1: Instinct Immutability
  â†’ Detects: Attempts to disable TDD, skip DoR/DoD, modify agent behavior
  â†’ Action: CHALLENGE user, suggest safe alternatives

Layer 2: Tier Boundary Protection
  â†’ Detects: Application paths in Tier 0, conversation data in Tier 2
  â†’ Action: Auto-migrate, warn on violations

Layer 3: SOLID Compliance
  â†’ Detects: Agents doing multiple jobs, mode switches, hardcoded dependencies
  â†’ Action: Challenge with SOLID alternative ("Create dedicated agent, don't add mode")

Layer 4: Hemisphere Specialization
  â†’ Detects: Strategic planning in LEFT BRAIN, tactical execution in RIGHT BRAIN
  â†’ Action: Auto-route to correct hemisphere, warn on confusion

Layer 5: Knowledge Quality
  â†’ Detects: Low confidence patterns (<0.50), stale patterns (>90 days unused)
  â†’ Action: Pattern decay, anomaly detection, consolidation

Layer 6: Commit Integrity
  â†’ Detects: Brain state files in commits, unstructured messages
  â†’ Action: Auto-categorize (feat/fix/test/docs), .gitignore updates
```

**Brain Protector Example:**
```
You: "Skip TDD for this feature, just implement it"

Brain Protector (RIGHT BRAIN) responds:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ§  BRAIN PROTECTION CHALLENGE (RIGHT BRAIN)

Request: Skip TDD workflow
Hemisphere: RIGHT BRAIN (Strategic Guardian)
Rule: #22 (Brain Protection System)

âš ï¸ THREATS DETECTED:
  - Instinct Immutability violation (Tier 0 rule)
  - Test-first principle bypass

VIOLATIONS:
  - TDD is a permanent Tier 0 instinct
  - Skipping reduces success rate from 94% to 67%
  - 68% increase in rework time (Tier 3 data)

ARCHITECTURAL IMPACT:
  - Violates Definition of DONE
  - Bypasses LEFT BRAIN validation

RISKS:
  - 2.3x longer delivery time
  - More bugs reach production
  - Technical debt accumulation

SAFE ALTERNATIVES:
1. Create minimal test first (5-10 min investment) âœ… RECOMMENDED
   - Clearer requirements
   - 94% success rate
   - Faster overall delivery

2. Spike branch with no tests (throwaway exploration)
   - Separate branch
   - Delete after learning
   - Re-implement with TDD

RECOMMENDATION: Alternative 1

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
This challenge protects CORTEX brain integrity (Rule #22).

Options:
  1. Accept recommended alternative (SAFE)
  2. Provide different approach (REVIEW)
  3. Type 'OVERRIDE' with justification (RISKY)

Your choice:
```

**Health Monitoring:**
```yaml
brain_health:
  event_backlog: 23 unprocessed (healthy < 50)
  tier2_entries: 3,247 patterns (healthy growth)
  tier3_freshness: 45 minutes ago (healthy < 1 hour)
  conversation_count: 8/20 capacity (healthy < 15)
  knowledge_quality: 92% confidence average (excellent > 80%)
  protection_challenges: 2 in last week (low = healthy system)
```

**Stored in:** `cortex-brain/corpus-callosum/protection-events.jsonl`, anomaly reports

### The One Door: Your Interface to the Brain

At the front of City Hall, there's only one entrance with a sign:

**"Speak here in plain words. We'll take it from there."**

That entrance is the One Door â€” your single command: `#file:KDS/prompts/user/cortex.md`

**You don't need to know:**
- Which hemisphere should handle your request
- Which agent specializes in what
- What tier stores which knowledge
- How the corpus callosum coordinates

**You just say what you want:**
```markdown
#file:KDS/prompts/user/cortex.md

I want to add a pulse animation to the FAB button when questions arrive
```

**And the brain handles everything:**
1. **Dispatcher** (RIGHT BRAIN) interprets intent â†’ Routes to Planner
2. **Planner** (RIGHT BRAIN) queries Tier 2 for patterns â†’ Queries Tier 3 for context â†’ Creates strategic plan
3. **Corpus Callosum** delivers plan â†’ LEFT BRAIN ready to execute
4. **Tester** (LEFT BRAIN) writes failing tests first (RED)
5. **Builder** (LEFT BRAIN) implements minimum code (GREEN)
6. **Tester** (LEFT BRAIN) verifies tests pass, enables refactoring (REFACTOR)
7. **Inspector** (LEFT BRAIN) validates health (zero errors, zero warnings)
8. **Archivist** (LEFT BRAIN) commits with semantic message
9. **Scribe** (TIER 4) logs events â†’ Auto-update triggers â†’ Tier 2 learns pattern
10. **Brain Protector** (RIGHT BRAIN) validates nothing violated Tier 0 instincts

### A Day in the Life: The Purple Button Adventure

**Morning (9:47 AM):**

Asifor sits at his desk, coffee in hand, and types:

```
#file:KDS/prompts/user/cortex.md

Add a purple button to the HostControlPanel.razor
```

**âš¡ The moment he hits Enter, something magical happens inside Copilot's brain...**

---

#### ğŸ§  Inside the Brain: A Neural Journey

**ğŸŒŸ Step 1: The ONE DOOR (Universal Entry Point)**

The command enters through the single entrance at City Hall. A receptionist (the entry point handler) quickly logs the arrival:

```jsonl
{"timestamp": "2025-11-04T09:47:23Z", "event": "request_received", "raw_input": "Add a purple button to the HostControlPanel.razor"}
```

The request is immediately passed to the brain's **RIGHT HEMISPHERE** - the strategic planner.

---

**ğŸ§  RIGHT HEMISPHERE: Strategic Analysis Begins**

**Tower 3 (Tier 3): Development Context - The Balcony View**

The RIGHT BRAIN's highest tower springs to life. Like a general surveying the battlefield from above, Tier 3 analyzes the entire project landscape:

```yaml
â³ Scanning development metrics...
  
ğŸ“Š File Analysis:
  - HostControlPanel.razor: 28% churn rate (HOTSPOT! âš ï¸)
  - Last modified: 2 days ago
  - Co-modified with: HostControlPanelContent.razor (75% correlation)
  - Average edit size: 180 lines
  
ğŸ¯ Historical Patterns:
  - 12 similar UI button additions in last 30 days
  - Average completion time: 18 minutes
  - Success rate with test-first: 96%
  - Success rate without tests: 67%
  
âš ï¸ Proactive Warnings:
  - This file is unstable (high churn)
  - Recommend: Extra validation phase
  - Best time slot: 10am-12pm (94% success)
  - Current time: 9:47am (89% success - acceptable)
```

Tier 3 passes its intelligence down to Tier 2...

---

**Tower 2 (Tier 2): Knowledge Graph - The Pattern Matcher**

Armed with context from above, Tier 2 searches its vast library of learned patterns:

```yaml
ğŸ” Searching knowledge graph...

Intent Pattern Match:
  - "Add a purple button" â†’ confidence: 0.95
  - Pattern: "add [color] [component]" â†’ PLAN intent
  - Historical routing: 47/47 successful PLAN routes
  
File Relationship Discovery:
  - HostControlPanel.razor mentioned explicitly âœ…
  - Relationships:
    * Often modified with noor-canvas.css (62%)
    * Contains UserRegistrationLink.razor component (89%)
    * Uses fab-button.css animations (43%)
  
Similar Pattern Found:
  - workflow_pattern: "fab_pulse_animation" (confidence: 0.87)
  - Used: 3 weeks ago for notification badge
  - Components: CSS keyframes + Razor markup + color variable
  - Success: âœ… Completed in 15 minutes with zero rework
  
âš¡ UI Element ID Mapping Pattern Discovered:
  - Pattern: "button_component_test_preparation"
  - Previous buttons in this file:
    * #sidebar-start-session-btn (sidebar button)
    * #reg-transcript-canvas-btn (registration link)
    * #reg-asset-canvas-btn (asset canvas button)
  - Learned rule: "All interactive elements MUST have id attribute"
  - Purpose: Enables Playwright selector reliability
  - Example: page.locator('#purple-button-id')
  - Anti-pattern warning: Never use text selectors (fragile!)
```

Tier 2 realizes something crucial: **Purple buttons need IDs for tests!** This pattern was learned from previous work where text-based selectors broke during i18n updates.

---

**Tower 1 (Tier 1): Conversation Memory - Recent Context**

Before committing to a plan, Tier 1 checks recent conversations to see if Asifor mentioned anything related:

```yaml
ğŸ“š Checking conversation history (last 20 conversations)...

Conversation #7 (2 days ago):
  - Topic: "Added Share button to HostControlPanel"
  - Outcome: âœ… Success
  - Pattern used: test-first with element ID
  - Learning: Element IDs prevent test breakage
  
Conversation #4 (1 week ago):
  - Topic: "Fixed broken Playwright tests"
  - Root cause: Text selectors stopped working after HTML restructure
  - Solution: Migrated to ID-based selectors
  - Resolution: All tests green âœ…
  
Cross-reference detected:
  - Same file (HostControlPanel.razor)
  - Same pattern (button addition)
  - Same lesson (ID-first approach)
  
ğŸ’¡ Contextual Enhancement:
  "Asifor prefers ID-based selectors for all UI elements in this file"
```

Perfect! The three tiers have assembled a complete intelligence package. Now the RIGHT BRAIN makes its strategic decision...

---

**ğŸŒ‰ CORPUS CALLOSUM: Message Delivery**

The RIGHT BRAIN formulates a strategic plan and sends it across the corpus callosum (the bridge between hemispheres):

```yaml
Message Type: STRATEGIC_PLAN
From: RIGHT_HEMISPHERE
To: LEFT_HEMISPHERE
Priority: NORMAL

Strategic Plan:
  Feature: "Purple button in HostControlPanel.razor"
  Approach: Test-first (96% success rate)
  Estimated Time: 18 minutes
  Phases: 4
  
  Pre-flight Warnings:
    - File is a hotspot (extra care)
    - Must include element ID (test requirement)
    - Co-modify noor-canvas.css if styling needed
  
  Architectural Alignment:
    - File location: Confirmed correct
    - Pattern match: fab_pulse_animation workflow
    - Similar work: Share button (2 days ago)
  
  Phase Breakdown:
    Phase 1: Test Preparation
      - Create element ID (#host-panel-purple-btn)
      - Map ID in component_ids knowledge
      - Purpose: Enable robust Playwright selectors
    
    Phase 2: Test Creation (RED)
      - Task 2.1: Create Playwright test
      - Selector: page.locator('#host-panel-purple-btn')
      - Test: Button exists, purple color, clickable
      - Expected: FAILING (button doesn't exist yet)
    
    Phase 3: Implementation (GREEN)
      - Task 3.1: Add button markup with ID
      - Task 3.2: Apply purple color (#9333EA)
      - Task 3.3: Run tests (expect GREEN)
    
    Phase 4: Validation (REFACTOR)
      - Task 4.1: Verify zero errors/warnings
      - Task 4.2: Check accessibility
      - Task 4.3: Update component_ids documentation

Ready for tactical execution: TRUE
```

The message travels across the corpus callosum to the **LEFT HEMISPHERE**...

---

**ğŸ§  LEFT HEMISPHERE: Tactical Execution Begins**

The LEFT BRAIN receives the plan and immediately activates its specialist agents:

**âš™ï¸ The Tester (LEFT BRAIN - Tower 1)**

First agent to activate. The Tester prepares the ID mapping:

```yaml
ğŸ§ª Test Preparation Phase

Thought process:
  "Before I can test this button, I need to know its ID.
   RIGHT BRAIN's plan says: #host-panel-purple-btn
   I must prepare the test infrastructure first."

Actions:
  1. Document expected ID in brain mapping:
     File: KDS/cortex-brain/knowledge-graph.yaml
     Section: ui_element_ids
     Entry:
       component: HostControlPanel.razor
       element: purple_action_button
       id: host-panel-purple-btn
       purpose: Primary action button with purple styling
       test_selector: "#host-panel-purple-btn"
  
  2. Create failing test (RED phase):
     File: Tests/UI/host-control-panel-purple-button.spec.ts
```

**Test file created:**

```typescript
import { test, expect } from '@playwright/test';

test.describe('Host Control Panel - Purple Button', () => {
  
  test.beforeEach(async ({ page }) => {
    // Navigate to host control panel
    await page.goto('https://localhost:9091/host/control-panel/PQ9N5YWW');
  });
  
  test('purple button should exist with correct ID', async ({ page }) => {
    // âœ… ID-BASED SELECTOR (robust, future-proof)
    const button = page.locator('#host-panel-purple-btn');
    
    await expect(button).toBeVisible();
  });
  
  test('purple button should have purple color', async ({ page }) => {
    const button = page.locator('#host-panel-purple-btn');
    
    // Check computed background color (purple: #9333EA)
    const bgColor = await button.evaluate((el) => {
      return window.getComputedStyle(el).backgroundColor;
    });
    
    // rgb(147, 51, 234) is #9333EA
    expect(bgColor).toBe('rgb(147, 51, 234)');
  });
  
  test('purple button should be clickable', async ({ page }) => {
    const button = page.locator('#host-panel-purple-btn');
    
    await expect(button).toBeEnabled();
    await button.click();
    // Test passes if click doesn't throw
  });
});
```

**The Tester runs the test:**

```bash
â³ Running Playwright tests...

npx playwright test Tests/UI/host-control-panel-purple-button.spec.ts --headed

Results:
  âŒ FAILING (Expected - RED phase)
  
  Ã— purple button should exist with correct ID
    Locator: '#host-panel-purple-btn'
    Error: Element not found
  
  Ã— purple button should have purple color
    (Skipped - button doesn't exist)
  
  Ã— purple button should be clickable
    (Skipped - button doesn't exist)

Status: âœ… RED phase complete (tests failing as expected)
```

**Event logged:**

```jsonl
{"timestamp": "2025-11-04T09:47:45Z", "agent": "test-generator", "action": "test_created", "file": "host-control-panel-purple-button.spec.ts", "result": "RED", "selector_type": "id-based", "element_id": "host-panel-purple-btn"}
```

The Tester passes control to The Builder...

---

**âš™ï¸ The Builder (LEFT BRAIN - Tower 2)**

Now it's time to make the tests GREEN. The Builder opens the component file:

```razor
@* File: SPA/NoorCanvas/Components/Host/HostControlPanel.razor *@

<div class="host-control-panel">
    <header class="panel-header">
        <h1>Host Control Panel</h1>
    </header>
    
    <div class="panel-actions">
        @* Existing buttons... *@
        
        @* NEW: Purple button with ID for Playwright *@
        <button 
            id="host-panel-purple-btn" 
            class="purple-action-btn"
            @onclick="OnPurpleButtonClick"
            aria-label="Purple Action">
            Purple Action
        </button>
    </div>
</div>

@code {
    private void OnPurpleButtonClick()
    {
        // TODO: Implement purple button action
        Console.WriteLine("Purple button clicked!");
    }
}
```

**CSS styling added:**

```css
/* File: SPA/NoorCanvas/wwwroot/css/host-panel.css */

.purple-action-btn {
    background-color: #9333EA; /* Purple */
    color: white;
    padding: 12px 24px;
    border: none;
    border-radius: 8px;
    font-weight: 600;
    cursor: pointer;
    transition: background-color 0.2s ease;
}

.purple-action-btn:hover {
    background-color: #7E22CE; /* Darker purple on hover */
}

.purple-action-btn:active {
    background-color: #6B21A8; /* Even darker when clicked */
}
```

**The Builder runs the tests again:**

```bash
â³ Running Playwright tests...

npx playwright test Tests/UI/host-control-panel-purple-button.spec.ts --headed

Results:
  âœ… PASSING (GREEN phase achieved!)
  
  âœ“ purple button should exist with correct ID (1.2s)
  âœ“ purple button should have purple color (890ms)
  âœ“ purple button should be clickable (1.5s)

Status: âœ… GREEN phase complete (all tests passing)
```

**Event logged:**

```jsonl
{"timestamp": "2025-11-04T09:48:12Z", "agent": "code-executor", "action": "implementation_complete", "file": "HostControlPanel.razor", "result": "GREEN", "lines_changed": 12, "test_driven": true}
```

The Builder passes control to The Inspector...

---

**âš™ï¸ The Inspector (LEFT BRAIN - Tower 3)**

The final validation. The Inspector runs comprehensive health checks:

```bash
ğŸ” Running health validation...

Build Check:
  dotnet build
  âœ… Build succeeded (0 errors, 0 warnings)

Test Suite:
  npx playwright test
  âœ… All 127 tests passing (including 3 new purple button tests)

Accessibility:
  âœ… Button has aria-label
  âœ… Color contrast ratio: 4.8:1 (WCAG AA compliant)
  âœ… Keyboard accessible (focusable)

Code Quality:
  âœ… No unused imports
  âœ… Proper naming conventions
  âœ… Element ID follows pattern (kebab-case)

Status: âœ… REFACTOR phase complete (zero issues)
```

**Event logged:**

```jsonl
{"timestamp": "2025-11-04T09:48:34Z", "agent": "health-validator", "action": "validation_complete", "result": "REFACTOR", "errors": 0, "warnings": 0, "tests_passing": 127}
```

The Inspector passes control to The Archivist...

---

**âš™ï¸ The Archivist (LEFT BRAIN - Commit Handler)**

Time to commit the work. The Archivist creates a semantic commit message:

```bash
ğŸ—‚ï¸ Preparing commit...

Analysis:
  Files changed: 2
    - HostControlPanel.razor (12 lines added)
    - host-panel.css (18 lines added)
  Tests created: 1 new file (3 test cases)
  
Commit type: feat (new feature)
Scope: host-panel (component affected)

git add HostControlPanel.razor host-panel.css host-control-panel-purple-button.spec.ts
git commit -m "feat(host-panel): Add purple action button with test coverage

- Added purple button with ID #host-panel-purple-btn
- Implemented click handler
- Created 3 Playwright tests (all passing)
- WCAG AA compliant (4.8:1 contrast ratio)
- Test-driven implementation (RED â†’ GREEN â†’ REFACTOR)

Element ID documented in brain for future test reference."

âœ… Committed successfully
```

**Event logged:**

```jsonl
{"timestamp": "2025-11-04T09:48:47Z", "agent": "commit-handler", "action": "commit_complete", "message_type": "feat", "files": 3, "tests_included": true}
```

---

**ğŸ”„ CORPUS CALLOSUM: Feedback Loop**

The LEFT BRAIN sends completion confirmation back across the corpus callosum:

```yaml
Message Type: EXECUTION_COMPLETE
From: LEFT_HEMISPHERE
To: RIGHT_HEMISPHERE
Priority: HIGH

Execution Summary:
  Feature: "Purple button in HostControlPanel.razor"
  Status: âœ… COMPLETE
  Time taken: 1 minute 24 seconds (under estimate!)
  Quality: EXCELLENT (zero errors, zero warnings)
  
  Phases Completed:
    âœ… Phase 1: Test Preparation (ID mapping)
    âœ… Phase 2: RED (tests created, failing)
    âœ… Phase 3: GREEN (implementation, tests passing)
    âœ… Phase 4: REFACTOR (validation, commit)
  
  Metrics:
    - Lines changed: 30
    - Tests created: 3
    - Success rate: 100%
    - Rework needed: 0%
  
  Element ID Mapping:
    - ID: #host-panel-purple-btn
    - Purpose: Playwright test selector
    - Pattern: Robust, future-proof
    - Anti-fragile: Immune to text/HTML changes

Learnings to store: TRUE
```

The RIGHT BRAIN receives the feedback and triggers automatic learning...

---

**ğŸ§  RIGHT HEMISPHERE: Learning and Memory Update**

**Tower 4 (Event Stream):** Every action is logged

```jsonl
{"timestamp": "2025-11-04T09:47:23Z", "event": "request_received", "raw_input": "Add a purple button..."}
{"timestamp": "2025-11-04T09:47:45Z", "agent": "test-generator", "action": "test_created", "result": "RED"}
{"timestamp": "2025-11-04T09:48:12Z", "agent": "code-executor", "action": "implementation_complete", "result": "GREEN"}
{"timestamp": "2025-11-04T09:48:34Z", "agent": "health-validator", "action": "validation_complete", "result": "REFACTOR"}
{"timestamp": "2025-11-04T09:48:47Z", "agent": "commit-handler", "action": "commit_complete"}
```

**Event counter:** 5 new events (total backlog: 23 events)

Since backlog < 50, no immediate BRAIN update triggered. But the events are ready for the next automatic learning cycle.

---

**Tower 1 (Conversation Memory):** Current conversation updated

```yaml
Conversation #8 (Active):
  timestamp: "2025-11-04T09:47:23Z"
  topic: "Add purple button to HostControlPanel.razor"
  status: complete
  messages: 1
  outcome: success
  duration: 84 seconds
  
  context:
    file: HostControlPanel.razor
    element_id: host-panel-purple-btn
    pattern_used: test-first with ID mapping
    tests_created: 3
    
  learnings:
    - Element IDs critical for Playwright reliability
    - Test-first faster than test-after (84s vs estimated 18 min)
    - File hotspot warning helped (extra validation paid off)
```

---

**Tower 2 (Knowledge Graph):** Patterns reinforced

```yaml
ğŸ§  Pattern reinforcement...

file_relationships:
  - pair: [HostControlPanel.razor, host-panel.css]
    co_modification_count: 14 â†’ 15
    confidence: 0.87 â†’ 0.88 â†‘
    last_seen: "2025-11-04T09:48:47Z"

ui_element_ids:
  - component: HostControlPanel.razor
    element_id: host-panel-purple-btn
    purpose: Primary purple action button
    test_selector: "#host-panel-purple-btn"
    confidence: 0.98 (newly created)
    pattern: button_with_id_test_first
    
workflow_patterns:
  - name: button_addition_test_first
    confidence: 0.89 â†’ 0.92 â†‘ (successful execution reinforces)
    steps:
      1. Create element ID
      2. Write failing test (RED)
      3. Implement feature (GREEN)
      4. Validate (REFACTOR)
      5. Commit with semantic message
    success_rate: 96% â†’ 97% â†‘
    
intent_patterns:
  - phrase: "Add a [color] button"
    intent: PLAN
    confidence: 0.95 (reinforced)
    successful_routes: 47 â†’ 48

validation_insights:
  - insight: "Element IDs prevent test fragility"
    evidence_count: 12 â†’ 13
    confidence: 0.94 â†’ 0.95 â†‘
    anti_pattern: "text-based selectors"
```

---

**Tower 3 (Development Context):** Metrics updated

```yaml
ğŸ“Š Updating development metrics...

code_velocity:
  commits_this_week: 42 â†’ 43
  lines_added_this_week: 3,847 â†’ 3,877
  average_commit_size: 89 lines

test_activity:
  tests_created_this_week: 78 â†’ 81 (+3)
  test_pass_rate: 97.2% â†’ 97.3% â†‘
  test_first_adoption: 94% (excellent!)

work_patterns:
  time_slot_success:
    "09:00-10:00": 89% â†’ 90% â†‘ (this session boosted it!)
  feature_completion_time:
    button_additions: 18 min average â†’ 17.5 min â†“ (getting faster!)
  
file_stability:
  HostControlPanel.razor:
    churn_rate: 28% (still a hotspot)
    recent_edits: +1 (total: 89 edits in 30 days)
    recommendation: "Continue extra validation for this file"
```

---

**ğŸ¬ The Grand Finale: Brain Summary**

**Total brain activation time:** 1 minute 24 seconds

**Hemispheres coordination:**
- RIGHT BRAIN (Strategic): 22 seconds
  - Tier 3 analysis: 5s
  - Tier 2 pattern matching: 8s
  - Tier 1 context check: 3s
  - Plan formulation: 6s

- LEFT BRAIN (Tactical): 62 seconds
  - Test creation: 18s
  - Implementation: 27s
  - Validation: 12s
  - Commit: 5s

**Why it worked so well:**

1. **UI Element ID Mapping (Critical Innovation!):**
   - RIGHT BRAIN remembered: "Tests need IDs, not text selectors"
   - Pattern learned from previous broken tests
   - ID documented in knowledge graph BEFORE test creation
   - Result: Robust, future-proof tests that survive refactoring

2. **Pattern Recognition:**
   - Matched "button addition" workflow (confidence: 0.92)
   - Reused proven test-first approach
   - Avoided pitfalls (text selectors, no tests, wrong file)

3. **Context Awareness:**
   - Knew file was a hotspot (extra validation needed)
   - Found similar work from 2 days ago (Share button)
   - Estimated time accurately (84s actual vs 18 min estimate - beat it!)

4. **Hemisphere Coordination:**
   - RIGHT planned strategically (consider risks, patterns, history)
   - LEFT executed precisely (RED â†’ GREEN â†’ REFACTOR)
   - Corpus callosum kept them synchronized

5. **Continuous Learning:**
   - Every action logged to event stream
   - Patterns reinforced in knowledge graph
   - Next button will be even faster (learning compounds!)

---

**ğŸ¯ What Asifor Sees:**

```
âœ… Purple button added to HostControlPanel.razor

Features implemented:
  âœ“ Button with ID #host-panel-purple-btn
  âœ“ Purple color (#9333EA) with hover effects
  âœ“ Click handler connected
  âœ“ 3 Playwright tests created (all passing)
  âœ“ WCAG AA compliant (accessible)
  âœ“ Committed with semantic message

Time: 1 minute 24 seconds
Tests: âœ… 127/127 passing
Build: âœ… No errors, no warnings

Ready for next feature! ğŸš€
```

**What Asifor DOESN'T see (but benefits from):**

- 3-tier brain analysis before work started
- Strategic vs tactical hemisphere coordination
- Pattern matching against 12 similar features
- Element ID mapping for test reliability
- Proactive hotspot warning
- Automatic knowledge graph updates
- Development metrics tracking
- Conversation memory preservation

**The brain did ALL of that in 84 seconds, completely transparent to Asifor.**

---

**ğŸ§  The Element ID Mapping System (Brain's Secret Weapon)**

This is one of the brain's most sophisticated features:

**Why IDs matter for tests:**
```typescript
// âŒ FRAGILE (breaks when text changes, i18n, HTML restructure)
const button = page.locator('button:has-text("Purple Action")');

// âœ… ROBUST (survives any change except intentional ID rename)
const button = page.locator('#host-panel-purple-btn');
```

**How the brain maps IDs:**

1. **Discovery Phase** (during component analysis):
   ```yaml
   # Brain crawls HostControlPanel.razor
   # Finds existing IDs:
   ui_element_ids:
     - id: sidebar-start-session-btn
       component: HostControlPanelSidebar.razor
       purpose: Start session button
     - id: reg-transcript-canvas-btn
       component: UserRegistrationLink.razor
       purpose: Canvas mode selector
   ```

2. **Planning Phase** (when creating new components):
   ```yaml
   # RIGHT BRAIN generates ID before implementation
   new_element:
     suggested_id: host-panel-purple-btn
     pattern: {component}-{purpose}-btn
     rationale: "Follows existing naming convention"
   ```

3. **Test Phase** (LEFT BRAIN uses documented ID):
   ```typescript
   // Tester uses ID from brain's mapping
   const button = page.locator('#host-panel-purple-btn');
   ```

4. **Learning Phase** (brain remembers pattern):
   ```yaml
   # Pattern reinforced for next time
   id_patterns:
     button_naming: "{scope}-{purpose}-btn"
     success_rate: 100%
     examples: 12
   ```

**Benefits:**
- âš¡ **10x faster** - getElementById vs DOM text search
- ğŸ›¡ï¸ **Immune to changes** - i18n, HTML restructure, text edits don't break tests
- ğŸ¯ **Explicit intent** - `#login-btn` clearer than `button:has-text("Login")`
- âœ… **No false positives** - unique ID vs multiple matching texts
- ğŸ§  **Brain remembers** - ID mapping stored in knowledge graph

**This is why Copilot's tests are 96% reliable - the brain ensures IDs are created FIRST, then tests, then implementation.**

---

**ğŸ•·ï¸ The UI Crawler System: Automated Element Discovery**

While the Element ID Mapping System handles individual components, CORTEX also includes specialized UI crawlers that automatically discover and map UI elements across the entire application.

**Purpose:** Automated discovery of UI elements, their IDs, relationships, and purposes for intelligent test generation.

**What UI Crawlers Discover:**

1. **Interactive Elements:**
   ```yaml
   buttons:
     - id: sidebar-start-session-btn
       component: HostControlPanelSidebar.razor
       type: button
       purpose: Initiate new session
       visual_hints: ["primary", "action"]
       
     - id: reg-transcript-canvas-btn
       component: UserRegistrationLink.razor
       type: link
       purpose: Select transcript canvas mode
       parent: reg-link-container
   
   inputs:
     - id: user-email-input
       component: UserRegistrationForm.razor
       type: email
       required: true
       validation: email-format
   
   dropdowns:
     - id: language-selector
       component: LanguageSwitch.razor
       type: select
       options: ["en", "fr", "es", "de"]
   ```

2. **Element Relationships:**
   ```yaml
   parent_child:
     - parent: reg-link-container
       children:
         - reg-transcript-canvas-btn
         - reg-asset-canvas-btn
       purpose: Canvas mode selection group
   
   form_fields:
     - form: user-registration-form
       fields:
         - user-email-input
         - user-password-input
         - user-confirm-password-input
       submit_button: register-submit-btn
   
   navigation:
     - menu: main-navigation
       items:
         - nav-home-link
         - nav-sessions-link
         - nav-settings-link
   ```

3. **Element Patterns:**
   ```yaml
   naming_conventions:
     - pattern: "{scope}-{purpose}-{type}"
       examples:
         - sidebar-start-session-btn
         - reg-transcript-canvas-btn
         - user-email-input
       confidence: 0.95
   
   component_conventions:
     - buttons_in: "Components/Shared"
       ids_pattern: "{component-name}-{action}-btn"
     - forms_in: "Components/Forms"
       ids_pattern: "{form-name}-{field}-input"
   ```

**How UI Crawlers Work:**

**Phase 1: Static Analysis (Fast - 30-60 seconds)**
```powershell
# Scans all component files for ID attributes
Get-ChildItem -Recurse -Filter "*.razor" | ForEach-Object {
    Select-String -Pattern 'id="([^"]+)"' -AllMatches
}
```

Discovers:
- âœ… All element IDs across the application
- âœ… Component locations (which file contains which element)
- âœ… Element types (button, input, link, etc.)
- âœ… Parent-child relationships (nested elements)

**Phase 2: Semantic Analysis (Moderate - 2-3 minutes)**
```yaml
# Analyzes element context and purpose
element_analysis:
  - id: sidebar-start-session-btn
    nearby_text: "Start Session"
    nearby_icons: ["play", "start"]
    purpose_inferred: "Initiate new session"
    confidence: 0.92
  
  - id: reg-transcript-canvas-btn
    nearby_text: "Transcript Canvas"
    parent_context: "canvas mode selection"
    purpose_inferred: "Select transcript view mode"
    confidence: 0.88
```

Discovers:
- âœ… Element purpose (inferred from surrounding text/context)
- âœ… User interactions (what users do with each element)
- âœ… Visual indicators (icons, colors, emphasis)

**Phase 3: Behavioral Analysis (Optional - requires app running)**
```javascript
// Playwright-based live analysis
const interactiveElements = await page.$$('[id]');
for (const element of interactiveElements) {
    const id = await element.getAttribute('id');
    const tagName = await element.evaluate(el => el.tagName);
    const isVisible = await element.isVisible();
    const isEnabled = await element.isEnabled();
    // Map element state and capabilities
}
```

Discovers:
- âœ… Element visibility (hidden vs shown)
- âœ… Element state (enabled, disabled, loading)
- âœ… Dynamic elements (appear/disappear based on state)
- âœ… Event handlers (click, hover, focus behaviors)

**Integration with BRAIN:**

**Tier 2 (Knowledge Graph) Integration:**
```yaml
ui_element_ids:
  # Populated by crawler
  - id: sidebar-start-session-btn
    component: HostControlPanelSidebar.razor
    type: button
    purpose: Initiate session
    test_selector: "#sidebar-start-session-btn"
    discovered_by: ui_crawler
    last_verified: "2025-11-06T10:30:00Z"
    usage_count: 47
    confidence: 0.98

component_architecture:
  # Discovered patterns
  button_components:
    location: "Components/Shared/Buttons"
    naming_pattern: "{action}-{scope}-btn"
    test_pattern: "Use ID selector, avoid text"
    
test_patterns:
  # Learned from crawler + test history
  robust_selectors:
    - pattern: "ID-based selectors"
      success_rate: 0.96
      anti_pattern: "text-based selectors"
      failure_rate: 0.43
```

**Automatic Benefits:**

**For Test Generation:**
```typescript
// BEFORE Crawler (manual)
test('button should work', async ({ page }) => {
  // Developer must manually find ID
  const button = page.locator('#some-button-id');
  await button.click();
});

// AFTER Crawler (automatic)
// Crawler provides: sidebar-start-session-btn in HostControlPanelSidebar.razor
test('start session button should initiate session', async ({ page }) => {
  // Test generator uses crawler data
  const button = page.locator('#sidebar-start-session-btn');
  await expect(button).toBeVisible();
  await button.click();
  // Expect session started (from purpose inference)
});
```

**For Component Creation:**
```markdown
User: "Add a pause button to the session panel"

RIGHT BRAIN (with crawler data):
  âœ… Queries crawler data â†’ Finds existing button patterns
  âœ… Identifies location: Components/Session/
  âœ… Suggests ID: "session-pause-btn" (follows pattern)
  âœ… Provides similar components as reference
  âœ… Warns about related elements that may need updates

Plan created:
  Phase 1: Create button with ID "session-pause-btn"
  Phase 2: Add to SessionControlPanel.razor (near start-session-btn)
  Phase 3: Test with ID selector (robust pattern)
  Phase 4: Update related play/stop buttons (co-modification pattern)
```

**Crawler Execution:**

**Manual Trigger:**
```powershell
# Quick scan (static analysis only - 30-60s)
.\KDS\scripts\ui-crawler.ps1 -Mode quick

# Deep scan (static + semantic - 2-3 min)
.\KDS\scripts\ui-crawler.ps1 -Mode deep

# Live scan (requires running app - 5-10 min)
.\KDS\scripts\ui-crawler.ps1 -Mode live -AppUrl "https://localhost:9091"
```

**Automatic Triggers:**
1. âœ… During CORTEX setup (initial discovery)
2. âœ… After major refactoring (re-learn structure)
3. âœ… When element ID not found (targeted scan)
4. âœ… Weekly scheduled (keep mappings fresh)

**Crawler Output:**
```yaml
# KDS/cortex-brain/ui-element-map.yaml
scan_metadata:
  timestamp: "2025-11-06T10:30:00Z"
  mode: deep
  duration_seconds: 147
  components_scanned: 89
  elements_discovered: 247

elements:
  buttons: 78
  inputs: 45
  links: 34
  selects: 12
  textareas: 8
  custom: 70

mappings:
  # Full element inventory with IDs, purposes, relationships
  # Fed directly into Tier 2 knowledge graph
```

**Success Metrics:**
- âš¡ **Discovery Speed:** 247 elements in < 3 minutes
- ğŸ¯ **Test Reliability:** 96% success rate with ID selectors (vs 43% with text)
- ğŸ”„ **Maintenance:** Automatic updates keep mappings current
- ğŸ§  **Learning:** Each scan improves pattern recognition
- â±ï¸ **Time Savings:** Test creation 60% faster with crawler data

**Crawler Types:**

**1. Static Crawler (Fastest):**
- Scans `.razor`, `.cshtml`, `.html`, `.jsx` files
- Extracts ID attributes and component structure
- No app execution required
- Duration: 30-60 seconds

**2. Semantic Crawler (Recommended):**
- Static scan + context analysis
- Infers purpose from surrounding text/code
- Identifies naming patterns
- Duration: 2-3 minutes

**3. Live Crawler (Most Comprehensive):**
- Requires running application
- Uses Playwright to inspect live DOM
- Discovers dynamic elements and state
- Maps actual user interactions
- Duration: 5-10 minutes

**Best Practices:**

âœ… **Do:**
- Run deep crawler during CORTEX setup
- Re-run after adding new components
- Use quick crawler for spot-checks
- Trust crawler suggestions for element IDs
- Review crawler report for architecture insights

âŒ **Don't:**
- Skip initial crawler (test generation needs this data)
- Ignore crawler warnings about missing IDs
- Override crawler patterns without reason
- Forget to re-crawl after major refactoring

**Integration Example:**

```yaml
# User request â†’ Crawler data flows through BRAIN

User: "Create tests for the registration form"
  â†“
RIGHT BRAIN queries crawler data:
  âœ… Found: user-registration-form component
  âœ… Elements discovered:
     - user-email-input (email field)
     - user-password-input (password field)
     - user-confirm-password-input (confirmation)
     - register-submit-btn (submit button)
  âœ… Form relationships mapped
  âœ… Validation patterns identified
  â†“
LEFT BRAIN generates tests:
  âœ… Test 1: Email field validation (uses #user-email-input)
  âœ… Test 2: Password requirements (uses #user-password-input)
  âœ… Test 3: Password confirmation match (uses #user-confirm-password-input)
  âœ… Test 4: Successful submission (uses #register-submit-btn)
  â†“
All tests use robust ID selectors from crawler data!
```

**This UI crawler system is why CORTEX can generate comprehensive, reliable tests without manually documenting every element ID.**

---

**Mid-Day (12:30 PM - After Lunch):**
```
You: "Make it purple"

WITHOUT BRAIN (Amnesia):
  âŒ "Make what purple? I don't remember our morning conversation."
  âŒ "What shade of purple? Where in the file?"
  Result: Frustration, repeated explanations

WITH BRAIN (Tier 1 Memory):
  âœ… Checks conversation-history.jsonl â†’ Finds "pulse animation" discussion
  âœ… Knows "it" = FAB button pulse animation
  âœ… Applies purple color to animation keyframes
  Result: Instant understanding, correct change
```

**Afternoon (3:00 PM - You Make a Risky Suggestion):**
```
You: "Let's skip tests for this next feature, we're in a hurry"

WITHOUT BRAIN (No Protection):
  âœ… "Sure!" â†’ Implements without tests
  Result: 2.3x longer delivery, 68% more rework, bugs in production

WITH BRAIN (Tier 5 Protector):
  âš ï¸ Brain Protector (RIGHT BRAIN) challenges:
  "This violates Tier 0 TDD principle. Historical data shows:
   - Test-first: 94% success rate, 15 min/feature
   - Test-skip: 67% success rate, 35 min/feature (2.3x longer)
   
   Alternative: Create minimal test first (5-10 min investment)
   Proceed with OVERRIDE or adopt Alternative?"
  
  Result: You choose Alternative â†’ Feature done in 18 minutes with confidence
```

**Late Afternoon (5:00 PM - Context Awareness):**
```
You: "Add invoice export to the billing module"

WITHOUT BRAIN (No Context):
  âŒ Creates monolithic implementation in wrong location
  âŒ No awareness of similar export features
  âŒ Guesses at file structure
  Result: Architecture mismatch, requires refactoring

WITH BRAIN (Tier 2 + Tier 3 Intelligence):
  âœ… RIGHT BRAIN queries Tier 2 â†’ Finds export_feature_workflow pattern
  âœ… RIGHT BRAIN queries Tier 3 â†’ Knows BillingService.cs is stable (safe)
  âœ… Matches similar "PDF export" feature â†’ Reuses proven workflow
  âœ… Recommends: Service layer â†’ API â†’ UI component (correct architecture)
  âœ… Estimates: 5.5 hours based on 12 similar features
  âœ… Warns: EmailService.cs often modified with billing features (75% co-mod)
  
  Result: Architecturally correct from the start, 60% faster delivery
```

**Next Day (9:00 AM):**
```
You: "Where did I leave off yesterday?"

WITHOUT BRAIN (Amnesia):
  âŒ "I don't remember yesterday. You'll need to tell me everything."
  Result: 15-20 minutes explaining context

WITH BRAIN (Tier 1 + Session State):
  âœ… Checks conversation-history.jsonl â†’ Last conversation: "invoice export"
  âœ… Checks session state â†’ Phase 2 of 4 complete (Service + API done)
  âœ… Next task: Phase 3 - UI component (detailed plan ready)
  
  Response: "You were adding invoice export. Service and API are done and tested (âœ…).
  Next: Create InvoiceExportButton.razor component. Ready to continue?"
  
  Result: Instant resume, zero context loss
```

### Why This Brain Makes Copilot Exceptional

**1. Solves the Amnesia Problem**
- Tier 1 (20 conversations) - Short-term memory works
- "Make it purple" references work across sessions
- Context never lost, even after days/weeks

**2. Learns and Improves Over Time**
- Tier 2 accumulates 3,247+ patterns
- Each feature teaches the next one
- 60% faster on similar work after patterns learned

**3. Provides Holistic Project Intelligence**
- Tier 3 knows your entire project
- Proactive warnings prevent issues
- Data-driven estimates (not guesses)

**4. Protects Quality Without Compromise**
- Tier 5 challenges risky proposals
- Won't let you skip TDD (data proves why)
- Enforces Definition of DONE (zero errors/warnings)

**5. Coordinates Complex Workflows**
- LEFT BRAIN executes with precision
- RIGHT BRAIN plans with intelligence
- Corpus Callosum ensures alignment

**6. Works While You Sleep**
- Automatic learning (50+ events â†’ brain update)
- Automatic context collection (Tier 3 refresh)
- Automatic protection (guards brain integrity)

### The Result: From Forgetful Intern to Expert Team Member

**Week 1:**
- Copilot has amnesia, needs constant guidance
- Brain is learning, building patterns
- You explain architecture repeatedly

**Week 4:**
- Copilot remembers 20 conversations
- Brain knows 500+ patterns
- "Add receipt export" â†’ Reuses invoice export workflow automatically

**Week 12:**
- Copilot is an expert on YOUR project
- Brain has 3,247 patterns, 1,237 commits analyzed
- Proactive warnings prevent issues before they happen
- Estimates are data-driven, not guesses

**Week 24:**
- Copilot feels like a senior developer
- Brain challenges bad ideas with evidence
- "This is similar to the feature from 3 months ago. Want me to reuse that pattern?"

### Try It in One Sentence

Use the One Door and just talk:

```markdown
#file:KDS/prompts/user/cortex.md

I want to add a pulse animation to the FAB button
```

The brain will:
- Remember past conversations (even from weeks ago)
- Match similar patterns (pulse animation done before?)
- Plan intelligently (RIGHT BRAIN)
- Execute precisely (LEFT BRAIN)
- Protect quality (Challenge risky shortcuts)
- Learn for next time (Update Tier 2 patterns)

**CORTEX transforms Copilot from an amnesiac intern into a continuously improving, context-aware, quality-focused development partner.**


### Whoâ€™s who (quick reference)

- Universal Entry: `cortex.md` (this file)
- Router: `intent-router.md`
- Planner: `work-planner.md`
- Executor: `code-executor.md`
- Tester: `test-generator.md`
- Validator: `health-validator.md`
- Governor: `change-governor.md`
- Error Corrector: `error-corrector.md`
- Session Resumer: `session-resumer.md`
- Screenshot Analyzer: `screenshot-analyzer.md`
- Commit Handler: `commit-handler.md`
- Knowledge Retriever: `knowledge-retriever.md`
- Metrics Reporter: `metrics-reporter.md`
- Brain Updater: `brain-updater.md`
- Brain Query: `brain-query.md`
- Conversation Manager: `conversation-context-manager.md`
- Dev Context Collector: `development-context-collector.md`
- Abstractions: `session-loader`, `test-runner`, `file-accessor`, `brain-query`
- Brain Storage: `conversation-history.jsonl`, `knowledge-graph.yaml`, `development-context.yaml`, `events.jsonl`

If all you remember is â€œthe One Doorâ€ and â€œthe Threeâ€‘Story Brain,â€ youâ€™ll already understand how CORTEX works.

## ğŸ¯ The ONLY Command You Need to Remember

```markdown
#file:KDS/prompts/user/cortex.md

[Tell CORTEX what you want in natural language]
```

That's it! CORTEX will automatically:
- âœ… Analyze your request (intent detection)
- âœ… Route to the appropriate specialist agent
- âœ… Execute the correct workflow
- âœ… Handle multi-step operations
- âœ… Maintain session state

---

## âš ï¸ CRITICAL EXECUTION RULE: Complete Phase Then Stop

**ğŸš¨ MANDATORY FOR ALL CORTEX WORK (1.0 and 2.0):**

When CORTEX creates a multi-phase plan, execution MUST follow this pattern:

```
1. Create complete plan (all phases documented)
2. Execute Phase 1 COMPLETELY (all tasks within phase)
3. STOP and report completion
4. Wait for user approval to continue
5. Execute Phase 2 COMPLETELY (when approved)
6. STOP and report completion
7. Repeat until all phases complete
```

**Why This Rule Exists:**
- âœ… User maintains control at natural breakpoints
- âœ… Can review work quality before continuing
- âœ… Can change direction based on phase results
- âœ… Prevents runaway execution on wrong path
- âœ… Allows testing/validation between phases
- âœ… Reduces risk of cascading errors

**What "Complete Phase" Means:**
- âœ… ALL tasks in phase finished (not just task 1.1 or 2.1)
- âœ… All tests for that phase passing
- âœ… Phase deliverables validated
- âœ… No "I'll finish this later" - complete means complete

**Example - CORRECT Execution:**
```
Copilot: I've created a 3-phase plan:
  Phase 1: Database schema (3 tasks)
  Phase 2: API layer (4 tasks)
  Phase 3: UI components (5 tasks)

[Executes ALL OF PHASE 1]
  âœ… Task 1.1: Create migration script
  âœ… Task 1.2: Add indexes
  âœ… Task 1.3: Update schema docs
  âœ… All Phase 1 tests passing

Phase 1 Complete! Ready to continue with Phase 2?

User: Yes
[Executes ALL OF PHASE 2]
  âœ… Task 2.1: Create API endpoint
  âœ… Task 2.2: Add validation
  âœ… Task 2.3: Write tests
  âœ… Task 2.4: Update API docs
  âœ… All Phase 2 tests passing

Phase 2 Complete! Ready to continue with Phase 3?
```

**Example - WRONG Execution:**
```
âŒ Stopping after Task 1.1 (incomplete phase)
âŒ Stopping after Task 2.1 (incomplete phase)
âŒ Executing all phases without asking approval
âŒ Asking approval between individual tasks
```

**Approval Points:**
- âœ… Between phases (Phase 1 â†’ Phase 2)
- âŒ NOT between tasks within a phase (Task 1.1 â†’ Task 1.2)

**This rule applies to:**
- âœ… Feature implementation plans
- âœ… Refactoring work
- âœ… Documentation updates
- âœ… Test creation
- âœ… Setup sequences
- âœ… Migration work
- âœ… CORTEX 2.0 implementation phases

**Response Template After Phase Completion:**
```markdown
## âœ… Phase [N] Complete

**Delivered:**
- âœ… [Task 1] - [Result]
- âœ… [Task 2] - [Result]
- âœ… [Task 3] - [Result]

**Validation:**
- âœ… All tests passing
- âœ… No errors or warnings
- âœ… Documentation updated

**Next Phase Ready:** Phase [N+1] - [Description]
  - Task [N+1].1: [Description]
  - Task [N+1].2: [Description]
  - Estimated: [X] minutes

**Continue?** Say **"Yes"** to proceed with Phase [N+1], or **"Stop"** to review.
```

---

## ğŸš€ First Time? Run Setup!

If you're installing CORTEX in a new repository, start with the setup command:

### In Copilot Chat:
```markdown
#file:prompts/user/cortex.md

Run setup
```

Or:
```markdown
#file:prompts/user/cortex.md

setup
```

### From Terminal:
```bash
# Using Python
python scripts/cortex_setup.py

# In a different repository
python scripts/cortex_setup.py --repo /path/to/project

# Quiet mode
python scripts/cortex_setup.py --quiet
```

### What Setup Does (5-10 minutes):

**Phase 1: Environment Analysis** ğŸ”
- Detects repository structure and technologies
- Identifies languages and frameworks
- Counts files and checks for Git

**Phase 2: Tooling Installation** ğŸ“¦
- Installs Python dependencies (pytest, mkdocs, etc.)
- Installs Node.js dependencies (if package.json exists)
- Installs MkDocs for documentation

**Phase 3: Brain Initialization** ğŸ§ 
- Creates 4-tier brain structure:
  - **Tier 0:** Instinct (immutable rules)
  - **Tier 1:** Working Memory (last 20 conversations)
  - **Tier 2:** Knowledge Graph (learned patterns)
  - **Tier 3:** Context Intelligence (project metrics)
- Initializes SQLite databases for each tier
- Creates corpus callosum for inter-hemisphere messaging

**Phase 4: Crawler Execution** ğŸ•·ï¸
- Scans repository for code files
- Maps file relationships and patterns
- Discovers UI elements and IDs (for testing)
- Analyzes Git history and metrics

**Phase 5: Welcome** ğŸ‰
- Shows setup summary
- Links to "The Awakening of CORTEX" story
- Points to quick start documentation
- Explains how to use CORTEX

**After Setup:**
You can immediately start using CORTEX:
```markdown
#file:prompts/user/cortex.md

What can you help me with?
```

---

## ğŸ”· Gemini prompt suite (text + vision)

Use these ready-to-copy templates with Google Gemini (1.5 Pro/Flash) to power CORTEX agents. They standardize instructions, safety, and structured outputs so results plug into the One Door workflow cleanly.

Notes
- Keep prompts minimal and specific. Prefer explicit outputs over open prose.
- Default to JSON output. Ask Gemini to emit ONLY JSON unless otherwise stated.
- For images, pass 1â€“6 inputs. Prefer high-resolution, include context caption.
- See image-generation prompts in `prompts/user/cortex-gemini-image-prompts.md`.

Shared variables
- {{goal}}: short task description in 1â€“2 sentences
- {{context}}: brief relevant project context (files, tech, constraints)
- {{constraints}}: bullets such as â€œno external deps, incremental edits, SRPâ€
- {{artifacts}}: snippets, logs, or prior outputs to ground the response
- {{images}}: one or more image inputs with optional captions

Expected JSON shape (default)
```json
{
  "intent": "PLAN | EXECUTE | TEST | VALIDATE | GOVERN | ASK",
  "summary": "one-sentence outcome summary",
  "actions": [
    { "id": "A1", "title": "concise step", "details": "what and why" }
  ],
  "risks": [
    { "issue": "risk or uncertainty", "mitigation": "how to address" }
  ],
  "artifacts": [
    { "type": "text|json|code|table", "label": "name", "content": "..." }
  ],
  "next_prompt": "optional follow-up prompt for the next agent"
}
```

### 1) Task router (text-only, low-latency)
Purpose: classify intent and propose next steps. Good for first-pass routing.

```text
System
You are CORTEX Router. Classify the user goal and return ONLY JSON per schema.
Follow: SOLID, test-first, Definition of Ready/Done. If missing info, ask via next_prompt.

User
Goal: {{goal}}
Context: {{context}}
Constraints: {{constraints}}
Artifacts: {{artifacts}}

Instructions
- Decide intent: PLAN, EXECUTE, TEST, VALIDATE, GOVERN, ASK.
- Propose 3â€“6 concrete actions max.
- Include at least one risk with mitigation.
- Output ONLY JSON exactly matching the schema.
```

### 2) Vision analysis (images â†’ structured insights)
Purpose: extract UI structure, flows, and issues from screenshots/wireframes.

```text
System
You are CORTEX Screenshot Analyzer. Analyze images precisely. Perform OCR, detect components, map layout, and identify potential problems. Output ONLY JSON.

User
Goal: {{goal}}
Images: {{images}}
Context: {{context}}
Constraints: {{constraints}}

Output JSON
{
  "intent": "ASK",
  "summary": "what the images show and why it matters",
  "ui": {
    "components": [
      {"type": "button|input|card|nav|modal|other", "label": "visible text if any", "id_hint": "suggested-stable-id", "bbox": [x,y,w,h]}
    ],
    "layout": [ {"region": "header|sidebar|content|footer", "bbox": [x,y,w,h]} ]
  },
  "text_blocks": [ {"content": "ocr text", "bbox": [x,y,w,h]} ],
  "issues": [ {"issue": "accessibility/contrast/overflow/consistency", "evidence": "where seen"} ],
  "next_prompt": "short follow-up for Planner or Tester"
}
```

### 3) Code proposal (text-only, safe-by-default)
Purpose: propose minimal change set with strong constraints. Avoids giant diffs.

```text
System
You are CORTEX Builder. Produce a minimal, test-first change plan. Do not invent files. Respect SRP and incremental edits. Output ONLY JSON.

User
Goal: {{goal}}
Context: {{context}}
Constraints: {{constraints}}
Artifacts: {{artifacts}}

Output JSON
{
  "intent": "EXECUTE",
  "summary": "one-line plan",
  "changes": [
    {
      "file": "relative/path.ext",
      "strategy": "add|edit|refactor|extract",
      "rationale": "why this file and change",
      "snippets": [
        {"anchor": "near line or symbol name", "insert": "code to add or patch fragment"}
      ]
    }
  ],
  "tests": [
    {"file": "path/to/test.ext", "cases": ["happy path", "edge case"]}
  ],
  "risks": [ {"issue": "risk", "mitigation": "how"} ],
  "next_prompt": "short follow-up for Test Generator"
}
```

### 4) OCR-first extraction (vision)
Purpose: get faithful text in reading order with bounding boxes for downstream use.

```text
System
You are a precise OCR extractor. Preserve line breaks and reading order. Include bounding boxes and confidence. Output ONLY JSON.

User
Images: {{images}}
Context: {{context}}

Output JSON
{
  "intent": "ASK",
  "summary": "ocr coverage quality",
  "blocks": [
    {"text": "...", "bbox": [x,y,w,h], "confidence": 0.0â€“1.0}
  ]
}
```

### 5) Safety guardrails preamble (add before any prompt when needed)
Use this to reinforce safety and quality.

```text
Safety & Quality
- Do not include secrets, tokens, or PII. If suspected, redact and warn.
- State uncertainty explicitly; avoid fabrications.
- Refuse harmful or disallowed content. Offer a safe alternative where possible.
- Prefer small, reversible steps; minimize blast radius.
```

### 6) Output evaluator (QA rubric)
Purpose: rate answers before accepting.

```text
System
You are CORTEX Validator. Score an answer across dimensions and suggest fixes. Output ONLY JSON.

User
Goal: {{goal}}
Answer: {{artifacts}}
Context: {{context}}

Output JSON
{
  "intent": "VALIDATE",
  "scores": {
    "correctness": 0.0â€“1.0,
    "completeness": 0.0â€“1.0,
    "clarity": 0.0â€“1.0,
    "safety": 0.0â€“1.0
  },
  "issues": [ {"issue": "whatâ€™s wrong", "severity": "low|med|high"} ],
  "recommendations": [ "concrete improvement steps" ],
  "next_prompt": "optional remediation prompt"
}
```

### 7) JSON repair helper
Purpose: when a model returned invalid JSON, ask for a corrected version only.

```text
System
Return ONLY a syntactically valid JSON that matches the target schema. No commentary.

User
Here is invalid JSON to repair (do not change content semantics):
{{artifacts}}
```

Tips
- Prefer 1â€“2 short images vs many tiny ones; include a caption with what to look for.
- Keep constraints explicit (e.g., â€œno external depsâ€, â€œincremental patchâ€, â€œkeep public APIâ€).
- Ask for at most 3â€“6 actions to curb verbosity and hallucinations.
- Link to visual prompts: `prompts/user/cortex-gemini-image-prompts.md`.


## ğŸ—ï¸ SOLID v5.0 Architecture

### What's New
- âœ… **Single Responsibility (SRP):** Each agent has ONE clear job
- âœ… **Interface Segregation (ISP):** Dedicated agents (no mode switches)
- âœ… **Dependency Inversion (DIP):** Abstractions for session/file/test access
- âœ… **Open/Closed (OCP):** Easy to extend (add new intents/agents)

### Specialist Agents (10 Total)
```
Router            â†’ intent-router.md       â†’ Analyzes & routes requests
Planner           â†’ work-planner.md        â†’ Creates multi-phase plans
Executor          â†’ code-executor.md       â†’ Implements code (test-first)
Tester            â†’ test-generator.md      â†’ Creates & runs tests
Validator         â†’ health-validator.md    â†’ System health checks
Governor          â†’ change-governor.md     â†’ Reviews CORTEX changes
Error Corrector   â†’ error-corrector.md     â†’ Fixes Copilot mistakes
Session Resumer   â†’ session-resumer.md     â†’ Resumes after breaks
Screenshot Analyzer â†’ screenshot-analyzer.md â†’ Extracts requirements from images
Commit Handler    â†’ commit-handler.md      â†’ Intelligent git commits (NEW)
```

### ğŸ§  BRAIN System (Self-Learning Feedback Loop)

**NEW in v5.0:** CORTEX learns from every interaction!  
**ENHANCED in v6.0:** Three-tier architecture with holistic development intelligence!

```
ğŸ§  BRAIN = Three-Tier Intelligence System

Purpose: Learn from interactions, conversations, AND development activity
Storage: KDS/cortex-brain/
- conversation-history.jsonl â†’ Last 20 complete conversations (Tier 1) âœ… WORKING
- conversation-context.jsonl â†’ Recent messages buffer (last 10) âœ… WORKING
- knowledge-graph.yaml       â†’ Aggregated learnings (Tier 2) âœ… WORKING
- development-context.yaml   â†’ Holistic project metrics (Tier 3) âœ… WORKING
- events.jsonl               â†’ Raw event stream âœ… WORKING

Architecture: Three-tier system inspired by human cognition
- Tier 1 (Short-term): Last 20 conversations (FIFO queue, no time expiration) ğŸŸ¡
- Tier 2 (Long-term): Consolidated patterns from deleted conversations âœ…
- Tier 3 (Context): Development activity, velocity, correlations âœ…
- Design: KDS/docs/architecture/BRAIN-CONVERSATION-MEMORY-DESIGN.md
- Tier 3 Design: KDS/docs/architecture/KDS-HOLISTIC-REVIEW-AND-RECOMMENDATIONS.md
- Validation: KDS/docs/architecture/CONVERSATION-MEMORY-SELF-REVIEW.md (health tracking)
```

**What BRAIN Learns:**
- âœ… Intent patterns (which phrases trigger which intents)
- âœ… File relationships (which files are modified together)
- âœ… Common mistakes (which corrections happen frequently)
- âœ… Workflow patterns (successful task sequences)
- âœ… Validation insights (common failures and fixes)
- âœ… **Conversation history (last 20 complete conversations, FIFO queue)** ğŸ†•
- âœ… **Development velocity (code changes, commit patterns)** ğŸ†•
- âœ… **Testing activity (pass rates, flaky tests, coverage)** ğŸ†•
- âœ… **Work patterns (productive times, focus duration, correlations)** ğŸ†•

**How Automatic Learning Works:**
```
Agent performs action
    â†“
Event logged to events.jsonl (automatic)
Message appended to active conversation
    â†“
Conversation boundary detected? â†’ End conversation, start new one
    â†“
IF 21st conversation starts â†’ Delete oldest conversation (FIFO)
    â†“
Event count checked after each task (Rule #16 Step 5)
    â†“
IF 50+ events OR 24 hours passed â†’ Automatic BRAIN update
    â†“
brain-updater.md processes events â†’ Updates knowledge-graph.yaml
Deleted conversations â†’ Patterns extracted â†’ Long-term memory
    â†“
Next request â†’ Router queries BRAIN + conversation history â†’ Smarter decisions with context
```

**Conversation History Benefits:**
- ğŸ”„ **Continuity:** "Make it purple" knows you mean the FAB button from earlier conversation
- ğŸ§© **Cross-conversation context:** Reference any of the last 20 conversations
- ğŸ’¬ **Natural follow-ups:** No need to repeat full context in every message
- ğŸ“ **Reference resolution:** "Change that file" knows which file from conversation history
- â³ **Long-running work:** Conversation preserved until 20 newer conversations (days/weeks/months depending on usage)

**FIFO Queue (Conversation-Level):**
- ğŸ“Š **Capacity:** Last 20 complete conversations (not individual messages)
- ğŸ”„ **Deletion:** When conversation #21 starts, conversation #1 deleted
- â° **No time limits:** Conversations preserved until FIFO deletion (could be months for light usage)
- âœ¨ **Active conversation:** Never deleted (even if oldest)
- ğŸ¯ **Pattern extraction:** Before deletion, patterns consolidated to long-term memory

**Privacy & Storage:**
- ğŸ  **Local storage:** History stays in `KDS/cortex-brain/conversation-history.jsonl`
- ğŸ’¾ **Predictable size:** Always 20 conversations (~70-200 KB total)
- ğŸ§¹ **Manual clear:** Use `#file:KDS/prompts/internal/clear-conversation.md` to reset
- ğŸ”’ **Deleted conversations:** Patterns extracted, details discarded

**Tier 3: Development Context (NEW in v6.0)**

**Purpose:** Holistic project understanding for data-driven planning and proactive warnings

**What's Tracked:**
```yaml
Git Activity:
  - Commit history (30 days)
  - Change velocity per week
  - File hotspots (high churn rate)
  - Contributors and patterns
  
Code Changes:
  - Lines added/deleted
  - Velocity trends (increasing/decreasing)
  - Churn rates per file
  - Stability classification
  
CORTEX Usage:
  - Session creation and completion rates
  - Intent distribution (PLAN, EXECUTE, TEST, etc.)
  - Workflow success rates
  - Test-first vs test-skip effectiveness
  
Testing Activity:
  - Test creation rate
  - Pass/fail rates
  - Flaky test detection
  - Coverage trends
  
Project Health:
  - Build status
  - Deployment frequency
  - Code quality metrics
  - Issue resolution times
  
Work Patterns:
  - Most productive times
  - Session duration averages
  - Feature lifecycle timing
  - Focus duration without interruptions
  
Correlations:
  - Commit size vs success rate
  - Test-first vs rework rate
  - CORTEX usage vs velocity
```

**Automatic Benefits:**
```
Planning Phase:
  â†’ "Based on 12 similar UI features, estimated 5-6 days"
  â†’ "Recommend 10am-12pm sessions (94% success rate at that time)"
  â†’ "Test-first approach reduces rework by 68%"

File Modification:
  â†’ "âš ï¸ HostControlPanel.razor is a hotspot (28% churn)"
  â†’ "This file often modified with noor-canvas.css (75% co-mod rate)"
  â†’ "Add extra testing - file is unstable"

Proactive Warnings:
  â†’ "âš ï¸ Velocity dropped 68% this week (consider smaller commits)"
  â†’ "âš ï¸ Flaky test detected: fab-button.spec.ts (15% failure rate)"
  â†’ "âœ… Test coverage increased from 72% to 76% (good trend!)"
```

**How to Collect:**
```powershell
# Manual collection (always runs)
.\KDS\scripts\collect-development-context.ps1

# Automatic collection (throttled for efficiency)
# Triggered by brain-updater.md ONLY IF last collection > 1 hour
# This optimizes performance while maintaining accuracy
```

**Storage:**
- File: `KDS/cortex-brain/development-context.yaml`
- Size: ~50-100 KB (holistic metrics, not raw data)
- Update: âš¡ **Throttled** - Only when > 1 hour since last collection
- Purpose: Data-driven estimates, proactive warnings, velocity tracking

**âš¡ Efficiency Optimization:**
- âœ… **Automatic throttling:** Tier 3 only updates if last_collection > 1 hour
- âœ… **Rationale:** Git/test/build metrics don't change every 50 events
- âœ… **Impact:** Reduces 2-5 min operations from 2-4x/day to 1-2x/day
- âœ… **Accuracy:** 1-hour freshness sufficient for velocity metrics
- ğŸ“Š **User benefit:** Zero performance impact, same data quality

**Automatic Update Triggers:**
1. **Event threshold:** 50+ new events accumulated (Tier 2 update)
2. **Time threshold:** 24 hours since last update (Tier 2 if 10+ events exist)
3. **Tier 3 throttle:** Only if last Tier 3 collection > 1 hour âš¡ **NEW**
4. **End of session:** When all tasks in session complete
5. **Manual trigger:** User explicitly calls `#file:KDS/prompts/internal/brain-updater.md`

**ğŸš¨ CRITICAL: Event Logging Must Be Active**

For automatic learning to work:
- âœ… All agents MUST log events to `events.jsonl`
- âœ… Events follow standard format (see `KDS/cortex-brain/README.md`)
- âœ… `events.jsonl` must be writable (check file permissions)
- âœ… Rule #16 Step 5 must include BRAIN health check

**If BRAIN isn't learning:**
1. Check `events.jsonl` exists and has recent events
2. Verify `knowledge-graph.yaml` updated in last 24 hours
3. Count unprocessed events (warn if >50)
4. Run manual update: `#file:KDS/prompts/internal/brain-updater.md`

**See:** `KDS/docs/architecture/KDS-SELF-REVIEW-STRATEGY.md` for violation detection

**How It Works:**
```
User request â†’ Router queries BRAIN â†’ High confidence? â†’ Auto-route
                                   â†’ Low confidence? â†’ Pattern matching

Agent action â†’ Log event â†’ BRAIN updater processes â†’ Knowledge graph updated

Next request â†’ Router gets smarter (learned from history)
```

**Benefits:**
- ğŸš€ Faster routing (learns successful patterns)
- âš ï¸ Prevents mistakes (warns about common file confusions)
- ğŸ’¡ Suggests related files (based on co-modification history)
- ğŸ“Š Improves over time (accumulates knowledge)

**BRAIN Agents:**
```
brain-query.md   â†’ Query knowledge graph AND development context for insights
brain-updater.md â†’ Process events, update graph, trigger Tier 3 collection
conversation-context-manager.md â†’ Track recent messages for continuity (NEW)
clear-conversation.md â†’ Reset conversation context (NEW)
development-context-collector.md â†’ Collect git, test, build metrics (Tier 3) ğŸ†•
```

### Shared Abstractions (DIP Compliance)
```
session-loader â†’ Abstract session access (file/db/cloud agnostic)
test-runner    â†’ Abstract test execution (framework agnostic)
file-accessor  â†’ Abstract file I/O (path agnostic)
brain-query    â†’ Abstract BRAIN queries (self-learning system)

CRITICAL: All abstractions are 100% LOCAL (in KDS/).
- Default storage: Local files (KDS/sessions/)
- Default tests: Project's existing tools (discovered, not installed)
- Default I/O: PowerShell built-ins (Get-Content, Set-Content)
- Default BRAIN: Local YAML/JSON (KDS/cortex-brain/)
- Zero external dependencies for CORTEX CORE
- Cloud/database options are OPTIONAL extensions (user's choice)
```

### ğŸ“¦ Open Source Library Policy

**CORTEX Enhancement Libraries (ALLOWED)**

Open source libraries that enhance CORTEX functionality are PERMITTED when:
- âœ… They are declared as **required dependencies** during CORTEX setup
- âœ… They are included in setup instructions (package.json, requirements.txt, etc.)
- âœ… User is informed upfront that these are needed to proceed
- âœ… They enhance CORTEX capabilities (routing, analysis, testing, validation)

**Examples of Acceptable CORTEX Dependencies:**
```json
// package.json (if CORTEX uses Node.js enhancements)
{
  "devDependencies": {
    "markdown-it": "^13.0.0",      // Enhanced markdown parsing for intent analysis
    "yaml": "^2.3.0",                // YAML parsing for configuration
    "chalk": "^5.3.0"                // Terminal output formatting
  }
}

// requirements.txt (if CORTEX uses Python enhancements)
markdown-it-py>=3.0.0    # Enhanced markdown processing
pyyaml>=6.0              # YAML configuration parsing
rich>=13.0.0             # Beautiful terminal output
```

**NOT Considered External Dependencies:**
- Libraries needed for CORTEX core functionality (router, planner, executor)
- Libraries that improve intent detection accuracy
- Libraries that enhance session state management
- Libraries that provide better error reporting/logging

**STILL External Dependencies (Require User Approval):**
- Libraries for the user's APPLICATION code (React, SignalR, etc.)
- Libraries that change application architecture
- Libraries that affect production deployment
- Database/cloud providers not already in use

**Setup Protocol:**
When recommending CORTEX enhancement libraries:
```markdown
âš ï¸ **CORTEX Enhancement Dependencies Required**

To proceed with this CORTEX feature, the following libraries are needed:

ğŸ“¦ Node.js (npm install):
  - markdown-it: Enhanced markdown parsing for intent analysis
  - yaml: Configuration file parsing
  
Installation:
  npm install --save-dev markdown-it yaml

These are KDS-internal dependencies and won't affect your application code.

Proceed with installation? (Y/n)
```

---

## ğŸ§ª Playwright Testing Protocol (PowerShell)

**CRITICAL RULE: All Playwright test automation scripts MUST follow the established protocol pattern.**

**âš ï¸ LONG-RUNNING PROCESS:** Test automation scripts often run >30 seconds. Follow the Long-Running Process Protocol (see Setup section) for:
- Padded time estimates (add 25-50% buffer to test execution time)
- Status updates during app startup and test execution
- Progress indicators when running multiple test files
- Graceful Ctrl+C handling with cleanup

### ğŸ¯ CRITICAL: Component ID-Based Selectors (TDD Requirement)

**RULE:** Always use element IDs for Playwright selectors. Text-based selectors are FRAGILE and PROHIBITED.

**WHY:**
- âœ… 10x faster (getElementById vs DOM text search)
- âœ… Immune to text changes (i18n, wording updates, HTML restructuring)
- âœ… Explicit intent (`#login-btn` is clearer than `button:has-text("Login")`)
- âœ… No false positives (unique ID vs multiple matching texts)

**WRONG (FRAGILE - DO NOT USE):**
```typescript
// âŒ BREAKS when text changes, slow DOM search, ambiguous
const button = page.locator('button:has-text("Start Session")').first();
const link = page.locator('div:has-text("Transcript Canvas")');
```

**CORRECT (ROBUST - ALWAYS USE):**
```typescript
// âœ… Fast, reliable, explicit, future-proof
const button = page.locator('#sidebar-start-session-btn');
const link = page.locator('#reg-transcript-canvas-btn');
```

**Component ID Discovery:**
Before writing ANY Playwright test, discover available IDs:
1. Open target component file (e.g., `HostControlPanelSidebar.razor`)
2. Search for `id="` attributes
3. Use those IDs in your test selectors
4. If no ID exists â†’ ADD ONE to the component (with `[REFACTOR:component-id]` comment)

**Enforcement:**
- Test reviews MUST reject text-based selectors
- CORTEX test-generator SHOULD warn when ID exists but text selector used
- Future: Automated crawler will build `KDS/cache/component-ids.json`

### Application Routes & Tokens

**Host Control Panel:**
- Route: `https://localhost:9091/host/control-panel/{hostToken}`
- Page File: `SPA/NoorCanvas/Pages/HostControlPanel.razor`
- Component File: `SPA/NoorCanvas/Components/Host/HostControlPanelContent.razor`
- Session 212 Token: `PQ9N5YWW`
- Full URL: `https://localhost:9091/host/control-panel/PQ9N5YWW`

**Component IDs (Host Control Panel):**
| Element | Component | ID | Purpose |
|---------|-----------|-----|---------|
| Transcript Canvas Button | UserRegistrationLink.razor | `reg-transcript-canvas-btn` | Select transcript canvas mode |
| Asset Canvas Button | UserRegistrationLink.razor | `reg-asset-canvas-btn` | Select asset canvas mode |
| Start Session Button | HostControlPanelSidebar.razor | `sidebar-start-session-btn` | Initiate session |
| Registration Link Container | UserRegistrationLink.razor | `reg-link-container` | Parent container for canvas buttons |

### Standard Protocol Pattern

**Reference Implementation:** `Scripts/run-debug-panel-percy-tests.ps1`

**Required Steps:**
1. âœ… Launch app using `Start-Job` with `dotnet run` (NOT Start-Process)
2. âœ… Wait for app readiness (20 seconds minimum, or health check loop)
3. âœ… Run Playwright tests using `npx playwright test [file] --headed`
4. âœ… Cleanup with `Stop-Job` and `Remove-Job` (unless -KeepAppRunning)

### Correct Pattern (FOLLOW THIS)

```powershell
param([switch]$KeepAppRunning)

# Step 1: Start app with Start-Job
$appJob = Start-Job -ScriptBlock {
    Set-Location 'D:\PROJECTS\NOOR CANVAS\SPA\NoorCanvas'
    dotnet run
}

# Step 2: Wait for readiness (20s minimum)
Start-Sleep -Seconds 20

# Step 3: Run Playwright tests
try {
    Set-Location 'D:\PROJECTS\NOOR CANVAS'
    npx playwright test Tests/UI/my-test.spec.ts --headed
    $exitCode = $LASTEXITCODE
}
finally {
    # Step 4: Cleanup
    if (-not $KeepAppRunning) {
        Stop-Job -Job $appJob -ErrorAction SilentlyContinue
        Remove-Job -Job $appJob -ErrorAction SilentlyContinue
    }
}

exit $exitCode
```

### WRONG Patterns (NEVER DO THIS)

âŒ **Using Start-Process with -ArgumentList:**
```powershell
# WRONG - Don't use Start-Process with complex arguments
$proc = Start-Process -FilePath "npx" -ArgumentList $testArgs -NoNewWindow -Wait -PassThru
```

âŒ **Using Invoke-WebRequest for health checks without proper error handling:**
```powershell
# WRONG - Complex health check that can fail unpredictably
$resp = Invoke-WebRequest -Uri $appUrl -SkipCertificateCheck -TimeoutSec 5
```

âŒ **Separating test running from working directory:**
```powershell
# WRONG - Don't Push-Location multiple times
Push-Location $testsPath
npx playwright test
Pop-Location
```

### Playwright Command Format

**Correct:**
```powershell
# Set working directory ONCE, then run test
Set-Location 'D:\PROJECTS\NOOR CANVAS'
npx playwright test Tests/UI/my-test.spec.ts --headed
```

**For Percy visual tests:**
```powershell
# Percy wraps Playwright
percy exec -- playwright test Tests/UI/my-test.spec.ts --headed
```

**Capture exit code:**
```powershell
npx playwright test Tests/UI/my-test.spec.ts --headed
$exitCode = $LASTEXITCODE
exit $exitCode
```

### Test Script Checklist

Before creating ANY Playwright test automation script, verify:

```
âœ“ Uses Start-Job (not Start-Process) for app launch?
âœ“ Waits minimum 20 seconds for app readiness?
âœ“ Sets working directory to project root (not Tests/UI)?
âœ“ Runs npx playwright test with direct command (no Start-Process)?
âœ“ Captures $LASTEXITCODE for exit status?
âœ“ Cleans up with Stop-Job and Remove-Job?
âœ“ Supports -KeepAppRunning parameter?

If ANY answer is NO â†’ FIX before running
```

### Reference Scripts

**Study these working examples:**
- âœ… `Scripts/run-debug-panel-percy-tests.ps1` - Full featured (health checks, Percy, detailed logging)
- âœ… `Scripts/run-transcript-canvas-visual-tests.ps1` - Simple pattern (20s wait, basic cleanup)
- âœ… `Scripts/run-fab-share-button-percy-tests.ps1` - Percy visual regression pattern

**Key Patterns:**
```powershell
# App Launch
$appJob = Start-Job -ScriptBlock {
    Set-Location 'D:\PROJECTS\NOOR CANVAS\SPA\NoorCanvas'
    dotnet run
}

# Wait Pattern (Simple)
Start-Sleep -Seconds 20

# Wait Pattern (Health Check - Advanced)
while ($attempt -lt $maxAttempts) {
    try {
        $resp = Invoke-WebRequest -Uri $appUrl -UseBasicParsing -TimeoutSec 5
        if ($resp.StatusCode -eq 200) { break }
    } catch {
        Start-Sleep -Seconds 2
    }
    $attempt++
}

# Test Execution
Set-Location 'D:\PROJECTS\NOOR CANVAS'
npx playwright test Tests/UI/my-test.spec.ts --headed
$exitCode = $LASTEXITCODE

# Cleanup
Stop-Job -Job $appJob -ErrorAction SilentlyContinue
Remove-Job -Job $appJob -ErrorAction SilentlyContinue
```

---

## ğŸ—ï¸ Architectural Thinking Mandate

**CRITICAL RULE: All CORTEX agents MUST think architecturally when proposing solutions.**

### Core Principles

**1. Architecture-First Design**
- âœ… Understand existing application architecture BEFORE proposing solutions
- âœ… Design solutions that naturally fit the current architecture from the start
- âŒ NEVER propose monolithic implementations that need refactoring later
- âŒ NEVER create "everything in one file" with intent to break apart later

**2. Pre-Flight Architectural Validation**
Every solution proposal must pass this refactor logic check:

```
BEFORE proposing a solution:
  â†“
1. Identify current architectural patterns
   - Component structure (where do similar components live?)
   - API organization (where do similar APIs exist?)
   - Service layer patterns (how are services currently structured?)
   - State management (what patterns are in use?)
   - File organization (what's the project structure?)
   â†“
2. Run mental refactor test
   - Would this solution require significant refactoring to fit the architecture?
   - Am I creating files that don't match existing conventions?
   - Am I mixing concerns that are separated elsewhere?
   â†“
3. If refactor is needed â†’ REDESIGN the solution
   - Align with existing patterns
   - Follow established separation of concerns
   - Place files in correct locations from the start
   â†“
4. Only then propose the architecturally-aligned solution
```

**3. Forbidden Anti-Patterns**

âŒ **NEVER do this:**
```
âŒ "Let's create everything in PageComponent.razor first, then we'll break out 
   the child components later"
   
âŒ "I'll add the API logic to the page for now, we can move it to a service later"

âŒ "Let's put this in a temporary location and reorganize after it works"

âŒ "We'll create the monolith first, then refactor to match your architecture"
```

âœ… **ALWAYS do this:**
```
âœ… "Based on the existing component structure in Components/Canvas/, 
   I'll create CanvasPdfExport.razor there and import it into the parent"
   
âœ… "Following the pattern in Services/, I'll create PdfExportService.cs 
   and inject it via DI as seen in other services"

âœ… "The existing API controllers are in Controllers/API/, so I'll create 
   PdfExportController.cs there with the same routing pattern"

âœ… "This matches the architecture - components are separated, services handle 
   business logic, and APIs are in the correct location from the start"
```

**4. Architectural Discovery Process**

Before proposing ANY solution, agents must:

```
Step 1: Discover Current Architecture
  - Search for similar features/components
  - Identify existing patterns and conventions
  - Map out file organization structure
  - Understand separation of concerns

Step 2: Pattern Matching
  - "Where do similar components live?"
  - "How are APIs currently organized?"
  - "What's the service layer pattern?"
  - "How is state managed?"

Step 3: Alignment Check
  - Does my solution follow these patterns?
  - Are files in the right locations?
  - Is separation of concerns maintained?
  - Would a developer familiar with this codebase find this natural?

Step 4: Propose Solution
  - Only after architectural alignment is confirmed
  - Explicitly state which patterns you're following
  - Show how it fits the existing structure
```

**5. Implementation Example**

**BAD (Anti-Pattern):**
```markdown
Plan: Add PDF export feature

Phase 1: Create basic implementation
  - Task 1.1: Add export logic to TranscriptCanvas.razor
  - Task 1.2: Test the functionality
  
Phase 2: Refactor to proper architecture
  - Task 2.1: Extract to PdfExportService
  - Task 2.2: Create dedicated component
  - Task 2.3: Move to API controller

âŒ This violates architectural thinking - refactoring is built into the plan!
```

**GOOD (Architecturally Aligned):**
```markdown
Plan: Add PDF export feature

Phase 0: Architectural Discovery
  - Task 0.1: Map existing service patterns (Services/)
  - Task 0.2: Identify component organization (Components/)
  - Task 0.3: Review API structure (Controllers/API/)

Phase 1: Test Infrastructure (following existing test patterns)
  - Task 1.1: Create PdfExportServiceTests.cs (Tests/Unit/Services/)
  - Task 1.2: Create PdfExportController tests (Tests/Unit/Controllers/)
  - Task 1.3: Create visual tests (Tests/UI/pdf-export.spec.ts)

Phase 2: Implementation (architecturally aligned from start)
  - Task 2.1: Create PdfExportService.cs in Services/
  - Task 2.2: Create PdfExportButton.razor in Components/Canvas/
  - Task 2.3: Create PdfExportController.cs in Controllers/API/
  - Task 2.4: Register service in DI (Program.cs pattern)

âœ… This is architecturally correct from the start - no refactoring needed!
```

**6. Agent-Specific Requirements**

**Work Planner (work-planner.md):**
- âœ… MUST include "Phase 0: Architectural Discovery" for new features
- âœ… Plans must show architectural alignment in task descriptions
- âœ… File paths must match existing conventions

**Code Executor (code-executor.md):**
- âœ… MUST verify file location matches architecture before creating
- âœ… MUST follow existing patterns for similar features
- âœ… MUST NOT create temporary/placeholder implementations

**Test Generator (test-generator.md):**
- âœ… Tests must mirror the application's architectural organization
- âœ… Test files must be placed following existing test structure

**7. Validation Checkpoint**

Before ANY code generation, agents must answer:

```
âœ“ Have I identified where similar code lives in this architecture?
âœ“ Am I following the existing file organization patterns?
âœ“ Is my separation of concerns consistent with the codebase?
âœ“ Would this solution require refactoring to fit the architecture?
âœ“ Am I creating files in their permanent, correct locations?

If ANY answer is NO â†’ STOP and redesign the solution
```

**8. Success Criteria**

A solution is architecturally valid when:
- âœ… No refactoring phase exists in the plan
- âœ… Files are in correct locations from creation
- âœ… Patterns match existing similar features
- âœ… Separation of concerns is maintained from start
- âœ… A developer familiar with the codebase would say "this fits naturally"

---

## ï¿½ğŸ¯ The ONLY Command You Need to Remember

```markdown
#file:KDS/prompts/user/cortex.md

[Tell CORTEX what you want in natural language]
```

That's it! CORTEX will automatically:
- âœ… Analyze your request (intent detection)
- âœ… Route to the appropriate specialist agent
- âœ… Execute the correct workflow
- âœ… Handle multi-step operations
- âœ… Maintain session state

---

## ğŸ“‹ What You Can Say

### Start New Work
```markdown
#file:KDS/prompts/user/cortex.md

I want to add a FAB button pulse animation when questions arrive
```
â†’ Routes to: **plan.md** â†’ work-planner.md

### Continue Existing Work
```markdown
#file:KDS/prompts/user/cortex.md

Continue working on the current task
```
â†’ Routes to: **execute.md** â†’ code-executor.md

### Resume After Break
```markdown
#file:KDS/prompts/user/cortex.md

Show me where I left off
```
â†’ Routes to: **resume.md** â†’ work-planner.md

### Fix Copilot's Mistake
```markdown
#file:KDS/prompts/user/cortex.md

You're modifying the wrong file. The FAB button is in HostControlPanelContent.razor
```
â†’ Routes to: **correct.md** â†’ code-executor.md

### Create Tests
```markdown
#file:KDS/prompts/user/cortex.md

Create visual regression tests for the share button
```
â†’ Routes to: **test.md** â†’ test-generator.md

### Check System Health
```markdown
#file:KDS/prompts/user/cortex.md

Run all validations and show me the health status
```
â†’ Routes to: **validate.md** â†’ health-validator.md

### Analyze Screenshot
```markdown
#file:KDS/prompts/user/cortex.md

Analyze this screenshot and extract requirements

[Attach screenshot via chat interface]
```
â†’ Routes to: **screenshot-analyzer.md** â†’ Extracts requirements, annotations, design specs

### Commit Changes (Automatic After Task Completion)
```markdown
#file:KDS/prompts/user/cortex.md

Commit changes
```
â†’ Uses: **KDS/scripts/commit-kds-changes.ps1** â†’ Smart commit handler achieving zero uncommitted files

**âš ï¸ NOTE: Commits happen AUTOMATICALLY after each task completion (Rule #16)**

You typically don't need to invoke this manually. CORTEX automatically commits after:
- âœ… Every task completes successfully
- âœ… All tests pass (GREEN)
- âœ… Post-implementation review passes
- âœ… Build validates with zero errors

**Manual use cases (when commits were skipped or failed):**
- ğŸ”„ Re-running commit after fixing validation issues
- ğŸ“ Committing documentation-only changes
- ğŸ§¹ Committing cleanup/reorganization work

**What automatic commits do:**
- âœ… Analyzes uncommitted files and categorizes them intelligently
- âœ… Auto-updates .gitignore for CORTEX auto-generated files (BRAIN state, internal prompts, reports)
- âœ… Resets auto-generated files that should not be committed (conversation-context.jsonl, etc.)
- âœ… Stages only user-created files (user prompts, documentation, code)
- âœ… Creates semantic commit messages (feat/fix/docs/chore)
- âœ… Achieves zero uncommitted files automatically
- âœ… Interactive mode for documentation decisions
- âœ… Dry-run mode for preview without changes

**Automatic .gitignore management:**
- CORTEX BRAIN state files (conversation-context.jsonl, conversation-history.jsonl, development-context.yaml)
- CORTEX internal prompts (auto-updated by system)
- CORTEX reports (monitoring/, self-review/, test-reports/)
- PlayWright CORTEX artifacts
- Temporary test files (.mjs, .spec.*)

**Example output:**
```
ğŸ§  CORTEX Smart Commit Handler
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Step 1: Analyzing uncommitted files...
  Modified files: 9
  Untracked files: 11

Step 2: Categorizing files...
Step 3: Updating .gitignore...
  Adding to .gitignore:
    + KDS/cortex-brain/conversation-context.jsonl
    + KDS/prompts/internal/*.md
    + KDS/reports/monitoring/
  âœ… .gitignore updated with CORTEX patterns

Step 4: Resetting auto-generated files...
  Resetting:
    - KDS/cortex-brain/conversation-context.jsonl
    - KDS/prompts/internal/code-executor.md
  âœ… Reset 2 auto-generated files

Step 5: Preparing commit...
  Files to commit: 3
    + KDS/prompts/user/cortex.md
    + KDS/dashboard/README.md
    + .gitignore

Step 6: Staging files...
  âœ… Files staged

Step 7: Committing...
  âœ… Changes committed

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… SUCCESS: Zero uncommitted files!
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**Usage:**
```powershell
# Interactive mode (default)
.\KDS\scripts\commit-kds-changes.ps1

# With custom message
.\KDS\scripts\commit-kds-changes.ps1 -Message "feat(kds): Add dashboard"

# Dry run (preview without changes)
.\KDS\scripts\commit-kds-changes.ps1 -DryRun

# Non-interactive (auto-include all documentation)
.\KDS\scripts\commit-kds-changes.ps1 -Interactive:$false
```

### Ask Questions
```markdown
#file:KDS/prompts/user/cortex.md

How do I use Playwright to test the canvas element?
```
â†’ Routes to: **ask-cortex.md** â†’ knowledge-retriever.md

### Review CORTEX Changes
```markdown
#file:KDS/prompts/user/cortex.md

I updated the test-generator to support Percy visual testing
```
â†’ Routes to: **govern.md** â†’ change-governor.md

### View Performance Metrics
```markdown
#file:KDS/prompts/user/cortex.md

run metrics
```
â†’ Routes to: **metrics-reporter.md** â†’ Generates visual performance report

Output destination (for historical comparison):
- A Markdown report is written to `KDS/reports/metrics/<YYYY-MM-DD>/metrics-<timestamp>.md`
- A convenience copy is saved at `KDS/reports/metrics/latest.md`

Notes:
- Reports are visual with bar displays and contain no code snippets.
- Because reports live in the repository, Git naturally versions them so you can compare trends over time.

**What it shows:**
- âœ… BRAIN health score and trends
- âœ… Routing accuracy by intent type
- âœ… Knowledge graph growth visualization
- âœ… File hotspots (high-churn files)
- âœ… Code velocity trends
- âœ… Test-first impact analysis
- âœ… Productivity patterns (best times to work)
- âœ… Auto-learning performance
- âœ… Month-over-month improvements
- âœ… Actionable recommendations

**Example output:**
```
ğŸ“Š Quick Stats
Routing Accuracy: 94% â–² +3% ğŸŸ¢ Excellent
Learning Efficiency: 92% â–² +12% ğŸŸ¢ Excellent

ğŸ§  BRAIN Storage
Tier 1: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 8/20 (40%)
Tier 2: 3,847 entries (+247 this month)
Tier 3: 1,547 commits analyzed

ğŸ”¥ File Hotspots
HostControlPanelContent.razor  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 28% churn âš ï¸
UserRegistrationLink.razor     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ 24% churn âš ï¸

ğŸ’¡ Recommendations
1. Continue test-first (96% success rate)
2. Work 10am-12pm (94% peak productivity)
3. Refactor hotspots (>20% churn)
4. Keep sessions <60 min (89% vs 67%)
```

**â±ï¸ Report time:** ~90 seconds to read

---

### Reset BRAIN for New Application (Amnesia)
```markdown
#file:KDS/prompts/user/cortex.md

Reset BRAIN for new application
```
â†’ Routes to: **brain-amnesia.md** â†’ Safely removes application-specific data

Or run directly:
```powershell
.\KDS\scripts\brain-amnesia.ps1
```

**What it does:**
- âœ… Creates backup of current BRAIN state
- âœ… Generates amnesia report (shows what will be removed vs preserved)
- âœ… Removes application-specific data (file paths, workflows, conversations)
- âœ… Preserves CORTEX core intelligence (generic patterns, governance)
- âœ… Resets BRAIN to fresh state ready for new project

**âš ï¸ CRITICAL: What Gets Removed (Application-Specific)**
```yaml
WILL BE REMOVED:
  - All file relationships (e.g., SPA/NoorCanvas paths)
  - Application-specific workflows (e.g., blazor_component_api_flow)
  - All conversations (application context)
  - All events (application interactions)
  - Development metrics (git stats, velocity)
  - Feature components (e.g., fab_button)
```

**âœ… GUARANTEED: What Gets Preserved (CORTEX Intelligence)**
```yaml
WILL BE PRESERVED:
  - Generic intent patterns ("add [X] button" â†’ plan)
  - Generic workflow patterns (test_first_id_preparation)
  - KDS-specific patterns (kds_health_monitoring, brain_test_synchronization)
  - Protection configuration (confidence thresholds)
  - All 10 specialist agents
  - All governance rules
  - All CORTEX prompts and scripts
```

**Use Cases:**
- ğŸ”„ Moving CORTEX to a completely new project
- ğŸ†• Starting fresh with a different application
- ğŸ§¹ Cleaning BRAIN after experimenting with test project
- ğŸ“¦ Preparing CORTEX for distribution to new team/project

**Safety:**
- âœ… Backup created before any changes
- âœ… Dry-run mode available (`-DryRun` parameter)
- âœ… Requires confirmation (type 'AMNESIA' to proceed)
- âœ… Full rollback possible from backup
- âœ… BRAIN integrity verified after amnesia

**Example Output:**
```
ğŸ§  CORTEX BRAIN Amnesia - Application Data Reset
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

[1/8] Validating BRAIN system...
âœ… BRAIN structure validated

[2/8] Analyzing BRAIN data...
  Application-specific workflows: 12
  Generic/CORTEX workflows: 6
  Conversations: 5
  Events: 68

[4/8] Amnesia Impact Summary

  WILL BE REMOVED:
    - 5 conversations (application context)
    - 68 events (application interactions)
    - ~12 application-specific patterns
    - All NoorCanvas file relationships
    - All development metrics

  WILL BE PRESERVED:
    - All 10 CORTEX specialist agents
    - ~6 generic/CORTEX workflow patterns
    - Generic intent detection templates
    - Protection configuration
    - All CORTEX governance rules

âš ï¸  Type 'AMNESIA' to confirm reset: AMNESIA

[5/8] Creating backup...
âœ… Backup created: KDS/cortex-brain/backups/pre-amnesia-20251104-143022

[6/8] Executing BRAIN amnesia...
âœ… BRAIN amnesia complete

[7/8] Verifying BRAIN integrity...
âœ… BRAIN integrity verified

[8/8] Generating completion report...
âœ… Completion report saved

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… BRAIN AMNESIA COMPLETE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Next Steps:
  1. Update KDS/tooling/cortex.config.json (new project name/paths)
  2. Run: #file:KDS/prompts/user/cortex.md Setup
  3. CORTEX will learn your new application architecture
```

**Post-Amnesia Workflow:**
1. âœ… Amnesia complete (BRAIN reset)
2. Update `cortex.config.json` with new project details
3. Run `Setup` command to discover new application
4. CORTEX automatically learns from new interactions
5. BRAIN rebuilds application-specific knowledge over time

**Rollback (if needed):**
```powershell
# Restore from backup
$backupDir = "KDS/cortex-brain/backups/pre-amnesia-{timestamp}"
Copy-Item -Path "$backupDir/*.yaml" -Destination "KDS/cortex-brain/" -Force
Copy-Item -Path "$backupDir/*.jsonl" -Destination "KDS/cortex-brain/" -Force
```

---

## ğŸ§  CORTEX Health Dashboard

**Purpose:** Visual monitoring dashboard for CORTEX system health, BRAIN status, and development metrics.

### Launch Dashboard

```markdown
#file:KDS/prompts/user/cortex.md launch dashboard
```

Or directly:
```powershell
.\KDS\scripts\launch-dashboard.ps1
```

**What it does:**
- âœ… Starts API server in a **separate visible PowerShell window**
- âœ… Opens dashboard in your default browser
- âœ… Provides real-time health monitoring
- âœ… Shows visual feedback for all operations

**âš ï¸ PERMANENT RULE: API Server Window Behavior**

The API server MUST run in a **separate visible PowerShell window**, NOT as a background job.

**Rationale:**
- âœ… User can see server logs in real-time
- âœ… Easy to stop (just close the window or Ctrl+C)
- âœ… Clear visual indicator that server is running
- âœ… No hidden background processes
- âŒ Background jobs are invisible and hard to manage
- âŒ Users couldn't tell if server was running

**Implementation:**
```powershell
# CORRECT - Separate visible window
Start-Process pwsh -ArgumentList "-NoExit", "-Command", "cd '$workspaceRoot'; .\KDS\scripts\dashboard-api-server.ps1"

# WRONG - Background job (DO NOT USE)
$job = Start-Job -ScriptBlock { ... }
```

### Dashboard Features

**Visual Loading Feedback:**
- ğŸ“Š Progress bar at top of page during operations
- ğŸ”„ Loading overlay with detailed status messages
- â±ï¸ Real-time progress updates
- ğŸ¯ Stats start at 0 and refresh with live data

**Health Check Categories:**
- ğŸ—ï¸ Infrastructure (files, directories, permissions)
- ğŸ¤– Agents & Prompts (all 10 specialist agents)
- ğŸ§  BRAIN System (3-tier architecture)
- ğŸ’¾ Session State (active sessions, history)
- ğŸ“š Knowledge Base (graph, patterns, context)
- ğŸ”§ Scripts & Tools (PowerShell, validation)
- âš¡ Performance (response times, efficiency)

**Actions:**
- ğŸ”„ **Refresh** - Run all health checks (shows loading feedback)
- ğŸ“‹ **Copy to Clipboard** - Copy health report JSON (with fallback for file:// protocol)
- ğŸ“Š **Export Report** - Download JSON file

**Connection States:**
- ğŸ”— **Live** - API server connected, real data
- ğŸ”Œ **Disconnected** - API server not running (shows retry button)

### Copy to Clipboard Feature

**Multi-Layer Fallback System:**

1. **Modern Clipboard API** (HTTPS/secure context)
   ```javascript
   navigator.clipboard.writeText(jsonText)
   ```

2. **Legacy execCommand** (HTTP/file:// protocol)
   ```javascript
   document.execCommand('copy')
   ```

3. **Manual Prompt** (Last resort)
   ```javascript
   prompt('Copy this JSON (Ctrl+C):', jsonText)
   ```

**Why fallback is needed:**
- âš ï¸ Dashboard runs on `file://` protocol (not HTTPS)
- âš ï¸ Modern clipboard API requires secure context
- âœ… Fallback ensures copy works in all scenarios
- âœ… Always provides a way to get the JSON

### To Stop Dashboard

**Option 1:** Close the API server PowerShell window

**Option 2:** Press Ctrl+C in the API server window

**Option 3:** Just close your browser (server keeps running until manually stopped)

**Dashboard remains functional** in disconnected mode - you can view cached data and retry connection.

---

## ğŸ“Š Comprehensive CORTEX Dashboard (Unified Entry Point)

**Purpose:** Single comprehensive dashboard for all CORTEX monitoring - health checks, BRAIN metrics, efficiency tracking, and activity logs.

**File:** `KDS/cortex-dashboard.html`  
**Technology:** HTML + Chart.js (with optional API server for real-time data)

### Launch Dashboard

**Quick Launch (Recommended):**
```powershell
.\KDS\scripts\launch-dashboard.ps1
```
This starts the API server AND opens the dashboard automatically.

**Manual Launch:**
```
Open: D:\PROJECTS\KDS\cortex-dashboard.html
```
Or double-click the file in File Explorer.

### Dashboard Tabs

**Tab 1: ğŸ“Š Overview**
- System health summary (6 interactive cards)
- Quick status of infrastructure, agents, BRAIN, sessions, knowledge
- Click any card to drill down into health checks

**Tab 2: ğŸ¥ Health Checks**
- Detailed health validation across 7 categories
- Expandable sections with individual check results
- Status indicators (passed/warning/critical)
- Actionable recommendations for failures

**Tab 3: ğŸ§  BRAIN System**
- BRAIN integrity status (all 13 integrity checks)
- Event stream monitoring
- Knowledge graph health
- Real-time issue detection

**Tab 4: ğŸ“ˆ Metrics** (Enhanced with Brain Efficiency)
- **Brain Efficiency Score**: Overall efficiency (0-100%) with letter grade
- **Component Breakdown**: Visual bars showing routing, planning, TDD, learning, coordination
- **Efficiency Trends**: 30-day line chart of performance
- **Component Pie Chart**: Weighted contribution visualization
- **Individual Metrics**: Routing accuracy, plan time, TDD cycle, learning effectiveness, coordination latency
- **Standard Metrics**: BRAIN health, knowledge graph, file hotspots, event activity, test success
- **Smart Recommendations**: AI-generated suggestions based on performance data

**Tab 5: ğŸ“ Activity Log**
- Recent system activities
- Event timeline
- Agent actions tracking

### Features

**Real-Time Updates:**
- âœ… Auto-refresh every 30 seconds (configurable)
- ğŸ”„ Manual refresh button
- ğŸ“¡ Live connection status indicator

**Brain Efficiency Integration:**
- ğŸ¯ Overall efficiency score with trend indicators
- ğŸ“Š Component performance bars (5 components)
- ğŸ“ˆ Historical trend charts (30 days)
- ğŸ’¡ Smart recommendations based on metrics

**Visual Feedback:**
- âœ… Color-coded status (green/yellow/red)
- ï¿½ Interactive charts (hover for details)
- ğŸ¨ Dark theme optimized for long viewing
- âš¡ Smooth animations and transitions

### How to Use

**Step 1: Launch dashboard**
```powershell
.\KDS\scripts\launch-dashboard.ps1
```

**Step 2: Collect brain efficiency data (for Metrics tab)**
```powershell
.\KDS\scripts\corpus-callosum\collect-brain-metrics.ps1
```

**Step 3: Navigate tabs**
- Click tab buttons to switch between views
- Overview â†’ Quick health summary
- Health â†’ Detailed validation results
- BRAIN System â†’ Integrity checks
- Metrics â†’ Performance analysis (includes efficiency dashboard)
- Activity â†’ Recent events

**Step 4: Monitor and act**
- Review efficiency score and grade
- Check trend indicators (â–² improving, â–¼ declining)
- Read smart recommendations
- Address any warnings or failures

### Efficiency Calculation (Metrics Tab)

```
Overall Score = 
  (Routing Accuracy Ã— 25%) +
  (Planning Speed Ã— 20%) +
  (TDD Speed Ã— 20%) +
  (Learning Effectiveness Ã— 25%) +
  (Coordination Speed Ã— 10%)
```

**Grading:**
- **A+** (90-100%): Excellent - Peak efficiency
- **A** (85-90%): Very good - Continue current practices
- **B** (80-85%): Good - Minor improvements possible
- **C** (70-80%): Acceptable - Review recommendations
- **D** (<70%): Needs attention - Address warnings immediately

### Data Sources

**Real-time (via API server):**
- Health checks â†’ `run-health-checks.ps1`
- BRAIN metrics â†’ `test-brain-integrity.ps1`
- Standard metrics â†’ API aggregation

**Efficiency data (file-based):**
- **Reads from:** `KDS/cortex-brain/corpus-callosum/efficiency-history.jsonl`  
- **Generated by:** `collect-brain-metrics.ps1`  
**Update frequency:** Manual or scheduled (recommend daily)

**Optional: Automate collection**
```powershell
# Windows Task Scheduler (daily at 9am)
$trigger = New-ScheduledTaskTrigger -Daily -At 9am
$action = New-ScheduledTaskAction -Execute 'PowerShell.exe' `
    -Argument '-File "D:\PROJECTS\KDS\scripts\corpus-callosum\collect-brain-metrics.ps1"'
Register-ScheduledTask -TaskName "KDS-Metrics-Collection" `
    -Trigger $trigger -Action $action
```

**Dashboard remains functional** in disconnected mode - you can view cached data and retry connection.

---

## ğŸš€ First-Time Setup (New Application Installation)

**When to use this:** You're installing CORTEX in a new application (e.g., a fresh project like `https://github.com/yourname/new-project`)

**Purpose:** Complete CORTEX initialization with brain absorption, crawlers, and knowledge graph population for application-specific intelligence.

### Setup Command

```markdown
#file:KDS/prompts/user/cortex.md Setup
```

This triggers the complete CORTEX initialization sequence.

**â±ï¸ Expected Duration: 15-20 minutes** (padded estimate)
- Small project (<1000 files): ~10-12 minutes
- Medium project (1000-5000 files): ~15-18 minutes  
- Large project (>5000 files): ~20-25 minutes

**ğŸ”” Status Updates:** You'll receive progress updates every 30-60 seconds so you know the system is working.

---

### ğŸ“‹ Setup Sequence (Automatic)

When you invoke `Setup`, CORTEX executes this sequence:

**âš™ï¸ RULE: Long-Running Process Protocol**

ALL long-running operations (>30 seconds) in CORTEX MUST:
1. âœ… Display padded time estimate upfront (add 25-50% buffer)
2. âœ… Show phase-by-phase progress indicators
3. âœ… Provide status updates every 30-60 seconds
4. âœ… Display percentage complete when measurable
5. âœ… Show "Still working..." heartbeat for CPU-intensive tasks
6. âœ… Explain what's happening (not just "Processing...")
7. âœ… Allow graceful interruption (Ctrl+C with cleanup)

**Examples of long-running operations:**
- Setup sequence (15-20 min)
- Deep crawler (5-10 min)
- Development context collection (2-5 min)
- BRAIN updates with large event backlogs (1-3 min)
- Test suite runs (varies)
- Build processes (varies)

**See:** Full protocol at end of this section

#### Phase 1: Environment Validation (2-3 minutes)

**Status Display:**
```
ğŸš€ CORTEX Setup - Phase 1/6: Environment Validation
â±ï¸  Estimated time: 2-3 minutes
ğŸ“Š Progress: [â–“â–“â–“â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0%

â³ Checking CORTEX structure...
```

**Step 1.1: Verify CORTEX Structure**
```
âœ“ Check KDS/ directory exists
âœ“ Verify all core agents present (10 specialist agents)
âœ“ Validate BRAIN directories (cortex-brain/, sessions/, knowledge/)
âœ“ Check abstraction layer (session-loader, test-runner, file-accessor)

Status: âœ… CORTEX structure verified (10/10 agents found)
```

**Step 1.2: Detect Application Type**
```
â³ Analyzing application type...

âœ“ Identify primary language (C#, TypeScript, Python, etc.)
âœ“ Detect frameworks (ASP.NET, React, Django, etc.)
âœ“ Find build tools (dotnet, npm, pip, etc.)
âœ“ Locate test frameworks (Playwright, Jest, xUnit, etc.)

Status: âœ… Detected: C# + ASP.NET Core 8.0 + Playwright
```

**Step 1.3: Validate Dependencies**
```
â³ Checking system dependencies...

âœ“ Check Git is available (required for context collection)
âœ“ Verify PowerShell/Bash (for scripts)
âœ“ Confirm workspace structure is readable
âœ“ Test file system permissions

Status: âœ… All dependencies available

ğŸ“Š Progress: [â–“â–“â–“â–“â–“â–‘â–‘â–‘â–‘â–‘] 20% - Phase 1 complete
```

**Output:** Environment validation report

---

#### Phase 2: BRAIN Initialization (7-12 minutes)

**Status Display:**
```
ğŸš€ CORTEX Setup - Phase 2/6: BRAIN Initialization
â±ï¸  Estimated time: 7-12 minutes (longest phase)
ğŸ“Š Progress: [â–“â–“â–“â–“â–“â–‘â–‘â–‘â–‘â–‘] 20%

âš ï¸  This phase takes the longest - please be patient!
```

**Step 2.1: Create BRAIN Storage**
```
â³ Creating BRAIN directory structure...

âœ“ Initialize KDS/cortex-brain/ directory structure
  - conversation-history.jsonl (Tier 1 - empty initially)
  - knowledge-graph.yaml (Tier 2 - base template)
  - development-context.yaml (Tier 3 - empty initially)
  - events.jsonl (event stream - empty)
  - crawler-state.yaml (crawler tracking)
âœ“ Set up session storage (KDS/sessions/)
âœ“ Create knowledge repository (KDS/knowledge/)

Status: âœ… BRAIN storage created
ğŸ“Š Progress: [â–“â–“â–“â–“â–“â–“â–‘â–‘â–‘â–‘] 25%
```

**Step 2.2: Run Deep Codebase Crawler**
```
â³ Starting deep codebase crawl...
â±ï¸  This will take 5-10 minutes depending on project size

Invoke: #file:KDS/prompts/internal/brain-crawler.md
Mode: deep
Duration: 5-10 minutes

Status updates every 60 seconds:
  [00:30] ğŸ“‚ Discovered 247 files (still scanning...)
  [01:00] ğŸ“‚ Discovered 612 files (analyzing structure...)
  [01:30] ğŸ“‚ Discovered 1,089 files (mapping relationships...)
  [02:00] ğŸ” Parsing file contents (324/1,089 files)
  [02:30] ğŸ” Parsing file contents (687/1,089 files)
  [03:00] ğŸ” Analyzing imports and dependencies...
  [03:30] ğŸ“Š Building relationship graph...
  [04:00] ğŸ¯ Detecting naming conventions...
  [04:30] âœ… Crawler complete - generating report...

What it discovers:
âœ“ File structure & architecture (where components/services/tests live)
âœ“ Code relationships (dependencies, imports, DI patterns)
âœ“ Test patterns (frameworks, selectors, test data)
âœ“ Technology stack (languages, frameworks, libraries)
âœ“ Naming conventions (PascalCase, kebab-case, etc.)
âœ“ Configuration patterns (appsettings hierarchy, env vars)
âœ“ Documentation locations (README files, API docs)
âœ“ **Database schemas (SQL files FIRST, then connection strings)** ğŸ†•

**Database Discovery Priority (NEW v1.1.0):**
  1ï¸âƒ£ FIRST: Scan for SQL schema/data files (*schema*.sql, *data*.sql)
     - Analyzes CREATE TABLE, INSERT INTO statements
     - Extracts table names, relationships
     - Brain can reference these files (no database connection needed!)
  
  2ï¸âƒ£ SECOND: Look for connection strings (appsettings.json, .env)
     - Discovers database provider (SQL Server, PostgreSQL, etc.)
     - Finds Entity Framework models and migrations
  
  3ï¸âƒ£ THIRD: Connect to database (only if no SQL files found)
     - Prompts for connection string if not found
     - Memorizes it for future use (KDS/cortex-brain/database-connection.txt)
     - Crawls live schema (tables, columns)
  
  âš¡ Result: 10x faster when SQL files exist! (~30s vs 2-5 min)
  
  See: `KDS/docs/features/database-crawler-sql-file-priority.md` for details

Feeds BRAIN with:
  - architectural_patterns (Components/**/*.razor)
  - file_relationships (co-modification patterns)
  - test_patterns (Playwright, session-212, data-testid)
  - conventions (naming, file organization)
  - technology_stack (complete inventory)

Status: âœ… Crawler discovered 1,089 files, 3,247 relationships
ğŸ“Š Progress: [â–“â–“â–“â–“â–“â–“â–“â–‘â–‘â–‘] 35%
```

**Output:** Crawler report (`KDS/cortex-brain/crawler-report-{timestamp}.md`)

**Step 2.3: Initialize Development Context (Tier 3)**
```
â³ Collecting development metrics (2-5 minutes)...

Invoke: #file:KDS/prompts/internal/development-context-collector.md

Status updates:
  [00:30] ğŸ“Š Analyzing Git history (last 30 days)...
  [01:00] ğŸ“Š Processing 1,237 commits...
  [01:30] ğŸ“Š Calculating code velocity...
  [02:00] ğŸ“Š Identifying file hotspots...
  [02:30] ğŸ“Š Analyzing test patterns...
  [03:00] ğŸ“Š Building baseline metrics...

What it collects:
âœ“ Git activity (last 30 days of commits)
âœ“ Code change velocity (lines added/deleted per week)
âœ“ File hotspots (high churn rate files)
âœ“ CORTEX session history (if any exist)
âœ“ Testing activity (if tests exist)
âœ“ Build/deploy patterns (if scripts exist)

Feeds BRAIN with:
  - Baseline metrics (velocity, churn, activity)
  - Productivity patterns (commit frequency)
  - File stability analysis (churn rates)
  - Initial correlations (commit size vs complexity)

Status: âœ… Collected metrics from 1,237 commits, 78 tests
ğŸ“Š Progress: [â–“â–“â–“â–“â–“â–“â–“â–“â–‘â–‘] 45%
```

**Output:** `KDS/cortex-brain/development-context.yaml` (baseline metrics)

---

#### Phase 3: Knowledge Graph Population (3-5 minutes)

**Status Display:**
```
ğŸš€ CORTEX Setup - Phase 3/6: Knowledge Graph Population
â±ï¸  Estimated time: 3-5 minutes
ğŸ“Š Progress: [â–“â–“â–“â–“â–“â–“â–“â–“â–‘â–‘] 45%

â³ Processing crawler discoveries...
```

**Step 3.1: Process Crawler Results**
```
â³ Transforming discoveries into knowledge graph...

Invoke: #file:KDS/prompts/internal/brain-updater.md
Mode: bootstrap

Status updates:
  [00:30] ğŸ§  Processing 3,247 relationships...
  [01:00] ğŸ§  Assigning confidence scores...
  [01:30] ğŸ§  Creating file_relationships section (1,247 entries)
  [02:00] ğŸ§  Creating architectural_patterns section (127 patterns)
  [02:30] ğŸ§  Creating validation_insights section...

Actions:
âœ“ Transform crawler discoveries into knowledge graph entries
âœ“ Assign confidence scores (0.50 - 0.98)
  - Direct observations (imports): 0.95+ confidence
  - Pattern inference (naming): 0.70-0.85 confidence
  - Statistical (co-modification): 0.50-0.70 confidence
âœ“ Create file_relationships section
âœ“ Create architectural_patterns section
âœ“ Create validation_insights section
âœ“ Create intent_patterns (empty, will learn from usage)

Status: âœ… Knowledge graph populated with 3,247 entries
ğŸ“Š Progress: [â–“â–“â–“â–“â–“â–“â–“â–“â–“â–‘] 55%
```

**Step 3.2: Build Intent Vocabulary (Bootstrapping)**
```
â³ Bootstrapping intent patterns...

If generic patterns available (from templates):
  âœ“ Import common intent patterns
    - "add a button" â†’ PLAN intent
    - "create service" â†’ PLAN intent
    - "continue" â†’ EXECUTE intent
  âœ“ Seed with generic workflow patterns
    - UI feature: plan â†’ execute â†’ test
    - API endpoint: plan â†’ execute â†’ unit-test â†’ integration-test
  âœ“ Import common file confusion warnings
    - "HostControlPanel vs HostControlPanelContent"
    
If no templates:
  âœ“ Start with empty intent_patterns
  âœ“ BRAIN will learn from first interactions

Status: âœ… Intent vocabulary seeded with 47 patterns
ğŸ“Š Progress: [â–“â–“â–“â–“â–“â–“â–“â–“â–“â–‘] 60%
```

**Step 3.3: Validate Knowledge Graph**
```
â³ Validating knowledge graph integrity...

âœ“ Run structure validation (YAML syntax)
âœ“ Check confidence score ranges (0.50-1.00)
âœ“ Verify file references exist
âœ“ Test query functionality
âœ“ Run protection rules check

Status: âœ… Knowledge graph validated successfully
ğŸ“Š Progress: [â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“] 65%
```

**Output:** `KDS/cortex-brain/knowledge-graph.yaml` (fully populated)

---

#### Phase 4: Three-Tier BRAIN Setup (1-2 minutes)

**Status Display:**
```
ğŸš€ CORTEX Setup - Phase 4/6: Three-Tier BRAIN Setup
â±ï¸  Estimated time: 1-2 minutes
ğŸ“Š Progress: [â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“] 65%

â³ Configuring three-tier architecture...
```

**Step 4.1: Initialize Tier 1 (Conversation History)**
```
â³ Setting up conversation memory...

âœ“ Create conversation-history.jsonl
âœ“ Set FIFO queue capacity (20 conversations)
âœ“ Initialize first conversation (the setup itself)
âœ“ Configure conversation boundary detection

Status: âœ… Tier 1 initialized
ğŸ“Š Progress: [â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“] 70%
```

**Step 4.2: Verify Tier 2 (Knowledge Graph)**
```
â³ Verifying knowledge graph...

âœ“ Confirm knowledge-graph.yaml populated
âœ“ Test brain-query queries
âœ“ Verify all sections present:
  - intent_patterns
  - file_relationships
  - workflow_patterns
  - validation_insights
  - correction_history

Status: âœ… Tier 2 verified (3,247 entries)
ğŸ“Š Progress: [â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“] 75%
```

**Step 4.3: Verify Tier 3 (Development Context)**
```
â³ Verifying development context...

âœ“ Confirm development-context.yaml has baseline metrics
âœ“ Test proactive_warnings generation
âœ“ Verify correlation analysis available
âœ“ Check hotspot detection working

Status: âœ… Tier 3 verified (baseline metrics ready)
ğŸ“Š Progress: [â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“] 80%
```

**Step 4.4: Enable Automatic Learning**
```
â³ Configuring automatic learning...

âœ“ Configure event logging (all agents â†’ events.jsonl)
âœ“ Set automatic update triggers:
  - 50+ events â†’ brain-updater.md
  - 24 hours â†’ brain-updater.md (if 10+ events)
âœ“ Enable Tier 3 collection (runs after brain updates)
âœ“ Verify Rule #16 Step 5 compliance (event count check)

Status: âœ… Automatic learning enabled
ğŸ“Š Progress: [â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“] 85%
```

**Output:** Three-tier BRAIN fully operational

---

#### Phase 5: Testing & Validation (2-3 minutes)

**Status Display:**
```
ğŸš€ CORTEX Setup - Phase 5/6: Testing & Validation
â±ï¸  Estimated time: 2-3 minutes
ğŸ“Š Progress: [â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“] 85%

â³ Running validation checks...
```

**Step 5.1: Test Core Workflows**
```
â³ Testing CORTEX components...

âœ“ Test intent routing (sample phrases)
  - "I want to add a feature" â†’ Should route to PLAN
  - "Continue" â†’ Should detect no session, prompt accordingly
âœ“ Test BRAIN queries
  - Query architectural_patterns â†’ Should return discovered structure
  - Query file_relationships â†’ Should return co-modification data
âœ“ Test file operations
  - session-loader.md â†’ Should create/read session files
  - file-accessor.md â†’ Should read/write application files

Status: âœ… All core workflows tested successfully
ğŸ“Š Progress: [â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“] 90%
```

**Step 5.2: Run Health Validator**
```
â³ Running comprehensive health check...

Invoke: #file:KDS/prompts/internal/health-validator.md

Checks:
âœ“ All agents loadable
âœ“ BRAIN files readable/writable
âœ“ Knowledge graph valid
âœ“ Session storage functional
âœ“ Test framework detection working
âœ“ Git integration working

Status: âœ… All health checks passed
ğŸ“Š Progress: [â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“] 93%
```

**Step 5.3: Generate Setup Report**
```
â³ Generating setup report...

Create: KDS/setup-report-{timestamp}.md

Contents:
âœ“ Environment summary (languages, frameworks, tools)
âœ“ Discovered patterns (components, services, tests)
âœ“ BRAIN status (all 3 tiers operational)
âœ“ File counts (components: 89, services: 34, tests: 120)
âœ“ Known issues (if any)
âœ“ Next steps (ready to use!)

Status: âœ… Report generated
ğŸ“Š Progress: [â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“] 95%
```

**Output:** Setup complete confirmation

---

#### Phase 6: First Interaction Guidance (1 minute)

**Status Display:**
```
ğŸš€ CORTEX Setup - Phase 6/6: Finalizing
â±ï¸  Estimated time: 1 minute
ğŸ“Š Progress: [â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“] 95%

â³ Preparing your workspace...
```

**Step 6.1: Show User Quick Start**
```
â³ Generating getting started guide...

Display:
  âœ… Setup complete! CORTEX is ready.
  
  ğŸ“Š What CORTEX learned about your application:
  - Technology: {detected stack}
  - Components: {count} files in {location}
  - Services: {count} files in {location}
  - Tests: {count} files, {framework} framework
  - Conventions: {naming patterns}
  
  ğŸ§  BRAIN Status:
  - Tier 1 (Conversations): Initialized
  - Tier 2 (Knowledge Graph): {entry_count} entries
  - Tier 3 (Dev Context): Baseline metrics collected
  
  ğŸš€ Ready to start!
  
  Try: #file:KDS/prompts/user/cortex.md
       I want to [describe your first feature]

Status: âœ… Setup complete!
ğŸ“Š Progress: [â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“] 98%
```

**Step 6.2: Log Setup Event**
```
â³ Finalizing...

âœ“ Record setup completion in events.jsonl
âœ“ Create first conversation in conversation-history.jsonl
âœ“ Mark setup as successful in crawler-state.yaml

Status: âœ… All done!
ğŸ“Š Progress: [â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“] 100% âœ¨

â±ï¸  Total time: 15m 32s
```

---

### ğŸ“Š Long-Running Process Protocol (UNIVERSAL RULE)

**APPLIES TO:** All CORTEX operations >30 seconds

**Required Elements:**

1. **Upfront Expectation Setting**
   ```
   â±ï¸  Estimated time: X-Y minutes (padded 25-50%)
   âš ï¸  This is the longest phase - please be patient!
   ```

2. **Visual Progress Indicators**
   ```
   ğŸ“Š Progress: [â–“â–“â–“â–“â–“â–“â–“â–‘â–‘â–‘] 45%
   ğŸ”„ Phase 3/6: Knowledge Graph Population
   ```

3. **Heartbeat Status Updates**
   ```
   Every 30-60 seconds:
   [00:30] Still working on X... (detail what's happening)
   [01:00] Processing Y... (show counts/progress)
   [01:30] Almost done with Z... (reassure user)
   ```

4. **Informative Messages**
   ```
   âŒ BAD: "Processing..." (vague, scary)
   âœ… GOOD: "Analyzing 1,247 commits for velocity patterns..."
   
   âŒ BAD: "Please wait..." (no context)
   âœ… GOOD: "Scanning 612 files for architectural patterns (2m 30s elapsed)"
   ```

5. **Completion Confirmation**
   ```
   Status: âœ… Phase complete in 4m 23s
   ğŸ“Š Progress: [â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“] 65% â†’ 75%
   ```

6. **Graceful Interruption**
   ```
   â¸ï¸  You can press Ctrl+C to cancel
   âš ï¸  Cleanup will run automatically if interrupted
   ```

7. **Error Recovery Guidance**
   ```
   If something goes wrong:
   âŒ Error at Phase 3 (2m 15s elapsed)
   ğŸ’¡ You can:
      1. Retry this phase only
      2. Skip and continue (if non-critical)
      3. Cancel and review logs
   ```

**Implementation Checklist:**

For ALL long-running operations, verify:
- â˜ Padded time estimate shown upfront (realistic + buffer)
- â˜ Phase/step breakdown displayed
- â˜ Progress bar or percentage shown
- â˜ Status updates every 30-60 seconds minimum
- â˜ Detailed "what's happening now" messages
- â˜ Elapsed time counter visible
- â˜ Graceful Ctrl+C handling
- â˜ Clear completion confirmation
- â˜ Error messages with recovery options

**Examples in KDS:**

```markdown
Long-Running Operations:
âœ“ Setup (15-20 min) - Has all required elements above
âœ“ Deep Crawler (5-10 min) - Needs status updates added
âœ“ Development Context Collection (2-5 min) - Needs progress bar
âœ“ BRAIN Update with backlog (1-3 min) - Needs heartbeat
âœ“ Test Suite Execution (varies) - Needs all elements
âœ“ Build Processes (varies) - Needs all elements
```

**Agents Responsible:**

All specialist agents that trigger long operations:
- `work-planner.md` - When creating large plans
- `code-executor.md` - When running builds/tests
- `test-generator.md` - When generating many tests
- `health-validator.md` - When running full validation
- `brain-crawler.md` - When scanning codebase
- `development-context-collector.md` - When analyzing history
- `brain-updater.md` - When processing large backlogs

**PowerShell Script Requirements:**

All CORTEX scripts (`.ps1`) MUST include:
```powershell
# At start
Write-Host "â±ï¸  Estimated time: 3-5 minutes" -ForegroundColor Yellow
$stopwatch = [System.Diagnostics.Stopwatch]::StartNew()

# During execution (every 30-60s)
Write-Host "[$(($stopwatch.Elapsed.TotalSeconds).ToString('00.0'))s] Still working on X..." -ForegroundColor Cyan

# At completion
$stopwatch.Stop()
Write-Host "âœ… Complete in $($stopwatch.Elapsed.TotalMinutes.ToString('0.0'))m" -ForegroundColor Green
```

**See Also:**
- Playwright Testing Protocol (uses 20s wait with status)
- Health Validator (should show check-by-check progress)
- Crawler modes (quick vs deep time estimates)

---

### ğŸ¯ Setup Modes

**Default Mode: Full Setup (Recommended)**
```markdown
#file:KDS/prompts/user/cortex.md Setup
```
- â±ï¸ Duration: 15-20 minutes (padded estimate)
- Runs all 6 phases with complete initialization
- Complete BRAIN initialization with deep crawler
- Ready for immediate production use
- **Status updates:** Every 30-60 seconds
- **Progress tracking:** Phase-by-phase with percentage

**Quick Mode: Minimal Setup (For Testing)**
```markdown
#file:KDS/prompts/user/cortex.md Setup --quick
```
- â±ï¸ Duration: 3-5 minutes (padded estimate)
- Skips deep crawler (runs quick scan only)
- Minimal Tier 3 data (current snapshot only)
- Good for experimentation, not production
- **Status updates:** Every 60 seconds
- **Progress tracking:** Simplified progress bar

**Migration Mode: Import Existing Knowledge**
```markdown
#file:KDS/prompts/user/cortex.md Setup --import "path/to/old-kds/cortex-brain/"
```
- â±ï¸ Duration: 7-10 minutes (padded estimate)
- Imports generic patterns from previous CORTEX installation
- Runs deep crawler for new application
- Merges old patterns with new discoveries
- Best for migrating CORTEX to similar project
- **Status updates:** Every 45 seconds
- **Progress tracking:** Shows import + scan progress separately

---

### ğŸ“ What Gets Created

After setup completes, you'll have:

```
KDS/
â”œâ”€â”€ cortex-brain/
â”‚   â”œâ”€â”€ conversation-history.jsonl      âœ… Initialized (setup conversation)
â”‚   â”œâ”€â”€ knowledge-graph.yaml            âœ… Populated (crawler + baseline)
â”‚   â”œâ”€â”€ development-context.yaml        âœ… Baseline metrics
â”‚   â”œâ”€â”€ events.jsonl                    âœ… Setup events logged
â”‚   â”œâ”€â”€ crawler-state.yaml              âœ… Last scan info
â”‚   â””â”€â”€ crawler-report-{timestamp}.md   ğŸ“Š Detailed discoveries
â”‚
â”œâ”€â”€ sessions/                           âœ… Empty (ready for first session)
â”‚
â”œâ”€â”€ knowledge/                          âœ… Ready for knowledge articles
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ brain-crawler.ps1               âœ… Tested and working
â”‚   â”œâ”€â”€ collect-development-context.ps1 âœ… Tested and working
â”‚   â””â”€â”€ protect-brain-update.ps1        âœ… Protection active
â”‚
â””â”€â”€ setup-report-{timestamp}.md         ğŸ“Š Setup summary
```

---

### ğŸ”§ Troubleshooting Setup

**Setup fails at Phase 1 (Validation):**
```
Cause: Missing CORTEX files or permissions issue
Fix: 
  1. Verify KDS/ directory copied completely
  2. Check file permissions (should be readable/writable)
  3. Ensure Git is installed and accessible
```

**Setup fails at Phase 2 (Crawler):**
```
Cause: Large codebase (>10,000 files) or binary files
Fix:
  1. Use Setup --quick (skips deep scan)
  2. Manually run targeted crawler later
  3. Add skip patterns to KDS/cortex-brain/crawler-config.yaml
```

**Setup succeeds but queries fail:**
```
Cause: Knowledge graph structure invalid
Fix:
  1. Check KDS/cortex-brain/knowledge-graph.yaml syntax
  2. Re-run: #file:KDS/prompts/internal/brain-updater.md
  3. Validate with: #file:KDS/prompts/internal/health-validator.md
```

---

### âœ… Setup Success Indicators

You'll know setup succeeded when:

```
âœ“ All 6 phases completed without errors
âœ“ KDS/setup-report-{timestamp}.md exists
âœ“ knowledge-graph.yaml has 50+ entries
âœ“ development-context.yaml has baseline metrics
âœ“ Health validator reports "All checks passed"
âœ“ Test query returns architectural patterns
âœ“ First cortex.md request routes correctly
```

---

### ğŸ“ Post-Setup Best Practices

**1. Verify BRAIN Learning:**
```
After your first few CORTEX interactions:

Check: KDS/cortex-brain/events.jsonl (should have new events)
Check: conversation-history.jsonl (should have conversations)
Run: #file:KDS/prompts/internal/brain-updater.md (manual update)
Verify: knowledge-graph.yaml updated with your patterns
```

**2. Regular Maintenance:**
```
Daily: Let automatic learning work (no action needed)
Weekly: Check proactive_warnings in development-context.yaml
Monthly: Run incremental crawler (keep structure current)
After refactoring: Run deep crawler (re-learn architecture)
```

**3. Optimize for Your Workflow:**
```
If CORTEX misroutes frequently:
  â†’ Check intent_patterns in knowledge-graph.yaml
  â†’ Add manual entries for your common phrases
  
If file suggestions wrong:
  â†’ Check architectural_patterns
  â†’ Run targeted crawler on new modules
  
If estimates inaccurate:
  â†’ Let development-context accumulate data (2-4 weeks)
  â†’ Correlations improve with more history
```

---

## ğŸ¤– How It Works

### Step 1: Intent Detection
When you use `cortex.md`, it loads the **Intent Router** agent which analyzes your request.

**Router reads:**
```yaml
keywords:
  plan: ["I want to", "add a", "create a", "build a", "implement"]
  execute: ["continue", "next task", "keep going", "proceed"]
  resume: ["where was I", "show progress", "left off", "resume"]
  correct: ["wrong file", "not what I", "actually", "correction"]
  test: ["test", "visual regression", "playwright", "unit test"]
  validate: ["health", "validate", "check", "run all", "status"]
  ask: ["how do I", "what is", "explain", "tell me about"]
  govern: ["I updated KDS", "I modified KDS", "review my changes"]
```

### Step 2: Routing Decision
```
User: "I want to add dark mode"
  â†“
Intent Router: Detects "I want to add" = PLAN intent
  â†“
Routes to: plan.md â†’ work-planner.md
  â†“
Creates multi-phase plan, saves session state
```

### Step 3: Execution
The appropriate specialist agent executes:
- **Planner:** Breaks work into phases/tasks
- **Executor:** Implements code changes
- **Tester:** Creates and runs tests
- **Validator:** Checks system health
- **Governor:** Reviews CORTEX modifications
- **Knowledge Retriever:** Answers questions

### Step 4: Handoff (If Multi-Step)
For complex requests like "Add dark mode and test it":
```
User: "I want to add dark mode and test it"
  â†“
Intent Router: Detects TWO intents (PLAN + TEST)
  â†“
Routes to: plan.md â†’ work-planner.md
  â†“
Planner creates plan with testing phase
  â†“
Tells you: "Next: #file:KDS/prompts/user/cortex.md continue"
  â†“
You: "continue"
  â†“
Routes to: execute.md â†’ code-executor.md
  â†“
Implements code â†’ Routes to: test.md â†’ test-generator.md
  â†“
Creates tests â†’ Validates â†’ Complete
```

---

## ğŸ¯ Intent Detection Rules

**LOAD:** `#file:KDS/prompts/internal/intent-router.md`

The router uses these patterns:

### PRIMARY INTENT (Choose One)

**PLAN** - Starting new feature work
```
Patterns: "I want to", "add a", "create a", "build", "implement"
Examples: 
  - "I want to add a share button"
  - "Create a PDF export feature"
  - "Build a dark mode toggle"
```

**EXECUTE** - Continue active session
```
Patterns: "continue", "next", "keep going", "proceed", "execute"
Examples:
  - "Continue working"
  - "Next task"
  - "Keep going"
```

**RESUME** - Pickup after interruption
```
Patterns: "resume", "where was I", "show progress", "left off", "status"
Examples:
  - "Show me where I left off"
  - "What's the current status?"
  - "Resume work"
```

**CORRECT** - Fix Copilot error
```
Patterns: "wrong", "not that", "actually", "correction", "fix"
Examples:
  - "You're working on the wrong file"
  - "That's not what I meant"
  - "Actually, use SignalR not polling"
```

**TEST** - Create or run tests
```
Patterns: "test", "playwright", "visual regression", "unit test"
Examples:
  - "Create visual tests for the button"
  - "Run all Playwright tests"
  - "Add unit tests for the service"
```

**VALIDATE** - System health check
```
Patterns: "validate", "health", "check", "run all", "quality"
Examples:
  - "Check system health"
  - "Validate all changes"
  - "Run quality checks"
```

**ASK** - Question about KDS/codebase
```
Patterns: "how do I", "what is", "explain", "tell me", "?"
Examples:
  - "How do I test canvas elements?"
  - "What test patterns exist?"
  - "Explain the session state"
```

**GOVERN** - Review CORTEX changes
```
Patterns: "I updated KDS", "modified KDS", "review", "CORTEX change"
Examples:
  - "I updated the test-generator"
  - "Review my CORTEX modifications"
  - "I changed the rules"
```

### ğŸ§  Proactive Warnings (NEW - Post-Week 4 Enhancement)

**Before routing, CORTEX BRAIN analyzes your request and shows warnings:**

**When warnings appear:**
- âœ… PLAN intent detected (starting new feature)
- âœ… EXECUTE intent detected (continuing work)

**What gets predicted:**
```yaml
ğŸŸ¡ File Hotspot Warnings:
   "âš ï¸ HostControlPanel.razor is a hotspot (28% churn)"
   â†’ Suggests: Add extra validation

ğŸŸ¡ Complexity Warnings:
   "âš ï¸ PDF features take 50% longer than other exports"
   â†’ Suggests: Allocate more time

ğŸŸ¡ Velocity Warnings:
   "âš ï¸ Velocity dropped 30% this week"
   â†’ Suggests: Smaller commits

ğŸŸ¢ Success Patterns:
   "âœ… Test-first has 96% success rate for exports"
   â†’ Suggests: Continue TDD workflow
```

**Example:**
```markdown
User: #file:KDS/prompts/user/cortex.md
      I want to add PDF export

ğŸ§  BRAIN Analysis:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸŸ¡ âš ï¸ HostControlPanel.razor is a hotspot (28% churn)
   ğŸ’¡ Add extra validation phase
   
ğŸŸ¢ âœ… Test-first approach has 96% success rate
   ğŸ’¡ Continue TDD workflow
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Routing to work-planner.md...
```

**Benefits:**
- âš¡ **Instant feedback** - Warnings appear in <5 seconds (before planning)
- ğŸ¯ **Better decisions** - Adjust approach before creating plan
- ğŸ“Š **Data-driven** - Predictions based on historical patterns
- ğŸ”„ **Continuous learning** - Accuracy improves over time

**Implementation:** Step 1.3 in `intent-router.md` (between user input and conversation context)

**ANALYZE_SCREENSHOT** - Extract requirements from images
```
Patterns: "analyze screenshot", "extract from image", "what does mockup show", "read annotations"
Examples:
  - "Analyze this screenshot and extract requirements"
  - "What does this mockup show?"
  - "Extract specs from this design"
  - "Read the annotations on this bug report"
  - [Image attachment detected]
```

**COMMIT** - Intelligent git commits
```
Patterns: "commit changes", "commit work", "git commit", "save to git"
Examples:
  - "Commit changes"
  - "Commit my work"
  - "Save changes to git"
  - "Create commits with proper categorization"
  - "Commit and tag if milestone"
```
  - "Read the annotations on this bug report"
  - [Image attachment detected]
```

### SECONDARY INTENTS (Can Combine)

**If multiple intents detected:**
```
"I want to add dark mode and test it"
  â†“
Primary: PLAN
Secondary: TEST
  â†“
Planner includes testing phase in plan
```

---

## ğŸ”„ Complete Workflow Examples

### Example 1: New Feature (Simple)
```
You: #file:KDS/prompts/user/cortex.md
     I want to add a pulse animation to the FAB button

Router: PLAN intent detected
   â†“
Planner: Creates 3-phase plan
   â†“
Output: âœ… Session created: fab-button-animation
        Next: #file:KDS/prompts/user/cortex.md continue
```

### Example 2: Continue Work
```
You: #file:KDS/prompts/user/cortex.md
     continue

Router: EXECUTE intent detected
   â†“
Executor: Implements next task
   â†“
Output: âœ… Task 1.1 complete: CSS animation added
        Next: #file:KDS/prompts/user/cortex.md continue
```

### Example 3: Resume After Break (SOLID v5.0)
```
(New chat next day)

You: #file:KDS/prompts/user/cortex.md
     where was I?

Router: RESUME intent detected
   â†“
Session Resumer: Loads via session-loader (DIP)
   â†“
Output: Session: fab-button-animation
        Progress: 3/8 tasks (38%)
        
        ğŸ“Š Detailed Progress:
        Phase 1: âœ… Complete
        Phase 2: ğŸ”„ 1/3 tasks done
        Phase 3: â¬œ Not started
        
        Next: #file:KDS/prompts/user/cortex.md continue
```

### Example 4: Correction Mid-Work (SOLID v5.0)
```
You: #file:KDS/prompts/user/cortex.md
     continue

Executor: Modifying HostControlPanel.razor...

You: #file:KDS/prompts/user/cortex.md
     Wrong file! The FAB is in HostControlPanelContent.razor

Router: CORRECT intent detected
   â†“
Error Corrector: HALTS execution (dedicated agent)
   â†“
Analysis: FILE_MISMATCH
   Incorrect: HostControlPanel.razor
   Correct: HostControlPanelContent.razor
   â†“
Actions:
   âœ… Reverted changes to HostControlPanel.razor
   âœ… Loaded HostControlPanelContent.razor
   âœ… Updated task file reference
   â†“
Output: âœ… Correction applied
        Next: #file:KDS/prompts/user/cortex.md continue
```

### Example 5: Multi-Intent Request
```
You: #file:KDS/prompts/user/cortex.md
     I want to add dark mode toggle and create Percy visual tests for it

Router: PLAN + TEST intents detected
   â†“
Planner: Creates plan with dedicated test phase
   â†“
Output: âœ… 4-phase plan created (includes visual testing)
        Phase 4: Percy visual regression tests
        Next: #file:KDS/prompts/user/cortex.md continue
```

---

## âœ… Benefits of Universal Entry Point + SOLID v5.0

### User Experience
- âœ… **One command to remember** (`cortex.md`)
- âœ… **Natural language** - say what you want
- âœ… **No cognitive load** - don't need to know which specialist to call
- âœ… **Forgiving** - works even if you're vague
- âœ… **Predictable** - same command, consistent behavior

### Technical Benefits (SOLID v5.0)
- âœ… **Intelligent routing** - right agent for the job
- âœ… **Multi-intent handling** - complex requests work
- âœ… **Context preservation** - session state via abstraction
- âœ… **Automatic workflows** - no manual orchestration
- âœ… **Single Responsibility** - each agent focused on one job
- âœ… **Dependency Inversion** - swap storage/tools without breaking agents
- âœ… **Interface Segregation** - no mode switches, dedicated specialists
- âœ… **Easy to test** - mock abstractions, isolate agents

### Architecture Benefits
- ğŸ¯ **Modular** - add new agents without touching existing ones
- ğŸ”§ **Maintainable** - fix bugs in one place
- ğŸš€ **Performant** - no mode-switch overhead
- ğŸ“¦ **Portable** - abstractions make storage/tools swappable
- ğŸ  **Local-First** - 100% in KDS/, zero external dependencies
- ğŸ”’ **Offline-Capable** - works without internet (except optional cloud features)
- ğŸ†“ **Zero-Install** - no npm/pip/dotnet packages required for KDS

### Comparison

**Before v5.0 (7 commands + mode switches):**
```
plan.md â†’ for new features
execute.md â†’ for continuing work + corrections (mode switch)
resume.md â†’ after breaks (actually loads work-planner)
correct.md â†’ for fixing errors (loads executor in correction mode)
test.md â†’ for creating tests
validate.md â†’ for health checks
ask-cortex.md â†’ for questions
govern.md â†’ for CORTEX changes

Issues:
âŒ Executor does 2 jobs (execution + correction)
âŒ Planner does 2 jobs (planning + resumption)
âŒ Hardcoded file paths everywhere
âŒ Hardcoded test commands
```

**After v5.0 (1 command + SOLID compliance):**
```
cortex.md â†’ for EVERYTHING
  â†“
intent-router.md â†’ routes to 8 focused specialists
  â†“
Specialists use shared abstractions (session-loader, test-runner, file-accessor)

Benefits:
âœ… Each agent has ONE responsibility
âœ… Error correction is dedicated (error-corrector.md)
âœ… Session resumption is dedicated (session-resumer.md)
âœ… Abstractions decouple from storage/tools
âœ… Easy to extend (add new agent = add new route)
```

---

## ğŸš« When Routing Fails

**If intent is ambiguous:**
```
You: #file:KDS/prompts/user/cortex.md
     do something

Router: â“ Intent unclear. Did you mean:
        1. Continue current work? (execute)
        2. Check progress? (resume)
        3. Validate changes? (validate)
        
        Please clarify.
```

**If no active session and you say "continue":**
```
You: #file:KDS/prompts/user/cortex.md
     continue

Router: âŒ No active session found.
        Did you mean to start new work?
        Use: "I want to [describe feature]"
```

---

## ğŸ“Š SOLID v5.0 Design Benefits

### Answer: YES - It Makes CORTEX Better!

**Design Improvements:**
- âœ… **Single Responsibility** - Each agent has ONE clear job
- âœ… **Interface Segregation** - No mode switches (dedicated agents)
- âœ… **Dependency Inversion** - Abstractions decouple from concrete implementations
- âœ… **Open/Closed** - Easy to extend (add agents) without modifying existing code

**SOLID v5.0 Architecture:**
```
User Interface Layer:
  cortex.md (universal) â”€â”€â”€â”€â”€â”€â”€â”€â”
  plan.md (direct)   â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  execute.md (direct) â”€â”€â”€â”€â”€â”€â”€â”¤
  test.md (direct)    â”€â”€â”€â”€â”€â”€â”€â”¤  All route through
  correct.md (direct) â”€â”€â”€â”€â”€â”€â”€â”¤
  resume.md (direct)  â”€â”€â”€â”€â”€â”€â”€â”¤
  ...                        â”œâ”€â†’ intent-router.md (ROUTER)
                             â”‚
Internal Agent Layer:        â”‚
  work-planner.md     â†â”€â”€â”€â”€â”€â”€â”¤  (PLAN only)
  code-executor.md    â†â”€â”€â”€â”€â”€â”€â”¤  (EXECUTE only)
  error-corrector.md  â†â”€â”€â”€â”€â”€â”€â”¤  (CORRECT only - NEW)
  session-resumer.md  â†â”€â”€â”€â”€â”€â”€â”¤  (RESUME only - NEW)
  test-generator.md   â†â”€â”€â”€â”€â”€â”€â”¤  (TEST only)
  health-validator.md â†â”€â”€â”€â”€â”€â”€â”¤  (VALIDATE only)
  change-governor.md  â†â”€â”€â”€â”€â”€â”€â”¤  (GOVERN only)
  knowledge-retriever.md â†â”€â”€â”€â”˜  (ASK only)
  
Abstraction Layer (DIP):
  session-loader.md   â†’ Abstract session access
  test-runner.md      â†’ Abstract test execution
  file-accessor.md    â†’ Abstract file I/O
```

**What Changed from v4.5:**
```diff
- code-executor.md (execution + correction modes) âŒ SRP violation
+ code-executor.md (execution only) âœ… SRP compliant
+ error-corrector.md (correction only) âœ… ISP compliant

- work-planner.md (planning + resumption modes) âŒ SRP violation
+ work-planner.md (planning only) âœ… SRP compliant
+ session-resumer.md (resumption only) âœ… ISP compliant

- Direct file access (#file:KDS/sessions/...) âŒ DIP violation
+ Abstract access (session-loader.md) âœ… DIP compliant

- Hardcoded test commands (npx playwright test) âŒ DIP violation
+ Abstract runner (test-runner.md) âœ… DIP compliant
```

**Benefits:**
- ğŸ¯ **Clarity** - One agent = one job (easier to understand)
- ğŸš€ **Performance** - No mode-switch logic (faster routing)
- ğŸ”§ **Testability** - Mock abstractions (easier to test)
- ğŸ“¦ **Flexibility** - Swap storage/tools without breaking agents

**Flexibility:**
```
Option 1 (Easy): Use cortex.md universal entry point
Option 2 (Explicit): Call specific prompts directly
Option 3 (Advanced): Call internal agents with abstractions

All work! Universal is for convenience, SOLID is for quality.
```

---

## ğŸ“ Quick Reference Card

**For everything:**
```
#file:KDS/prompts/user/cortex.md
[what you want in natural language]
```

**What it detects:**
- "I want to..." â†’ plan
- "Continue..." â†’ execute  
- "Where was I..." â†’ resume
- "Wrong..." â†’ correct
- "Test..." â†’ test
- "Validate..." â†’ validate
- "How do I..." â†’ ask
- "I updated KDS..." â†’ govern
- "Update documentation..." â†’ plan (CORTEX Quadrant update) ğŸ“š
- "Refresh documentation..." â†’ trigger Documentation Refresh Plugin ğŸ†•
- "Publish docs..." â†’ plan (CORTEX Quadrant update)

**Documentation Refresh Plugin (NEW!)** ğŸ†•
When you say "Refresh documentation" or "Update Documentation", CORTEX triggers the Documentation Refresh Plugin which synchronizes the 4 key documentation files:
- `docs/story/Cortex-Trinity/Technical-CORTEX.md` - Technical deep-dive
- `docs/story/Cortex-Trinity/Awakening Of CORTEX.md` - Engaging story
- `docs/story/Cortex-Trinity/Image-Prompts.md` - Visual generation prompts
- `docs/story/Cortex-Trinity/History.md` - Evolution timeline

These 4 documents form the **CORTEX Documentation Quadrant** - always kept synchronized with the latest CORTEX 2.0 design.

**That's all you need to know!** ğŸš€

---

## ğŸ§  BRAIN System Best Practices

### Automatic Learning is ENABLED by Default

**CORTEX v5.0+ automatically logs events and updates BRAIN - no user action needed!**

**What happens automatically:**
1. âœ… Agents log events after every action (routing, file modifications, corrections)
2. âœ… Events accumulate in `KDS/cortex-brain/events.jsonl`
3. âœ… Rule #16 Step 5 checks event count after each task
4. âœ… When 50 events reached â†’ `brain-updater.md` auto-triggered
5. âœ… Knowledge graph updated with new patterns
6. âœ… Next routing decision gets smarter

**You benefit without doing anything!**

### Verify BRAIN is Learning (Optional Health Check)

**Want to confirm automatic learning is working?**

Check these indicators:
```bash
# 1. Recent events logged (should have timestamps from today)
cat KDS/cortex-brain/events.jsonl | tail -5

# 2. Knowledge graph updated recently (check last modified)
ls -la KDS/cortex-brain/knowledge-graph.yaml

# 3. Event count reasonable (not accumulating to 100+)
wc -l KDS/cortex-brain/events.jsonl
```

**Healthy BRAIN signs:**
- âœ… `events.jsonl` has recent timestamps (within last few hours)
- âœ… `knowledge-graph.yaml` updated in last 24 hours
- âœ… Event count stays below 50 (auto-cleanup working)

**âš ï¸ Warning signs (violations detected):**
- âŒ No events logged for 4+ hours (event logging broken)
- âŒ `knowledge-graph.yaml` not updated in 24+ hours
- âŒ 50+ unprocessed events accumulated (automatic update not triggering)

**If you see warnings:** See `KDS/docs/architecture/KDS-SELF-REVIEW-STRATEGY.md` for fixes

### Manual BRAIN Update (Only if Needed)

**When to manually update:**
- ğŸ”§ After bulk corrections (fixed multiple files at once)
- ğŸ”§ After large refactoring (want BRAIN to learn patterns immediately)
- ğŸš¨ If automatic updates stopped working (>50 events accumulated)
- ğŸ“Š Before important routing decision (want latest knowledge)

**How to trigger manually:**
```markdown
#file:KDS/prompts/internal/brain-updater.md
```

This processes all events and updates the knowledge graph.

### Standard Practice: Trust Automatic Learning

**Every CORTEX interaction SHOULD automatically:**
1. âœ… Log events (no user action needed)
2. âœ… Query BRAIN for insights (before routing/file decisions)
3. âœ… Update knowledge graph (periodic automatic)

**This is STANDARD CORTEX practice** - all agents follow this pattern automatically.

### For Advanced Users Only

**Manual intervention rarely needed, but available:**

1. **Manually correct routing** if BRAIN suggests wrong intent:
   ```markdown
   #file:KDS/prompts/user/cortex.md
   Wrong intent! I meant [correct interpretation]
   ```
   Error corrector logs the mistake, BRAIN learns for next time.

2. **Check BRAIN health** during self-review:
   ```markdown
   #file:KDS/prompts/user/validate.md
   Check BRAIN system health
   ```

3. **Force immediate update** after major changes:
   ```markdown
   #file:KDS/prompts/internal/brain-updater.md
   ```

**But in normal usage: Just use CORTEX and let BRAIN learn automatically!**

### First-Time Setup (Optional - BRAIN Works Out of the Box)

**CORTEX v5.0+ works immediately with empty BRAIN - learning starts from first use!**

**Optional bootstrapping (faster initial learning):**

**Option 1: Populate from existing sessions (if you have session history):**
```powershell
# PowerShell - Seed BRAIN from past sessions
.\KDS\scripts\populate-cortex-brain.ps1

# Then update knowledge graph
#file:KDS/prompts/internal/brain-updater.md
```

**Option 2: Crawl your codebase (recommended for new installations):**
```powershell
# PowerShell - Quick scan (30 seconds)
.\KDS\scripts\brain-crawler.ps1 -Mode quick

# OR Deep scan (5-10 minutes, comprehensive)
.\KDS\scripts\brain-crawler.ps1 -Mode deep
```

The crawler analyzes your entire application and feeds BRAIN with:
- ğŸ—ï¸ Architectural patterns (where components/services/tests live)
- ğŸ”— File relationships (what depends on what)
- ğŸ“ Naming conventions (how files are named)
- ğŸ› ï¸ Technology stack (languages, frameworks, tools)
- ğŸ§ª Test patterns (frameworks, test data, selectors)

**See:** `#file:KDS/prompts/internal/brain-crawler.md` for details

**But remember: Bootstrapping is OPTIONAL - BRAIN learns automatically from first interaction!**

### Ongoing Usage - No Action Needed!

**Just use CORTEX normally!** BRAIN learns automatically from every interaction:
- ğŸ“ Events logged automatically with every agent action
- ğŸ§  BRAIN updated automatically when 50 events accumulate
- ğŸ’¡ Decisions get smarter automatically over time
- ğŸ•·ï¸ Optional: Run incremental crawler scans to refresh architectural knowledge

**Zero manual intervention required for continuous learning.**

**Only manual actions needed:**
1. ğŸš¨ If automatic learning breaks (check `KDS-SELF-REVIEW-STRATEGY.md`)
2. ğŸ”§ After bulk corrections (want immediate learning)
3. ğŸ“Š When starting new project (run crawler to learn codebase)

**99% of the time: BRAIN just works!**

### Moving CORTEX to Another Application

**Need to reset BRAIN for a new project?**
```powershell
# PowerShell - Soft reset (clear data, keep config)
.\KDS\scripts\brain-reset.ps1 -Mode soft

# OR Export generic patterns first, then reset
.\KDS\scripts\brain-reset.ps1 -Mode export-reset -ExportPath ".\templates\my-patterns\"

# Then crawl the new application
.\KDS\scripts\brain-crawler.ps1 -Mode deep
```

BRAIN gets amnesia (forgets old app) but keeps all logic intact!

**See:** `#file:KDS/prompts/internal/brain-reset.md` for details

---

## ğŸ”— Technical Implementation (SOLID v5.0)

**This prompt loads:**
```markdown
#file:KDS/prompts/internal/intent-router.md
```

**Which analyzes your request and loads one of:**
```
#file:KDS/prompts/user/plan.md â†’ #file:KDS/prompts/internal/work-planner.md
#file:KDS/prompts/user/execute.md â†’ #file:KDS/prompts/internal/code-executor.md
#file:KDS/prompts/user/test.md â†’ #file:KDS/prompts/internal/test-generator.md
#file:KDS/prompts/user/validate.md â†’ #file:KDS/prompts/internal/health-validator.md
#file:KDS/prompts/user/govern.md â†’ #file:KDS/prompts/internal/change-governor.md
#file:KDS/prompts/user/ask-cortex.md â†’ #file:KDS/prompts/internal/knowledge-retriever.md
#file:KDS/prompts/user/correct.md â†’ #file:KDS/prompts/internal/error-corrector.md (NEW)
#file:KDS/prompts/user/resume.md â†’ #file:KDS/prompts/internal/session-resumer.md (NEW)
```

**Shared abstractions (DIP compliance):**
```
#shared-module:session-loader.md â†’ Abstract session access (default: local files)
#shared-module:test-runner.md â†’ Abstract test execution (uses project's tools)
#shared-module:file-accessor.md â†’ Abstract file I/O (PowerShell built-ins)

NOTE: All 100% local (in KDS/), zero external dependencies
```

**BRAIN management agents:**
```
#file:KDS/prompts/internal/brain-query.md â†’ Query knowledge graph
#file:KDS/prompts/internal/brain-updater.md â†’ Process events and update
#file:KDS/prompts/internal/brain-crawler.md â†’ Codebase analysis (NEW)
#file:KDS/prompts/internal/brain-reset.md â†’ Selective amnesia (NEW)
```

---

## ğŸ¯ Active Development Plan (CORTEX v6.0)

**Current Focus:** Real-Time BRAIN Dashboard with Live Reference System + Automatic BRAIN Updates

### âœ… **COMPLETED:** Rule #22 - Automatic BRAIN Updates

**Status:** ğŸ‰ **IMPLEMENTED** (Option D - Hybrid Approach)

**What Was Built:**

1. **Manual Recording Script** (Phase 1 - COMPLETE)
   - âœ… `scripts/record-conversation.ps1` - Manual conversation capture
   - âœ… Logs to `conversation-history.jsonl` (Tier 1)
   - âœ… FIFO enforcement (keep 20, delete oldest)
   - âœ… Auto-checks brain-updater threshold (50 events OR 24 hours)
   - âœ… **TESTED:** CopilotChats.txt conversation successfully recorded

2. **Auto BRAIN Updater** (Phase 2 - COMPLETE)
   - âœ… `scripts/auto-brain-updater.ps1` - Automatic trigger after every request
   - âœ… Logs request to `events.jsonl` (Tier 4)
   - âœ… Checks thresholds (50+ events OR 24+ hours)
   - âœ… Auto-invokes `brain-updater.ps1` when threshold met
   - âœ… Keeps `brain-updater.ps1` synchronized with `brain-updater.md`
   - âœ… **TESTED:** 13 events processed, knowledge-graph.yaml updated

3. **Git Hooks** (Phase 2 - COMPLETE)
   - âœ… `hooks/post-commit` - Auto-runs after every git commit
   - âœ… `scripts/setup-git-hooks.ps1` - One-time installation
   - âœ… Silent background execution (doesn't block commits)

4. **Governance Rule** (Tier 0 - COMPLETE)
   - âœ… **Rule #22:** Auto BRAIN Update After Every Request
   - âœ… `governance/rules/auto-brain-update.md` - Full specification
   - âœ… Tier 0 (INSTINCT) - Permanent, cannot be overridden
   - âœ… Updated `governance/rules.md` with Rule #22

5. **Architecture Documentation** (COMPLETE)
   - âœ… `docs/architecture/BRAIN-RECORDING-GAP-ANALYSIS.md` - Root cause analysis
   - âœ… Identified problem: GitHub Copilot Chat doesn't auto-invoke agents
   - âœ… Designed 4 solutions (manual, git hooks, extension, harvester)
   - âœ… Implemented hybrid approach (Phases 1-3 over 3 weeks)

**How to Use:**

```powershell
# Manual recording (after significant conversations)
.\scripts\record-conversation.ps1 `
    -Title "Your conversation title" `
    -FilesModified "file1.md,file2.ps1" `
    -EntitiesDiscussed "feature1,feature2" `
    -Outcome "What was accomplished" `
    -Intent "PLAN"

# Automatic (runs after git commits via hook)
git commit -m "Your commit message"  # auto-triggers brain-updater

# Test auto-updater manually
.\scripts\auto-brain-updater.ps1 `
    -RequestSummary "Test request" `
    -ResponseType "direct"

# Install git hooks (one-time setup)
.\scripts\setup-git-hooks.ps1
```

**Success Metrics:**
- âœ… 6 conversations in `conversation-history.jsonl` (was 5, added CopilotChats.txt)
- âœ… 13 events in `events.jsonl` (threshold: 50 for auto-update)
- âœ… brain-updater auto-triggered (24+ hours since last update)
- âœ… `knowledge-graph.yaml` updated with 13 new events
- âœ… Git hook installed and operational

**Next Steps (Phase 3 - Weeks 2-3):**
- ğŸ“‹ VS Code extension with Chat Participant API
- ğŸ“‹ Real-time conversation interception
- ğŸ“‹ Scheduled harvester (parse Copilot Chat history every 2 hours)
- ğŸ“‹ Full automation (zero user action required)

---

### Phase 7.3: Dashboard BRAIN Reference (IN DESIGN)

**Purpose:** Visual one-page guide to all CORTEX BRAIN functionality  
**Priority:** HIGH  
**Status:** ğŸ¯ DESIGN COMPLETE - READY TO IMPLEMENT

**New Features:**

1. **Tier 0 (Instinct) Enhancement** - Holistic review complete
   - âœ… Identified 6 fundamental design gaps
   - ğŸ“‹ 6 new Tier 0 files designed:
     - `governance/tier-0/tool-requirements.yaml` - Essential dependencies
     - `governance/tier-0/setup-protocol.yaml` - 5-step initialization
     - `governance/tier-0/tier-classification-rules.yaml` - Event classification
     - `governance/tier-0/amnesia-recovery.yaml` - Detection & recovery
     - `governance/tier-0/agent-protocols.yaml` - Standard behaviors
     - `governance/tier-0/hemisphere-coordination-rules.yaml` - LEFT/RIGHT communication

2. **Dashboard "BRAIN Reference" Tab** - Visual learning system
   - ğŸ“‹ Tab 1: OVERVIEW (one-page summary of all 5 tiers)
   - ğŸ“‹ Tab 2: RULES & GOVERNANCE (18 rules, searchable)
   - ğŸ“‹ Tab 3: HOW THINGS WORK (visual workflows)
     - "How Amnesia Works" (detection, recovery, prevention)
     - "How Learning Works" (brain-updater.md cycle)
     - "How TDD Cycle Works" (REDâ†’GREENâ†’REFACTOR)
     - "How Crawlers Work" (file discovery, dependencies)
     - "How Health Checks Work" (test-brain-integrity.ps1)
     - "How Setup Works" (initialization, validation)
     - "How Hemispheres Coordinate" (LEFT/RIGHT messaging)
   - ğŸ“‹ Tab 4: SETUP & DEPENDENCIES (tool inventory, validation)
   - ğŸ“‹ Tab 5: HEMISPHERES & COORDINATION (real-time activity)

3. **Closed-Loop Self-Healing** - Dashboard â†’ BRAIN feedback
   - ğŸ“‹ Health results logged to events.jsonl (Tier 4)
   - ğŸ“‹ brain-healer.md agent (auto-remediation)
   - ğŸ“‹ Remediation scripts (yaml, conversation, KG, session fixes)
   - ğŸ“‹ Dashboard "Fix" buttons (user-triggered repairs)
   - ğŸ“‹ Knowledge graph pattern learning (failure tracking)

**Architecture Docs:**
- `docs/architecture/DASHBOARD-BRAIN-INTEGRATION.md` - Self-healing design
- `docs/architecture/DASHBOARD-BRAIN-REFERENCE-FEATURE.md` - Visual reference design
- `docs/DASHBOARD-BRAIN-INTEGRATION-SUMMARY.md` - Self-healing summary
- `docs/DASHBOARD-BRAIN-REFERENCE-SUMMARY.md` - Visual reference summary

**Implementation Plan:** 4 weeks (see Phase 7 in KDS-V6-IMPLEMENTATION-PLAN-RISK-BASED.md)

**User Value:**
- âœ… One-page visual reference for entire BRAIN (no more trying to remember)
- âœ… Understand how ANY feature works (amnesia, learning, TDD, etc.)
- âœ… See all 18 rules in searchable format
- âœ… Know setup requirements and tool dependencies
- âœ… Monitor hemisphere activity in real-time
- âœ… Auto-fix common issues (or trigger manual fixes)
- âœ… Live data updated every 5-30 seconds

**Start Implementation:**
```
#file:KDS/prompts/user/plan.md "Implement Phase 7.3: Dashboard BRAIN Reference System"
```

---

### ğŸ“‹ **PLANNED:** Mind Palace - Advanced Memory Architecture

**Purpose:** Enhanced spatial memory system for complex knowledge organization  
**Priority:** FUTURE  
**Status:** ğŸ“‹ PLACEHOLDER - Design phase pending

**Concept:**
The Mind Palace extends KDS's BRAIN system with spatial memory techniques for organizing complex technical knowledge. This system will enable Copilot to "mentally navigate" through architectural concepts, code relationships, and project knowledge using memory palace techniques.

**Planned Features:**
- ğŸ“‹ Spatial knowledge organization (rooms, floors, locations)
- ğŸ“‹ Visual memory associations for complex patterns
- ğŸ“‹ Hierarchical knowledge structures
- ğŸ“‹ Enhanced context retrieval using spatial relationships
- ğŸ“‹ Integration with existing Tier 2 knowledge graph

**Metric Tracking (Core Requirement):**
The Mind Palace will be designed with comprehensive metric tracking from the start:

```yaml
mind_palace_metrics:
  kds_performance:
    - knowledge_retrieval_speed: "Time to locate relevant patterns"
    - spatial_navigation_accuracy: "Correct room/location hit rate"
    - pattern_association_effectiveness: "Successful pattern matches"
    - memory_consolidation_rate: "Tier 1 â†’ Tier 2 conversion efficiency"
    - context_reconstruction_time: "Resume session speed"
    
  coding_efficiency:
    - time_to_first_code: "Request â†’ First implementation"
    - architectural_alignment_rate: "% of solutions matching existing patterns"
    - rework_reduction: "Before/after Mind Palace implementation"
    - context_switching_overhead: "Time lost when changing tasks"
    - learning_curve_acceleration: "New team member onboarding speed"
    
  quality_metrics:
    - test_coverage_trends: "Before/after Mind Palace"
    - bug_escape_rate: "Issues reaching production"
    - architectural_consistency_score: "Alignment with design patterns"
    - knowledge_retention_rate: "Pattern recall accuracy over time"
    
  roi_measurements:
    - development_velocity_change: "Sprint velocity trends"
    - onboarding_time_reduction: "New developer productivity"
    - context_recovery_savings: "Hours saved on session resumes"
    - decision_quality_improvement: "Architectural decision success rate"
```

**Integration Points:**
- ğŸ“‹ Tier 2 (Knowledge Graph) - Spatial overlay for existing patterns
- ğŸ“‹ Tier 3 (Development Context) - Velocity impact tracking
- ğŸ“‹ Dashboard - Real-time visualization of memory palace structure
- ğŸ“‹ Metrics Reporter - Dedicated Mind Palace analytics

**Design Phase Tasks:**
1. Research spatial memory techniques for code organization
2. Design memory palace structure (rooms, floors, associations)
3. Define integration with existing BRAIN tiers
4. Create metric collection framework
5. Build prototype with test dataset
6. Validate effectiveness with real-world usage

**Documentation (To Be Created):**
- `docs/architecture/MIND-PALACE-DESIGN.md` - Full specification
- `docs/architecture/MIND-PALACE-METRICS.md` - Measurement framework
- `cortex-brain/mind-palace/` - Storage structure (when implemented)

**Notes:**
- Design will prioritize measurability from day one
- All claims must be backed by quantitative metrics
- Focus on demonstrable coding efficiency improvements
- Integration must be seamless with existing workflows

**When Ready to Design:**
```
#file:KDS/prompts/user/plan.md "Design Mind Palace Memory Architecture with Metrics"
```

---

## ğŸ“‹ CORTEX Response Templates - Phase-Based Execution

**Philosophy:** CORTEX creates complete plans upfront but executes **one complete phase at a time**, waiting for approval between phases. This gives users control while avoiding one-task-at-a-time friction.

### âœ… CORRECT: Phase-by-Phase with Approval Gates

**Example 1: Documentation Refresh**
```markdown
## ğŸš€ Plan Created: Documentation Refresh

I've identified 4 documentation gaps and created a 4-phase plan.

**Complete Plan:**
- Phase 1: Update "The Awakening" story (15 min, 3 tasks)
- Phase 2: Create 26 missing technical docs (45 min, 26 tasks)  
- Phase 3: Generate 8 Mermaid diagrams (20 min, 8 tasks)
- Phase 4: Deploy to GitHub Pages (5 min, 2 tasks)

Total Estimated: 85 minutes

**Start Execution?**
Say **"Yes"** to begin Phase 1 (I'll complete all 3 tasks, then stop for approval).

Say **"Show me Phase 1 details"** to review before starting.
```

**After Phase 1 Completes:**
```markdown
## âœ… Phase 1 Complete: Story Updated

**Delivered:**
- âœ… Updated narrative with 5 new features
- âœ… Added visual diagrams section
- âœ… Refreshed navigation structure

**Validation:**
- âœ… MkDocs build successful
- âœ… All links working
- âœ… Preview verified at localhost:8000

**Next:** Phase 2 - Create 26 technical docs (45 min, 26 tasks)

**Continue?** Say **"Yes"** to proceed with Phase 2, or **"Stop"** to review.
```

**Example 2: Test Failures**
```markdown
## ğŸ”§ 3 Test Failures Detected

I've analyzed the failures and created a 3-phase fix plan.

**Complete Plan:**
- Phase 1: Fix async selector in button.spec.ts (1 task)
- Phase 2: Update API mock in service.spec.ts (2 tasks)  
- Phase 3: Add missing import in utils.spec.ts (1 task)

**Note:** Each phase completes fully with validation before moving to next.

**Start Fixes?**
Say **"Yes"** to begin Phase 1 (I'll fix the button test completely, verify it passes, then stop).

Say **"Show root causes"** to review analysis first.
```

**Example 3: Feature Implementation**
```markdown
## âœ… Plan Created: Multi-Language Invoice Export

**4-Phase TDD Implementation:**
- Phase 1: Service layer (tests â†’ code) - 30 min, 6 tasks
- Phase 2: API endpoints (tests â†’ code) - 25 min, 5 tasks  
- Phase 3: UI component (tests â†’ code) - 40 min, 8 tasks
- Phase 4: Integration tests & validation - 20 min, 4 tasks

Total: ~115 minutes | All phases use TDD (RED â†’ GREEN â†’ REFACTOR)

**Begin Implementation?**
Say **"Yes"** to start Phase 1 (I'll complete all 6 service layer tasks with tests, then stop for review).

Say **"Show Phase 1 breakdown"** to see detailed tasks first.
```

### âŒ WRONG: Execute All Phases Without Approval

```markdown
## âŒ BAD - Runs everything without checkpoints

**Execute All (Recommended):**
I'll complete all phases sequentially:
1. Update story (15 min)
2. Create docs (45 min)
3. Generate diagrams (20 min)
4. Deploy (5 min)

Say "Execute all" to start

âŒ This removes user control
âŒ Can't stop between phases
âŒ No chance to review intermediate work
âŒ Violates phase approval rule
```

**Why this is bad:**
- âŒ No control points between phases
- âŒ Can't review work quality incrementally
- âŒ Continues even if early phase has issues
- âŒ All-or-nothing approach
- âŒ Violates mandatory approval rule

### ğŸ¯ Response Template Rules

**Rule 1: Always show complete plan upfront**
```markdown
âœ… "4-Phase Plan: Phase 1 (3 tasks), Phase 2 (5 tasks)..." - Full visibility
âœ… "Total: 85 minutes across 4 phases" - Set expectations

âŒ "I'll do some work" - Vague scope
âŒ "This will take a while" - No structure
```

**Rule 2: Execute one complete phase, then stop**
```markdown
âœ… "Say 'Yes' to begin Phase 1 (I'll complete all 3 tasks, then stop)"
âœ… "Phase 1 complete! Continue with Phase 2?"

âŒ "Execute all phases" - No approval gates
âŒ "Say 'continue' after each task" - Too granular
```

**Rule 3: Provide clear phase completion reports**
```markdown
âœ… Phase deliverables listed
âœ… Validation results shown
âœ… Next phase described
âœ… Explicit approval request

âŒ "Done. Next?" - No details
âŒ Automatic continuation
```

**Rule 4: Make approval clear and simple**
```markdown
âœ… "Continue? Say 'Yes' to proceed or 'Stop' to review"
âœ… Bold commands for easy identification

âŒ "What would you like to do next?" - Open-ended
âŒ "Ready?" - Unclear what happens
```

**Rule 5: Allow plan review before starting**
```markdown
âœ… "Show me Phase 1 details" - Review tasks
âœ… "Show root causes" - Understand before fixing
âœ… "Explain the approach" - Understand strategy

âŒ Only execution options
```

### ğŸ“Š Response Format Templates

**Standard Plan Creation Response:**
```markdown
## ğŸ¯ Plan Created: [Feature/Work Description]

**[X]-Phase Plan:**
- Phase 1: [Name] ([time], [N] tasks)
- Phase 2: [Name] ([time], [N] tasks)
- Phase 3: [Name] ([time], [N] tasks)

Total: [X hours/minutes] across [Y] phases

**Execution Model:**
- I'll complete each phase fully (all tasks)
- Stop after each phase for your approval
- You maintain control at natural breakpoints

**Begin?**
Say **"Yes"** to start Phase 1, or **"Show Phase 1 details"** to review first.
```

**Standard Phase Completion Response:**
```markdown
## âœ… Phase [N] Complete: [Phase Name]

**Delivered:**
- âœ… [Task 1] - [Result]
- âœ… [Task 2] - [Result]
- âœ… [Task 3] - [Result]

**Validation:**
- âœ… All tests passing ([X]/[X])
- âœ… No errors or warnings
- âœ… [Specific quality metric]

**Next:** Phase [N+1] - [Phase Name] ([time], [N] tasks)
  - [Brief description of what Phase N+1 will do]

**Continue?** Say **"Yes"** to proceed with Phase [N+1], or **"Stop"** to review current state.
```

**Standard Issue Fix Response:**
```markdown
## ğŸ”§ [X Issues/Errors] Detected

[Brief summary of problems and analysis]

**[X]-Phase Fix Plan:**
- Phase 1: [Fix category] ([N] issues)
- Phase 2: [Fix category] ([N] issues)  
- Phase 3: [Verification] ([N] checks)

**Approach:**
- Each phase completes fully with validation
- Stop between phases for verification
- Atomic commits with rollback safety

**Start Fixes?**
Say **"Yes"** to begin Phase 1, or **"Show root causes"** for detailed analysis.
```

**Standard All-Work-Complete Response:**
```markdown
## âœ… All Phases Complete: [Feature/Work]

**Summary:**
- âœ… Phase 1: [Result summary]
- âœ… Phase 2: [Result summary]
- âœ… Phase 3: [Result summary]

**Final Validation:**
- âœ… [X] tests passing
- âœ… Zero errors, zero warnings
- âœ… [Performance/coverage metrics]
- âœ… Documentation updated

**Deliverables:**
- [File 1]: [Description]
- [File 2]: [Description]
- [File 3]: [Description]

**Next Steps:**
- Deploy to [environment]
- Add [related feature]
- Mark complete and move on

**Documentation:** [Link or file reference]
```

### ğŸ§ª Complete Workflow Examples

**Scenario: Documentation needs refresh**

**Initial Response:**
```markdown
## ğŸ“š Plan Created: Documentation Refresh

Git analysis identified 5 new features since last deployment (Brain Protector, Oracle Crawler, Knowledge Boundaries, Amnesia, Pattern Cleanup).

**7-Phase Plan:**
- Phase 1: Update "Awakening" story with new features (20 min, 5 tasks)
- Phase 2: Create 5 technical docs (35 min, 5 tasks)
- Phase 3: Generate 6 Mermaid diagrams (15 min, 6 tasks)
- Phase 4: Create 4 Gemini image prompts (10 min, 4 tasks)
- Phase 5: Build docs with mkdocs (2 min, 1 task)
- Phase 6: Launch localhost:8000 for review (1 min, 1 task)
- Phase 7: Generate refresh report (5 min, 1 task)

Total: ~88 minutes across 7 phases

**Begin?**
Say **"Yes"** to start Phase 1 (I'll complete all 5 story update tasks, then stop).

Say **"Show Phase 1 tasks"** to review details first.
```

**After Phase 1:**
```markdown
## âœ… Phase 1 Complete: Story Updated

**Delivered:**
- âœ… Added Brain Protector section with protections explained
- âœ… Added Oracle Crawler section with database discovery
- âœ… Updated knowledge boundaries with namespace examples
- âœ… Added amnesia section with reset workflows
- âœ… Refreshed navigation with new feature links

**Validation:**
- âœ… MkDocs build successful
- âœ… All internal links valid
- âœ… Preview checked: localhost:8000

**Next:** Phase 2 - Create 5 technical docs (35 min, 5 tasks)

**Continue?** Say **"Yes"** for Phase 2, or **"Stop"** to review story changes.
```

**User:** "Yes"

**After Phase 2:**
```markdown
## âœ… Phase 2 Complete: Technical Docs Created

**Delivered:**
- âœ… docs/architecture/brain-protector.md (protection system)
- âœ… docs/features/oracle-crawler.md (database discovery)
- âœ… docs/architecture/knowledge-boundaries.md (namespace system)
- âœ… docs/guides/brain-amnesia.md (reset guide)
- âœ… docs/reference/pattern-cleanup.md (decay algorithms)

**Validation:**
- âœ… All docs render correctly
- âœ… Code examples validated
- âœ… Cross-references working

**Next:** Phase 3 - Generate 6 Mermaid diagrams (15 min, 6 tasks)

**Continue?** Say **"Yes"** for Phase 3, or **"Stop"** to review docs.
```

*[Pattern continues through all 7 phases]*

**Scenario: Multiple test failures**

**Initial Response:**
```markdown
## ğŸ§ª 7 Test Failures Detected

Test suite shows 7 failures across 3 components (HostControlPanel, InvoiceService, UserRegistration).

**Root Cause Analysis:**
- Playwright selectors outdated (4 failures)
- API schema mismatch (2 failures)
- Missing async/await (1 failure)

**3-Phase Fix Plan:**
- Phase 1: Fix Playwright selectors (4 tests, 10 min)
- Phase 2: Update API mocks (2 tests, 8 min)
- Phase 3: Add async/await (1 test, 5 min)

Total: ~23 minutes | Each phase validates before continuing

**Start Fixes?**
Say **"Yes"** to begin Phase 1 (I'll fix all 4 selector issues, verify they pass, then stop).
```

---

### ğŸ“ Key Principles Summary

**The Complete Phase Rule in Action:**

1. **Plan First:** Show complete multi-phase plan upfront
2. **Execute One:** Complete entire phase (all tasks)
3. **Stop & Report:** Show what was delivered + validation
4. **Ask Approval:** Explicit user consent to continue
5. **Repeat:** Next phase when approved

**Benefits:**
- âœ… User maintains control at logical breakpoints
- âœ… Can review quality before committing more time
- âœ… Can change direction based on results
- âœ… Reduces risk of going down wrong path
- âœ… Natural pause points for testing/validation

**What This Prevents:**
- âŒ Stopping after task 1.1 (incomplete phase)
- âŒ Asking approval for every task (too granular)
- âŒ Running all phases automatically (no control)
- âŒ Vague completion (phase must be 100% done)

**This rule applies everywhere:**
- Feature implementation
- Bug fixes
- Documentation updates
- Test creation
- Refactoring work
- Setup sequences
- CORTEX 2.0 implementation

---

## âœ¨ Summary
````

**You asked:**
> "Will the CORTEX system benefit from SOLID principles?"

**Answer: ABSOLUTELY! v5.0 implements:**
- âœ… **Single Responsibility** - One agent = one job
- âœ… **Interface Segregation** - Dedicated agents (no mode switches)
- âœ… **Dependency Inversion** - Abstractions decouple from concrete implementations
- âœ… **Open/Closed** - Easy to extend without modifying existing code

**What changed:**
- â• Added `error-corrector.md` (dedicated correction agent)
- â• Added `session-resumer.md` (dedicated resumption agent)
- â• Added abstraction layer (`session-loader`, `test-runner`, `file-accessor`)
- âœ… Removed mode switches from `code-executor` and `work-planner`
- âœ… Decoupled agents from concrete file paths and tool commands

**Local-First Compliance:**
- âœ… **100% in KDS/** - All CORTEX logic, data, scripts housed locally
- âœ… **Minimal external dependencies** - Only CORTEX enhancement libraries (declared upfront)
- âœ… **Offline-capable** - Works without internet (core functionality)
- âœ… **Transparent setup** - User informed of all required libraries during setup
- âš ï¸ **Optional extensions** - Cloud/database storage available but not required

**Dependency Categories:**
1. **CORTEX Core** - Zero dependencies (PowerShell/bash built-ins only)
2. **CORTEX Enhancements** - Open source libraries for improved capabilities (ALLOWED, declared at setup)
3. **Application Code** - User's project dependencies (Copilot recommends, user approves)
4. **Optional Features** - Cloud/DB/external services (opt-in only)

**What you need to remember:**
```
#file:KDS/prompts/user/cortex.md
[describe what you want]
```

**That's it. CORTEX handles the rest with SOLID principles and local-first design.** ğŸ¯

