# CORTEX Implementation Plan v3.0 - Complete Consolidated Plan

**Date:** 2025-11-06  
**Status:** üéØ ACTIVE EXECUTION PLAN  
**Previous Versions:** v1.0 (original), v2.0 (holistic review), v2.1 (MkDocs)  
**Current Plan:** 9 phases (including Phase -2), 79-101 hours  
**Branch:** cortex-migration ‚Üí will become main after Phase -2  
**Repository:** KDS ‚Üí CORTEX (renamed in Phase -2)

---

## üìã Executive Summary

This implementation plan represents the **complete, consolidated CORTEX migration strategy** incorporating all design decisions, holistic review findings, and operational improvements. This v3.0 plan integrates:

- **Phase -2 (NEW):** Project reorganization (KDS ‚Üí CORTEX, folder restructure, repo rename)
- **Rule #23 (NEW):** Git-based documentation storage with smart cleanup hooks
- **Rule #24 (NEW):** Mandatory assumption validation before implementation
- **MkDocs integration:** Professional documentation from Phase 0
- **Architecture validation:** Real benchmarks before implementation (Phase -1)
- **Early migration tools:** Tested in Phase 0.5, deployed in Phase 6
- **All phase plans consolidated:** Single source of truth (no separate phase files)

### Version History

**v3.0 (2025-11-06) - Current:**
- Added Phase -2 (Project Reorganization)
- Added Rule #23 (Git-Based Storage & Smart Cleanup)
- Added Rule #24 (Assumption Validation)
- Consolidated all phase-plans/*.md into this file
- Added stragglers from design documents

**v2.1 (2025-11-06) - Archived:**
- Added MkDocs documentation setup
- Enhanced Phase 0 with documentation infrastructure

**v2.0 (2025-11-06) - Archived:**
- Incorporated holistic review findings
- Added Phase -1 (Architecture Validation)
- Added Phase 0.5 (Migration Tools)
- Enhanced phases with validation checkpoints

**v1.0 (2025-11-05) - Archived:**
- Original 6-phase plan (Phases 0-6)

### Key Changes from v2.1

**Added:**
- ‚úÖ **Phase -2: Project Reorganization** (4-6 hours) - KDS ‚Üí CORTEX migration FIRST
- ‚úÖ **Rule #23: Git-Based Storage** - Smart cleanup with auto/manual modes
- ‚úÖ **Rule #24: Assumption Validation** - Mandatory clarification before implementation
- ‚úÖ **Consolidated phase plans** - All phases in this single file
- ‚úÖ **Straggler management** - Archive completed docs to Git with index

**Timeline Impact:**
- Original v1.0: 61-77 hours (7.5-10 days)
- Previous v2.1: 75-95 hours (9.5-12 days)
- **Current v3.0: 79-101 hours (10-13 days)**
- Net addition: +4-6 hours for Phase -2 (project reorganization)
- Net benefit: **Clean start, no legacy path issues, Git-based doc management**

---

## üö® Critical Updates in v3.0

### 1. Phase -2 Added (MUST Execute First)

**Why First:**
- All subsequent phases reference `D:\PROJECTS\CORTEX` paths
- Benchmark scripts in Phase -1 use new structure
- Avoids massive path updates after implementation starts
- Clean Git history from the start

### 2. Git-Based Documentation Management

**Concept:** Use Git as versioned storage for completed documentation

**Benefits:**
- Working directory stays clean (only active files)
- Full history preserved in Git
- Easy retrieval with ARCHIVE-INDEX.md
- Automatic cleanup based on file age/completion

### 3. Smart Cleanup Hook (Rule #23)

**Tiered Enforcement:**
```yaml
Auto (Safe):
  - Files marked COMPLETE, SUMMARY, FINDINGS
  - Unchanged for 30+ days
  - No active references
  - Merged into consolidated plan

Manual Approval (Breaking):
  - Referenced in active code
  - Modified in last 7 days
  - Contains TODO, WIP, ACTIVE markers
  - Used in CI/CD pipelines
```

### 4. Mandatory Assumption Validation (Rule #24)

**Before ANY implementation:**
1. CORTEX identifies all assumptions
2. Presents assumptions to user
3. Waits for explicit validation
4. Documents validated assumptions
5. Only then begins implementation

**Example:**
```
User: "Add export button"

CORTEX Response:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
üîç ASSUMPTION VALIDATION (Rule #24)

Request: "Add export button"

Assumptions Detected:
1. Export format: PDF (based on previous exports)
2. Location: Host Control Panel (current context)
3. Style: Follow existing button patterns
4. Functionality: Export current session transcript
5. Technology: Blazor component + C# service

Questions:
- Is PDF the correct format, or do you need CSV/JSON?
- Should this be in Host Control Panel or elsewhere?
- Any specific styling requirements?
- What should be exported (transcript, assets, both)?

Please validate or correct these assumptions before I proceed.
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
```

---

## üö® Critical Risks Addressed

### Risk Mitigation Summary

| Risk | Severity | Mitigation | Phase |
|------|----------|------------|-------|
| Browser API compatibility | HIGH | Polling fallback added | Phase -1 |
| sql.js performance | HIGH | Real benchmarks required | Phase -1 |
| Migration complexity | MEDIUM | Tools created in Phase 0.5 | Phase 0.5 |
| Unified schema lock contention | MEDIUM | Analysis + contingency | Phase -1 |
| Test enforcement gaps | MEDIUM | Pre-commit hooks + CI/CD | Phase 0 |
| Phase dependency cascade | LOW-MED | Contingency plans added | All phases |

---

## üìÖ Updated Phase Timeline

### Overview

```
Phase -2: Project Reorganization (NEW)      ‚Üí  4-6 hours
Phase -1: Architecture Validation (NEW)     ‚Üí  6-8 hours
Phase 0: Governance + CI/CD + Docs          ‚Üí  6-8 hours (enhanced, +2 hrs for MkDocs)
Phase 0.5: Migration Tools (NEW)            ‚Üí  3-4 hours
Phase 1: Working Memory                     ‚Üí  9-11 hours (schema stability)
Phase 2: Long-Term Knowledge                ‚Üí  11-13 hours (FTS5 validation)
Phase 3: Context Intelligence               ‚Üí  11-13 hours
Phase 4: Agents                             ‚Üí  13-17 hours
Phase 5: Entry Point                        ‚Üí  7-9 hours
Phase 6: Migration Validation               ‚Üí  5-7 hours (simpler, tools tested)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
TOTAL: 79-101 hours (10-13 days focused work)
```

**Critical Path:** Phase -2 MUST complete before Phase -1 (new paths required for benchmarks)

---

## ‚úÖ Global Phase Exit Checklist (NEW)

To enforce traceable, incremental delivery, CORTEX requires a Git checkpoint after EVERY phase. This complements task-level automation and is mandatory per the CORTEX Rulebook (Tier 0 rule: PHASE_GIT_CHECKPOINT).

End-of-phase steps (apply to phases -2, -1, 0, 0.5, 1, 2, 3, 4, 5, 6):

- Validate phase success criteria and quality gates (build/tests/docs) ‚Äî must PASS
- Commit all changes with a semantic message and clear summary
   - Format: `chore(phase-X): complete Phase X ‚Äî <one-line summary>`
   - Body: brief highlights (benchmarks, schema/tag versions, docs updated)
- Push to origin on the active branch
- Optional: create a lightweight tag for easy retrieval
   - Tag format: `phase-X-complete` (e.g., `phase-1-complete`)
- Update `cortex-design/CHANGELOG.md` with a Phase X section

Example commands:

```
git add -A
git commit -m "chore(phase-1): complete Phase 1 ‚Äî Tier 1 schema frozen (v1.0), tests added, benchmarks recorded"
git push origin HEAD
git tag -a phase-1-complete -m "Phase 1 complete: Schema v1.0 frozen"
git push origin phase-1-complete
```

---

## üîß PHASE -2: Project Reorganization (NEW - EXECUTE FIRST)

**Duration:** 4-6 hours  
**Priority:** P0 - MUST COMPLETE BEFORE ALL OTHER PHASES  
**Purpose:** Reorganize project structure, rename repo, establish Git-based documentation management

### Why Phase -2 Comes First

**Dependencies:**
- ‚úÖ Phase -1 benchmarks reference `D:\PROJECTS\CORTEX` paths
- ‚úÖ Phase 0 governance files use new structure
- ‚úÖ All documentation assumes CORTEX repo name
- ‚úÖ CI/CD workflows reference correct paths
- ‚úÖ MkDocs configuration points to new location

**Without Phase -2:**
- ‚ùå Would need to update paths in every subsequent phase
- ‚ùå Mixed KDS/CORTEX references cause confusion
- ‚ùå Git history shows legacy paths
- ‚ùå Documentation deployment breaks

### Objectives

1. ‚úÖ Move `D:\PROJECTS\KDS` ‚Üí `D:\PROJECTS\CORTEX`
2. ‚úÖ Restructure folders (CORTEX-only under new root)
3. ‚úÖ Rename GitHub repo: `KDS` ‚Üí `CORTEX`
4. ‚úÖ Commit all KDS files before deletion (safety tag)
5. ‚úÖ Implement Git-based documentation storage (Rule #23)
6. ‚úÖ Add assumption validation to governance (Rule #24)
7. ‚úÖ Update all path references in code/docs/configs
8. ‚úÖ Establish smart cleanup hooks

---

### Task -2.1: Backup Current State (30 minutes)

**Goal:** Create safety checkpoint before major reorganization

**Steps:**

1. Commit all current changes:
   ```powershell
   cd D:\PROJECTS\KDS
   git add .
   git commit -m "Pre-reorganization checkpoint: KDS v8 final state"
   git push origin cortex-migration
   ```

2. Create safety tag:
   ```powershell
   git tag -a v8-final-kds -m "Final KDS state before CORTEX reorganization"
   git push origin v8-final-kds
   ```

3. Create backup branch (reference only):
   ```powershell
   git checkout -b kds-v8-archive
   git push origin kds-v8-archive
   git checkout cortex-migration
   ```

4. Verify backup integrity:
   ```powershell
   # Verify tag exists
   git tag -l "v8-final-kds"
   
   # Verify branch exists
   git branch -a | grep kds-v8-archive
   
   # Verify remote synchronized
   git ls-remote --tags origin | grep v8-final-kds
   ```

**Deliverables:**
- ‚úÖ Git tag `v8-final-kds` created and pushed
- ‚úÖ Archive branch `kds-v8-archive` created
- ‚úÖ Remote backup verified
- ‚úÖ Can rollback with `git checkout v8-final-kds` if needed

---

### Task -2.2: Create New CORTEX Directory Structure (1 hour)

**Goal:** Establish clean project structure at `D:\PROJECTS\CORTEX`

**Steps:**

1. Create new directory:
   ```powershell
   mkdir D:\PROJECTS\CORTEX
   cd D:\PROJECTS\CORTEX
   ```

2. Initialize Git with existing remote:
   ```powershell
   # Clone existing repo to new location
   git clone https://github.com/asifhussain60/CORTEX.git .
   git checkout cortex-migration
   ```

3. Restructure folders (keep only CORTEX-related):
   ```powershell
   # Keep these folders:
   CORTEX/                    # Main implementation
   cortex-design/            # Active design docs (will be cleaned)
   cortex-agents/            # Agent implementations
   .github/                  # CI/CD workflows
   governance/               # Rules and policies
   
   # Archive these to Git (Task -2.4):
   kds-brain/                # Will be migrated to cortex-brain in Phase 6
   prompts/                  # KDS-specific prompts (archive after migration)
   scripts/                  # Migrate useful ones, archive rest
   docs/                     # Consolidate into cortex-design/ or archive
   
   # Delete these (no longer needed):
   _archive/                 # Old backups
   backups/                  # Redundant with Git
   dashboard/                # Old dashboard (replaced by dashboard-wpf)
   dashboard-wpf/            # KDS-specific dashboard (archive reference)
   emsdk/                    # Build tools (reinstall if needed)
   knowledge/                # Migrated to cortex-brain
   reports/                  # Generated files (not in Git)
   sessions/                 # Runtime data (not in Git)
   sql.js/                   # NPM package (reinstall)
   templates/                # Migrate useful ones
   tests/                    # Migrate to CORTEX/tests/
   tooling/                  # Migrate to CORTEX/tooling/
   hooks/                    # Git hooks (migrate to .git/hooks/)
   ```

4. Create clean CORTEX structure:
   ```
   D:\PROJECTS\CORTEX\
   ‚îú‚îÄ‚îÄ CORTEX/                        # Main implementation
   ‚îÇ   ‚îú‚îÄ‚îÄ src/                       # Source code
   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tier0/                 # Governance
   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tier1/                 # Working memory
   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tier2/                 # Knowledge graph
   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tier3/                 # Context intelligence
   ‚îÇ   ‚îú‚îÄ‚îÄ cortex-agents/             # Specialist agents
   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ user/                  # User-facing entry points
   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ internal/              # Internal agents
   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ shared/                # Shared utilities
   ‚îÇ   ‚îú‚îÄ‚îÄ tests/                     # Test suite (370 tests)
   ‚îÇ   ‚îú‚îÄ‚îÄ cortex-brain.db            # SQLite database
   ‚îÇ   ‚îú‚îÄ‚îÄ docs/                      # MkDocs documentation
   ‚îÇ   ‚îú‚îÄ‚îÄ package.json
   ‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
   ‚îÇ   ‚îî‚îÄ‚îÄ README.md
   ‚îú‚îÄ‚îÄ cortex-design/                 # Active design documents
   ‚îÇ   ‚îú‚îÄ‚îÄ CORTEX-DNA.md              # Core principles (ACTIVE)
   ‚îÇ   ‚îú‚îÄ‚îÄ IMPLEMENTATION-PLAN.md     # This file (ACTIVE)
   ‚îÇ   ‚îú‚îÄ‚îÄ CHANGELOG.md               # Version history (ACTIVE)
   ‚îÇ   ‚îú‚îÄ‚îÄ ARCHIVE-INDEX.md           # Git-archived docs index (NEW)
   ‚îÇ   ‚îú‚îÄ‚îÄ README.md                  # Design docs entry point
   ‚îÇ   ‚îî‚îÄ‚îÄ archive/                   # Local archive (before Git commit)
   ‚îÇ       ‚îú‚îÄ‚îÄ v1.0-original-6-phase.md
   ‚îÇ       ‚îú‚îÄ‚îÄ v2.0-holistic-review.md
   ‚îÇ       ‚îî‚îÄ‚îÄ v2.1-mkdocs-integration.md
   ‚îú‚îÄ‚îÄ .github/                       # CI/CD workflows
   ‚îÇ   ‚îú‚îÄ‚îÄ workflows/
   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ cortex-ci.yml
   ‚îÇ   ‚îî‚îÄ‚îÄ CopilotContext.txt
   ‚îú‚îÄ‚îÄ governance/                    # Rules and policies
   ‚îÇ   ‚îú‚îÄ‚îÄ rules.md                   # Tier 0 immutable rules
   ‚îÇ   ‚îî‚îÄ‚îÄ tier-0/                    # Governance implementation
   ‚îú‚îÄ‚îÄ .gitignore
   ‚îú‚îÄ‚îÄ README.md                      # Project entry point
   ‚îî‚îÄ‚îÄ LICENSE
   ```

**Deliverables:**
- ‚úÖ `D:\PROJECTS\CORTEX` directory created
- ‚úÖ Clean folder structure established
- ‚úÖ Legacy folders identified for archival
- ‚úÖ New structure documented

---

### Task -2.3: Implement Git-Based Documentation Storage (1.5 hours)

**Goal:** Archive completed design documents to Git with retrieval index

**Create ARCHIVE-INDEX.md:**

```powershell
# Create archive index file
cd D:\PROJECTS\CORTEX\cortex-design
cat > ARCHIVE-INDEX.md << 'EOF'
# CORTEX Documentation Archive Index

## Purpose
This index tracks documentation archived to Git history. Archived files are removed from the working directory but preserved in Git with easy retrieval commands.

## Archive Strategy

**Files are archived when:**
- ‚úÖ Marked as COMPLETE, SUMMARY, or FINDINGS
- ‚úÖ Unchanged for 30+ days
- ‚úÖ Merged into consolidated plan
- ‚úÖ No active code references

**Retrieval:**
```bash
# Single file
git show <commit>:<path> > restored-file.md

# View on GitHub
https://github.com/asifhussain60/CORTEX/blob/<commit>/<path>
```

## Archived Documents

### Design Phase Complete (2025-11-06) - Tag: `design-phase-complete`

| Document | Commit | Retrieval | Reason |
|----------|--------|-----------|--------|
| CONVERSATION-LOG.md | `xxxxx` | `git show xxxxx:cortex-design/CONVERSATION-LOG.md` | Historical record, inactive |
| HOLISTIC-REVIEW.md | `xxxxx` | `git show xxxxx:cortex-design/HOLISTIC-REVIEW.md` | Review complete, findings incorporated |
| HOLISTIC-REVIEW-FINDINGS.md | `xxxxx` | `git show xxxxx:cortex-design/HOLISTIC-REVIEW-FINDINGS.md` | Incorporated into v3.0 plan |
| HOLISTIC-REVIEW-PROTOCOL.md | `xxxxx` | `git show xxxxx:cortex-design/HOLISTIC-REVIEW-PROTOCOL.md` | Process doc, no longer active |
| PROGRESS.md | `xxxxx` | `git show xxxxx:cortex-design/PROGRESS.md` | Outdated, Git log is source of truth |
| STRATEGIC-REFINEMENTS.md | `xxxxx` | `git show xxxxx:cortex-design/STRATEGIC-REFINEMENTS.md` | Refinements applied to v3.0 |
| WHY-CORTEX-IS-BETTER.md | `xxxxx` | `git show xxxxx:cortex-design/WHY-CORTEX-IS-BETTER.md` | Marketing doc, static reference |
| FTS5-DECISION-SUMMARY.md | `xxxxx` | `git show xxxxx:cortex-design/FTS5-DECISION-SUMMARY.md` | Decision finalized, merged |
| DESIGN-IMPROVEMENTS-SUMMARY.md | `xxxxx` | `git show xxxxx:cortex-design/DESIGN-IMPROVEMENTS-SUMMARY.md` | Improvements applied |
| PHASE-MINUS-1-FINDINGS.md | `xxxxx` | `git show xxxxx:cortex-design/PHASE-MINUS-1-FINDINGS.md` | Will be replaced by real Phase -1 results |
| IMPLEMENTATION-PLAN-SUMMARY.md | `xxxxx` | `git show xxxxx:cortex-design/IMPLEMENTATION-PLAN-SUMMARY.md` | Merged into main plan |
| IMPLEMENTATION-QUICK-REFERENCE.md | `xxxxx` | `git show xxxxx:cortex-design/IMPLEMENTATION-QUICK-REFERENCE.md` | Redundant, main plan is reference |
| MIGRATION-STRATEGY.md | `xxxxx` | `git show xxxxx:cortex-design/MIGRATION-STRATEGY.md` | Merged into Phase 6 |
| CORTEX-IMAGE-PROMPTS.md | `xxxxx` | `git show xxxxx:cortex-design/CORTEX-IMAGE-PROMPTS.md` | Initial design artifacts |

### Phase Plans Consolidated (2025-11-06) - Tag: `phase-plans-archived`

| Document | Commit | Retrieval | Reason |
|----------|--------|-----------|--------|
| phase-0-governance.md | `xxxxx` | `git show xxxxx:cortex-design/phase-plans/phase-0-governance.md` | Merged into IMPLEMENTATION-PLAN.md Phase 0 |
| phase-1-working-memory.md | `xxxxx` | `git show xxxxx:cortex-design/phase-plans/phase-1-working-memory.md` | Merged into IMPLEMENTATION-PLAN.md Phase 1 |
| phase-2-knowledge-graph.md | `xxxxx` | `git show xxxxx:cortex-design/phase-plans/phase-2-knowledge-graph.md` | Merged into IMPLEMENTATION-PLAN.md Phase 2 |
| phase-3-context-intelligence-updated.md | `xxxxx` | `git show xxxxx:cortex-design/phase-plans/phase-3-context-intelligence-updated.md` | Merged into IMPLEMENTATION-PLAN.md Phase 3 |
| phase-4-agents.md | `xxxxx` | `git show xxxxx:cortex-design/phase-plans/phase-4-agents.md` | Merged into IMPLEMENTATION-PLAN.md Phase 4 |
| phase-5-entry-point.md | `xxxxx` | `git show xxxxx:cortex-design/phase-plans/phase-5-entry-point.md` | Merged into IMPLEMENTATION-PLAN.md Phase 5 |
| phase-6-migration-validation.md | `xxxxx` | `git show xxxxx:cortex-design/phase-plans/phase-6-migration-validation.md` | Merged into IMPLEMENTATION-PLAN.md Phase 6 |
| phase-5-progress.md | `xxxxx` | `git show xxxxx:cortex-design/phase-plans/phase-5-progress.md` | Progress tracking obsolete |
| COMPLETE-SUMMARY.md | `xxxxx` | `git show xxxxx:cortex-design/phase-plans/COMPLETE-SUMMARY.md` | Redundant with main plan |

### Folders Archived

| Folder | Commit | Retrieval | Reason |
|--------|--------|-----------|--------|
| feature-inventory/ | `xxxxx` | `git show xxxxx:cortex-design/feature-inventory/` | Catalog complete, merged |
| test-specifications/ | `xxxxx` | Will archive after tests written | Reference for test creation |

## Active Documents (Keep in Working Directory)

| Document | Status | Purpose |
|----------|--------|---------|
| CORTEX-DNA.md | ACTIVE | Core principles reference |
| IMPLEMENTATION-PLAN.md | ACTIVE | Current execution plan (this is v3.0) |
| CHANGELOG.md | ACTIVE | Version history tracker |
| README.md | ACTIVE | Entry point for design docs |
| dashboard-requirements.md | ACTIVE | Until dashboard built |
| ARCHIVE-INDEX.md | ACTIVE | This file |

## How to Archive a Document

```bash
# 1. Commit the file
git add <file>
git commit -m "Archive: <filename> (reason)"

# 2. Add entry to this index
# (Edit ARCHIVE-INDEX.md)

# 3. Create tag if milestone
git tag -a <tagname> -m "Description"

# 4. Remove from working directory
rm <file>

# 5. Commit the removal
git add <file>
git commit -m "Remove archived file: <filename> (now in Git)"
git push origin cortex-migration --tags
```

## Rollback / Retrieval Examples

```bash
# Restore single file temporarily
git show a1b2c3d:cortex-design/HOLISTIC-REVIEW.md > HOLISTIC-REVIEW.md

# View file in browser (GitHub)
https://github.com/asifhussain60/CORTEX/blob/a1b2c3d/cortex-design/HOLISTIC-REVIEW.md

# Restore entire folder at tag
git checkout design-phase-complete -- cortex-design/

# Compare current vs archived
git diff HEAD:IMPLEMENTATION-PLAN.md a1b2c3d:IMPLEMENTATION-PLAN-V2.md
```
EOF
```

**Execute archival:**

```powershell
# Archive completed design documents
$archiveFiles = @(
    "CONVERSATION-LOG.md",
    "HOLISTIC-REVIEW.md",
    "HOLISTIC-REVIEW-FINDINGS.md",
    "HOLISTIC-REVIEW-PROTOCOL.md",
    "PROGRESS.md",
    "STRATEGIC-REFINEMENTS.md",
    "WHY-CORTEX-IS-BETTER.md",
    "FTS5-DECISION-SUMMARY.md",
    "DESIGN-IMPROVEMENTS-SUMMARY.md",
    "PHASE-MINUS-1-FINDINGS.md",
    "IMPLEMENTATION-PLAN-SUMMARY.md",
    "IMPLEMENTATION-QUICK-REFERENCE.md",
    "MIGRATION-STRATEGY.md",
    "CORTEX-IMAGE-PROMPTS.md"
)

# Commit all files to Git
foreach ($file in $archiveFiles) {
    if (Test-Path "cortex-design\$file") {
        git add "cortex-design\$file"
    }
}

git commit -m "Archive: Design phase documentation (complete, merged into v3.0 plan)"
$designCommit = git rev-parse HEAD

# Create milestone tag
git tag -a design-phase-complete -m "Design phase complete: All findings incorporated into IMPLEMENTATION-PLAN.md v3.0"

# Archive phase plans
git add cortex-design/phase-plans/
git commit -m "Archive: Phase plans (all merged into consolidated IMPLEMENTATION-PLAN.md)"
$phasePlansCommit = git rev-parse HEAD

# Create tag
git tag -a phase-plans-archived -m "Phase plans consolidated into single IMPLEMENTATION-PLAN.md file"

# Update ARCHIVE-INDEX.md with real commit hashes
# (Replace xxxxx with actual commit hashes)

# Remove files from working directory
foreach ($file in $archiveFiles) {
    if (Test-Path "cortex-design\$file") {
        Remove-Item "cortex-design\$file"
    }
}

Remove-Item -Recurse cortex-design/phase-plans/

# Commit removals
git add .
git commit -m "Cleanup: Removed archived documentation (preserved in Git history)"

# Push everything
git push origin cortex-migration --tags
```

**Deliverables:**
- ‚úÖ `ARCHIVE-INDEX.md` created
- ‚úÖ Completed docs committed to Git
- ‚úÖ Tags created (`design-phase-complete`, `phase-plans-archived`)
- ‚úÖ Files removed from working directory
- ‚úÖ Clean cortex-design/ folder (only active files remain)

---

### Task -2.4: Rename GitHub Repository (30 minutes)

**Goal:** Rename repo from "KDS" to "CORTEX" on GitHub

**Steps:**

1. Rename on GitHub:
   ```
   1. Go to https://github.com/asifhussain60/CORTEX
   2. Click Settings
   3. Scroll to "Repository name"
   4. Change "KDS" ‚Üí "CORTEX"
   5. Click "Rename"
   ```

2. Update local remote:
   ```powershell
   cd D:\PROJECTS\CORTEX
   git remote set-url origin https://github.com/asifhussain60/CORTEX.git
   git remote -v  # Verify new URL
   ```

3. Update CI/CD references:
   ```yaml
   # .github/workflows/cortex-ci.yml
   # Update any hardcoded repo names
   # Update badge URLs in README.md
   ```

4. Update documentation URLs:
   ```bash
   # Search and replace KDS ‚Üí CORTEX in relevant files
   grep -r "github.com/asifhussain60/CORTEX" . --include="*.md"
   # Replace with CORTEX
   ```

**Deliverables:**
- ‚úÖ GitHub repo renamed to "CORTEX"
- ‚úÖ Local remote URL updated
- ‚úÖ CI/CD workflows reference correct repo
- ‚úÖ Documentation links updated

---

### Task -2.5: Add New Governance Rules (1 hour)

**Goal:** Add Rule #23 (Cleanup Hook) and Rule #24 (Assumption Validation)

**Update governance/rules.md:**

```markdown
## Rule #23: Git-Based Storage & Smart Cleanup (NEW)

**Severity:** MEDIUM  
**Category:** Organization  
**Immutable:** TRUE

**Description:**
CORTEX maintains a clean working directory by archiving completed documentation to Git history with an index-based retrieval system.

**Requirements:**

1. **Smart Detection:**
   - Files marked COMPLETE, SUMMARY, FINDINGS ‚Üí Auto-archive
   - Files unchanged for 30+ days ‚Üí Auto-archive
   - Files merged into consolidated plans ‚Üí Auto-archive
   - Files with active references ‚Üí Require approval before archive

2. **Archive Process:**
   - Commit file to Git with descriptive message
   - Add entry to ARCHIVE-INDEX.md with retrieval command
   - Create Git tag if milestone
   - Update references to point to Git commit
   - Remove from working directory

3. **Enforcement Tiers:**
   ```yaml
   SAFE (Auto-archive without approval):
     - Completion markers (COMPLETE, SUMMARY, FINDINGS)
     - Age > 30 days unchanged
     - No active code references
     - Merged into consolidated docs
   
   BREAKING (Require user approval):
     - Referenced in active code/scripts
     - Modified in last 7 days
     - Contains TODO, WIP, ACTIVE markers
     - Used in CI/CD pipelines
   ```

4. **Cleanup Hook Execution:**
   - Runs during BRAIN updates (Rule #22 trigger)
   - Scans cortex-design/ for archival candidates
   - Presents summary of safe auto-archives
   - Requests approval for breaking changes
   - Logs all actions to cleanup-log.jsonl

**Validation:**
- [ ] ARCHIVE-INDEX.md exists and up-to-date
- [ ] Archived files have Git commit reference
- [ ] Working directory contains only active files
- [ ] All archived files retrievable via index

**Anti-Patterns:**
- ‚ùå Deleting files without Git commit
- ‚ùå Archiving files with active references without approval
- ‚ùå Missing index entries for archived files

---

## Rule #24: Mandatory Assumption Validation (NEW)

**Severity:** HIGH  
**Category:** Quality  
**Immutable:** TRUE

**Description:**
Before implementing ANY user request, CORTEX MUST identify all assumptions, present them to the user for validation, and receive explicit confirmation before proceeding.

**Requirements:**

1. **Assumption Identification:**
   - Analyze user request for implicit assumptions
   - Identify: format, location, technology, functionality, style
   - Document each assumption clearly

2. **Validation Protocol:**
   ```
   User Request: [Original request]
   
   ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
   üîç ASSUMPTION VALIDATION (Rule #24)
   
   Assumptions Detected:
   1. [Assumption with reasoning]
   2. [Assumption with reasoning]
   3. [...]
   
   Questions:
   - [Clarifying question for assumption 1]
   - [Clarifying question for assumption 2]
   - [...]
   
   Please validate or correct these assumptions before I proceed.
   ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
   ```

3. **User Response Handling:**
   - Wait for explicit user validation
   - Update assumptions based on clarifications
   - Re-present if significant changes
   - Only proceed after user confirmation

4. **Documentation:**
   - Log validated assumptions to conversation context
   - Reference assumptions in implementation
   - Create pattern for similar future requests

**Validation:**
- [ ] Assumptions presented before implementation
- [ ] User provided explicit validation
- [ ] Assumptions documented in context
- [ ] Implementation matches validated assumptions

**Anti-Patterns:**
- ‚ùå Implementing without assumption validation
- ‚ùå Making critical assumptions silently
- ‚ùå Proceeding with "probably" or "I think"
- ‚ùå Skipping validation for "simple" requests

**Example Flow:**

```
User: "Add export feature"

‚ùå WRONG (Skip validation):
> Creating PDF export service...

‚úÖ CORRECT (Validate first):
> üîç ASSUMPTION VALIDATION (Rule #24)
> 
> Request: "Add export feature"
> 
> Assumptions Detected:
> 1. Export format: PDF (based on previous exports)
> 2. Export content: Current session transcript
> 3. Location: Host Control Panel
> 4. Technology: C# service + Blazor component
> 
> Questions:
> - Should this export PDF, CSV, JSON, or multiple formats?
> - What should be exported (transcript, assets, both)?
> - Where should the export button be located?
> - Any specific formatting requirements?
> 
> Please validate before I proceed.

[Wait for user response]

User: "PDF and CSV, export transcript only, Host Control Panel is correct"

> ‚úÖ Assumptions validated:
> - Formats: PDF + CSV
> - Content: Transcript only
> - Location: Host Control Panel
> - Technology: C# service + Blazor component
> 
> Proceeding with implementation...
```
```

**Deliverables:**
- ‚úÖ Rule #23 added to governance/rules.md
- ‚úÖ Rule #24 added to governance/rules.md
- ‚úÖ Cleanup hook design documented
- ‚úÖ Assumption validation protocol documented

---

### Task -2.6: Update All Path References (1 hour)

**Goal:** Update all references from KDS ‚Üí CORTEX paths

**Files to update:**

```powershell
# PowerShell script to update paths
$files = @(
    "CORTEX/package.json",
    "CORTEX/tsconfig.json",
    "CORTEX/requirements.txt",
    ".github/workflows/cortex-ci.yml",
    "cortex-design/CORTEX-DNA.md",
    "cortex-design/IMPLEMENTATION-PLAN.md",
    "cortex-design/README.md",
    "CORTEX/docs/mkdocs.yml",
    "README.md",
    ".gitignore"
)

foreach ($file in $files) {
    if (Test-Path $file) {
        (Get-Content $file) -replace 'D:\\PROJECTS\\KDS', 'D:\PROJECTS\CORTEX' | Set-Content $file
        (Get-Content $file) -replace 'KDS/prompts', 'CORTEX/cortex-agents' | Set-Content $file
        (Get-Content $file) -replace 'kds-brain', 'cortex-brain' | Set-Content $file
    }
}

# Verify no KDS paths remain
grep -r "D:\\\\PROJECTS\\\\KDS" . --include="*.md" --include="*.json" --include="*.yml" --include="*.py" --include="*.ts"
```

**Specific updates:**

1. **package.json:**
   ```json
   {
     "name": "cortex-performance-tests",
     "scripts": {
       "test": "cd D:\\PROJECTS\\CORTEX\\CORTEX && pytest tests/"
     }
   }
   ```

2. **mkdocs.yml:**
   ```yaml
   site_name: CORTEX Documentation
   repo_url: https://github.com/asifhussain60/CORTEX
   ```

3. **CI/CD workflows:**
   ```yaml
   - name: Checkout
     uses: actions/checkout@v3
     with:
       repository: asifhussain60/CORTEX
   ```

4. **README.md:**
   ```markdown
   # CORTEX - Cognitive Intelligence System
   
   Repository: https://github.com/asifhussain60/CORTEX
   Path: D:\PROJECTS\CORTEX
   ```

**Deliverables:**
- ‚úÖ All path references updated to CORTEX
- ‚úÖ No KDS paths remain in active files
- ‚úÖ CI/CD workflows reference correct paths
- ‚úÖ Documentation links correct

---

### Task -2.7: Validation & Testing (30 minutes)

**Goal:** Verify reorganization success

**Validation Checklist:**

```powershell
# 1. Verify directory structure
Test-Path D:\PROJECTS\CORTEX\CORTEX                     # Should be TRUE
Test-Path D:\PROJECTS\CORTEX\cortex-design              # Should be TRUE
Test-Path D:\PROJECTS\CORTEX\cortex-design\archive      # Should be TRUE

# 2. Verify Git configuration
cd D:\PROJECTS\CORTEX
git remote -v  # Should show github.com/asifhussain60/CORTEX

# 3. Verify tags exist
git tag -l  # Should include: v8-final-kds, design-phase-complete, phase-plans-archived

# 4. Verify archived files in Git
git show design-phase-complete:cortex-design/HOLISTIC-REVIEW.md  # Should display file

# 5. Verify ARCHIVE-INDEX.md
Test-Path cortex-design\ARCHIVE-INDEX.md  # Should be TRUE

# 6. Verify clean working directory
Get-ChildItem cortex-design -File | Where-Object {$_.Name -like "*COMPLETE*"}  # Should be empty

# 7. Verify governance rules
cat governance\rules.md | Select-String "Rule #23"  # Should find Rule #23
cat governance\rules.md | Select-String "Rule #24"  # Should find Rule #24

# 8. Run basic tests (if any exist)
cd CORTEX
pytest tests/ --dry-run  # Should show test collection

# 9. Verify no path errors
grep -r "D:\\\\PROJECTS\\\\KDS" . --include="*.md" --include="*.json"  # Should be empty

# 10. Verify Git status
git status  # Should show clean or only expected changes
```

**Deliverables:**
- ‚úÖ All validation checks pass
- ‚úÖ Directory structure correct
- ‚úÖ Git configuration updated
- ‚úÖ Archives retrievable
- ‚úÖ No legacy KDS references

---

### Phase -2 Success Criteria

‚úÖ **Project reorganized:** D:\PROJECTS\KDS ‚Üí D:\PROJECTS\CORTEX  
‚úÖ **GitHub repo renamed:** KDS ‚Üí CORTEX  
‚úÖ **Backup created:** Git tag `v8-final-kds` exists  
‚úÖ **Git-based archival:** ARCHIVE-INDEX.md functional  
‚úÖ **Completed docs archived:** Working directory clean  
‚úÖ **Governance rules added:** Rule #23 and #24 documented  
‚úÖ **Path references updated:** No KDS paths remain  
‚úÖ **Validation passed:** All checks green  

**‚ö†Ô∏è DO NOT PROCEED TO PHASE -1 UNTIL ALL CRITERIA MET**

**Rollback Procedure (if needed):**
```powershell
# Emergency rollback
git checkout v8-final-kds
cd D:\PROJECTS
Remove-Item -Recurse -Force CORTEX
Rename-Item KDS CORTEX  # Revert directory name change
cd CORTEX
git checkout cortex-migration
# Fix repo name on GitHub manually
```

---

## üî¨ PHASE -1: Architecture Validation (NEW)

**Duration:** 6-8 hours  
**Priority:** P0 - MUST COMPLETE BEFORE PHASE 0  
**Purpose:** Validate core assumptions, prevent costly rework later

### Objectives

1. ‚úÖ Benchmark sql.js actual performance (not estimates)
2. ‚úÖ Test browser API compatibility (File System Access API)
3. ‚úÖ Analyze unified schema lock contention
4. ‚úÖ Validate dashboard technology choices
5. ‚úÖ Document findings and contingency plans

### Tasks

#### Task -1.1: sql.js Performance Benchmarking (2-3 hours)

**Goal:** Measure real sql.js query performance, validate <100ms targets

**Steps:**
1. Create realistic test database:
   ```python
   # generate-test-data.py
   import sqlite3
   
   db = sqlite3.connect('test-cortex-brain.db')
   
   # Generate 1000 conversations
   for i in range(1000):
       # Insert conversation + messages
       
   # Generate 3000 patterns
   for i in range(3000):
       # Insert pattern + components
   
   # Total size: ~500 KB (realistic)
   ```

2. Create benchmark script:
   ```python
   # benchmark-sql-js.py
   import time
   import statistics
   
   # Test queries:
   # - Tier 1: Conversation lookup (20 runs)
   # - Tier 1: Entity search (20 runs)
   # - Tier 2: FTS5 pattern search (20 runs)
   # - Tier 2: Confidence calculation (20 runs)
   
   # Measure: p50, p95, p99 latency
   # Target: p95 < 50ms (Tier 1), < 100ms (Tier 2)
   ```

3. Run benchmarks:
   ```bash
   # Native SQLite (baseline)
   python benchmark-sqlite.py
   
   # sql.js (browser WASM)
   # Use Playwright to run in browser
   npx playwright test benchmark-sql-js.spec.ts
   ```

4. Compare results:
   ```yaml
   Expected Results:
     Native SQLite:
       Tier 1: 5-10ms (p95)
       Tier 2 FTS5: 20-50ms (p95)
     
     sql.js (WASM):
       Tier 1: 50-100ms (p95) - 10x slower
       Tier 2 FTS5: 100-300ms (p95) - 5-6x slower
   ```

5. **DECISION POINT:**
   - ‚úÖ If p95 < 50ms (Tier 1) & < 100ms (Tier 2): **PROCEED** with sql.js
   - ‚ö†Ô∏è If p95 50-150ms: **ADD CACHING**, optimize queries, re-test
   - ‚ùå If p95 > 150ms: **PIVOT** to server-side API (contingency plan B)

**Contingency Plan B (if sql.js too slow):**
```markdown
Server-Side API Approach:
1. Create Node.js Express server
2. Use better-sqlite3 (native SQLite, no WASM overhead)
3. REST API endpoints:
   - GET /api/conversations
   - GET /api/patterns/search
   - POST /api/patterns
4. Dashboard uses fetch() instead of sql.js
5. Real-time via WebSocket (not File System Access API)

Trade-off: Adds server dependency (violates "zero server" goal)
Decision: Make server OPTIONAL (power users only)
```

**Deliverables:**
- ‚úÖ `benchmark-sql-js.spec.ts` (browser benchmarks)
- ‚úÖ `test-cortex-brain.db` (realistic test data)
- ‚úÖ Benchmark report: `phase-minus-1-benchmark-report.md`
- ‚úÖ Decision: sql.js or server-side API

---

#### Task -1.2: Browser API Compatibility Testing (1-2 hours)

**Goal:** Validate File System Access API support, implement fallback

**Steps:**
1. Test on all browsers:
   ```typescript
   // test-file-system-api.spec.ts
   test('File System Access API availability', async ({ browserName }) => {
     // Chrome/Edge: Should have API
     // Firefox: Should NOT have API (fallback required)
     // Safari: Should have API but require permission
   });
   ```

2. Implement polling fallback:
   ```typescript
   // src/hooks/useFileWatcher.ts
   export function useFileWatcher(filePath: string) {
     const [hasFileSystemAPI] = useState(
       'showDirectoryPicker' in window
     );
     
     if (hasFileSystemAPI) {
       // Use File System Access API (real-time)
       return useFileSystemWatcher(filePath);
     } else {
       // Fallback: Poll every 1 second
       return usePollingWatcher(filePath, 1000);
     }
   }
   ```

3. Test fallback performance:
   ```typescript
   // Measure:
   // - Real-time: <100ms from file write ‚Üí UI update
   // - Polling: ~1 second delay (acceptable)
   ```

**Deliverables:**
- ‚úÖ `useFileWatcher.ts` with fallback
- ‚úÖ Browser compatibility matrix in dashboard-requirements.md
- ‚úÖ Polling fallback tested on Firefox

---

#### Task -1.3: Unified Schema Lock Contention Analysis (1-2 hours)

**Goal:** Validate single DB won't cause blocking issues

**Steps:**
1. Simulate concurrent operations:
   ```python
   # test-lock-contention.py
   import sqlite3
   import threading
   
   db_path = 'test-cortex-brain.db'
   
   # Thread 1: Long read (dashboard refresh)
   def long_read():
       conn = sqlite3.connect(db_path)
       # Query takes 200ms
       
   # Thread 2: Write (BRAIN update)
   def write_pattern():
       conn = sqlite3.connect(db_path)
       # INSERT INTO patterns (blocked?)
       
   # Run concurrently, measure blocking time
   ```

2. Test with WAL mode:
   ```sql
   PRAGMA journal_mode=WAL; -- Enable Write-Ahead Logging
   -- WAL allows: Concurrent reads + single writer
   ```

3. Measure contention:
   ```yaml
   Without WAL:
     - Write blocks all reads (worst case)
     - Blocking time: 50-200ms
   
   With WAL:
     - Reads don't block writes
     - Writes don't block reads (usually)
     - Blocking time: <10ms
   ```

4. **DECISION POINT:**
   - ‚úÖ If WAL reduces contention < 10ms: **PROCEED** with unified DB
   - ‚ö†Ô∏è If contention 10-50ms: **ACCEPTABLE**, document in architecture
   - ‚ùå If contention > 50ms: **CONSIDER** separate databases (contingency)

**Contingency Plan (if contention high):**
```markdown
Separate Databases Approach:
1. Split into tier-specific DBs:
   - tier1-working-memory.db
   - tier2-knowledge.db
   - tier3-context.db (or stay JSON)
2. Benefits: No lock contention, independent schemas
3. Trade-offs: Cross-tier queries harder (manual joins)
4. Decision: Only if contention > 50ms (unlikely with WAL)
```

**Deliverables:**
- ‚úÖ `test-lock-contention.py` (concurrency test)
- ‚úÖ Lock contention report: `phase-minus-1-contention-analysis.md`
- ‚úÖ Decision: Unified DB or separate DBs

---

#### Task -1.4: Dashboard Technology Validation (1-2 hours)

**Goal:** Confirm React + Tailwind + Shadcn/ui is feasible

**Steps:**
1. Create minimal dashboard prototype:
   ```bash
   npm create vite@latest cortex-dashboard -- --template react-ts
   cd cortex-dashboard
   npm install
   npx shadcn-ui@latest init
   npm install sql.js recharts
   ```

2. Build one component:
   ```tsx
   // src/components/ConversationList.tsx
   import { Card } from '@/components/ui/card';
   import initSqlJs from 'sql.js';
   
   export function ConversationList() {
     const [conversations, setConversations] = useState([]);
     
     useEffect(() => {
       loadConversations();
     }, []);
     
     // Test: Can we load sql.js + query DB + render?
   }
   ```

3. Measure development time:
   ```yaml
   Setup: 30 minutes (actual)
   Learn Shadcn/ui: 1 hour (estimated in review)
   Build component: 1 hour
   Total: 2.5 hours for first component
   
   Validates dashboard estimate: 12-16 hours (includes learning)
   ```

**Deliverables:**
- ‚úÖ `cortex-dashboard/` prototype (minimal)
- ‚úÖ `ConversationList.tsx` working component
- ‚úÖ Validation: Technology stack works as expected

---

#### Task -1.5: Document Findings & Contingencies (1 hour)

**Goal:** Create comprehensive validation report

**Report Contents:**
1. **sql.js Benchmarks:**
   - Native vs WASM performance
   - Decision: Proceed or pivot
   - Contingency: Server-side API

2. **Browser Compatibility:**
   - API support matrix
   - Fallback strategy validated
   - Impact: 30% users use polling (acceptable)

3. **Lock Contention:**
   - WAL mode effectiveness
   - Decision: Unified DB or separate
   - Expected contention: <10ms (acceptable)

4. **Dashboard Feasibility:**
   - Technology stack validated
   - Timeline adjustment: +4 hours (learning curve)
   - Confidence: HIGH

5. **Go/No-Go Decision:**
   - ‚úÖ All validations passed: **PROCEED TO PHASE 0**
   - ‚ö†Ô∏è 1-2 concerns: **ADJUST PLAN**, re-validate
   - ‚ùå Major blocker: **REDESIGN ARCHITECTURE**, restart Phase -1

**Deliverables:**
- ‚úÖ `phase-minus-1-validation-report.md` (comprehensive)
- ‚úÖ Decision: GO/NO-GO for Phase 0
- ‚úÖ Contingency plans documented (if needed)

---

### Phase -1 Success Criteria

‚úÖ **sql.js benchmarked** with realistic data  
‚úÖ **Performance decision** made (sql.js or server API)  
‚úÖ **Browser fallback** implemented and tested  
‚úÖ **Lock contention** analyzed (WAL mode validated)  
‚úÖ **Dashboard prototype** working  
‚úÖ **Validation report** complete  
‚úÖ **Go/No-Go decision** documented  

**‚ö†Ô∏è DO NOT PROCEED TO PHASE 0 UNTIL ALL CRITERIA MET**

---

## üîê PHASE 0: Governance + CI/CD + Documentation (Enhanced)

**Duration:** 6-8 hours (was 4-6, +2 hours for CI/CD + MkDocs)  
**Priority:** P0 - Foundation  
**Dependencies:** Phase -1 complete (GO decision)

### Changes from Original Plan

**Added Tasks:**
1. ‚úÖ Pre-commit hooks (pytest with coverage enforcement)
2. ‚úÖ GitHub Actions CI/CD workflow
3. ‚úÖ Coverage monitoring (must be ‚â•95%)
4. ‚úÖ Performance regression detection
5. ‚úÖ MkDocs documentation setup (NEW)

**Enhanced Tasks:**
- Rule validation now includes pre-commit integration
- Holistic review includes CI/CD validation
- Documentation infrastructure from day 1

### Tasks (Original + New)

#### Task 0.1-0.5: (Original tasks from phase-0-governance.md)
- GovernanceEngine class
- YAML ‚Üí SQLite migration
- Rule query API
- Violation tracking
- 15 unit + 2 integration tests

#### Task 0.6: CI/CD Setup (NEW - 1 hour)

**Goal:** Automated testing on every commit

**Steps:**
1. Create pre-commit hook:
   ```bash
   # .git/hooks/pre-commit
   #!/bin/bash
   
   echo "Running CORTEX tests..."
   pytest cortex-tests/ \
     --cov=cortex-brain \
     --cov=cortex-agents \
     --cov-report=term \
     --cov-fail-under=95
   
   if [ $? -ne 0 ]; then
     echo "‚ùå Tests failed or coverage <95%. Commit blocked."
     exit 1
   fi
   
   echo "‚úÖ All tests passed, coverage ‚â•95%"
   ```

2. Create GitHub Actions workflow:
   ```yaml
   # .github/workflows/cortex-ci.yml
   name: CORTEX CI
   
   on: [push, pull_request]
   
   jobs:
     test:
       runs-on: ubuntu-latest
       steps:
         - uses: actions/checkout@v3
         - uses: actions/setup-python@v4
           with:
             python-version: '3.11'
         - run: pip install -r requirements.txt
         - run: pytest cortex-tests/ --cov --cov-fail-under=95
         - run: python cortex-tests/performance/benchmark-all.py
         
         # Upload coverage report
         - uses: codecov/codecov-action@v3
   ```

3. Install coverage tools:
   ```bash
   pip install pytest pytest-cov
   ```

4. Test hook:
   ```bash
   # Make hook executable
   chmod +x .git/hooks/pre-commit
   
   # Test
   git add cortex-brain/governance.py
   git commit -m "test: Verify pre-commit hook"
   # Should run tests, check coverage
   ```

**Deliverables:**
- ‚úÖ `.git/hooks/pre-commit` (enforces tests)
- ‚úÖ `.github/workflows/cortex-ci.yml` (automated CI)
- ‚úÖ `requirements.txt` (pytest, pytest-cov)
- ‚úÖ Pre-commit hook tested and working

---

#### Task 0.7: MkDocs Documentation Setup (NEW - 1 hour)

**Goal:** Establish documentation infrastructure from day 1

**Why MkDocs:**
- ‚úÖ **Small footprint** (~10 MB total with dependencies)
- ‚úÖ **No server required** for viewing (generates static HTML)
- ‚úÖ **Markdown-based** (familiar format, easy to write)
- ‚úÖ **Rich formatting** (diagrams, code blocks, admonitions)
- ‚úÖ **Mermaid support** (flowcharts, diagrams built-in)
- ‚úÖ **Image support** (screenshots, architecture diagrams)
- ‚úÖ **Search built-in** (automatic client-side search)
- ‚úÖ **Fast builds** (<1 second for CORTEX-sized docs)

**Steps:**

1. Install MkDocs with Material theme:
   ```bash
   pip install mkdocs mkdocs-material
   pip install mkdocs-mermaid2-plugin  # For flowcharts
   ```

2. Initialize MkDocs project:
   ```bash
   cd CORTEX
   mkdocs new docs
   ```

3. Configure `mkdocs.yml`:
   ```yaml
   site_name: CORTEX Documentation
   site_description: Cognitive Intelligence System for KDS
   site_author: CORTEX Team
   
   theme:
     name: material
     palette:
       primary: indigo
       accent: purple
     features:
       - navigation.tabs
       - navigation.sections
       - toc.integrate
       - search.suggest
       - content.code.copy
   
   plugins:
     - search
     - mermaid2
   
   markdown_extensions:
     - admonition
     - codehilite
     - pymdownx.highlight
     - pymdownx.superfences:
         custom_fences:
           - name: mermaid
             class: mermaid
             format: !!python/name:mermaid2.fence_mermaid
     - pymdownx.tabbed
     - pymdownx.details
     - attr_list
     - md_in_html
   
   nav:
     - Home: index.md
     - Getting Started:
       - Quick Start: getting-started/quick-start.md
       - Installation: getting-started/installation.md
     - Architecture:
       - Overview: architecture/overview.md
       - Tier 0 (Governance): architecture/tier0-governance.md
       - Tier 1 (STM): architecture/tier1-working-memory.md
       - Tier 2 (LTM): architecture/tier2-knowledge-graph.md
       - Tier 3 (Context): architecture/tier3-context-intelligence.md
     - API Reference:
       - Tier 0 API: api/tier0-api.md
       - Tier 1 API: api/tier1-api.md
       - Tier 2 API: api/tier2-api.md
       - Tier 3 API: api/tier3-api.md
     - Guides:
       - Migration from KDS: guides/kds-migration.md
       - Agent Development: guides/agent-development.md
       - Testing: guides/testing.md
     - Development:
       - Contributing: development/contributing.md
       - Phase Plans: development/phase-plans.md
   ```

4. Create initial documentation structure:
   ```bash
   CORTEX/docs/
   ‚îú‚îÄ‚îÄ index.md                      # Home page
   ‚îú‚îÄ‚îÄ getting-started/
   ‚îÇ   ‚îú‚îÄ‚îÄ quick-start.md            # 5-minute intro
   ‚îÇ   ‚îî‚îÄ‚îÄ installation.md           # Setup guide
   ‚îú‚îÄ‚îÄ architecture/
   ‚îÇ   ‚îú‚îÄ‚îÄ overview.md               # 4-tier system
   ‚îÇ   ‚îú‚îÄ‚îÄ tier0-governance.md       # Governance layer
   ‚îÇ   ‚îú‚îÄ‚îÄ tier1-working-memory.md   # STM details
   ‚îÇ   ‚îú‚îÄ‚îÄ tier2-knowledge-graph.md  # LTM details
   ‚îÇ   ‚îî‚îÄ‚îÄ tier3-context-intelligence.md
   ‚îú‚îÄ‚îÄ api/
   ‚îÇ   ‚îú‚îÄ‚îÄ tier0-api.md              # Governance API
   ‚îÇ   ‚îú‚îÄ‚îÄ tier1-api.md              # STM API
   ‚îÇ   ‚îú‚îÄ‚îÄ tier2-api.md              # LTM API
   ‚îÇ   ‚îî‚îÄ‚îÄ tier3-api.md              # Context API
   ‚îú‚îÄ‚îÄ guides/
   ‚îÇ   ‚îú‚îÄ‚îÄ kds-migration.md          # KDS ‚Üí CORTEX
   ‚îÇ   ‚îú‚îÄ‚îÄ agent-development.md      # Creating agents
   ‚îÇ   ‚îî‚îÄ‚îÄ testing.md                # Testing guide
   ‚îî‚îÄ‚îÄ development/
       ‚îú‚îÄ‚îÄ contributing.md           # Dev guidelines
       ‚îî‚îÄ‚îÄ phase-plans.md            # Implementation phases
   ```

5. Create sample documentation with Mermaid diagrams:
   ```markdown
   # CORTEX Architecture Overview
   
   CORTEX is a 4-tier cognitive intelligence system:
   
   ```mermaid
   graph TB
       A[User Request] --> B[Entry Point]
       B --> C{Intent Router}
       C --> D[Tier 0: Governance]
       C --> E[Tier 1: Working Memory]
       C --> F[Tier 2: Knowledge Graph]
       C --> G[Tier 3: Context Intelligence]
       D --> H[Specialist Agents]
       E --> H
       F --> H
       G --> H
       H --> I[Response]
   ```
   
   ## Quick Stats
   
   !!! info "Performance Targets"
       - **Query Latency:** <100ms (10-100x faster than KDS)
       - **Storage Size:** <270 KB (47% smaller than KDS)
       - **Response Length:** <10 lines (5x more concise)
       - **Test Coverage:** 95%+ (370 permanent tests)
   
   ## Tier Breakdown
   
   | Tier | Purpose | Storage | Size |
   |------|---------|---------|------|
   | **Tier 0** | Governance Rules | YAML | ~20 KB |
   | **Tier 1** | Working Memory (20 conversations) | SQLite | <100 KB |
   | **Tier 2** | Knowledge Graph (patterns) | SQLite + FTS5 | <120 KB |
   | **Tier 3** | Context Intelligence (git/test) | JSON | <50 KB |
   ```

6. Build and test documentation:
   ```bash
   # Build static site
   mkdocs build
   
   # Output: CORTEX/site/ (static HTML)
   # Can be opened directly in browser (no server needed!)
   
   # For development (auto-reload on changes)
   mkdocs serve
   # Opens http://localhost:8000
   ```

7. Add to `.gitignore`:
   ```gitignore
   # MkDocs build output
   site/
   ```

8. Add MkDocs to CI/CD:
   ```yaml
   # .github/workflows/cortex-ci.yml
   jobs:
     docs:
       runs-on: ubuntu-latest
       steps:
         - uses: actions/checkout@v3
         - uses: actions/setup-python@v4
         - run: pip install mkdocs mkdocs-material mkdocs-mermaid2-plugin
         - run: mkdocs build --strict  # Fail on warnings
         - uses: actions/upload-artifact@v3
           with:
             name: documentation
             path: site/
   ```

**Usage Examples:**

```markdown
# In any documentation file

## Code Example
```python
def query_patterns(search_term: str):
    """Query knowledge graph patterns"""
    return db.execute("""
        SELECT * FROM patterns 
        WHERE pattern_components MATCH ?
    """, (search_term,))
```

## Flowchart
```mermaid
sequenceDiagram
    User->>Router: "Add export button"
    Router->>Tier2: Query patterns
    Tier2-->>Router: Similar pattern found
    Router->>Planner: Create plan
    Planner-->>User: 4-phase plan
```

## Warning Box
!!! warning "Schema Freeze"
    After Phase 1, the Tier 1 schema is FROZEN. No ALTER TABLE allowed!

## Image
![CORTEX Architecture](../images/cortex-architecture.png)
```

**Benefits:**

- ‚úÖ **No server required for viewing** - Just open `site/index.html`
- ‚úÖ **Offline-friendly** - All assets bundled in static site
- ‚úÖ **Fast search** - Client-side JavaScript search (no backend)
- ‚úÖ **Professional look** - Material theme looks polished
- ‚úÖ **Easy to write** - Just Markdown files
- ‚úÖ **Diagrams included** - Mermaid renders flowcharts automatically
- ‚úÖ **Version control friendly** - Docs live in Git with code
- ‚úÖ **CI/CD integrated** - Docs built and validated on every commit

**Deliverables:**
- ‚úÖ `mkdocs.yml` configuration
- ‚úÖ `CORTEX/docs/` structure created
- ‚úÖ Initial documentation pages (index, architecture overview)
- ‚úÖ Sample Mermaid diagram working
- ‚úÖ MkDocs added to `requirements.txt`
- ‚úÖ CI/CD validates docs build
- ‚úÖ `site/` in `.gitignore`

**Documentation Maintenance:**

```bash
# During development: Add docs as you build features
Phase 0: Document Tier 0 governance
Phase 1: Document Tier 1 STM API
Phase 2: Document Tier 2 LTM API
Phase 3: Document Tier 3 Context API
Phase 4: Document agent development
Phase 5: Document entry point usage
Phase 6: Document migration guide

# Rebuild docs
mkdocs build

# View locally (no server install needed!)
open CORTEX/site/index.html  # macOS
start CORTEX/site/index.html  # Windows
xdg-open CORTEX/site/index.html  # Linux
```

---

### Phase 0 Success Criteria (Enhanced)

‚úÖ All original criteria (from phase-0-governance.md)  
‚úÖ **Pre-commit hook** installed and tested  
‚úÖ **CI/CD workflow** passing on GitHub  
‚úÖ **Coverage** validated ‚â•95%  
‚úÖ **Performance benchmarks** integrated  
‚úÖ **MkDocs installed** and configured  
‚úÖ **Initial documentation** built successfully  
‚úÖ **Sample diagram** rendering (Mermaid test)  

**‚ö†Ô∏è DO NOT PROCEED TO PHASE 0.5 UNTIL CI/CD + DOCS VALIDATED**

---

## üîß PHASE 0.5: Migration Tools (NEW)

**Duration:** 3-4 hours  
**Priority:** P1 - Early preparation  
**Purpose:** Create & test migration scripts BEFORE Phase 6

### Objectives

1. ‚úÖ Build migration scripts (Tier 1, 2, 3)
2. ‚úÖ Test on sample KDS data
3. ‚úÖ Validate transformation accuracy
4. ‚úÖ Document rollback procedures

### Tasks

#### Task 0.5.1: Tier 1 Migration Script (1-1.5 hours)

**Goal:** Migrate conversation-history.jsonl ‚Üí SQLite

**Steps:**
1. Create migration script:
   ```python
   # scripts/migrate-tier1-conversations.py
   import json
   import sqlite3
   from pathlib import Path
   
   def migrate_conversations(jsonl_path, db_path):
       """
       Migrate conversation-history.jsonl to SQLite
       
       Transformations:
       - JSONL line ‚Üí conversations table row
       - Extract entities ‚Üí entities table
       - Extract files ‚Üí files_mentioned table
       """
       
       conn = sqlite3.connect(db_path)
       
       with open(jsonl_path) as f:
           for line in f:
               conv = json.loads(line)
               
               # Insert conversation
               conn.execute("""
                   INSERT INTO conversations 
                   (conversation_id, title, created_at, message_count)
                   VALUES (?, ?, ?, ?)
               """, (conv['id'], conv['title'], ...))
               
               # Extract entities
               for entity in extract_entities(conv):
                   conn.execute("""
                       INSERT INTO entities (...)
                   """, (...))
       
       conn.commit()
       return True
   ```

2. Test on sample data:
   ```python
   # Create sample JSONL
   sample = Path('kds-brain/conversation-history-sample.jsonl')
   # Copy 10 conversations from real file
   
   # Run migration
   migrate_conversations(sample, 'test-cortex-brain.db')
   
   # Validate
   conn = sqlite3.connect('test-cortex-brain.db')
   count = conn.execute('SELECT COUNT(*) FROM conversations').fetchone()[0]
   assert count == 10, "Migration failed"
   ```

**Deliverables:**
- ‚úÖ `migrate-tier1-conversations.py`
- ‚úÖ Tested on sample data (10 conversations)
- ‚úÖ Validation: 100% accuracy

---

#### Task 0.5.2: Tier 2 Migration Script (1-1.5 hours)

**Goal:** Migrate knowledge-graph.yaml ‚Üí SQLite

**Steps:**
1. Create migration script:
   ```python
   # scripts/migrate-tier2-patterns.py
   import yaml
   import sqlite3
   
   def migrate_patterns(yaml_path, db_path):
       """
       Migrate knowledge-graph.yaml to SQLite
       
       Transformations:
       - YAML patterns ‚Üí patterns table
       - Nested components ‚Üí pattern_components table
       - File relationships ‚Üí file_relationships table
       """
       
       with open(yaml_path) as f:
           data = yaml.safe_load(f)
       
       conn = sqlite3.connect(db_path)
       
       # Migrate patterns
       for pattern in data.get('patterns', []):
           conn.execute("""
               INSERT INTO patterns (pattern_id, name, ...)
           """, (...))
           
           # Migrate components (nested structure)
           for component in pattern.get('components', []):
               conn.execute("""
                   INSERT INTO pattern_components (...)
               """, (...))
       
       # Migrate file relationships
       for rel in data.get('file_relationships', []):
           conn.execute("""
               INSERT INTO file_relationships (...)
           """, (...))
       
       conn.commit()
   ```

2. Test on sample data:
   ```python
   # Create sample YAML (10 patterns)
   sample = Path('kds-brain/knowledge-graph-sample.yaml')
   
   # Run migration
   migrate_patterns(sample, 'test-cortex-brain.db')
   
   # Validate
   conn = sqlite3.connect('test-cortex-brain.db')
   count = conn.execute('SELECT COUNT(*) FROM patterns').fetchone()[0]
   assert count == 10
   ```

**Deliverables:**
- ‚úÖ `migrate-tier2-patterns.py`
- ‚úÖ Tested on sample data (10 patterns)
- ‚úÖ Validation: Nested structure preserved

---

#### Task 0.5.3: Validation Script (30 minutes)

**Goal:** Compare KDS vs CORTEX queries (data parity)

**Steps:**
1. Create validation script:
   ```python
   # scripts/validate-migration.py
   import json
   import yaml
   import sqlite3
   
   def validate_tier1(jsonl_path, db_path):
       """Compare conversation counts, entity counts"""
       
       # KDS: Count conversations in JSONL
       with open(jsonl_path) as f:
           kds_count = sum(1 for _ in f)
       
       # CORTEX: Count conversations in SQLite
       conn = sqlite3.connect(db_path)
       cortex_count = conn.execute(
           'SELECT COUNT(*) FROM conversations'
       ).fetchone()[0]
       
       assert kds_count == cortex_count, "Conversation count mismatch!"
       
       # Validate entities, files, etc.
       ...
   
   def validate_tier2(yaml_path, db_path):
       """Compare pattern counts, relationships"""
       ...
   
   if __name__ == '__main__':
       validate_tier1(...)
       validate_tier2(...)
       print("‚úÖ Migration validation: 100% data parity")
   ```

**Deliverables:**
- ‚úÖ `validate-migration.py`
- ‚úÖ Validation: 100% data parity confirmed

---

#### Task 0.5.4: Rollback Procedure Documentation (30 minutes)

**Goal:** Document how to undo migration if needed

**Document:**
```markdown
# Migration Rollback Procedure

## Scenario 1: Migration Failed (Pre-commit)
1. Delete test-cortex-brain.db
2. Fix migration script
3. Re-run migration
4. Validate again

## Scenario 2: Partial Migration (Mid-phase)
1. Stop migration script (Ctrl+C)
2. Delete cortex-brain.db
3. Restore KDS YAML/JSONL backups
4. Investigate failure
5. Fix script, restart

## Scenario 3: Data Corruption (Post-migration)
1. Restore backup:
   ```bash
   cp backups/cortex-brain-backup.db cortex-brain.db
   ```
2. Verify checksums match
3. Re-run validation
4. If backup also corrupted: Restart from KDS YAML/JSONL

## Scenario 4: Emergency Full Rollback
1. git checkout main (abandon cortex-migration branch)
2. Delete all CORTEX files
3. Verify KDS v8 operational
4. Document failure, create issue
5. Restart migration after fix

## Backup Strategy
- Before Phase 6: Create full backup of KDS YAML/JSONL
- Before migration: Backup cortex-brain.db
- After migration: Create migration-complete backup
- Retention: Keep backups for 30 days
```

**Deliverables:**
- ‚úÖ `MIGRATION-ROLLBACK-GUIDE.md`
- ‚úÖ Backup procedures documented

---

### Phase 0.5 Success Criteria

‚úÖ **Tier 1 migration script** working (tested on 10 conversations)  
‚úÖ **Tier 2 migration script** working (tested on 10 patterns)  
‚úÖ **Tier 3 migration** planned (YAML ‚Üí JSON, simple)  
‚úÖ **Validation script** confirms 100% data parity  
‚úÖ **Rollback guide** documented  
‚úÖ **Migration tools** ready for Phase 6  

**Impact:** Phase 6 reduced from 4-6 hours ‚Üí 2-3 hours (tools already tested)

**‚ö†Ô∏è DO NOT PROCEED TO PHASE 1 UNTIL MIGRATION TOOLS VALIDATED**

---

## üíæ PHASE 1: Working Memory (Enhanced)

**Duration:** 9-11 hours (was 8-10, +1 hour for schema stability)  
**Dependencies:** Phase 0, Phase 0.5 complete

### Changes from Original Plan

**Added:**
1. ‚úÖ **Schema Stability Commitment** - No changes after dashboard built
2. ‚úÖ **Schema Freeze** - Tier 1 schema locked before Phase 2
3. ‚úÖ **Dashboard coordination** - Schema must support future dashboard needs

**Process:**
```yaml
Phase 1 Tasks 1-5: (Original tasks)
  ‚Üí Implement Tier 1 STM
  ‚Üí Write tests (26 total)
  ‚Üí Benchmark performance

Phase 1 Task 6: Schema Stability Review (NEW - 1 hour)
  ‚Üí Review schema with dashboard requirements
  ‚Üí Ensure all dashboard queries supported
  ‚Üí FREEZE schema (no future changes)
  ‚Üí Document schema version 1.0
  ‚Üí Commit schema lock
```

### Schema Stability Protocol

**Before Schema Freeze:**
```python
# Review dashboard requirements
dashboard_queries = [
    'SELECT * FROM conversations ORDER BY created_at DESC LIMIT 20',
    'SELECT * FROM entities WHERE conversation_id = ?',
    'SELECT * FROM files_mentioned WHERE conversation_id = ?',
    # ... all queries dashboard will need
]

# Test all queries work with current schema
for query in dashboard_queries:
    result = conn.execute(query)
    assert result, f"Query failed: {query}"

# FREEZE: No more schema changes
schema_version = 1.0
```

**After Schema Freeze:**
- ‚ùå **No ALTER TABLE allowed** (would break dashboard)
- ‚úÖ **Only add new tables** (if absolutely needed, separate)
- ‚úÖ **Dashboard builds on frozen schema** (Phase 2+)

**Deliverables (Enhanced):**
- ‚úÖ All original deliverables (from phase-1-working-memory.md)
- ‚úÖ **Schema v1.0 finalized** (documented in storage-schema.md)
- ‚úÖ **Dashboard query validation** (all queries tested)
- ‚úÖ **Schema freeze commit** (tagged in git)

---

## üß† PHASE 2: Long-Term Knowledge (Enhanced)

**Duration:** 11-13 hours (was 10-12, +1 hour for FTS5 validation)  
**Dependencies:** Phase 1 complete (schema frozen)

### Changes from Original Plan

**Added:**
1. ‚úÖ **FTS5 Performance Validation** - Real benchmarks with 3000+ patterns
2. ‚úÖ **Contingency if slow** - Fallback plans documented
3. ‚úÖ **Pattern consolidation algorithm** - Tested with real data

**Enhanced Task 2.3: FTS5 Search Performance (was basic, now comprehensive)**

**Steps:**
1. Create realistic test data:
   ```python
   # Generate 3000 patterns (realistic scale)
   for i in range(3000):
       conn.execute("""
           INSERT INTO patterns (pattern_id, name, ...)
       """, (...))
   ```

2. Benchmark FTS5:
   ```python
   # Measure search latency
   queries = [
       'export button',
       'fix navigation bug',
       'add PDF feature',
       # ... 20 common queries
   ]
   
   latencies = []
   for query in queries:
       start = time.time()
       conn.execute("""
           SELECT * FROM patterns
           WHERE pattern_components MATCH ?
           ORDER BY rank
           LIMIT 10
       """, (query,))
       latencies.append(time.time() - start)
   
   p95 = percentile(latencies, 95)
   print(f"FTS5 p95 latency: {p95*1000:.0f}ms")
   ```

3. **DECISION POINT:**
   - ‚úÖ If p95 < 100ms: **PROCEED** (target met)
   - ‚ö†Ô∏è If p95 100-200ms: **OPTIMIZE** (add indexes, tune tokenizer)
   - ‚ùå If p95 > 200ms: **FALLBACK** (use LIKE queries, defer FTS5)

**Contingency Plan (if FTS5 too slow):**
```markdown
Fallback: Basic Text Search
1. Replace FTS5 with LIKE queries:
   ```sql
   SELECT * FROM patterns
   WHERE name LIKE '%' || ? || '%'
   OR pattern_components LIKE '%' || ? || '%'
   ```
2. Slower (200-300ms), but functional
3. Note in documentation: "FTS5 search deferred to v1.1"
4. Still ship Phase 2 (pattern learning works, search basic)
```

**Deliverables (Enhanced):**
- ‚úÖ All original deliverables
- ‚úÖ **FTS5 benchmark results** (p50, p95, p99)
- ‚úÖ **Decision documented** (FTS5 or fallback)
- ‚úÖ **Optimization notes** (if needed)

---

## üìä PHASE 3: Context Intelligence (Original)

**Duration:** 11-13 hours  
**Dependencies:** Phase 2 complete  
**Changes:** None (plan already comprehensive)

See: `phase-3-context-intelligence-updated.md`

---

## ü§ñ PHASE 4: Agents (Original)

**Duration:** 13-17 hours  
**Dependencies:** Phase 0-3 complete  
**Changes:** None (plan already comprehensive)

See: `phase-4-agents.md`

---

## üöÄ PHASE 5: Entry Point (Original)

**Duration:** 7-9 hours  
**Dependencies:** Phase 0-4 complete  
**Changes:** None (plan already comprehensive)

See: `phase-5-entry-point.md`

---

## ‚úÖ PHASE 6: Migration Validation (Simplified)

**Duration:** 5-7 hours (was 4-6, but SIMPLER because tools tested in 0.5)  
**Dependencies:** Phase 0-5 complete, Phase 0.5 tools ready

### Changes from Original Plan

**Simplified (tools already tested):**
- ‚ùå **No tool creation** (done in Phase 0.5)
- ‚ùå **No sample testing** (done in Phase 0.5)
- ‚úÖ **Just run on full data** (migration scripts proven)
- ‚úÖ **Validation faster** (scripts optimized)

**Process:**
```yaml
Phase 6 Task 1: Full Data Migration (2-3 hours)
  ‚Üí Run migrate-tier1-conversations.py (full data)
  ‚Üí Run migrate-tier2-patterns.py (full data)
  ‚Üí Run migrate-tier3-context.py (full data)
  ‚Üí Expected: Smooth (tools tested in Phase 0.5)

Phase 6 Task 2: Validation (1-2 hours)
  ‚Üí Run validate-migration.py
  ‚Üí Compare KDS vs CORTEX queries
  ‚Üí Verify 100% data parity
  ‚Üí Expected: Pass (scripts proven)

Phase 6 Task 3: Integration Tests (2 hours)
  ‚Üí Run 50 integration tests (from original plan)
  ‚Üí Feature parity validation
  ‚Üí Performance comparison
  ‚Üí Expected: All pass

Phase 6 Task 4: Final Review (1 hour)
  ‚Üí Holistic review of entire system
  ‚Üí Go/No-Go decision
  ‚Üí Production deployment approval
```

**Deliverables:**
- ‚úÖ Full migration complete (all tiers)
- ‚úÖ Validation report (100% parity)
- ‚úÖ Integration test results (50/50 passing)
- ‚úÖ Final Go/No-Go decision

---

## üìä Updated Timeline Summary

### Phase Overview

| Phase | Duration | Cumulative | New/Enhanced |
|-------|----------|------------|--------------|
| **Phase -1** | 6-8 hrs | 6-8 hrs | üÜï NEW (validation) |
| **Phase 0** | 6-8 hrs | 12-16 hrs | ‚ö° Enhanced (CI/CD + MkDocs) |
| **Phase 0.5** | 3-4 hrs | 15-20 hrs | üÜï NEW (migration tools) |
| **Phase 1** | 9-11 hrs | 24-31 hrs | ‚ö° Enhanced (schema freeze) |
| **Phase 2** | 11-13 hrs | 35-44 hrs | ‚ö° Enhanced (FTS5 validation) |
| **Phase 3** | 11-13 hrs | 46-57 hrs | Original |
| **Phase 4** | 13-17 hrs | 59-74 hrs | Original |
| **Phase 5** | 7-9 hrs | 66-83 hrs | Original |
| **Phase 6** | 5-7 hrs | 71-90 hrs | ‚ö° Simplified (tools ready) |

**Total: 75-95 hours (9.5-12 days)**

### Comparison with Original Plan

```yaml
Original Plan:
  Phases: 0-6 (6 phases)
  Duration: 61-77 hours (7.5-10 days)
  Risks: Unvalidated assumptions, late failures
  Documentation: Not included

Updated Plan:
  Phases: -1, 0, 0.5, 1-6 (8 phases)
  Duration: 75-95 hours (9.5-12 days)
  Benefits: Early validation, proven migration tools, documentation from day 1
  Documentation: MkDocs integrated in Phase 0
  
Net Change: +14-18 hours upfront
Net Benefit: Prevents 20-40 hours rework later + professional docs
ROI: 1.5-2.5x time savings overall + better maintainability
```

---

## üéØ Critical Success Factors

### Phase -1 (Validation)
- ‚úÖ sql.js performance validated (<100ms or contingency plan)
- ‚úÖ Browser compatibility confirmed (fallback tested)
- ‚úÖ Lock contention acceptable (<10ms with WAL)
- ‚úÖ Dashboard prototype working
- ‚úÖ **GO decision** to proceed

### Phase 0 (Governance + CI/CD)
- ‚úÖ Pre-commit hooks enforcing tests
- ‚úÖ CI/CD passing on GitHub
- ‚úÖ Coverage ‚â•95% (automated)
- ‚úÖ Governance tests passing
- ‚úÖ **MkDocs installed and configured**
- ‚úÖ **Initial documentation built**

### Phase 0.5 (Migration Tools)
- ‚úÖ Migration scripts working (sample data)
- ‚úÖ Validation script confirms 100% parity
- ‚úÖ Rollback procedures documented
- ‚úÖ **Tools ready** for Phase 6

### Phase 1 (Working Memory)
- ‚úÖ Schema frozen (no future changes)
- ‚úÖ Dashboard queries validated
- ‚úÖ Tests passing (26/26)
- ‚úÖ Performance <50ms

### Phase 2 (Knowledge Graph)
- ‚úÖ FTS5 validated (<100ms or fallback)
- ‚úÖ Pattern extraction working
- ‚úÖ Tests passing (34/34)
- ‚úÖ Confidence decay tested

### Phases 3-5 (Original criteria)
- See phase-specific plans

### Phase 6 (Migration)
- ‚úÖ Full data migrated (using Phase 0.5 tools)
- ‚úÖ 100% data parity validated
- ‚úÖ Integration tests passing (50/50)
- ‚úÖ **GO decision** for production

---

## üö® Risk Mitigation Summary

### Risks Addressed

| Risk | Original Plan | Updated Plan | Status |
|------|---------------|--------------|---------|
| sql.js performance | Assumed <100ms | Benchmarked in Phase -1 | ‚úÖ Validated |
| Browser compatibility | Assumed universal | Fallback in Phase -1 | ‚úÖ Mitigated |
| Migration complexity | Phase 6 only | Tools in Phase 0.5 | ‚úÖ Early testing |
| Lock contention | Not analyzed | Phase -1 analysis | ‚úÖ Validated |
| Test enforcement | Manual | CI/CD in Phase 0 | ‚úÖ Automated |
| Schema stability | Not considered | Phase 1 freeze | ‚úÖ Protected |
| FTS5 performance | Assumed <100ms | Phase 2 validation | ‚úÖ Validated |
| Phase dependencies | Rigid | Contingencies added | ‚úÖ Flexible |

---

## üìã Deliverables Checklist

### Documentation
- ‚úÖ Phase -1 validation report
- ‚úÖ Phase 0.5 migration guide
- ‚úÖ Rollback procedures
- ‚úÖ Schema freeze documentation
- ‚úÖ FTS5 benchmark results
- ‚úÖ Final migration report
- ‚úÖ Production deployment guide
- ‚úÖ **MkDocs site (architecture, API, guides)**

### Code
- ‚úÖ Pre-commit hooks
- ‚úÖ CI/CD workflow
- ‚úÖ Migration scripts (Tier 1, 2, 3)
- ‚úÖ Validation scripts
- ‚úÖ Benchmark scripts
- ‚úÖ Dashboard fallback (polling)

### Tests
- ‚úÖ Phase -1: Browser API tests
- ‚úÖ Phase 0: Governance tests (17)
- ‚úÖ Phase 1: STM tests (26)
- ‚úÖ Phase 2: LTM tests (34)
- ‚úÖ Phase 3: Context tests
- ‚úÖ Phase 4: Agent tests (40)
- ‚úÖ Phase 5: Workflow tests (29)
- ‚úÖ Phase 6: Integration tests (50)
- **Total: 196+ tests**

---

## üéØ Next Steps

### Immediate Actions (Today)

1. **Review this plan** - Validate approach with holistic review findings
2. **Approve Phase -1** - Confirm architecture validation is necessary
3. **Schedule work** - 9-12 days focused work (74-93 hours)

### Week 1: Validation & Foundation
- Day 1: Phase -1 (6-8 hrs) - Architecture validation
- Day 2: Phase 0 (6-8 hrs) - Governance + CI/CD + MkDocs
- Day 3: Phase 0.5 (3-4 hrs) + Phase 1 start (3-4 hrs)
- Day 4-5: Phase 1 complete (6-7 hrs remaining)

### Week 2: Core Implementation
- Day 6-7: Phase 2 (11-13 hrs)
- Day 8-9: Phase 3 (11-13 hrs)
- Day 10-12: Phase 4 (13-17 hrs)

### Week 3: Entry Point & Migration
- Day 13-14: Phase 5 (7-9 hrs)
- Day 15: Phase 6 (5-7 hrs)
- Day 16: Buffer (contingency, polish)

---

## ‚úÖ Approval & Sign-Off

**Plan Version:** 2.0 (Holistic Review Integration)  
**Created:** 2025-11-06  
**Status:** üéØ READY FOR APPROVAL  

**Approvals Needed:**
- [ ] **Architecture validation** approach (Phase -1)
- [ ] **Timeline extension** (74-93 hrs vs 61-77 hrs)
- [ ] **Migration tools** early creation (Phase 0.5)
- [ ] **CI/CD integration** in Phase 0
- [ ] **Overall plan** approved

**Once approved, proceed to Phase -1 immediately.**

---

**Created By:** GitHub Copilot  
**Date:** 2025-11-06  
**Incorporates:** HOLISTIC-REVIEW-FINDINGS.md (comprehensive analysis)  
**Status:** ‚úÖ COMPREHENSIVE PLAN COMPLETE  
**Next:** Approval ‚Üí Phase -1 (Architecture Validation)
