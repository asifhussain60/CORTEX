# CORTEX Response Template - Sample Demo
# This demonstrates the template structure and composition system
# Author: Asif Hussain | Â© 2024-2025

version: "2.0"
created: "2025-11-20"
purpose: "Demonstration of template system architecture"

# ============================================================================
# BASE TEMPLATE STRUCTURE (Used by all templates)
# ============================================================================

base_template:
  name: "Base Response Template"
  description: "Foundation template inherited by all response templates"
  structure:
    header:
      format: "ğŸ§  **CORTEX {operation_type}**\nAuthor: Asif Hussain | Â© 2024-2025 | github.com/asifhussain60/CORTEX"
      required: true
      
    understanding:
      format: "ğŸ¯ **My Understanding Of Your Request:**\n   {user_intent_summary}"
      required: true
      max_length: 150
      
    challenge:
      format: "âš ï¸ **Challenge:** {accept_or_challenge}"
      required: true
      options:
        accept: "âœ“ **Accept**\n   {rationale}"
        challenge: "âš¡ **Challenge**\n   {concern}\n   \n   **Alternatives:**\n   {alternatives}"
      
    response:
      format: "ğŸ’¬ **Response:**\n   {natural_language_explanation}"
      required: true
      guidelines:
        - "Explain in natural language"
        - "No code snippets by default"
        - "Professional, measured tone"
        - "Focus on WHAT, not HOW"
        
    request_echo:
      format: "ğŸ“ **Your Request:** {refined_request}"
      required: true
      placement: "Between response and next_steps"
      max_length: 80
      
    next_steps:
      format: "ğŸ” **Next Steps:**\n{context_specific_format}"
      required: true
      formats:
        - numbered_list
        - phases
        - tracks
        - milestones

# ============================================================================
# MIXIN TEMPLATES (Composable components)
# ============================================================================

mixins:
  
  progress_mixin:
    name: "Progress Indicator Mixin"
    description: "Adds progress tracking to templates"
    components:
      phase_indicator:
        format: "â˜ Phase {number}: {name} ({status})"
        statuses: ["not_started", "in_progress", "complete", "blocked"]
        
      progress_bar:
        format: "â–“â–“â–“â–“â–“â–“â–“â–“â–‘â–‘ {percentage}%"
        
      time_estimate:
        format: "â±ï¸ Estimated: {estimate} | Elapsed: {elapsed}"
        
      milestone_status:
        format: "ğŸ¯ Milestone {number}: {name} - {status}"
        
    usage_example: |
      â˜ Phase 1: Discovery & Analysis (in_progress)
      â–“â–“â–“â–“â–‘â–‘â–‘â–‘â–‘â–‘ 40%
      â±ï¸ Estimated: 2 hours | Elapsed: 48 minutes
      
  validation_mixin:
    name: "Validation Gate Mixin"
    description: "Adds validation checklists and gates"
    components:
      checklist:
        format: "â˜ {item} - {status}"
        
      validation_result:
        format: "{emoji} {category}: {message}"
        emojis:
          success: "âœ…"
          warning: "âš ï¸"
          error: "âŒ"
          info: "â„¹ï¸"
          
      remediation:
        format: "**Fix:** {action}\n**Impact:** {impact}"
        
    usage_example: |
      âœ… Requirements: Documented with zero ambiguity
      âš ï¸ Dependencies: 2 external services need validation
      âŒ Security: OWASP checklist incomplete (3/10 items)
      
      **Fix:** Complete A01, A03, A07 security reviews
      **Impact:** Blocks development phase
      
  data_display_mixin:
    name: "Data Display Mixin"
    description: "Adds tables, summaries, and reports"
    components:
      table:
        format: "| {column1} | {column2} | {column3} |\n|----------|----------|----------|"
        
      summary_stats:
        format: "ğŸ“Š **Summary:**\nâ€¢ Total: {total}\nâ€¢ Passed: {passed}\nâ€¢ Failed: {failed}"
        
      file_list:
        format: "ğŸ“ **Files:**\nâ€¢ {file1}\nâ€¢ {file2}"
        
    usage_example: |
      ğŸ“Š **Summary:**
      â€¢ Total Tests: 897
      â€¢ Passed: 834
      â€¢ Failed: 0
      â€¢ Skipped: 63
      â€¢ Pass Rate: 100%
      
  test_metrics_mixin:
    name: "Test Metrics Mixin"
    description: "Adds test execution and coverage metrics"
    components:
      test_results:
        format: "Tests: {passed}/{total} ({pass_rate}%) | Coverage: {coverage}%"
        
      coverage_breakdown:
        format: "**Coverage:**\nâ€¢ Unit: {unit}%\nâ€¢ Integration: {integration}%\nâ€¢ E2E: {e2e}%"
        
      quality_gate:
        format: "{emoji} Quality Gate: {status}\n**Threshold:** {threshold}% | **Actual:** {actual}%"
        
    usage_example: |
      Tests: 834/897 (93.0%) | Coverage: 88.2%
      
      **Coverage:**
      â€¢ Unit: 92%
      â€¢ Integration: 85%
      â€¢ E2E: 78%
      
      âœ… Quality Gate: PASSED
      **Threshold:** 80% | **Actual:** 88.2%

# ============================================================================
# SAMPLE TEMPLATE 1: Feature Implementation Start
# ============================================================================

feature_implementation_start:
  name: "Feature Implementation Start"
  category: "entry_point"
  inherits: ["base_template"]
  uses_mixins: ["progress_mixin", "validation_mixin"]
  
  triggers:
    - "implement {feature}"
    - "start implementing {feature}"
    - "begin feature {feature}"
    - "let's implement {feature}"
    
  placeholders:
    operation_type: "Feature Implementation"
    user_intent_summary: "You want to implement {feature_name} with {approach}"
    accept_or_challenge: "âœ“ **Accept**\n   {feature_name} is well-defined and ready for implementation. Dependencies validated, test strategy defined."
    natural_language_explanation: "I'll implement {feature_name} using TDD approach:\n   \n   **Phase 1: Foundation**\n   â€¢ Create base structure\n   â€¢ Set up tests\n   \n   **Phase 2: Core Logic**\n   â€¢ Implement functionality\n   â€¢ Add validation\n   \n   **Phase 3: Integration**\n   â€¢ Connect to existing systems\n   â€¢ End-to-end testing"
    refined_request: "Implement {feature_name} with TDD approach"
    context_specific_format: "phases"
    
  next_steps_template: |
    â˜ Phase 1: Foundation & Setup (2 hours)
       â€¢ Create module structure in src/{module_path}/
       â€¢ Initialize test suite (tests/test_{module_name}.py)
       â€¢ Set up fixtures and mocks
    
    â˜ Phase 2: Core Implementation (4 hours)
       â€¢ Write failing tests (RED)
       â€¢ Implement functionality (GREEN)
       â€¢ Refactor for quality (REFACTOR)
       â€¢ Achieve 90%+ test coverage
    
    â˜ Phase 3: Integration & Validation (2 hours)
       â€¢ Integration tests with existing systems
       â€¢ Update documentation
       â€¢ Code review and approval
    
    Ready to begin Phase 1?
    
  example_rendered_output: |
    # ğŸ§  CORTEX Feature Implementation
    **Author:** Asif Hussain | Â© 2024-2025 | github.com/asifhussain60/CORTEX
    
    ## ğŸ¯ My Understanding Of Your Request
    You want to implement user authentication with JWT tokens and session management
    
    ## âš ï¸ Challenge: âœ“ Accept
    User authentication is well-defined and ready for implementation. Dependencies validated, test strategy defined.
    
    ## ğŸ’¬ Response
    I'll implement user authentication using TDD approach:
    
    ### Phase 1: Foundation
    - Create base structure
    - Set up tests
    
    ### Phase 2: Core Logic
    - Implement functionality
    - Add validation
    
    ### Phase 3: Integration
    - Connect to existing systems
    - End-to-end testing
    
    ## ğŸ“ Your Request
    Implement user authentication with TDD approach
    
    ## ğŸ” Next Steps
    
    <details>
    <summary><strong>â˜ Phase 1: Foundation & Setup</strong> (2 hours)</summary>
    
    - Create module structure in `src/auth/`
    - Initialize test suite (`tests/test_auth.py`)
    - Set up fixtures and mocks
    </details>
    
    <details>
    <summary><strong>â˜ Phase 2: Core Implementation</strong> (4 hours)</summary>
    
    - Write failing tests (RED)
    - Implement functionality (GREEN)
    - Refactor for quality (REFACTOR)
    - Achieve 90%+ test coverage
    </details>
    
    <details>
    <summary><strong>â˜ Phase 3: Integration & Validation</strong> (2 hours)</summary>
    
    - Integration tests with existing systems
    - Update documentation
    - Code review and approval
    </details>
    
    ---
    
    **Ready to begin Phase 1?**

# ============================================================================
# SAMPLE TEMPLATE 2: Test Execution Results
# ============================================================================

test_execution_results:
  name: "Test Execution Results"
  category: "completion"
  inherits: ["base_template"]
  uses_mixins: ["test_metrics_mixin", "data_display_mixin"]
  
  triggers:
    - "run tests"
    - "execute tests"
    - "test results"
    
  placeholders:
    operation_type: "Test Execution Results"
    user_intent_summary: "You want to see the test execution results and coverage metrics"
    accept_or_challenge: "âœ“ **Accept**\n   Test suite execution complete. All quality gates evaluated."
    natural_language_explanation: "Executed full test suite across {test_count} tests in {execution_time}s. {pass_rate}% pass rate achieved, meeting quality threshold of {threshold}%."
    refined_request: "Show test execution results with coverage metrics"
    context_specific_format: "data_table"
    
  next_steps_template: |
    1. Review failing tests (if any) and address issues
    2. Analyze coverage gaps in low-coverage modules
    3. Run integration tests if unit tests pass
    4. Generate coverage report for PR review
    
  example_rendered_output: |
    # ğŸ§  CORTEX Test Execution Results
    **Author:** Asif Hussain | Â© 2024-2025 | github.com/asifhussain60/CORTEX
    
    ## ğŸ¯ My Understanding Of Your Request
    You want to see the test execution results and coverage metrics
    
    ## âš ï¸ Challenge: âœ“ Accept
    Test suite execution complete. All quality gates evaluated.
    
    ## ğŸ’¬ Response
    Executed full test suite across **897 tests** in **31.89s**. **100% pass rate** achieved, meeting quality threshold of 90%.
    
    ### ğŸ“Š Test Summary
    
    | Metric | Value |
    |--------|-------|
    | **Total Tests** | 897 |
    | **Passed** | 834 (93.0%) |
    | **Skipped** | 63 |
    | **Failed** | 0 |
    | **Pass Rate** | 100% âœ… |
    | **Coverage** | 88.2% |
    | **Execution Time** | 31.89s |
    
    ### ğŸ“ˆ Coverage Breakdown
    
    | Test Type | Coverage | Tests Passed | Tests Total |
    |-----------|----------|--------------|-------------|
    | Unit Tests | 92% ğŸŸ¢ | 682 | 741 |
    | Integration Tests | 85% ğŸŸ¡ | 134 | 158 |
    | E2E Tests | 78% ğŸŸ¡ | 18 | 23 |
    
    <details>
    <summary><strong>âœ… Quality Gate: PASSED</strong></summary>
    
    - **Threshold:** 80%
    - **Actual:** 88.2%
    - **Status:** PASSED (+8.2% above threshold)
    </details>
    
    ### ğŸ“‹ Test Categories
    
    | Category | Total | Passed | Skipped | Pass Rate |
    |----------|-------|--------|---------|-----------|
    | Unit | 741 | 682 | 59 | 100% âœ… |
    | Integration | 158 | 134 | 24 | 100% âœ… |
    | E2E | 23 | 18 | 5 | 100% âœ… |
    | **Total** | **897** | **834** | **63** | **100%** âœ… |
    
    ## ğŸ“ Your Request
    Show test execution results with coverage metrics
    
    ## ğŸ” Next Steps
    
    1. **Review skipped tests** - Determine priority for implementing 63 skipped tests
    2. **Analyze coverage gaps** - Focus on Tier 3 modules (lowest coverage at 78%)
    3. **Run security scan** - Execute OWASP dependency check
    4. **Generate coverage report** - Prepare detailed report for PR review

# ============================================================================
# SAMPLE TEMPLATE 3: Planning DoR Validation
# ============================================================================

planning_dor_validation:
  name: "Planning DoR Validation"
  category: "planning"
  inherits: ["base_template"]
  uses_mixins: ["validation_mixin", "progress_mixin"]
  
  triggers:
    - "validate dor"
    - "check definition of ready"
    - "dor validation"
    
  placeholders:
    operation_type: "Planning - DoR Validation"
    user_intent_summary: "You want to validate that Definition of Ready (DoR) is met before proceeding with implementation"
    accept_or_challenge: "âš¡ **Challenge**\n   DoR validation found {issue_count} issues that must be addressed before development begins."
    natural_language_explanation: "I've validated your planning document against DoR checklist. Found {complete_count}/{total_count} items complete. {issue_count} blocking issues identified that require clarification."
    refined_request: "Validate DoR for {feature_name}"
    context_specific_format: "checklist"
    
  next_steps_template: |
    1. **Address Blocking Issues** - Clarify ambiguous requirements
    2. **Validate Dependencies** - Confirm all referenced files/services exist
    3. **Security Review** - Complete OWASP checklist (3/10 items remain)
    4. **Resubmit for Approval** - Once all items addressed
    
  example_rendered_output: |
    # ğŸ§  CORTEX Planning - DoR Validation
    **Author:** Asif Hussain | Â© 2024-2025 | github.com/asifhussain60/CORTEX
    
    ## ğŸ¯ My Understanding Of Your Request
    You want to validate that Definition of Ready (DoR) is met before proceeding with implementation
    
    ## âš ï¸ Challenge: âš¡ Challenge
    DoR validation found **4 blocking issues** that must be addressed before development begins.
    
    ## ğŸ’¬ Response
    I've validated your planning document against DoR checklist. Found **7/11 items complete**. **4 blocking issues** identified that require clarification.
    
    ### ğŸ“‹ Definition of Ready Checklist
    
    | # | Item | Status | Notes |
    |---|------|--------|-------|
    | 1 | Requirements | âœ… Pass | Documented with zero ambiguity |
    | 2 | Technical Design | âœ… Pass | Architecture approved |
    | 3 | Test Strategy | âœ… Pass | Defined with coverage targets |
    | 4 | Dependencies | âš ï¸ Warning | 2 external services need validation |
    | 5 | Security Review | âŒ Fail | OWASP checklist incomplete (3/10 items) |
    | 6 | Acceptance Criteria | âœ… Pass | Measurable and testable |
    | 7 | Ambiguity Check | âŒ Fail | 3 vague terms detected (see below) |
    | 8 | User Approval | âœ… Pass | Scope confirmed by stakeholder |
    | 9 | Resource Availability | âŒ Fail | Database schema migration pending |
    | 10 | Documentation Plan | âœ… Pass | Templates prepared |
    | 11 | Deployment Strategy | âœ… Pass | CI/CD pipeline configured |
    
    **Overall Status:** âŒ **NOT READY** (7/11 complete, 4 blockers)
    
    ---
    
    ### ğŸš« Ambiguities Detected (Line-Level Feedback)
    
    <details>
    <summary><strong>âŒ Line 15: "improve performance"</strong></summary>
    
    **Issue:** VAGUE TERM - "improve"
    
    **Challenge:** Improve by how much? What specific metric?
    
    **Fix:** Define target metric
    ```
    âŒ Before: "improve performance"
    âœ… After: "Reduce API response time from 500ms to <100ms"
    ```
    
    **Impact:** Cannot write measurable acceptance criteria without specific target
    </details>
    
    <details>
    <summary><strong>âŒ Line 23: "the system will handle user requests"</strong></summary>
    
    **Issue:** UNDEFINED - "the system"
    
    **Challenge:** Which system specifically? Which component/service?
    
    **Fix:** Be explicit about the component
    ```
    âŒ Before: "the system will handle user requests"
    âœ… After: "The authentication service (AuthService.cs) will handle user login requests"
    ```
    
    **Impact:** Ambiguous ownership and scope
    </details>
    
    <details>
    <summary><strong>âŒ Line 31: "optimize database queries"</strong></summary>
    
    **Issue:** VAGUE TERM - "optimize"
    
    **Challenge:** Optimize what specifically? What's the target?
    
    **Fix:** Define measurable goal
    ```
    âŒ Before: "optimize database queries"
    âœ… After: "Reduce query execution time from 500ms to <100ms"
    ```
    
    **Impact:** Cannot validate success without specific metric
    </details>
    
    ## ğŸ“ Your Request
    Validate DoR for user authentication feature
    
    ## ğŸ” Next Steps
    
    ### ğŸ”´ Critical Path (Must Complete)
    
    1. **Address Blocking Issues** â±ï¸ 1 hour
       - Clarify 3 vague terms (see line-level feedback above)
       - Replace ambiguous language with specific, measurable terms
    
    2. **Validate Dependencies** â±ï¸ 30 minutes
       - Confirm `UserService.cs` exists and is accessible
       - Verify `AuthDatabase` connection and schema
    
    3. **Complete Security Review** â±ï¸ 2 hours
       - OWASP A01: Broken Access Control
       - OWASP A03: Injection
       - OWASP A07: Identification & Authentication Failures
    
    4. **Resource Validation** â±ï¸ 1 hour
       - Verify database migration script ready
       - Test migration in development environment
    
    5. **Resubmit for Approval**
       - Once all 11/11 items complete
       - All ambiguities resolved
    
    > âš ï¸ **GATE ENFORCEMENT:** I will not proceed until DoR is met with zero ambiguity.

# ============================================================================
# REUSABILITY METRICS
# ============================================================================

reusability_analysis:
  base_template_usage: "100% (all templates inherit)"
  
  mixin_usage:
    progress_mixin: "60% (entry_point, progress, completion templates)"
    validation_mixin: "40% (planning, testing, quality templates)"
    data_display_mixin: "30% (results, reports, status templates)"
    test_metrics_mixin: "25% (testing, quality, completion templates)"
    
  unique_content_per_template: "~30%"
  shared_content_per_template: "~70%"
  
  token_optimization:
    base_template: 250
    mixins_average: 150
    unique_per_template: 150
    effective_per_template: 450
    without_reusability: 1500
    reduction_percentage: 70
    
  composition_example: |
    feature_implementation_start template breakdown:
    â€¢ base_template: 250 tokens (shared)
    â€¢ progress_mixin: 120 tokens (shared)
    â€¢ validation_mixin: 130 tokens (shared)
    â€¢ unique content: 150 tokens (specific to this template)
    â€¢ Total: 650 tokens (450 effective with caching)

# ============================================================================
# TEMPLATE COMPOSITION PATTERNS
# ============================================================================

composition_patterns:
  
  pattern_1_simple_response:
    name: "Simple Response (No mixins)"
    inherits: ["base_template"]
    uses_mixins: []
    use_cases: ["quick questions", "status checks", "simple confirmations"]
    token_cost: 400
    
  pattern_2_progress_tracking:
    name: "Progress Tracking Response"
    inherits: ["base_template"]
    uses_mixins: ["progress_mixin"]
    use_cases: ["multi-step operations", "long-running tasks"]
    token_cost: 550
    
  pattern_3_validation_gate:
    name: "Validation Gate Response"
    inherits: ["base_template"]
    uses_mixins: ["validation_mixin"]
    use_cases: ["DoR/DoD checks", "quality gates", "security reviews"]
    token_cost: 580
    
  pattern_4_test_results:
    name: "Test Results Response"
    inherits: ["base_template"]
    uses_mixins: ["test_metrics_mixin", "data_display_mixin"]
    use_cases: ["test execution", "coverage reports", "quality metrics"]
    token_cost: 650
    
  pattern_5_comprehensive:
    name: "Comprehensive Response"
    inherits: ["base_template"]
    uses_mixins: ["progress_mixin", "validation_mixin", "data_display_mixin"]
    use_cases: ["complex operations", "planning with execution", "full lifecycle"]
    token_cost: 800

# ============================================================================
# IMPLEMENTATION NOTES
# ============================================================================

implementation:
  template_loader:
    strategy: "lazy_load"
    caching: true
    cache_ttl: 3600
    
  placeholder_substitution:
    engine: "jinja2"
    escaping: "markdown"
    validation: "strict"
    
  mixin_composition:
    strategy: "merge"
    priority: "base_template > mixins > unique"
    conflict_resolution: "unique_wins"
    
  performance_targets:
    load_time: "< 50ms"
    render_time: "< 100ms"
    cache_hit_rate: "> 90%"
    
  quality_gates:
    required_fields: ["name", "category", "inherits", "triggers"]
    max_token_count: 1000
    min_reusability: 50

# ============================================================================
# USAGE EXAMPLES
# ============================================================================

usage_examples:
  
  example_1_feature_start:
    user_request: "implement user authentication"
    template_triggered: "feature_implementation_start"
    placeholders_filled:
      feature_name: "user authentication"
      approach: "JWT tokens and session management"
      module_path: "auth"
      module_name: "authentication"
    rendering_time: "87ms"
    token_count: 612
    
  example_2_test_results:
    user_request: "show me test results"
    template_triggered: "test_execution_results"
    placeholders_filled:
      test_count: 897
      execution_time: "31.89"
      pass_rate: "100"
      threshold: "90"
    rendering_time: "94ms"
    token_count: 743
    
  example_3_dor_validation:
    user_request: "validate DoR for authentication feature"
    template_triggered: "planning_dor_validation"
    placeholders_filled:
      feature_name: "user authentication"
      issue_count: 4
      complete_count: 7
      total_count: 11
    rendering_time: "103ms"
    token_count: 891

# ============================================================================
# FUTURE ENHANCEMENTS
# ============================================================================

roadmap:
  version_2_1:
    - "Dynamic mixin selection based on context"
    - "Template analytics and usage tracking"
    - "A/B testing framework for template variations"
    
  version_2_2:
    - "User-customizable templates"
    - "Template versioning and rollback"
    - "Multi-language support"
    
  version_3_0:
    - "AI-powered template suggestions"
    - "Adaptive templates based on user feedback"
    - "Template marketplace for sharing"
