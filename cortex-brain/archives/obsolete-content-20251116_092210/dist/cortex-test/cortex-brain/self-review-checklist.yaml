# ============================================================================
# CORTEX Self-Review Comprehensive Checklist
# ============================================================================
#
# This YAML defines a comprehensive self-review operation that validates:
# - All brain protection layers have complete test coverage
# - All protection rules are tested
# - Standard coding practices are followed
# - Architecture integrity is maintained
# - Documentation is up to date
#
# Version: 1.0
# Created: 2025-11-09
# Author: CORTEX Team
# ============================================================================

version: "1.0"
type: "validation"
name: "Comprehensive Self-Review Checklist"
description: "Automated comprehensive validation of CORTEX integrity and quality"

# ============================================================================
# BRAIN PROTECTION TEST COVERAGE
# ============================================================================
brain_protection_coverage:
  name: "Brain Protection Test Coverage"
  priority: 1  # HIGHEST PRIORITY
  description: "Ensure ALL brain protection layers have comprehensive test coverage"
  
  required_test_count: 118  # Current count from pytest collection
  minimum_pass_rate: 100  # 100% pass rate is MANDATORY
  
  layers:
    # ------------------------------------------------------------------------
    # Layer 1: Instinct Immutability
    # ------------------------------------------------------------------------
    layer1_instinct_immutability:
      name: "Layer 1: Instinct Immutability"
      description: "Tier 0 governance rules cannot be bypassed"
      test_file: "tests/tier0/test_brain_protector.py"
      
      rules_to_test:
        - rule_id: "TDD_ENFORCEMENT"
          test_names:
            - "test_blocks_code_without_tests"
            - "test_allows_test_first_development"
            - "test_detects_tdd_bypass_keywords"
            - "test_provides_tdd_alternatives"
          min_test_count: 4
          status: "required"
        
        - rule_id: "DEFINITION_OF_DONE"
          test_names:
            - "test_blocks_work_with_warnings"
            - "test_blocks_work_with_errors"
            - "test_allows_clean_completion"
            - "test_validates_dod_criteria"
          min_test_count: 4
          status: "required"
        
        - rule_id: "DEFINITION_OF_READY"
          test_names:
            - "test_blocks_work_without_requirements"
            - "test_validates_dor_criteria"
            - "test_requires_acceptance_criteria"
          min_test_count: 3
          status: "required"
        
        - rule_id: "BRAIN_PROTECTION_TESTS_MANDATORY"
          test_names:
            - "test_blocks_skip_brain_tests"
            - "test_requires_100_percent_pass_rate"
            - "test_detects_brain_test_bypass"
            - "test_brain_test_failure_blocks_work"
          min_test_count: 4
          status: "required"
        
        - rule_id: "MACHINE_READABLE_FORMATS"
          test_names:
            - "test_warns_markdown_for_structured_data"
            - "test_suggests_yaml_for_config"
            - "test_suggests_json_for_metrics"
            - "test_allows_markdown_for_narratives"
          min_test_count: 4
          status: "required"
        
        - rule_id: "ACTIVE_NARRATOR_VOICE"
          test_names:
            - "test_detects_passive_verbs"
            - "test_detects_documentary_markers"
            - "test_suggests_active_alternatives"
            - "test_preserves_third_person"
          min_test_count: 4
          status: "required"
          test_file: "tests/tier0/test_active_narrator_voice.py"
      
      total_required_tests: 23
      validation_command: "pytest tests/tier0/test_brain_protector.py tests/tier0/test_active_narrator_voice.py -v"
    
    # ------------------------------------------------------------------------
    # Layer 2: Tier Boundary Protection
    # ------------------------------------------------------------------------
    layer2_tier_boundary:
      name: "Layer 2: Tier Boundary Protection"
      description: "Data stored in correct tier"
      test_file: "tests/tier0/test_brain_protector.py"
      
      rules_to_test:
        - rule_id: "TIER0_APPLICATION_DATA"
          test_names:
            - "test_blocks_application_data_in_tier0"
            - "test_detects_app_specific_paths"
            - "test_suggests_tier2_for_app_data"
          min_test_count: 3
          status: "required"
        
        - rule_id: "TIER2_CONVERSATION_DATA"
          test_names:
            - "test_warns_conversation_in_tier2"
            - "test_suggests_tier1_for_conversations"
            - "test_allows_patterns_in_tier2"
          min_test_count: 3
          status: "required"
      
      total_required_tests: 6
      validation_command: "pytest tests/tier0/test_brain_protector.py::TestTierBoundary -v"
    
    # ------------------------------------------------------------------------
    # Layer 3: SOLID Compliance
    # ------------------------------------------------------------------------
    layer3_solid_compliance:
      name: "Layer 3: SOLID Compliance"
      description: "No God Objects, proper separation"
      test_file: "tests/tier0/test_brain_protector.py"
      
      rules_to_test:
        - rule_id: "SINGLE_RESPONSIBILITY"
          test_names:
            - "test_warns_god_object_pattern"
            - "test_detects_multiple_responsibilities"
            - "test_suggests_dedicated_agent"
          min_test_count: 3
          status: "required"
        
        - rule_id: "DEPENDENCY_INVERSION"
          test_names:
            - "test_warns_hardcoded_dependency"
            - "test_suggests_dependency_injection"
            - "test_detects_fixed_paths"
          min_test_count: 3
          status: "required"
        
        - rule_id: "OPEN_CLOSED"
          test_names:
            - "test_warns_modifying_behavior"
            - "test_suggests_extension_pattern"
            - "test_detects_alteration_keywords"
          min_test_count: 3
          status: "required"
      
      total_required_tests: 9
      validation_command: "pytest tests/tier0/test_brain_protector.py::TestSOLIDCompliance -v"
    
    # ------------------------------------------------------------------------
    # Layer 4: Hemisphere Specialization
    # ------------------------------------------------------------------------
    layer4_hemisphere_specialization:
      name: "Layer 4: Hemisphere Specialization"
      description: "Strategic vs tactical separation"
      test_file: "tests/tier0/test_brain_protector.py"
      
      rules_to_test:
        - rule_id: "LEFT_BRAIN_TACTICAL"
          test_names:
            - "test_warns_planning_in_executor"
            - "test_detects_strategy_keywords"
            - "test_suggests_work_planner_delegation"
          min_test_count: 3
          status: "required"
        
        - rule_id: "RIGHT_BRAIN_STRATEGIC"
          test_names:
            - "test_warns_execution_in_planner"
            - "test_detects_implementation_keywords"
            - "test_suggests_left_brain_delegation"
          min_test_count: 3
          status: "required"
      
      total_required_tests: 6
      validation_command: "pytest tests/tier0/test_brain_protector.py::TestHemisphereSpecialization -v"
    
    # ------------------------------------------------------------------------
    # Layer 5: Knowledge Quality
    # ------------------------------------------------------------------------
    layer5_knowledge_quality:
      name: "Layer 5: Knowledge Quality"
      description: "Pattern validation and confidence thresholds"
      test_file: "tests/tier0/test_brain_protector.py"
      
      rules_to_test:
        - rule_id: "MIN_OCCURRENCES"
          test_names:
            - "test_warns_high_confidence_single_event"
            - "test_requires_three_occurrences"
            - "test_allows_low_confidence_provisional"
          min_test_count: 3
          status: "required"
        
        - rule_id: "PATTERN_VALIDATION"
          test_names:
            - "test_warns_unvalidated_pattern"
            - "test_requires_validation_evidence"
            - "test_allows_hypothesis_marking"
          min_test_count: 3
          status: "required"
      
      total_required_tests: 6
      validation_command: "pytest tests/tier0/test_brain_protector.py::TestKnowledgeQuality -v"
    
    # ------------------------------------------------------------------------
    # Layer 6: Commit Integrity
    # ------------------------------------------------------------------------
    layer6_commit_integrity:
      name: "Layer 6: Commit Integrity"
      description: "Brain state files excluded from commits"
      test_file: "tests/tier0/test_brain_protector.py"
      
      rules_to_test:
        - rule_id: "BRAIN_STATE_GITIGNORE"
          test_names:
            - "test_warns_brain_state_commit"
            - "test_detects_conversation_history"
            - "test_suggests_gitignore"
          min_test_count: 3
          status: "required"
        
        - rule_id: "TEMP_FILES_COMMIT"
          test_names:
            - "test_warns_temp_file_commit"
            - "test_detects_cache_directories"
            - "test_suggests_cleanup"
          min_test_count: 3
          status: "required"
      
      total_required_tests: 6
      validation_command: "pytest tests/tier0/test_brain_protector.py::TestCommitIntegrity -v"
    
    # ------------------------------------------------------------------------
    # Integration Tests
    # ------------------------------------------------------------------------
    integration_tests:
      name: "Brain Protection Integration Tests"
      description: "End-to-end brain protection workflows"
      test_file: "tests/tier0/test_brain_protector_conversation_tracking.py"
      
      test_categories:
        - category: "Conversation Tracking Integration"
          test_names:
            - "test_conversation_tracking_integration"
            - "test_conversation_memory_persistence"
            - "test_cross_session_memory"
          min_test_count: 3
        
        - category: "New Protection Rules"
          test_file: "tests/tier0/test_brain_protector_new_rules.py"
          test_names:
            - "test_new_rule_detection"
            - "test_new_rule_enforcement"
            - "test_new_rule_alternatives"
          min_test_count: 3
        
        - category: "FIFO Enforcement"
          test_file: "tests/tier0/test_fifo_enforcement.py"
          test_names:
            - "test_fifo_order_maintained"
            - "test_oldest_removed_first"
            - "test_capacity_enforcement"
          min_test_count: 3
        
        - category: "Governance Integration"
          test_file: "tests/tier0/test_governance.py"
          test_names:
            - "test_governance_rule_loading"
            - "test_governance_violation_detection"
            - "test_governance_enforcement"
          min_test_count: 3
      
      total_required_tests: 12
      validation_command: "pytest tests/tier0/ -v"
  
  summary:
    total_layers: 6
    total_rules: 16
    total_required_tests: 68
    current_test_count: 118
    coverage_percentage: 174  # 118/68 = 173.5% (exceeds requirements)
    status: "excellent"

# ============================================================================
# STANDARD CODING PRACTICES
# ============================================================================
standard_practices:
  name: "Standard Coding Practices"
  priority: 2
  description: "Ensure standard coding practices are followed"
  
  checks:
    # ------------------------------------------------------------------------
    # Test-Driven Development
    # ------------------------------------------------------------------------
    - check_id: "TDD_COMPLIANCE"
      name: "Test-Driven Development Compliance"
      severity: "critical"
      description: "All code must follow RED → GREEN → REFACTOR pattern"
      
      validation:
        - criterion: "Tests written before implementation"
          command: "git log --all --oneline --no-merges | grep -E '(test|spec)' | wc -l"
          expected: ">0"
        
        - criterion: "Test pass rate is 100%"
          command: "pytest tests/ --tb=no -q"
          expected: "100% pass rate"
        
        - criterion: "No skipped tests without justification"
          command: "pytest tests/ --tb=no -v | grep -i skip"
          expected: "All skips documented"
      
      alternatives:
        - "Write failing test first"
        - "Use pytest-watch for continuous testing"
        - "Document skip reasons with issue numbers"
    
    # ------------------------------------------------------------------------
    # SOLID Principles
    # ------------------------------------------------------------------------
    - check_id: "SOLID_PRINCIPLES"
      name: "SOLID Principles Adherence"
      severity: "high"
      description: "Code follows SOLID design principles"
      
      validation:
        - criterion: "Single Responsibility - files <500 lines"
          command: "find src/ -name '*.py' -exec wc -l {} \\; | awk '$1 > 500 {print $2}'"
          expected: "Empty output"
        
        - criterion: "Dependency Inversion - no hardcoded paths"
          command: "grep -r 'D:\\\\PROJECTS\\\\CORTEX' src/ || true"
          expected: "No hardcoded paths found"
        
        - criterion: "Open/Closed - extension via inheritance"
          command: "grep -r 'class.*\\(Base' src/ | wc -l"
          expected: ">10"
      
      alternatives:
        - "Break large files into modules <500 lines"
        - "Use dependency injection via constructors"
        - "Prefer composition and inheritance over modification"
    
    # ------------------------------------------------------------------------
    # Code Quality
    # ------------------------------------------------------------------------
    - check_id: "CODE_QUALITY"
      name: "Code Quality Standards"
      severity: "medium"
      description: "Code meets quality standards"
      
      validation:
        - criterion: "No TODO comments without tickets"
          command: "grep -r 'TODO' src/ | grep -v '#' | wc -l"
          expected: "0"
        
        - criterion: "All functions have docstrings"
          command: "python -c \"import ast; import sys; files=[f for f in sys.argv[1:] if f.endswith('.py')]; [print(f, 'missing docstring') for f in files if any(not ast.get_docstring(node) for node in ast.walk(ast.parse(open(f).read())) if isinstance(node, ast.FunctionDef) and not node.name.startswith('_'))]\""
          expected: "Empty output"
        
        - criterion: "No print() statements in production code"
          command: "grep -r 'print(' src/ --include='*.py' | grep -v test | grep -v '#' | wc -l"
          expected: "0"
      
      alternatives:
        - "Convert TODOs to GitHub issues"
        - "Add docstrings to all public functions"
        - "Use logging instead of print()"
    
    # ------------------------------------------------------------------------
    # Documentation
    # ------------------------------------------------------------------------
    - check_id: "DOCUMENTATION_COMPLETENESS"
      name: "Documentation Completeness"
      severity: "medium"
      description: "All features are documented"
      
      validation:
        - criterion: "README.md is up to date"
          command: "git log -1 --format=%ci README.md"
          expected: "Recent update (within 30 days)"
        
        - criterion: "All modules have design docs"
          command: "ls docs/design/*.md | wc -l"
          expected: ">30"
        
        - criterion: "API reference exists"
          command: "test -f docs/api/index.md && echo 'exists' || echo 'missing'"
          expected: "exists"
      
      alternatives:
        - "Update README with recent changes"
        - "Create design doc for new modules"
        - "Generate API docs from docstrings"
    
    # ------------------------------------------------------------------------
    # Version Control
    # ------------------------------------------------------------------------
    - check_id: "VERSION_CONTROL_HYGIENE"
      name: "Version Control Hygiene"
      severity: "medium"
      description: "Git repository is clean and well-maintained"
      
      validation:
        - criterion: "No uncommitted changes"
          command: "git status --porcelain | wc -l"
          expected: "0 or documented"
        
        - criterion: ".gitignore is complete"
          command: "test -f .gitignore && cat .gitignore | wc -l"
          expected: ">20"
        
        - criterion: "Commit messages are descriptive"
          command: "git log --oneline -10 | awk '{print $2}' | wc -w"
          expected: ">20"
      
      alternatives:
        - "Commit work in progress with WIP prefix"
        - "Update .gitignore for temp files"
        - "Write descriptive commit messages (50 char summary)"

# ============================================================================
# ARCHITECTURE INTEGRITY
# ============================================================================
architecture_integrity:
  name: "Architecture Integrity"
  priority: 3
  description: "Validate CORTEX architectural patterns"
  
  checks:
    # ------------------------------------------------------------------------
    # 4-Tier Brain Architecture
    # ------------------------------------------------------------------------
    - check_id: "TIER_ARCHITECTURE"
      name: "4-Tier Brain Architecture"
      severity: "critical"
      description: "Tier 0-3 boundaries are respected"
      
      validation:
        - criterion: "Tier 0 is immutable (YAML only)"
          command: "test -f cortex-brain/brain-protection-rules.yaml && echo 'exists' || echo 'missing'"
          expected: "exists"
        
        - criterion: "Tier 1 uses SQLite"
          command: "test -f cortex-brain/tier1/conversation-history.jsonl && echo 'exists' || echo 'missing'"
          expected: "exists"
        
        - criterion: "Tier 2 uses YAML"
          command: "test -f cortex-brain/knowledge-graph.yaml && echo 'exists' || echo 'missing'"
          expected: "exists"
        
        - criterion: "Tier 3 uses Python scripts"
          command: "ls src/tier3/*.py | wc -l"
          expected: ">5"
      
      alternatives:
        - "Keep Tier 0 rules in YAML only"
        - "Use Tier 1 for conversation history (FIFO)"
        - "Use Tier 2 for patterns (accumulated knowledge)"
        - "Use Tier 3 for context generation scripts"
    
    # ------------------------------------------------------------------------
    # Dual-Hemisphere Agent System
    # ------------------------------------------------------------------------
    - check_id: "AGENT_SYSTEM"
      name: "Dual-Hemisphere Agent System"
      severity: "high"
      description: "10 agents maintain specialization"
      
      validation:
        - criterion: "5 LEFT brain agents exist"
          command: "ls src/cortex_agents/left_brain/*.py | wc -l"
          expected: "5"
        
        - criterion: "5 RIGHT brain agents exist"
          command: "ls src/cortex_agents/right_brain/*.py | wc -l"
          expected: "5"
        
        - criterion: "Corpus callosum coordinates"
          command: "test -d src/cortex_agents/corpus_callosum && echo 'exists' || echo 'missing'"
          expected: "exists"
      
      alternatives:
        - "Ensure LEFT brain is tactical (execute)"
        - "Ensure RIGHT brain is strategic (plan)"
        - "Use corpus callosum for coordination"
    
    # ------------------------------------------------------------------------
    # Plugin Architecture
    # ------------------------------------------------------------------------
    - check_id: "PLUGIN_ARCHITECTURE"
      name: "Plugin Architecture"
      severity: "medium"
      description: "Plugin system is extensible"
      
      validation:
        - criterion: "BasePlugin interface exists"
          command: "test -f src/plugins/base_plugin.py && echo 'exists' || echo 'missing'"
          expected: "exists"
        
        - criterion: "Command registry exists"
          command: "test -f src/plugins/command_registry.py && echo 'exists' || echo 'missing'"
          expected: "exists"
        
        - criterion: "Plugins are discoverable"
          command: "ls src/plugins/*_plugin.py | wc -l"
          expected: ">3"
      
      alternatives:
        - "All plugins inherit from BasePlugin"
        - "Register commands via command_registry"
        - "Use plugin discovery pattern"

# ============================================================================
# MACHINE-SPECIFIC TRACKING
# ============================================================================
machine_tracking:
  name: "Machine-Specific Work Tracking"
  priority: 4
  description: "Validate machine-aware task tracking"
  
  checks:
    - check_id: "MACHINE_CONFIG"
      name: "Machine Configuration"
      severity: "medium"
      description: "Both machines configured in cortex.config.json"
      
      validation:
        - criterion: "Windows machine configured"
          command: "grep -q 'AHHOME' cortex.config.json && echo 'exists' || echo 'missing'"
          expected: "exists"
        
        - criterion: "Mac machine configured"
          command: "grep -q 'Asifs-MacBook-Pro.local' cortex.config.json && echo 'exists' || echo 'missing'"
          expected: "exists"
        
        - criterion: "Machine-specific paths set"
          command: "jq '.machines | length' cortex.config.json"
          expected: ">=2"
      
      alternatives:
        - "Add machine hostname to cortex.config.json"
        - "Set rootPath and brainPath for each machine"
        - "Use platform detection for auto-config"
    
    - check_id: "MACHINE_WORK_PLAN"
      name: "Machine-Specific Work Plan"
      severity: "medium"
      description: "Machine work assignments documented"
      
      validation:
        - criterion: "Machine work plan exists"
          command: "test -f cortex-brain/cortex-2.0-design/MACHINE-SPECIFIC-WORK-PLAN.md && echo 'exists' || echo 'missing'"
          expected: "exists"
        
        - criterion: "Parallel work visual exists"
          command: "test -f cortex-brain/cortex-2.0-design/PARALLEL-WORK-VISUAL.md && echo 'exists' || echo 'missing'"
          expected: "exists"
        
        - criterion: "STATUS.md has machine sections"
          command: "grep -q 'Machine 1.*Windows' cortex-brain/cortex-2.0-design/STATUS.md && echo 'exists' || echo 'missing'"
          expected: "exists"
      
      alternatives:
        - "Create machine-specific work assignments"
        - "Document parallel work strategy"
        - "Add machine detection to 'continue' command"

# ============================================================================
# COMPREHENSIVE SELF-REVIEW REPORT
# ============================================================================
report_generation:
  name: "Self-Review Report Generation"
  description: "Generate comprehensive self-review report"
  
  report_sections:
    - section: "Executive Summary"
      content:
        - "Overall health score"
        - "Critical issues count"
        - "High priority issues count"
        - "Recommendations summary"
    
    - section: "Brain Protection Coverage"
      content:
        - "Layer-by-layer test count"
        - "Missing tests identification"
        - "Pass rate per layer"
        - "Integration test results"
    
    - section: "Standard Practices Compliance"
      content:
        - "TDD compliance score"
        - "SOLID principles adherence"
        - "Code quality metrics"
        - "Documentation completeness"
    
    - section: "Architecture Integrity"
      content:
        - "Tier boundary validation"
        - "Agent system specialization"
        - "Plugin architecture health"
    
    - section: "Machine-Specific Tracking"
      content:
        - "Machine configuration status"
        - "Work plan completeness"
        - "Parallel work setup"
    
    - section: "Recommendations"
      content:
        - "High priority actions"
        - "Medium priority improvements"
        - "Long-term enhancements"
  
  report_format: "markdown"
  report_location: "cortex-brain/SELF-REVIEW-REPORT.md"
  report_frequency: "weekly"
  report_triggers:
    - "Before major milestone"
    - "After significant changes"
    - "Before production deployment"
    - "On demand via /CORTEX, run self-review"

# ============================================================================
# VALIDATION COMMAND
# ============================================================================
validation:
  run_command: "python scripts/cortex/comprehensive_self_review.py"
  report_output: "cortex-brain/SELF-REVIEW-REPORT.md"
  exit_on_critical: true
  exit_on_high: false
  
  thresholds:
    critical_failures: 0  # No critical failures allowed
    high_failures: 3  # Max 3 high priority failures
    medium_failures: 10  # Max 10 medium priority failures
    
    test_pass_rate: 100  # 100% required
    brain_protection_coverage: 90  # 90% minimum coverage
    code_quality_score: 80  # 80% minimum quality

# ============================================================================
# METADATA
# ============================================================================
metadata:
  version: "1.0"
  created: "2025-11-09"
  author: "CORTEX Team"
  description: "Comprehensive self-review checklist for CORTEX validation"
  last_updated: "2025-11-09"
  
  statistics:
    total_checks: 15
    critical_checks: 3
    high_priority_checks: 4
    medium_priority_checks: 8
    total_brain_protection_tests: 118
    required_brain_protection_tests: 68
    coverage_percentage: 174
