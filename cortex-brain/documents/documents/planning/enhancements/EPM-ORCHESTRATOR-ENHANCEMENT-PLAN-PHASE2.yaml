# EPM Orchestrator Enhancement Plan - Phase 2: Implementation Specifications
# Version: 1.0.0
# Created: 2025-11-26
# Author: Asif Hussain
# Status: ACTIVE

metadata:
  phase: 2
  title: "Implementation Specifications"
  prerequisites: ["Phase 1 complete"]
  estimated_duration: "4-6 hours implementation"

track_a_code_quality_enforcement:
  priority: "HIGHEST"
  
  component_1_code_cleanup_validator:
    file: "src/workflows/code_cleanup_validator.py"
    class_name: "CodeCleanupValidator"
    responsibility: "Scan code for debug artifacts and production anti-patterns"
    
    interface:
      methods:
        scan_file:
          signature: "def scan_file(self, file_path: Path) -> List[CleanupIssue]"
          description: "Scan single file for cleanup issues"
          returns: "List of cleanup issues found"
        
        scan_directory:
          signature: "def scan_directory(self, dir_path: Path, recursive: bool = True) -> Dict[Path, List[CleanupIssue]]"
          description: "Scan directory for cleanup issues"
          returns: "Dictionary mapping file paths to their issues"
        
        validate_production_ready:
          signature: "def validate_production_ready(self, files: List[Path]) -> Tuple[bool, List[str]]"
          description: "Validate all files are production ready"
          returns: "Tuple of (is_ready, blocking_issues)"
    
    detection_patterns:
      debug_statements:
        - "print("
        - "console.log("
        - "Console.WriteLine("
        - "logger.debug("
        - "debugger;"
        - "import pdb; pdb.set_trace()"
      
      temporary_code:
        - "# TODO:"
        - "# FIXME:"
        - "# HACK:"
        - "# XXX:"
        - "throw new NotImplementedException"
      
      commented_code:
        pattern: "Lines with 80%+ commented code"
        threshold: 0.8
      
      hardcoded_values:
        - "localhost"
        - "127.0.0.1"
        - "http://example.com"
        - "password = "
        - "api_key = "
    
    exemptions:
      files:
        - "**/*test*.py"
        - "**/*Test*.cs"
        - "**/*.spec.ts"
        - "**/debug_*.py"
      
      markers:
        - "# PRODUCTION_SAFE: [reason]"
        - "// PRODUCTION_SAFE: [reason]"
  
  component_2_lint_integration_wrapper:
    file: "src/workflows/lint_integration.py"
    class_name: "LintIntegration"
    responsibility: "Execute lint validation and parse results"
    
    interface:
      methods:
        run_lint:
          signature: "def run_lint(self, file_path: Path, config: Optional[Dict] = None) -> LintResult"
          description: "Run linter on file"
          returns: "LintResult with violations"
        
        run_lint_directory:
          signature: "def run_lint_directory(self, dir_path: Path) -> Dict[Path, LintResult]"
          description: "Run linter on directory"
          returns: "Dictionary of file paths to lint results"
        
        get_blocking_violations:
          signature: "def get_blocking_violations(self, results: Dict[Path, LintResult]) -> List[Violation]"
          description: "Filter violations that block production"
          returns: "List of CRITICAL/HIGH severity violations"
    
    supported_linters:
      python:
        tool: "pylint"
        config_file: ".pylintrc"
        blocking_severities: ["error", "fatal"]
      
      csharp:
        tool: "dotnet format"
        config_file: ".editorconfig"
        blocking_severities: ["error"]
      
      typescript:
        tool: "eslint"
        config_file: ".eslintrc.json"
        blocking_severities: ["error"]
    
    result_format:
      class: "LintResult"
      fields:
        file_path: "Path"
        violations: "List[Violation]"
        total_violations: "int"
        blocking_violations: "int"
        passed: "bool"
  
  component_3_production_readiness_checklist:
    file: "src/workflows/production_readiness.py"
    class_name: "ProductionReadinessChecklist"
    responsibility: "Comprehensive production readiness validation"
    
    interface:
      methods:
        validate_session:
          signature: "def validate_session(self, session_data: Dict) -> ChecklistResult"
          description: "Validate entire TDD session for production readiness"
          returns: "ChecklistResult with pass/fail and details"
        
        generate_report:
          signature: "def generate_report(self, result: ChecklistResult) -> str"
          description: "Generate human-readable report"
          returns: "Markdown formatted report"
    
    checklist_items:
      tests:
        - name: "All tests passing"
          validator: "TestSuiteValidator"
          blocking: true
        - name: "Test coverage >= 80%"
          validator: "CoverageValidator"
          blocking: false
          warning_threshold: 0.7
      
      code_quality:
        - name: "No debug statements"
          validator: "CodeCleanupValidator.scan_directory"
          blocking: true
        - name: "Lint validation passed"
          validator: "LintIntegration.run_lint_directory"
          blocking: true
        - name: "No code smells (critical)"
          validator: "CodeSmellDetector.analyze_directory"
          blocking: true
          severity_threshold: "critical"
      
      documentation:
        - name: "Public APIs documented"
          validator: "DocumentationValidator"
          blocking: false
        - name: "README updated"
          validator: "ReadmeValidator"
          blocking: false
      
      security:
        - name: "No hardcoded secrets"
          validator: "SecretScanner"
          blocking: true
        - name: "Dependencies up to date"
          validator: "DependencyScanner"
          blocking: false
      
      git:
        - name: "No uncommitted changes"
          validator: "GitStatusValidator"
          blocking: true
        - name: "Branch up to date with main"
          validator: "GitBranchValidator"
          blocking: false
  
  integration_into_session_completion:
    file: "src/orchestrators/session_completion_orchestrator.py"
    method: "complete_session"
    
    new_validation_pipeline:
      current_flow: |
        1. Run full test suite
        2. Compare before/after metrics
        3. Generate git diff summary
        4. Validate SKULL rules
        5. Generate completion report
      
      enhanced_flow: |
        1. Run full test suite
        2. Compare before/after metrics
        3. **NEW: Run code cleanup validation**
        4. **NEW: Execute lint validation**
        5. **NEW: Check production readiness**
        6. Generate git diff summary
        7. Validate SKULL rules
        8. Generate completion report with quality section
      
    implementation:
      pseudo_code: |
        def complete_session(self, session_id: str) -> Dict:
            # Existing validations
            test_results = self.run_full_test_suite()
            metrics = self.compare_metrics()
            
            # NEW: Code quality enforcement
            cleanup_validator = CodeCleanupValidator()
            cleanup_issues = cleanup_validator.scan_directory(self.project_root)
            if cleanup_issues:
                return self._fail_with_cleanup_issues(cleanup_issues)
            
            lint_integration = LintIntegration()
            lint_results = lint_integration.run_lint_directory(self.project_root)
            blocking_violations = lint_integration.get_blocking_violations(lint_results)
            if blocking_violations:
                return self._fail_with_lint_violations(blocking_violations)
            
            readiness_checker = ProductionReadinessChecklist()
            readiness_result = readiness_checker.validate_session({
                'test_results': test_results,
                'metrics': metrics,
                'cleanup_issues': cleanup_issues,
                'lint_results': lint_results
            })
            
            if not readiness_result.passed:
                return self._fail_with_readiness_issues(readiness_result)
            
            # Existing completions
            git_diff = self.generate_git_diff()
            skull_validation = self.validate_skull_rules()
            report = self.generate_completion_report({
                'test_results': test_results,
                'metrics': metrics,
                'quality': readiness_result,  # NEW
                'git_diff': git_diff,
                'skull_validation': skull_validation
            })
            
            return report

track_b_brain_documentation_organization:
  priority: "HIGH"
  
  component_1_document_organizer:
    file: "src/utils/document_organizer.py"
    class_name: "DocumentOrganizer"
    responsibility: "Auto-organize documents into brain structure"
    
    interface:
      methods:
        determine_category:
          signature: "def determine_category(self, doc_type: str, context: Dict) -> str"
          description: "Determine document category from context"
          returns: "Category name (tdd-sessions, code-reviews, etc.)"
        
        generate_path:
          signature: "def generate_path(self, category: str, metadata: Dict) -> Path"
          description: "Generate organized file path"
          returns: "Full path following naming conventions"
        
        file_document:
          signature: "def file_document(self, content: str, doc_type: str, metadata: Dict) -> Path"
          description: "Save document to organized location"
          returns: "Path where document was saved"
        
        update_index:
          signature: "def update_index(self, doc_path: Path, metadata: Dict) -> None"
          description: "Update category index with new document"
          returns: "None"
    
    folder_structure:
      root: "cortex-brain/documents/"
      
      tdd_sessions:
        path: "tdd-sessions/{YYYY-MM-DD}/"
        naming: "SESSION-{timestamp}-{feature_name}.md"
        index: "tdd-sessions/INDEX.md"
        metadata:
          - "session_id"
          - "feature_name"
          - "start_time"
          - "end_time"
          - "test_results"
          - "refactorings_applied"
      
      code_reviews:
        path: "code-reviews/{YYYY-MM-DD}/"
        naming: "REVIEW-{timestamp}-{target}.md"
        index: "code-reviews/INDEX.md"
        metadata:
          - "review_type"
          - "target_files"
          - "smell_count"
          - "lint_violations"
          - "readiness_score"
      
      ado_work_items:
        path: "ado-work-items/ADO-{id}/"
        naming: "ADO-{id}-{status}-{timestamp}.md"
        index: "ado-work-items/INDEX.md"
        metadata:
          - "ado_id"
          - "work_item_type"
          - "status"
          - "created_date"
          - "completed_date"
          - "related_files"
      
      planning:
        path: "planning/{type}/"
        naming: "PLAN-{date}-{name}.yaml"
        index: "planning/{type}/INDEX.md"
        types:
          - "features"
          - "enhancements"
          - "architecture"
          - "refactoring"
  
  component_2_index_maintenance:
    responsibility: "Keep category indexes up to date"
    
    index_format:
      markdown_template: |
        # {Category} Index
        
        **Last Updated:** {timestamp}
        **Total Documents:** {count}
        
        ## Recent Documents
        
        | Date | Document | Type | Status |
        |------|----------|------|--------|
        {rows}
        
        ## Quick Links
        
        - [View All](./)
        - [Active Items](./active/)
        - [Completed Items](./completed/)
    
    auto_update_triggers:
      - "Document filed"
      - "Document status changed"
      - "Document deleted"
      - "Hourly cleanup task"
  
  integration_into_orchestrators:
    session_completion:
      enhancement: "Auto-file session report to tdd-sessions/"
      code_addition: |
        organizer = DocumentOrganizer()
        report_path = organizer.file_document(
            content=session_report,
            doc_type='tdd_session',
            metadata={
                'session_id': session_id,
                'feature_name': self.feature_name,
                'test_results': test_results
            }
        )
    
    planning_orchestrator:
      enhancement: "Auto-file plans to planning/{type}/"
      code_addition: |
        organizer = DocumentOrganizer()
        plan_path = organizer.file_document(
            content=plan_yaml,
            doc_type='feature_plan',
            metadata={
                'plan_name': plan_name,
                'plan_type': 'features',
                'status': 'active'
            }
        )

track_c_incremental_planning:
  priority: "HIGHEST"
  
  component_1_incremental_plan_generator:
    file: "src/workflows/incremental_plan_generator.py"
    class_name: "IncrementalPlanGenerator"
    responsibility: "Generate plans in token-safe chunks"
    
    interface:
      methods:
        generate_skeleton:
          signature: "def generate_skeleton(self, plan_request: PlanRequest) -> PlanSkeleton"
          description: "Generate plan structure without content"
          returns: "Plan skeleton with sections defined"
          token_budget: 200
        
        fill_section:
          signature: "def fill_section(self, skeleton: PlanSkeleton, section_id: str) -> SectionContent"
          description: "Fill one section with content"
          returns: "Section content with token count"
          token_budget: 500
        
        stream_to_file:
          signature: "def stream_to_file(self, skeleton: PlanSkeleton, output_path: Path) -> None"
          description: "Stream plan to file in chunks"
          returns: "None"
        
        validate_token_budget:
          signature: "def validate_token_budget(self, content: str) -> Tuple[bool, int]"
          description: "Check if content fits budget"
          returns: "Tuple of (fits_budget, token_count)"
    
    chunking_strategy:
      phase_1_skeleton:
        content:
          - "Plan metadata (title, version, status)"
          - "Section headers only"
          - "Phase names and objectives"
        token_limit: 200
        user_interaction: "Present skeleton for review"
      
      phase_2_section_filling:
        approach: "One section per API call"
        sections:
          - "Overview and problem statement"
          - "Current state assessment"
          - "Gap analysis"
          - "Design decisions"
          - "Implementation approach"
          - "Validation criteria"
        token_limit_per_section: 500
        user_interaction: "Checkpoint after each section"
      
      phase_3_detail_expansion:
        approach: "Expand subsections on demand"
        trigger: "User requests detail on specific section"
        token_limit: 500
        user_interaction: "Iterative detail addition"
    
    token_budget_enforcement:
      hard_limit: 500
      soft_limit: 400
      action_on_exceed:
        soft: "Warning to user, suggest splitting"
        hard: "Automatic pause, require user continuation"
      
      estimation_method:
        formula: "len(text.split()) * 1.3"  # Rough token estimate
        validation: "Use tiktoken for accurate count"
  
  component_2_streaming_plan_writer:
    file: "src/workflows/streaming_plan_writer.py"
    class_name: "StreamingPlanWriter"
    responsibility: "Write plans to disk incrementally"
    
    interface:
      methods:
        open_stream:
          signature: "def open_stream(self, output_path: Path, format: str) -> StreamContext"
          description: "Open streaming write context"
          returns: "Stream context for incremental writes"
        
        write_chunk:
          signature: "def write_chunk(self, context: StreamContext, chunk: str) -> None"
          description: "Write chunk to stream"
          returns: "None"
        
        close_stream:
          signature: "def close_stream(self, context: StreamContext) -> Path"
          description: "Close stream and finalize file"
          returns: "Path to completed file"
    
    formats:
      yaml:
        purpose: "CORTEX brain consumption"
        encoding: "utf-8"
        buffering: 4096
        validation: "YAML syntax check after each chunk"
      
      markdown:
        purpose: "User review and editing"
        encoding: "utf-8"
        buffering: 4096
        validation: "Markdown lint after completion"
  
  integration_into_planning_orchestrator:
    file: "src/orchestrators/planning_orchestrator.py"
    
    current_approach: |
      def create_plan(self, plan_request: PlanRequest) -> Dict:
          # PROBLEM: Generates entire plan in memory
          plan_content = self._generate_full_plan(plan_request)
          # Causes excessive data error if plan is large
          return plan_content
    
    enhanced_approach: |
      def create_plan(self, plan_request: PlanRequest) -> Dict:
          generator = IncrementalPlanGenerator()
          writer = StreamingPlanWriter()
          
          # Phase 1: Generate skeleton (200 tokens)
          skeleton = generator.generate_skeleton(plan_request)
          self._present_skeleton_for_review(skeleton)
          
          # Phase 2: Fill sections incrementally
          yaml_stream = writer.open_stream(yaml_path, 'yaml')
          md_stream = writer.open_stream(md_path, 'markdown')
          
          for section_id in skeleton.sections:
              # Generate one section (500 token budget)
              section_content = generator.fill_section(skeleton, section_id)
              
              # Validate token budget
              valid, token_count = generator.validate_token_budget(section_content)
              if not valid:
                  self._handle_budget_exceeded(section_id, token_count)
              
              # Stream to both formats
              writer.write_chunk(yaml_stream, section_content.to_yaml())
              writer.write_chunk(md_stream, section_content.to_markdown())
              
              # Checkpoint
              self._present_section_for_review(section_id, section_content)
          
          # Phase 3: Finalize
          yaml_path = writer.close_stream(yaml_stream)
          md_path = writer.close_stream(md_stream)
          
          return {
              'yaml_path': yaml_path,
              'md_path': md_path,
              'sections_completed': len(skeleton.sections)
          }

implementation_order:
  sprint_1:
    - "Create CodeCleanupValidator"
    - "Create LintIntegration"
    - "Integrate into session_completion_orchestrator"
    - "Test with sample TDD session"
  
  sprint_2:
    - "Create ProductionReadinessChecklist"
    - "Create DocumentOrganizer"
    - "Create folder structure in brain"
    - "Test auto-filing logic"
  
  sprint_3:
    - "Create IncrementalPlanGenerator"
    - "Create StreamingPlanWriter"
    - "Integrate into planning_orchestrator"
    - "Test with complex feature plan"
  
  sprint_4:
    - "Integration testing across all orchestrators"
    - "Update documentation"
    - "Create migration guide"
    - "Deploy to production"

testing_strategy:
  unit_tests:
    - "test_code_cleanup_validator.py"
    - "test_lint_integration.py"
    - "test_production_readiness.py"
    - "test_document_organizer.py"
    - "test_incremental_plan_generator.py"
    - "test_streaming_plan_writer.py"
  
  integration_tests:
    - "test_session_completion_with_quality.py"
    - "test_planning_incremental_generation.py"
    - "test_document_auto_filing.py"
  
  end_to_end_tests:
    - "test_full_tdd_session_with_enforcement.py"
    - "test_complete_planning_workflow.py"

rollout_plan:
  phase_1_soft_launch:
    - "Deploy with warning-only mode"
    - "Collect metrics on violations found"
    - "Tune detection patterns"
  
  phase_2_enforcement:
    - "Enable blocking mode for critical issues"
    - "Monitor for false positives"
    - "Adjust exemption rules"
  
  phase_3_full_deployment:
    - "Enable all validations"
    - "Update documentation"
    - "Train users on new workflow"
