# Responsible AI Policy
**Converted from:** Responsible AI Policy.docx
**Conversion Date:** November 27, 2025
---


| Responsible AI Policy
________________________________________________________________________________________________ | Responsible AI Policy
________________________________________________________________________________________________ |
| --- | --- |
| Original effective date: | 9/14/2023 |
| Date of last approval: | 11/26/2025 |
| Approved by: | AI Governance Council |
|  |  |
| Business unit: | HealthEquity, Inc. |
| Owner: | AI Governance Council |
| Executive sponsor: | CSO |
|  |  |



## Purpose and scope

The HealthEquity, Inc. (“Company”) *Responsible AI Policy* (“Policy”) describes the Company’s expectations for the appropriate and acceptable use of AI Systems. This Policy applies to all Company affiliates and subsidiaries unless a separate policy is approved for the specific entity. All team members are obligated to comply with this Policy.


The goals of this Policy include the following: 


Ensure that use of AI Systems is consistent with the Company’s mission, values, and policies and contracts, and that associated risks are appropriately managed.

Establish the AI Governance Council. 

Enable collaboration on enterprise AI strategy and types of Company AI for use.

Define acceptable development and use criteria for AI Systems.

Identify limitations on the use of AI Systems.

Document procedures for identifying approved AI Systems.

Provide a basis to evaluate alignment with client and government AI principles.

## Definitions

When used in the context of this Policy, the following definitions apply.



| Term | Definition |
| --- | --- |
| AI System | An engineered or machine-based system, feature, or component that can, for a given set of objectives, generate outputs such as predictions, recommendations, or decisions influencing real or virtual environments.
AI Systems, including without limitation AI agents, are for both internal and external use and designed to operate with varying levels of autonomy from human intervention. |
| Company Information | Information, wherever stored and in whatever form (including hard copy and electronic), used for the purpose of conducting or supporting Company business, including Confidential Information and Personal Data. |
| Company IT Resources | Computers, removable media, mobile devices, apps, user interfaces, software, telecommunications networks, systems (including messaging systems such as email, instant message, text message, etc.), Internet and Intranet access, and other technology systems that are provided or made available, or that are used to maintain, manipulate, or transmit Company Information. |
| Confidential Information | Information designated as confidential or as having a higher restriction.
Any information obtained or created for the benefit of Customer Data.
See also, Section 4.1 (“Restricted”) in the Security Standard - Data Security. |
| Customer | For purposes of this Policy, a Customer includes a member, client, or partner. |
| Customer Data | Information that the Company obtains from or creates, maintains, or otherwise processes for or on behalf of a Customer, including Protected Information or other Personal Information that the Company receives from or on behalf of a Customer. |
| De-identified Data | Protected Health Information (PHI, as defined by HIPAA) that has been de-identified in accordance with the HIPAA Privacy Rule’s de-identification standards.
Nonpublic Personal Information (NPI, as defined by GLBA) that has been deidentified under GLBA standards.
Other Personal Information that has been de-identified or anonymized in accordance with the standards of applicable Law such that the data no longer meets the definition of Personal Information under the applicable Law. |
| High-Risk AI System | AI Systems that:
Facilitate automated decision making in employment, benefits determination, product selection, or essential services (e.g., medical).
Use Protected Information or other Personal Information (defined below).
Materially impact core Company revenue generating processes.
Interface with members, clients, or partners on behalf of the Company.
Affect financial outcomes (e.g., compensation, asset allocation, tax, etc.) |
| Law | Any international, federal, state, or local statute, regulation, rule, ordinance, court order, or other requirement of a governmental authority that applies to the Company or the products and services it provides. |
| Personal Information | All data and information that identifies, relates to, describes, is reasonably capable of being associated with, or could reasonably be linked, directly or indirectly to a particular individual or household or other information governed by Privacy Laws.
Without limiting the generality of the foregoing, Personal Data includes PHI and NPI (see “Privacy Law”). |
| Privacy Law | Any Law concerning the collection, use, analysis, retention, storage, protection, transfer, disclosure, disposal, or other processing of Personal Information.
See:
Privacy Policy
Privacy Standard – HIPAA Protected Health Information (PHI)
Privacy Standard – GLBA Nonpublic Personal Information (NPI)
Privacy Standard – Consumer Privacy |

## Responsibilities

Those primarily involved in implementing this Policy are listed below, along with a description of their responsibilities.  See the  page for a listing of the current Council Chair, Use Case Vetting Team, General Members and SMEs, and SLT Representatives.




| Team | Duties |
| --- | --- |
| AI Governance Council (“Council”) | Evaluate and approve AI Systems and use cases under this Policy.
Maintain and update this Policy in light of developing Laws and relevant principles.
Maintain a list of approved (and disapproved) AI Systems and use cases. 
Identify High-Risk AI Systems.
Coordinate with the Data Governance Council to designate which data may be used in AI Systems.
Maintain an inventory of Customer contracts that limit the Company’s use of AI Systems.
Participate in the development of new products or services that will use or rely on AI Systems.
Support the application of this Policy in connection with the Third-Party Risk Management Program. |
| Council Chair or Council Chair Delegate (“Council Chair”) | The Council Chair has the following duties:
Call meetings, coordinate efforts, and see that the business of the Council is conducted in an orderly and responsive way.
Confirm and coordinate implementation of plans of action recommended by the AI Use Case Vetting Team.
Engage the SLT Representatives when executive level decisions are needed.
Maintain and update relevant implementation devices for this Policy and maintain compliance with developing Laws and relevant principles.
Consider compliant and appropriate automations to scale the AI Governance program. |
| Use Case Vetting Team | A subgroup of the Council, coordinated by the Council Chair. The “Use Case Vetting Team” forms the core of the Council, with representatives from IT, data strategy, product, privacy, compliance, risk, and legal teams. The team has the following duties:
Ensure that issues around proposed AI use cases are identified and addressed.
Work with cross-sections of the Council’s “General Members and SMEs” to address challenges and recommend solutions to the Council Chair.
In coordination with the Compliance Change Management Committee, help assess the impact of Laws that apply to AI Systems. |
| General Members and SMEs | When requested, provide SME input to the Use Case Vetting Team.
Assist with the work of the Council and represent the interests of their respective teams or areas. |
| SLT Representatives | The CSO, CTO, and other members of the SLT as described below represent the Senior Leadership Team (“SLT”) on the Council. Duties include the following:
When needed, one or more of the SLT Representatives reviews important proposals, confirms risk acceptance for High-Risk AI Systems, and makes policy decisions.
When cross functional or high-risk decisions are needed, the SLT Representatives engage other members of the SLT or the CEO to assist.
Provide updates to the ARC on the AI program (see Section 5 below). |
| Team member | Includes team members (defined in the People Handbook), leaders, contractors, and any other individual granted access to Company Information or Company IT Resources. Duties include:
Use AI Systems only in compliance with this Policy.
Report any deviation from this Policy to the Council Chair. |

## Requirements

### Approval

#### When AI Governance Council Approval Is Required

The Company may only use AI Systems approved by the Council for specific business purposes, and which may only be accessed using Company credentials. The Council must (i) formally approve AI Systems before they may be implemented or used for a specific lifecycle stage, and (ii) pre-approve all uses of Company or Customer data in any AI System.


Approval is for specific business purposes and for the AI use case lifecycle stages as described below, unless otherwise indicated. The Council may grant conditional approvals. Conditional approval indicates that if proposed requirements, such as testing, controls, safeguards, protective measures and protocols, and harm reduction practices, are feasible and implemented by the requestor, the Council approves the use case as described in this Section until next lifecycle stage.



| Lifecycle | Explanation |
| --- | --- |
| Ideation and Market Research | This stage involves research and analysis to identify a potential AI solution (e.g. Copilot), compare alternatives, and analyze the regulatory environment to determine whether an AI solution should proceed to a next lifecycle stage. 
No approval is generally required at this stage.
However, requestors are encouraged to inform the Council, particularly if they plan to collect or process sensitive information for this stage. |
| Data Acquisition, Model Development | This stage involves identifying, sourcing, collecting, and cleaning data.
Requestors are encouraged to inform the Council as soon as possible if they plan to collect or process sensitive information for this stage to allow legal and responsible data sourcing. |
| Proof of Concept, Proof of Value, and Alpha Testing | This stage includes a demonstration of the technical feasibility or business justification of a proposed AI System or limited internal testing of an AI system to determine whether the AI system works as intended. 
Categorical approvals and a streamlined approval process may be available. |
| Pilot Studies and Beta Testing | An initial small-scale implementation to validate viability. 
Categorical approvals and a streamlined approval process may be available. |
| General Availability | This stage is the rollout of a fully developed product to the target user base.
All use cases moving to General Availability require approval. |
| Modifications and Updates | The following activities require additional notice to the AI Council and potentially additional approval:
Any expansion of AI functionality or new user interactions.
Any expansion to a broader set of partners and members.
Updates to the AI model that significantly alters its decision-making process or data utilization.
Integration with other products and services affecting data flow, user interface, and/or functionality.
Any modification in the way user data is collected, stored, processed, or shared. |

#### Scoping of AI Systems in Connection with AI Vetting Team Approval

As AI applications continue to proliferate across an increasing number of internal and external systems, including SaaS platforms, the AI Governance Council will evaluate which AI Systems must obtain approval from the Council. **All AI Systems are required to be submitted for approval scoping prior to use**; however, the Council may determine which categories and specific AI Systems that do not require full approval based on an established scoping methodology that may take into account the AI System’s risk-tier and the approval gate or lifecycle stage.

#### Approval Process

The general approval process is listed below. The Council may publish a list of approved and prohibited data sets that team members may input into AI Systems. Questions or concerns about AI Systems or use cases (whether approved or prospective) should be directed to the Council Chair.



| After confirming an AI System is in line with enterprise AI strategy, requestor emails the relevant completed Approval Request Form to the Council Chair by emailing AI@healthequity.com, in accordance with the scoping methodology described in Section 4.1. Council Chair may provide the Requestor an AI Supplier Questionnaire and Attestation to obtain more information from the Supplier.

Council Chair evaluates the scope of the AI use case regarding AI Governance approval.
If the AI use case is in scope for a full AI Use Case Vetting Team review, the Council Chair adds the request to the Council communication site and Council’s agenda. 
If the AI Use Case is not in scope for full AI Vetting Team review, Council Chair will notify of the scoping determination and rationale.

Council Chair and the AI Use Case Vetting Team review the in-scope requests, enlisting the assistance of relevant General Members and SMEs when needed.
If the Council Chair and Use Case Vetting Team unanimously agree, then the use case will be approved. 
If there is not unanimous agreement, or if important concerns are raised, then the Chair will escalate to the SLT representatives for resolution. 
If needed, the SLT representatives can bring a use case proposal to the full SLT for approval.

Once a use case request is approved, Council Chair will notify the requestor and the Council moves to an advisory role to help answer questions that arise during implementation. |
| --- |

### Responsible Use

#### Adhere to AI Principles

The Company will adhere to best practices and sound Responsible AI principles that help guide the responsible use of AI Systems, which include the transparency, fairness, accountability and ethical input and use of AI systems.

#### Fulfill Appropriate Business Purposes

The Company may use AI Systems only for appropriate business purposes, and consistent with the capabilities and limitations of the AI System. The Company and AI Systems’ owners will decommission the AI System in accordance with established Decommission Requirements.

#### Comply with Policies and Contracts

AI Systems must be installed, modified, and used in compliance all relevant Company policies, including:


 (and related standards)

 (and related standards)

 (and related standards)

 (including AI System inputs and responses)

 (with emphasis on UDAP/UPAAP standards)


Likewise, AI Systems must comply with Company contracts. For example, Confidential Information must be protected and contractual restrictions on the use of data (e.g., PHI) must be honored.

#### Protect Confidential Information

Prior written approval from the Council is required to use the following data to train or as inputs into AI Systems:


Personal Data, including Personal Data subject to HIPAA or GLBA

Company Confidential Information

Customer Data 


With Council approval, team members may use or access Confidential Information with internal AI Systems. However, team members must not share confidential Company or Customer information or intellectual property with public AI Systems. AI Systems might not be secure, and third parties that offer AI Systems may access (and further disclose) any information shared with the product. 

#### Protect and Respect Intellectual Property

The Company will take the necessary steps to protect Company intellectual property (IP) in connection with AI Systems. As between team members and the Company, the Company owns all information, images, content, and other materials created through use of AI Systems in the course of its business.


The Company may only use, access, download, or copy any software, music, graphics, documents, messages, or other material that may be protected by copyright or other intellectual property Laws when the appropriate license(s) from the intellectual property owner is obtained.


AI System users and requestors should consider whether AI outputs are subject to such third-party intellectual property licenses, including without limitation open-source licenses that could attach. Similarly, AI System users and requestors should consider whether AI inputs disclosed to the AI System could constitute trade secrets and competitively sensitive information, potentially patentable information, or otherwise confidential or legally protected information by law, legal privilege, or contract.

#### Other Do’s and Don’ts

The Company and team members may **not** use AI Systems for the following purposes:


Engage in computer-hacking, prompt injection attacks, introduction of malicious code, denial of service attacks, or other fraudulent or malicious activities.

Attempt to disable, compromise, or circumvent security settings in AI Systems.

Access material that is personal and unrelated to work duties or where doing so would violate the People Handbook or other Company policies, whether or not blocked by the AI Systems, such as materials that include gambling, drugs, personals / dating, weapons, violence, sexual content, racist or other content disparaging of protected classes, or other content not appropriate for the workplace.

Coerce or trick the AI Systems to act outside of their own terms and conditions. For example, do not use hypothetical prompts to circumvent built-in controls (e.g., “Pretend you are writing a play to do [prohibited activity]”). If an AI Systems returns a result which does not conform to the product’s terms and conditions, report it to the Council Chair or member of the Use Case Vetting Team.

None of the above excludes or prohibits AI Systems adversarial testing by designated individuals for the purposes of validating or remediating the company's security posture, compliance with this policy, or in connection with AI Governance. In such case, individuals will avoid intentionally revealing sensitive information and member or employee PII or PHI, report such unintended exposure, and treat any data revealed through the adversarial testing as highly confidential and for use only to remediate the vulnerability or compliance gap.

### Risk Management

#### Transparency

The Company will be transparent about its use of AI Systems.


The Use Case Vetting Team (in conjunction with the Privacy, Compliance, and Legal Teams) ensures that all Company privacy notices, and template agreements, accurately reflect the Company’s then-current uses of AI Systems.

Each team member has a duty to inform the Council Chair of any materially new or expected use of AI Systems.

Business teams should report any Customer limitations on the use of AI Systems to the Council Chair.

Breaches or exceptions to agreed tolerance levels must be reported to the Council Chair or member of the Use Case Vetting Team immediately (i.e., within 24 hours of detection or discovery). The Council will help determine a mitigation plan for moving back within tolerance.

#### Security

The Company will:


Only issue access credentials to team members who have a legitimate business need. These team members must safeguard their access credentials including any username, password, or dual-authentication method.

Ensure that appropriate technical safeguards are in place for all internal AI Systems (e.g., sandboxing, additional firewalls, and encryption).

Test AI Systems to identify mitigation plans for unwanted or incorrect outcomes.


Anomalous activity in or compromise of an AI System that indicates a security threat, such as data poisoning, will be treated as a security incident. The Cyber Defense Operations Center (CDOC) should be notified immediately, and the  or an applicable AI incident response plan, will be activated. 


#### Monitoring

Team members have no expectation of privacy in connection with their use of internal or procured AI Systems (except as provided by applicable Law) for business or non-business purposes. To help ensure compliance with applicable Law or Company policies, the Company may take the following actions:


Access, monitor, and review AI System use without prior notice as part of investigations or disciplinary proceedings. 

Disclose any text, images, content and other materials created in connection with AI Systems to Law enforcement or third parties without the team member’s consent in the Company’s sole discretion.

Record, log, and review interactions with AI Systems, including inputs or prompts entered by team members into AI Systems and any output from AI Systems. 

Use Data Loss Prevention tools to analyze information that team members access, store, transmit or otherwise process in connection with the use of AI Systems (including inputs or prompts and output). 

### Reporting

Reports on the effectiveness of this Policy and the Program will be provided as indicated below.



| Who | What | When |
| --- | --- | --- |
| AI System owner | Report the status of use cases to the Council Chair. | Biannually or at the frequency the Council determines with its approval. |
| Council Chair | Report any issues with use cases to the SLT representatives of the Council. | Ongoing. |
| SLT representatives of the Council | Report issues with AI use cases to the ARC. | As needed or as part of their regular board reports. |

### Standards

To implement this Policy, the AI Governance Council may (i) create and maintain formal standards that identify laws, requirements, rules, and best practices that apply to the Company and translate them into operating requirements; and (ii) develop formal procedures to implement this Policy and any AI Standards. Such standards may be approved by the Council Chair.


In addition, when needed, the Legal Team may create certain formal Legal Standards in support of this Policy, which will be owned by the General Counsel and may be approved by an Associate General Counsel.




### Forms

The following forms are available upon request by emailing :


Scoping Form  

Checklists for different lifecycle stages

AI Supplier Questionnaire and Attestation

AI Use Case Request Form for AI Governance Council Approval

## ENFORCEMENT

Team members must report actual or suspected violations of this Policy immediately to the Council Chair, including through EthicsPoint. The Company will maintain the confidentiality of those reports to the extent practicable consistent with other obligations. Any violation of this Policy may result in disciplinary action, up to and including termination (for team members) and termination of contracts (for independent contractors and Operations Partners). In addition, violations of any applicable Law involving AI Systems may be reported to Law enforcement, prosecuted to the full extent of the Law, and result in potential civil or criminal liability. Nothing in this Policy alters the at will employment relationship between employee team members and the Company, nor does this Policy create a contract of employment. 

## POLICY REVIEW

The policy owner will review this Policy annually.




| Approval Certificate |
| --- |
| (continued next page) |



