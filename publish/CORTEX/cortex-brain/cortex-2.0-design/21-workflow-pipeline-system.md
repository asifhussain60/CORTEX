# CORTEX 2.0 Workflow Pipeline System

**Document:** 21-workflow-pipeline-system.md  
**Version:** 2.0.0-alpha  
**Date:** 2025-11-07  
**Status:** Design Complete

---

## üéØ Purpose

Enable users to build and execute **chainable task workflows** with stages like threat modeling, DoD/DoR clarification, TDD implementation, cleanup, and documentation‚Äîall in any order they specify.

**Goals:**
- Declarative workflow definitions (YAML)
- Individual stage scripts (single responsibility)
- Dependency management (DAG validation)
- State sharing between stages
- Error recovery (retries, checkpoints)
- Performance optimization (context injected once)
- Full extensibility (add stages without touching core)

---

## üèóÔ∏è Architecture Overview

### Three-Layer Design

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  LAYER 1: Workflow Definitions (Declarative YAML)      ‚îÇ
‚îÇ  - User defines task chains                            ‚îÇ
‚îÇ  - Specifies dependencies                              ‚îÇ
‚îÇ  - Configures retries, timeouts                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  LAYER 2: Orchestrator (Python Engine)                 ‚îÇ
‚îÇ  - Validates DAG (no cycles)                           ‚îÇ
‚îÇ  - Manages shared state                                ‚îÇ
‚îÇ  - Executes in topological order                       ‚îÇ
‚îÇ  - Handles errors, retries, checkpoints                ‚îÇ
‚îÇ  - Injects context once (Tier 1-3)                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  LAYER 3: Stage Scripts (Python Modules)               ‚îÇ
‚îÇ  - Individual, focused tasks                           ‚îÇ
‚îÇ  - Implement WorkflowStage interface                   ‚îÇ
‚îÇ  - Reusable across workflows                           ‚îÇ
‚îÇ  - Independently testable                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìù Workflow Definition Format

### YAML Schema

```yaml
workflow_id: string                # Unique workflow identifier
name: string                       # Human-readable name
description: string                # Multi-line description

stages:
  - id: string                     # Unique stage ID
    script: string                 # Python module name
    required: boolean              # Abort on failure? (default: true)
    depends_on: [string]           # List of dependency stage IDs
    retryable: boolean             # Enable retries? (default: false)
    max_retries: integer           # Max retry attempts (default: 3)
    timeout_seconds: integer       # Execution timeout (default: 300)
```

### Example: Secure Feature Creation

```yaml
workflow_id: "secure_feature_creation"
name: "Secure Feature Creation"
description: |
  Complete feature workflow with security and quality gates

stages:
  # Stage 1: Threat Modeling
  - id: "threat_model"
    script: "threat_modeler"
    required: true
    depends_on: []
    timeout_seconds: 60
  
  # Stage 2: DoD/DoR Clarification
  - id: "clarify_dod_dor"
    script: "dod_dor_clarifier"
    required: true
    depends_on: ["threat_model"]
    timeout_seconds: 30
  
  # Stage 3: Planning
  - id: "plan"
    script: "work_planner"
    required: true
    depends_on: ["clarify_dod_dor"]
    timeout_seconds: 120
  
  # Stage 4: TDD Implementation
  - id: "tdd_cycle"
    script: "tdd_workflow"
    required: true
    depends_on: ["plan"]
    retryable: true
    max_retries: 3
    timeout_seconds: 600
  
  # Stage 5: Test Execution
  - id: "run_tests"
    script: "test_runner"
    required: true
    depends_on: ["tdd_cycle"]
    timeout_seconds: 300
  
  # Stage 6: DoD Validation
  - id: "validate_dod"
    script: "dod_validator"
    required: true
    depends_on: ["run_tests"]
    timeout_seconds: 60
  
  # Stage 7: Code Cleanup (Optional)
  - id: "cleanup"
    script: "code_cleanup"
    required: false               # Won't block if fails
    depends_on: ["validate_dod"]
    timeout_seconds: 120
  
  # Stage 8: Documentation
  - id: "document"
    script: "doc_generator"
    required: true
    depends_on: ["cleanup"]
    timeout_seconds: 180
```

---

## üîß Stage Interface

### WorkflowStage Protocol

```python
class WorkflowStage(Protocol):
    """Interface that all workflow stages must implement"""
    
    def execute(self, state: WorkflowState) -> StageResult:
        """
        Execute this stage
        
        Args:
            state: Shared workflow state
                - state.user_request: Original request
                - state.context: Tier 1-3 context (injected once)
                - state.stage_outputs: Outputs from previous stages
        
        Returns:
            StageResult with status, outputs, errors
        """
        ...
    
    def validate_input(self, state: WorkflowState) -> bool:
        """
        Validate inputs before execution
        
        Returns:
            True if inputs are valid
        """
        ...
    
    def on_failure(self, state: WorkflowState, error: Exception):
        """
        Handle stage failure
        
        Use for cleanup, logging, rollback
        """
        ...
```

### Example Stage Implementation

```python
# src/workflows/stages/threat_modeler.py

from src.workflows.workflow_pipeline import (
    WorkflowStage, WorkflowState, StageResult, StageStatus
)

class ThreatModelerStage:
    """STRIDE threat modeling stage"""
    
    def execute(self, state: WorkflowState) -> StageResult:
        # Analyze request for threats
        threats = self._identify_threats(state.user_request)
        risk_level = self._calculate_risk_level(threats)
        
        return StageResult(
            stage_id="threat_model",
            status=StageStatus.SUCCESS,
            duration_ms=0,
            output={
                "threats": threats,
                "risk_level": risk_level,
                "recommendations": self._generate_recommendations(threats)
            }
        )
    
    def validate_input(self, state: WorkflowState) -> bool:
        return bool(state.user_request)
    
    def on_failure(self, state: WorkflowState, error: Exception):
        print(f"Threat modeling failed: {error}")

def create_stage() -> WorkflowStage:
    return ThreatModelerStage()
```

---

## üîÑ Orchestration Flow

### Execution Sequence

```
1. Load workflow definition (YAML)
   ‚Üì
2. Validate DAG (check for cycles)
   ‚Üì
3. Initialize WorkflowState
   ‚Üì
4. Inject context ONCE (Tier 1-3) ‚Üê PERFORMANCE OPTIMIZATION
   ‚Üì
5. Get execution order (topological sort)
   ‚Üì
6. For each stage:
   a. Check dependencies satisfied
   b. Validate inputs
   c. Execute with timeout
   d. Handle errors/retries
   e. Update shared state
   f. Log to Tier 1
   ‚Üì
7. Return final WorkflowState
```

### State Management

```python
@dataclass
class WorkflowState:
    """Shared state passed between all stages"""
    
    workflow_id: str              # UUID of this workflow run
    conversation_id: str          # Tier 1 conversation UUID
    user_request: str             # Original request
    
    # Context injected ONCE at start (not per-stage)
    context: Dict[str, Any]       # Tier 1-3 data
    
    # Outputs from each stage
    stage_outputs: Dict[str, Dict[str, Any]]
    
    # Status tracking
    stage_statuses: Dict[str, StageStatus]
    
    start_time: datetime
    end_time: datetime
    current_stage: str
```

---

## ‚ö° Performance Optimization

### Context Injection (Key Innovation)

**Problem:** Querying Tier 1-3 context per-stage is slow

**‚ùå Inefficient Approach:**
```python
# Each stage queries context independently
for stage in stages:
    context = inject_context()  # 200ms per call
    stage.execute(context)

# 8 stages √ó 200ms = 1,600ms overhead
```

**‚úÖ Optimized Approach:**
```python
# Context injected ONCE at workflow start
context = inject_context()  # 200ms (once)

for stage in stages:
    stage.execute(state_with_context)  # 0ms overhead

# 1 √ó 200ms = 200ms overhead
# SAVINGS: 1,400ms (88% reduction)
```

### Performance Metrics

| Metric | Without Orchestrator | With Orchestrator | Savings |
|--------|---------------------|-------------------|---------|
| Context queries | 8 √ó 200ms = 1,600ms | 1 √ó 200ms = 200ms | **1,400ms** |
| Total time (8 stages) | 7,230ms | 5,830ms | **19% faster** |
| Validation | Runtime (late) | Compile-time (early) | **Fail fast** |

---

## üéØ Built-in Workflows

### 1. Secure Feature Creation (Full Workflow)

**Use When:**
- New features with security implications
- Authentication/authorization features
- Data handling features
- Production-critical code

**Stages:** threat_model ‚Üí clarify_dod_dor ‚Üí plan ‚Üí tdd_cycle ‚Üí run_tests ‚Üí validate_dod ‚Üí cleanup ‚Üí document

**Duration:** ~6 seconds (8 stages)

### 2. Quick Feature (Fast Track)

**Use When:**
- Simple, low-risk features
- Internal tools
- Prototypes
- Bug fixes

**Stages:** clarify_dod_dor ‚Üí plan ‚Üí tdd_cycle ‚Üí validate_dod

**Duration:** ~3 seconds (4 stages)

### 3. Custom Pipeline (User-Defined)

**Use When:**
- Unique project requirements
- Experimental workflows
- Domain-specific task chains

**Example:** security_review ‚Üí plan ‚Üí tdd_cycle ‚Üí penetration_test ‚Üí validate_dod

---

## üß© Extensibility

### Adding New Stages

**1. Create Stage Module**

```python
# src/workflows/stages/my_new_stage.py

class MyNewStage:
    def execute(self, state: WorkflowState) -> StageResult:
        # Your logic here
        return StageResult(...)
    
    def validate_input(self, state: WorkflowState) -> bool:
        return True
    
    def on_failure(self, state: WorkflowState, error: Exception):
        pass

def create_stage() -> WorkflowStage:
    return MyNewStage()
```

**2. Add to Workflow Definition**

```yaml
stages:
  - id: "my_stage"
    script: "my_new_stage"
    required: true
    depends_on: ["previous_stage"]
```

**3. Execute**

```python
workflow_def = WorkflowDefinition.from_yaml("my_workflow.yaml")
orchestrator = WorkflowOrchestrator(workflow_def, ...)
state = orchestrator.execute("User request", "conv-123")
```

**No core code changes needed!** ‚úÖ

### Creating Custom Workflows

Users can create any workflow by:
1. Copying `custom_pipeline.yaml` template
2. Adding/removing/reordering stages
3. Defining dependencies
4. Executing via entry point

**Example Custom Workflow:**
```yaml
workflow_id: "documentation_first"
name: "Documentation-First Development"

stages:
  - id: "document_requirements"
    script: "requirements_documenter"
    depends_on: []
  
  - id: "plan"
    script: "work_planner"
    depends_on: ["document_requirements"]
  
  - id: "tdd_cycle"
    script: "tdd_workflow"
    depends_on: ["plan"]
  
  - id: "generate_api_docs"
    script: "api_doc_generator"
    depends_on: ["tdd_cycle"]
```

---

## üîó Integration with CORTEX 2.0

### Entry Point Integration

```python
# src/entry_point/cortex_entry_workflows.py

class CortexEntryWithWorkflows(CortexEntry):
    """Extended entry point with workflow support"""
    
    def process(self, user_message: str, workflow_id: Optional[str] = None):
        # Auto-select workflow or use specified
        if self._should_use_workflow(user_message):
            return self._process_with_workflow(
                user_message,
                workflow_id or self._select_workflow(user_message)
            )
        else:
            # Fallback to original routing
            return super().process(user_message)
```

### Workflow Selection Logic

**Priority:**
1. User-specified: `workflow_id="secure_feature_creation"`
2. In-message: `"Add auth. WORKFLOW: secure_feature_creation"`
3. Auto-select: Keywords ‚Üí workflow mapping
4. Default: `quick_feature`

**Auto-selection Keywords:**
- `"security"`, `"auth"`, `"threat"` ‚Üí `secure_feature_creation`
- `"dod"`, `"dor"`, `"definition"` ‚Üí `secure_feature_creation`
- Default ‚Üí `quick_feature`

### Plugin System Integration

Workflows can be plugins! (See 02-plugin-system.md)

```python
# Plugin: custom_workflow_pack

hooks = ["workflow.register"]

def register_workflows(registry):
    registry.add_workflow("security_audit", {
        "definition": "security_audit.yaml",
        "stages": ["audit_stage_1", "audit_stage_2"]
    })
```

---

## üîí Security Integration

### Sandboxing (See 19-security-model.md)

**Stage Execution with Security:**
```python
# Orchestrator applies security layers
for stage in stages:
    # 1. Validate stage script (whitelist)
    if not is_whitelisted(stage.script):
        raise SecurityError("Stage not whitelisted")
    
    # 2. Load in sandboxed environment
    stage_module = load_with_sandbox(stage.script)
    
    # 3. Check permissions
    if not has_capability(stage_module, required_caps):
        raise SecurityError("Insufficient permissions")
    
    # 4. Enforce resource limits
    with ResourceMonitor(max_time=stage.timeout, max_memory=100):
        result = stage_module.execute(state)
    
    # 5. Log to audit trail
    audit_logger.log_event("stage_executed", {
        "stage_id": stage.id,
        "duration": result.duration_ms,
        "status": result.status
    })
```

### Threat Modeling Stage

Integrates with security model by:
- Using STRIDE threat categories
- Calculating risk scores
- Generating security recommendations
- Feeding into DoD criteria (high-risk features require extra validation)

---

## üìä Monitoring Integration

### Dashboard Metrics (See 17-monitoring-dashboard.md)

```python
# Workflow metrics tracked automatically
workflow_metrics = {
    "total_executions": 127,
    "success_rate": 0.94,
    "avg_duration_seconds": 5.8,
    "stage_success_rates": {
        "threat_model": 0.99,
        "clarify_dod_dor": 0.98,
        "plan": 0.97,
        "tdd_cycle": 0.92,
        "run_tests": 0.94,
        "validate_dod": 0.95,
        "cleanup": 0.87,
        "document": 0.96
    },
    "common_failures": [
        {"stage": "tdd_cycle", "error": "Test timeout", "count": 8},
        {"stage": "cleanup", "error": "Linter failures", "count": 5}
    ]
}
```

### Real-time Monitoring

```
Current Workflow Execution
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
Workflow: secure_feature_creation
Progress: 5/8 stages (62%)
Duration: 3.2s / ~6s estimated

‚úÖ threat_model (0.5s)
‚úÖ clarify_dod_dor (0.3s)
‚úÖ plan (1.2s)
‚úÖ tdd_cycle (4.8s)
üîÑ run_tests (running...)
‚è≥ validate_dod (pending)
‚è≥ cleanup (pending)
‚è≥ document (pending)
```

---

## üß™ Testing Strategy

### Unit Tests (Per Stage)

```python
# tests/workflows/stages/test_threat_modeler.py

def test_threat_modeler_identifies_auth_threats():
    stage = ThreatModelerStage()
    state = WorkflowState(
        workflow_id="test",
        conversation_id="conv",
        user_request="Add login authentication",
        context={}
    )
    
    result = stage.execute(state)
    
    assert result.status == StageStatus.SUCCESS
    assert "Spoofing" in [t["category"] for t in result.output["threats"]]
    assert result.output["risk_level"] in ["medium", "high"]
```

### Integration Tests (Workflow End-to-End)

```python
# tests/workflows/test_secure_feature_workflow.py

def test_secure_feature_workflow_end_to_end():
    workflow_def = WorkflowDefinition.from_yaml("secure_feature_creation.yaml")
    orchestrator = WorkflowOrchestrator(workflow_def, ...)
    
    state = orchestrator.execute(
        user_request="Add authentication",
        conversation_id="test-conv"
    )
    
    # Verify all stages completed
    assert len(state.stage_statuses) == 8
    assert all(s == StageStatus.SUCCESS for s in state.stage_statuses.values())
    
    # Verify outputs exist
    assert "threats" in state.stage_outputs["threat_model"]
    assert "dor" in state.stage_outputs["clarify_dod_dor"]
    assert "phases" in state.stage_outputs["plan"]
```

### DAG Validation Tests

```python
# tests/workflows/test_dag_validation.py

def test_dag_detects_cycles():
    workflow_def = WorkflowDefinition(
        workflow_id="bad",
        name="Bad Workflow",
        stages=[
            StageDefinition(id="A", depends_on=["B"]),
            StageDefinition(id="B", depends_on=["A"])  # Cycle!
        ]
    )
    
    errors = workflow_def.validate_dag()
    assert len(errors) > 0
    assert "cycle" in errors[0].lower()
```

---

## üìã Implementation Checklist

### Phase 1: Core System ‚úÖ
- [x] WorkflowOrchestrator class
- [x] WorkflowDefinition (YAML loader)
- [x] WorkflowState (shared state management)
- [x] StageResult (typed outputs)
- [x] DAG validation and topological sort
- [x] Stage interface (WorkflowStage protocol)

### Phase 2: Built-in Stages ‚úÖ / üìã
- [x] Threat modeler (`threat_modeler.py`)
- [x] DoD/DoR clarifier (`dod_dor_clarifier.py`)
- [ ] Code cleanup (`code_cleanup.py`)
- [ ] Documentation generator (`doc_generator.py`)
- [ ] DoD validator (`dod_validator.py`)
- [ ] Test runner wrapper (`test_runner.py`)

### Phase 3: Workflows ‚úÖ
- [x] Secure feature creation workflow
- [x] Quick feature workflow
- [x] Custom pipeline template

### Phase 4: Integration ‚úÖ
- [x] Entry point integration (`cortex_entry_workflows.py`)
- [x] Workflow selection logic
- [x] Auto-detection of workflow needs

### Phase 5: Documentation ‚úÖ
- [x] User guide (`workflow-pipeline-guide.md`)
- [x] Visual architecture (`workflow-pipeline-visual.md`)
- [x] Recommendation summary

### Phase 6: Enhancements üìã
- [ ] Checkpoint/resume from failure
- [ ] Parallel execution (independent stages)
- [ ] Conditional execution (if/else)
- [ ] Workflow templates (parameterized)
- [ ] Web UI for workflow visualization

---

## üí° Design Decisions

### Why YAML Instead of Code?

**Pros:**
- ‚úÖ Non-programmers can define workflows
- ‚úÖ Version control friendly (git diff readable)
- ‚úÖ No Python syntax errors in definitions
- ‚úÖ Easy to template and parameterize

**Cons:**
- ‚ùå Limited logic (no conditionals/loops in YAML)
- ‚ùå Requires Python for complex logic

**Decision:** YAML for definitions, Python for stage logic. Best of both worlds.

### Why DAG Instead of Simple Chain?

**Pros:**
- ‚úÖ Allows parallel execution (future enhancement)
- ‚úÖ Validates impossible orderings (compile-time)
- ‚úÖ Flexible dependencies (A depends on B+C)
- ‚úÖ Industry standard (Airflow, Prefect, GitLab CI)

**Cons:**
- ‚ùå More complex implementation
- ‚ùå Steeper learning curve

**Decision:** DAG for robustness. Complexity handled by orchestrator, hidden from users.

### Why Context Injection Once?

**Problem:** Each stage querying Tier 1-3 = 8√ó overhead

**Alternatives Considered:**
1. ‚ùå Query per-stage (slow, 1,600ms overhead)
2. ‚úÖ Query once, share via state (fast, 200ms overhead)
3. ‚ùå Cache per-workflow run (complex, same benefit as #2)

**Decision:** Query once at start, share via `WorkflowState.context`. Simple and fast.

---

## üîó Related Documents

- **02-plugin-system.md** - Workflows can be plugins
- **07-self-review-system.md** - Workflows include validation stages
- **10-agent-workflows.md** - Individual stages use existing agents
- **19-security-model.md** - Stage execution sandboxing
- **17-monitoring-dashboard.md** - Workflow metrics display

---

## üìö External References

### Similar Systems (Inspiration)
- **GitHub Actions** - YAML workflows, DAG dependencies
- **GitLab CI** - Declarative pipelines, stage artifacts
- **Apache Airflow** - DAG orchestration, Python tasks
- **Prefect** - Workflow engine, state management
- **Luigi** - Task dependency management

### Key Differences
- CORTEX workflows are **AI-assisted** (not just automation)
- **Context-aware** (Tier 1-3 intelligence)
- **Conversation-driven** (tracks to brain)
- **Threat modeling** (security-first)

---

## ‚úÖ Extensibility Answer

**Question:** "Will this model be extensible?"

**Answer:** **YES! Extremely extensible.** ‚úÖ

### 1. Add New Stages (Zero Core Changes)

```python
# Just create new Python module
# src/workflows/stages/my_custom_stage.py

class MyCustomStage:
    def execute(self, state):
        return StageResult(...)

def create_stage():
    return MyCustomStage()
```

Add to workflow:
```yaml
stages:
  - id: "my_stage"
    script: "my_custom_stage"
```

**No orchestrator changes needed!**

### 2. Create Custom Workflows (Pure YAML)

```yaml
# my_team_workflow.yaml
workflow_id: "my_team"
stages:
  # Mix and match any stages
  - id: "custom_review"
    script: "my_team_reviewer"
  - id: "tdd_cycle"
    script: "tdd_workflow"  # Reuse built-in stage
```

**No Python coding required!**

### 3. Plugin-Based Workflows (See 02-plugin-system.md)

```python
# Plugin can provide:
# - New stages
# - Complete workflows
# - Custom validators

plugin_manifest = {
    "workflows": ["security_audit.yaml"],
    "stages": ["audit_stage_1.py", "audit_stage_2.py"]
}
```

### 4. Conditional Logic (Future)

```yaml
stages:
  - id: "security_review"
    condition: "threat_model.risk_level == 'high'"
```

### 5. Parallel Execution (Future)

```yaml
stages:
  - id: "lint"
    depends_on: ["plan"]
  
  - id: "security_scan"
    depends_on: ["plan"]  # Runs parallel with lint
  
  - id: "implement"
    depends_on: ["lint", "security_scan"]  # Waits for both
```

**Extensibility Score: 10/10** üéØ

---

**Status:** ‚úÖ Design Complete  
**Confidence:** 95%  
**Risk:** üü¢ LOW  
**Implementation Time:** 8-12 hours for remaining stages  
**Maintenance:** üü¢ LOW (declarative, minimal code)

**Next:** 22-implementation-roadmap.md (overall 2.0 roadmap with workflow integration)
