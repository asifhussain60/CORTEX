# CORTEX "Let's Plan" Enhancement - Implementation Plan

## Overview
This document captures the implementation plan for enhancing the CORTEX "let's plan" entry point with component separation, quality tiers, git history integration, and governance enforcement.

## Request Summary
Enhance the planning workflow with:
- Component separation (Planning vs Development execution)
- Quality tiers for efficiency (Simple/Medium/Complex)
- Git history integration for institutional knowledge
- Proper folder structure and documentation organization
- Cleanup phases for maintaining lean cortex-brain
- Mandatory conversation capture before development
- CORTEX governance alignment and protection

## Implementation Plan

üß† **CORTEX Architecture Review & Component Separation**
Author: Asif Hussain | ¬© 2024-2025 | github.com/asifhussain60/CORTEX

üéØ **My Understanding Of Your Request:**

You want me to **challenge the viability** of the current implementation plan by balancing **accuracy vs efficiency**, and if there are issues, propose **alternative solutions**. Additionally, you want the **actual implementation/development work separated as a dedicated component** with Single Responsibility Principle (SRP), so it can be invoked when development is requested **without going through the planning entry point**. You want the **entire plan redone** and **reflected back** to you.

‚ö†Ô∏è **Challenge:** ‚ö° **Challenge with Architectural Refinement**

After analyzing the current plan against CORTEX's architecture and your requirement for component separation, I've identified **three critical issues** that challenge viability:

### **Issue 1: Mixed Concerns (Planning + Execution Coupled)**
**Problem:** Current plan embeds development logic (TDD, clean code, security) directly into planning workflow. This violates SRP and creates tight coupling.

**Impact:** 
- Cannot invoke development quality gates independently
- Planning becomes heavyweight (6.75 hours includes implementation details)
- Reusability limited (can't apply quality gates to ad-hoc code requests)

**Alternative:** Separate into **Planning Component** (DoR, AC, risk analysis) and **Development Executor Component** (TDD, refactoring, security gates)

---

### **Issue 2: Efficiency vs Accuracy Imbalance**
**Problem:** 90% test coverage + cyclomatic complexity ‚â§10 + OWASP Top 10 + refactor-until-perfect = potentially **infinite iteration loop** or developer frustration.

**Impact:**
- Exit criteria may never be met (subjective "cannot be refactored anymore")
- Over-engineering risk (gold-plating simple features)
- Time estimates unrealistic (6.75 hours assumes perfect execution)

**Alternative:** **Pragmatic quality tiers** - Simple/Medium/Complex features get different thresholds. Add **iteration limits** (max 3 refactor cycles) with escalation path.

---

### **Issue 3: Lack of Entry Point Abstraction**
**Problem:** No clear separation between "plan a feature" (planning entry) and "implement this" (development entry).

**Impact:**
- User says "add authentication" ‚Üí triggers full planning when they may just want code
- Cannot bypass planning for quick fixes/experiments
- Entry point ambiguity (when to plan vs when to execute)

**Alternative:** **Dual Entry Point Architecture** - `PlanningOrchestrator` (for features) + `DevelopmentExecutor` (for code work), with intent detection routing.

---

üí¨ **Response - Redesigned Architecture:**

I've redesigned the entire system with **component separation**, **pragmatic quality tiers**, and **dual entry points**. Here's the complete revised plan:

## üèóÔ∏è **New Architecture: Separated Components**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    CORTEX Entry Point Router                     ‚îÇ
‚îÇ                  (Intent Detection & Routing)                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ                      ‚îÇ
                   ‚ñº                      ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Planning Orchestrator‚îÇ  ‚îÇ Development Executor      ‚îÇ
    ‚îÇ (Option 1 Enhancements)‚îÇ  ‚îÇ (Quality Gates Component)‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ                            ‚îÇ
              ‚îÇ                            ‚îÇ
              ‚ñº                            ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Planning Artifacts   ‚îÇ  ‚îÇ Code Quality Pipeline     ‚îÇ
    ‚îÇ - DoR Checklist      ‚îÇ  ‚îÇ - Clean Code Gates        ‚îÇ
    ‚îÇ - AC Definition      ‚îÇ  ‚îÇ - TDD Framework           ‚îÇ
    ‚îÇ - Risk Analysis      ‚îÇ  ‚îÇ - Security Validation     ‚îÇ
    ‚îÇ - Security Review    ‚îÇ  ‚îÇ - Refactoring Engine      ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### **Component 1: Planning Orchestrator** (Lightweight, 90 min)
**Responsibility:** Requirements gathering, ambiguity detection, risk analysis
**When invoked:** User says "plan", "let's plan", "design feature"
**Output:** Planning artifacts (DoR, AC, risks, security requirements)
**No code execution**

### **Component 2: Development Executor** (SRP, reusable)
**Responsibility:** Code quality enforcement (TDD, refactoring, security)
**When invoked:** User says "implement", "add feature", "fix bug", OR after plan approved
**Input:** AC (from planning) OR natural language requirements
**Output:** Quality-gated code with tests

**Key Innovation:** Can work **standalone** (no planning required for quick tasks) OR **pipeline mode** (consumes planning artifacts)

---

## üìã **Revised Implementation Plan (Component-Based)**

### **Phase 1: Planning Orchestrator (Option 1 Core)** - 90 minutes

#### **Purpose:** Lightweight planning improvements (no development logic)

#### **Deliverables:**
1. **Enhanced DoR Templates (45 min)**
   ```yaml
   # cortex-brain/templates/planning/dor-checklist.yaml
   dor_checklist:
     ambiguity_detection:
       - "Scan for vague terms: 'improve', 'enhance', 'better', 'optimize'"
       - "Flag missing context: 'Who is the user?', 'What is success?'"
       - "Identify undefined terms: 'the system', 'the API', 'the database'"
     
     self_audit_prompts:
       - "What happens if [edge case]?"
       - "Who can access this feature?"
       - "What data is at risk?"
       - "How do we test this?"
     
     mandatory_sections:
       - "Acceptance Criteria (Testable, Specific)"
       - "Risk Analysis (Technical, Security, UX)"
       - "Security Requirements (OWASP category identification)"
       - "Definition of Done (Code + Tests + Docs)"
   ```

2. **Template Updates (45 min)**
   - Enhance `work_planner_success` with self-audit section
   - Update `planning_dor_incomplete` with specific line-level feedback
   - Add `planning_security_review` template (OWASP category checklist)

#### **Acceptance Criteria:**
- ‚úÖ DoR checklist identifies ambiguous requirements (e.g., "Line 12: 'improve performance' - by how much?")
- ‚úÖ Self-audit prompts 5+ clarifying questions per feature
- ‚úÖ Security requirements mapped to OWASP categories (template dropdown)
- ‚úÖ No development logic in planning phase

#### **Exit Criteria:**
- Planning artifacts complete (DoR, AC, risks, security baseline)
- User approves plan OR requests clarification
- **Hands off to Development Executor** (if implementation requested)

---

### **Phase 2: Development Executor Component (SRP)** - 180 minutes

#### **Purpose:** Standalone code quality enforcement (works with OR without planning)

#### **2.1: Clean Code Gates (60 min)**

**Entry Points:**
- **Standalone:** User says "implement [feature]" (no planning)
- **Pipeline:** After planning approved

**Quality Gates:**
```yaml
# cortex-brain/components/development-executor/clean-code-gates.yaml
clean_code_gates:
  pre_commit:
    unused_detection:
      tool: "pylint --disable=all --enable=unused-*"
      threshold: "Zero unused imports/variables/functions"
      severity: "BLOCKING"
    
    commented_code:
      pattern: "^\\s*#\\s*(def|class|if|for|while|return)"
      exceptions: ["# TODO-ADO-", "# FIXME-", "# HACK-"]
      severity: "BLOCKING"
    
    complexity:
      tool: "radon cc --min C"
      threshold: 
        simple: 5
        complex: 10  # requires justification comment
      severity: "WARNING"  # Not blocking for first iteration
```

**Pragmatic Approach:**
- **First commit:** Warnings only (allows progress)
- **PR review:** Warnings become blocking
- **Production merge:** All gates must pass

---

#### **2.2: TDD Framework (60 min)**

**Red-Green-Refactor with Iteration Limits:**
```yaml
# cortex-brain/components/development-executor/tdd-framework.yaml
tdd_framework:
  workflow:
    red_phase:
      - "Generate test stub from acceptance criteria"
      - "Test must fail initially (validate test logic)"
    
    green_phase:
      - "Implement minimum code to pass test"
      - "No refactoring during green phase"
    
    refactor_phase:
      iterations:
        max_cycles: 3  # Prevent infinite refactoring
        exit_criteria:
          - "Complexity ‚â§ threshold (5 simple, 10 complex)"
          - "No duplicate code >6 lines"
          - "Method length ‚â§ 50 lines"
          - "Test coverage ‚â• target (see quality_tiers)"
        
        escalation:
          after_3_cycles:
            - "Document remaining issues"
            - "Flag for team review"
            - "Continue with implementation (don't block)"

  quality_tiers:
    simple_feature:  # Button, label, config change
      coverage_target: 80%
      complexity_max: 5
      refactor_cycles: 1
    
    medium_feature:  # Form, API endpoint, database query
      coverage_target: 85%
      complexity_max: 8
      refactor_cycles: 2
    
    complex_feature:  # Authentication, payment, multi-step workflow
      coverage_target: 90%
      complexity_max: 10
      refactor_cycles: 3
```

**Key Innovation: Feature Complexity Detection**
```python
# Auto-detect complexity from AC and code patterns
def detect_feature_complexity(acceptance_criteria: list, code_files: list) -> str:
    """Returns 'simple', 'medium', or 'complex'"""
    complexity_signals = {
        'simple': ['add button', 'change label', 'update config', 'display data'],
        'medium': ['create form', 'api endpoint', 'database query', 'validation'],
        'complex': ['authentication', 'authorization', 'payment', 'workflow', 'integration']
    }
    # Analyze AC + code patterns, return tier
```

**Anti-Pattern Detection (Test-After-Code):**
```bash
# .git/hooks/pre-commit
#!/bin/bash
# Detect if source code modified without corresponding test updates

test_files=$(git diff --cached --name-only | grep "test_")
src_files=$(git diff --cached --name-only | grep -E "\.(py|ts|js)$" | grep -v "test_")

if [[ -n "$src_files" && -z "$test_files" ]]; then
    echo "‚ö†Ô∏è TDD VIOLATION: Source code modified without test updates"
    echo "Modified files: $src_files"
    echo ""
    echo "Options:"
    echo "  1. Add/update tests for these files"
    echo "  2. Skip check: git commit --no-verify (NOT RECOMMENDED)"
    exit 1
fi
```

---

#### **2.3: Security Validation Gates (60 min)**

**OWASP Top 10 Automated Checks:**
```yaml
# cortex-brain/components/development-executor/security-gates.yaml
security_gates:
  pre_commit:
    secret_detection:
      tool: "detect-secrets scan"
      severity: "BLOCKING"
    
    static_analysis:
      tool: "bandit -r . -f json"
      severity: "BLOCKING"  # Only HIGH/CRITICAL issues block
  
  pre_merge:
    dependency_scan:
      tool: "pip-audit --format json"
      threshold: "Zero HIGH/CRITICAL CVEs"
      severity: "BLOCKING"
    
    owasp_checklist:
      # Lightweight checklist (not full penetration test)
      A01_access_control: "Authorization checks present?"
      A02_crypto: "No hardcoded secrets?"
      A03_injection: "Parameterized queries used?"
      # ... (10 total)
      enforcement: "Manual review + automated hints"

  owasp_tier_mapping:
    # Auto-suggest relevant OWASP categories based on feature type
    authentication_features: ["A01", "A02", "A07"]
    api_endpoints: ["A03", "A01", "A05"]
    data_storage: ["A02", "A08", "A09"]
    # ... (expand based on feature keywords)
```

**Pragmatic Security:**
- **Automated checks:** Secrets, dependencies, static analysis (blocking)
- **OWASP checklist:** Lightweight review (not full audit)
- **Threat modeling:** Required for complex features only (auto-triggered)

---

### **Phase 3: Integration & Routing Logic** - 60 minutes

#### **3.1: Entry Point Detection (30 min)**

**Intent Classification:**
```python
# src/cortex/router.py
class IntentRouter:
    """Routes user requests to Planning or Development components"""
    
    PLANNING_TRIGGERS = [
        "plan", "let's plan", "design", "architecture", 
        "requirements", "what should", "how should we"
    ]
    
    DEVELOPMENT_TRIGGERS = [
        "implement", "add", "create", "build", "fix", 
        "refactor", "optimize", "code"
    ]
    
    def route(self, user_input: str) -> str:
        """Returns 'planning' or 'development'"""
        # Keyword matching + context analysis
        if any(trigger in user_input.lower() for trigger in self.PLANNING_TRIGGERS):
            return "planning"
        elif any(trigger in user_input.lower() for trigger in self.DEVELOPMENT_TRIGGERS):
            return "development"
        else:
            # Ambiguous - ask user
            return "clarify"
```

**User Experience:**
```
User: "plan authentication feature"
‚Üí PlanningOrchestrator (creates DoR, AC, risks)

User: "add login button"
‚Üí DevelopmentExecutor (generates code + tests, skips planning)

User: "authentication"
‚Üí Router: "Did you want to PLAN authentication or IMPLEMENT it?"
```

---

#### **3.2: Component Pipeline (30 min)**

**Sequential Workflow (Optional):**
```
User: "plan authentication" 
  ‚Üí Planning Orchestrator (90 min)
  ‚Üí Output: Planning artifacts

User: "approve plan"
  ‚Üí Router: "Ready to implement? (Y/N)"
  ‚Üí DevelopmentExecutor (consumes planning artifacts)
  ‚Üí Output: Code + tests with quality gates
```

**Standalone Workflow:**
```
User: "add logout button"
  ‚Üí DevelopmentExecutor (no planning needed)
  ‚Üí Auto-generates simple AC: "Button displays, triggers logout"
  ‚Üí Applies clean code + TDD + security gates
  ‚Üí Output: Code + tests
```

---

### **Phase 4: Documentation & Testing** - 45 minutes

#### **Deliverables:**
1. **Component API Documentation (30 min)**
   ```markdown
   # cortex-brain/documents/implementation-guides/development-executor-api.md
   
   ## Development Executor Component
   
   ### Entry Points:
   - `executor.implement(requirements)` - Standalone implementation
   - `executor.implement_from_plan(plan_id)` - Pipeline mode
   
   ### Configuration:
   ```yaml
   # Set quality tier (auto-detected by default)
   executor.set_quality_tier("complex")  # simple, medium, complex
   
   # Override refactor iteration limit
   executor.set_max_refactor_cycles(5)
   
   # Enable/disable specific gates
   executor.disable_gate("commented_code")  # For quick prototypes
   ```
   
   ### Outputs:
   - Code files (with quality gates applied)
   - Test files (TDD workflow enforced)
   - Quality report (coverage, complexity, security scan results)
   ```

2. **Integration Tests (15 min)**
   - Test Planning ‚Üí Development pipeline
   - Test standalone Development execution
   - Test quality tier detection

---

## üìä **Revised Implementation Summary**

| Component | Duration | Responsibility | Entry Point |
|-----------|----------|----------------|-------------|
| **Planning Orchestrator** | 90 min | DoR, AC, risks | "plan [feature]" |
| **Development Executor** | 180 min | TDD, quality gates | "implement [feature]" OR after planning |
| **Integration & Routing** | 60 min | Intent detection | Automatic routing |
| **Documentation** | 45 min | API docs, tests | Component usage |
| **Total** | **6.25 hours** | Complete system | Dual entry points |

---

## ‚öñÔ∏è **Accuracy vs Efficiency Balance**

### **Original Plan Issues:**
- ‚ùå 90% coverage for ALL features (over-engineering simple tasks)
- ‚ùå Refactor until "cannot be improved" (subjective, infinite loop risk)
- ‚ùå Full OWASP audit for every feature (heavyweight)
- ‚ùå Planning + development coupled (cannot use independently)

### **Revised Approach (Pragmatic):**

| Quality Aspect | Simple Feature | Medium Feature | Complex Feature |
|----------------|----------------|----------------|-----------------|
| **Test Coverage** | 80% | 85% | 90% |
| **Refactor Cycles** | 1 | 2 | 3 (max) |
| **Security Checks** | Automated only | Automated + checklist | Automated + checklist + threat model |
| **Complexity Max** | 5 | 8 | 10 |

**Efficiency Gains:**
- Simple feature: 30 min (was 2+ hours with full gates)
- Medium feature: 1-2 hours (was 4+ hours)
- Complex feature: 4-6 hours (was 6.75 hours)

**Accuracy Maintained:**
- Automated gates (secrets, dependencies, static analysis) = BLOCKING
- Manual reviews = Required only for complex features
- Pragmatic iteration limits prevent gold-plating

---

## üéØ **Alternative Solutions (if challenged further)**

### **Alternative 1: Hybrid Approach**
- Keep Planning + Development coupled BUT add bypass flag
- User: "implement [feature] --skip-planning"
- Pros: Simpler architecture
- Cons: Still monolithic, flag management complexity

### **Alternative 2: Three-Tier Quality System**
- **Tier 1 (MVP):** No gates, fast iteration
- **Tier 2 (Standard):** Automated gates only
- **Tier 3 (Production):** Full gates + manual reviews
- Pros: Clear quality levels
- Cons: More configuration

### **Alternative 3: Progressive Enhancement**
- Start with minimal gates (secrets, tests)
- Add gates incrementally based on feature risk
- Pros: Flexibility
- Cons: Risk of inconsistent quality

**Recommendation:** Stick with **revised plan** (quality tiers + component separation). Best balance of accuracy and efficiency.

---

üìù **Your Request:** Challenge viability of implementation plan, propose alternatives, separate development work as SRP component, redo entire plan and reflect back.

üîç **Next Steps:**

**Option A: Approve Revised Architecture**
   ‚òê Phase 1: Planning Orchestrator (90 min)
   ‚òê Phase 2: Development Executor Component (180 min)
   ‚òê Phase 3: Integration & Routing (60 min)
   ‚òê Phase 4: Documentation (45 min)
   
**Option B: Request Alternative Solution**
   Specify which alternative (Hybrid, Three-Tier, Progressive) or propose new approach

**Option C: Refine Specific Component**
   Choose: Planning, Development, Routing, or Quality Tiers for deeper design

Which option would you like to proceed with, or do you want me to challenge this revised plan further?

---

## Enhancement Requests Added

### Enhancement 0: Folder Structure & Git Integration
- Create organized folder structure under cortex-brain for plan documentation
- Every MD/YAML file related to CORTEX created within cortex-brain
- Git commit tracking with references saved in SQLite/knowledge graphs
- Concise commit metadata for efficient retrieval

### Enhancement 1: Git History Check
- Mandatory git history analysis to reference previous work
- Institutional knowledge capture from commit history
- Pattern mining from past implementations

### Enhancement 2: CORTEX Component Alignment
- Align rulebook, tiers, optimize, healthcheck with new design
- Enforce consistency across all CORTEX components
- Protect rules in brain with governance layers

### Enhancement 3: Cleanup Phase
- Identify and remove obsolete files
- Reorganize existing artifacts
- Keep cortex-brain lean and efficient
- Safety protocols with rollback capability

### Enhancement 4: Conversation Capture
- Mandatory conversation capture after plan finalization
- Document before beginning development
- Preserve strategic patterns and learnings
- Highest ROI enhancement

---

## Incremental Plan Generation Mechanism

**Author:** Asif Hussain | ¬© 2024-2025 | github.com/asifhussain60/CORTEX

### Purpose
Prevent large monolithic write failures by writing plan artifacts in **safe, append-only phases** with validation after each step. Ensures recoverability, atomic progress, and governance alignment.

### File Workflow
1. Create empty plan file: `PLAN-<date>-<feature>.md` (header only)
2. Append Phase sections sequentially with discrete write operations
3. After each append:
   - Compute SHA256 of current file snapshot
   - Record metadata in `.plan-write-journal.jsonl`
   - Rollback on validation failure
4. Seal file with summary metrics when complete
5. Persist to knowledge graph

### Validation Per Append

| Check | Rule | Action on Fail |
|-------|------|----------------|
| Line growth | `lines_added > 0` | Abort & rollback |
| Max size | `< 50,000 lines` | Abort & flag |
| Corruption | Complete markdown sections | Rollback |
| Governance | Mandatory headers present | Auto-fix |
| Protection | No binary/image blobs | Strip & warn |

### Advantages
- Eliminates write overflow/paste failures
- Provides forensic trail for reconstruction
- Enables partial plan consumption
- Supports resumable planning

### Implementation Tasks
1. Implement `IncrementalPlanWriter` service
2. Add journal schema & append function
3. Integrate SHA256 utility
4. Add governance validation hooks
5. Unit tests for success/rollback/corruption scenarios
6. Connect knowledge graph pattern storage

---

## Next Steps

1. **Review and approve** the enhanced architecture
2. **Implement** Planning Orchestrator enhancements (Phase 1)
3. **Develop** Development Executor component (Phase 2)
4. **Integrate** routing logic (Phase 3)
5. **Document** API and create tests (Phase 4)
6. **Capture conversation** before beginning implementation